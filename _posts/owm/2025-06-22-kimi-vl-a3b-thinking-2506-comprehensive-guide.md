---
title: "Kimi-VL-A3B-Thinking-2506: íš¨ìœ¨ì ì¸ MoE ë¹„ì „-ì–¸ì–´ ëª¨ë¸ì˜ ìƒˆë¡œìš´ ì§€í‰"
excerpt: "Moonshot AIì˜ ê°œì„ ëœ Vision-Language ëª¨ë¸ë¡œ í† í° ì†Œë¹„ 20% ê°ì†Œí•˜ë©´ì„œ ì¶”ë¡  ëŠ¥ë ¥ ëŒ€í­ í–¥ìƒ"
date: 2025-06-22
categories: 
  - owm
  - research
tags: 
  - vision-language-model
  - multimodal-ai
  - moonshot-ai
  - thinking-model
  - moe-architecture
author_profile: true
toc: true
toc_label: "Kimi-VL-A3B-Thinking-2506 ê°€ì´ë“œ"
---

## ëª¨ë¸ ê°œìš”

[Kimi-VL-A3B-Thinking-2506](https://huggingface.co/moonshotai/Kimi-VL-A3B-Thinking-2506)ì€ Moonshot AIì—ì„œ ê°œë°œí•œ ê°œì„ ëœ Vision-Language ëª¨ë¸ì…ë‹ˆë‹¤. ì´ì „ ë²„ì „ì¸ Kimi-VL-A3B-Thinkingì˜ ì—…ê·¸ë ˆì´ë“œ ë²„ì „ìœ¼ë¡œ, **ë” ìŠ¤ë§ˆíŠ¸í•œ ì¶”ë¡ **ê³¼ **ë” ì ì€ í† í° ì†Œë¹„**ë¥¼ ì‹¤í˜„í–ˆìŠµë‹ˆë‹¤.

### í•µì‹¬ íŠ¹ì§•

- **ëª¨ë¸ í¬ê¸°**: 16.4B ë§¤ê°œë³€ìˆ˜
- **ì•„í‚¤í…ì²˜**: MoE (Mixture of Experts) ê¸°ë°˜
- **ë¼ì´ì„ ìŠ¤**: MIT
- **ìµœëŒ€ í† í° ìƒì„±**: 32K í† í°
- **ê³ í•´ìƒë„ ì§€ì›**: 3.2M í”½ì…€ (ì´ì „ ë²„ì „ ëŒ€ë¹„ 4ë°° ì¦ê°€)

## ì£¼ìš” ê°œì„ ì‚¬í•­

### ğŸ§  ë” ìŠ¤ë§ˆíŠ¸í•œ ì¶”ë¡ , ë” ì ì€ í† í° ì†Œë¹„

2506 ë²„ì „ì€ ë©€í‹°ëª¨ë‹¬ ì¶”ë¡  ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ë©°, **í‰ê·  20% ì ì€ ì¶”ë¡  ê¸¸ì´**ë¡œ ë” ë‚˜ì€ ì •í™•ë„ë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤:

- **MathVision**: 56.9 (+20.1)
- **MathVista**: 80.1 (+8.4)  
- **MMMU-Pro**: 46.3 (+3.3)
- **MMMU**: 64.0 (+2.1)

### ğŸ‘ï¸ í–¥ìƒëœ ì‹œê°ì  ì¸ì‹ê³¼ ì´í•´

ì¼ë°˜ì ì¸ ì‹œê°ì  ì¸ì‹ ë° ì´í•´ ì‘ì—…ì—ì„œë„ ë¹„-thinking ëª¨ë¸ê³¼ ë™ë“±í•˜ê±°ë‚˜ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤:

- **MMBench-EN-v1.1**: 84.4
- **MMStar**: 70.4
- **RealWorldQA**: 70.0
- **MMVet**: 78.4

### ğŸ¥ ë¹„ë””ì˜¤ ì‹œë‚˜ë¦¬ì˜¤ í™•ì¥

ë¹„ë””ì˜¤ ì¶”ë¡  ë° ì´í•´ ë²¤ì¹˜ë§ˆí¬ì—ì„œë„ í–¥ìƒëœ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤:

- **VideoMMMU**: 65.2 (ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ ì¤‘ SOTA)
- **Video-MME**: 71.9 (Kimi-VL-A3B-Instructì™€ ë™ë“±)

### ğŸ–¥ï¸ ê³ í•´ìƒë„ ë° ì—ì´ì „íŠ¸ ê¸°ëŠ¥

3.2M í”½ì…€ ì§€ì›ìœ¼ë¡œ ê³ í•´ìƒë„ ì¸ì‹ ë° OS ì—ì´ì „íŠ¸ ì‘ì—…ì—ì„œ ëŒ€í­ ê°œì„ :

- **V* Benchmark**: 83.2 (ì¶”ê°€ ë„êµ¬ ì—†ì´)
- **ScreenSpot-Pro**: 52.8
- **OSWorld-G**: 52.5

## ì„±ëŠ¥ ë¹„êµ

### íš¨ìœ¨ì ì¸ ëª¨ë¸ê³¼ì˜ ë¹„êµ

| ë²¤ì¹˜ë§ˆí¬ | GPT-4o | Qwen2.5-VL-7B | Kimi-VL-A3B-Thinking-2506 |
|---------|--------|---------------|---------------------------|
| **ì¼ë°˜ ë©€í‹°ëª¨ë‹¬** |
| MMBench-EN-v1.1 | 83.1 | 83.2 | **84.4** |
| RealWorldQA | 75.4 | 68.5 | **70.0** |
| OCRBench | 815 | 864 | **869** |
| MMStar | 64.7 | 63.0 | **70.4** |
| MMVet | 69.1 | 67.1 | **78.1** |
| **ì¶”ë¡ ** |
| MMMU | 69.1 | 58.6 | **64.0** |
| MMMU-Pro | 51.7 | 38.1 | **46.3** |
| **ìˆ˜í•™** |
| MATH-Vision | 30.4 | 25.0 | **56.9** |
| MathVista_MINI | 63.8 | 68.0 | **80.1** |

### ëŒ€ê·œëª¨ ëª¨ë¸ê³¼ì˜ ë¹„êµ

| ë²¤ì¹˜ë§ˆí¬ | Kimi-VL-A3B-Thinking-2506 | Qwen2.5-VL-32B | Qwen2.5-VL-72B |
|---------|---------------------------|----------------|----------------|
| MMBench-EN-v1.1 | 84.4 | - | 88.3 |
| RealWorldQA | 70.0 | - | 75.7 |
| MMMU | 64.0 | 60.7 | 68.1 |
| MMMU-Pro | 46.3 | 41.3 | 50.6 |

## ì‚¬ìš© ë°©ë²•

### VLLMì„ ì´ìš©í•œ ì¶”ë¡  (ê¶Œì¥)

32K í† í°ê¹Œì§€ ìƒì„±í•˜ëŠ” long-decode ëª¨ë¸ì´ë¯€ë¡œ VLLM ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤:

```bash
MAX_JOBS=4 pip install vllm==0.9.1 blobfile flash-attn --no-build-isolation
```

```python
from transformers import AutoProcessor
from vllm import LLM, SamplingParams

model_path = "moonshotai/Kimi-VL-A3B-Thinking-2506"
llm = LLM(
    model_path,
    trust_remote_code=True,
    max_num_seqs=8,
    max_model_len=131072,
    limit_mm_per_prompt={"image": 256}
)

processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)
sampling_params = SamplingParams(max_tokens=32768, temperature=0.8)

# ì¶”ë¡  ë° ê²°ê³¼ ì²˜ë¦¬
def extract_thinking_and_summary(text: str, bot: str = "â—thinkâ–·", eot: str = "â—/thinkâ–·") -> str:
    if bot in text and eot not in text:
        return ""
    if eot in text:
        return text[text.index(bot) + len(bot):text.index(eot)].strip(), text[text.index(eot) + len(eot) :].strip()
    return "", text

OUTPUT_FORMAT = "--------Thinking--------\n{thinking}\n\n--------Summary--------\n{summary}"
```

### Hugging Face Transformers ì‚¬ìš©

```python
from PIL import Image
from transformers import AutoModelForCausalLM, AutoProcessor

model_path = "moonshotai/Kimi-VL-A3B-Thinking-2506"
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    torch_dtype="auto",
    device_map="auto",
    trust_remote_code=True,
)
processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)

# ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ì¶”ë¡ 
messages = [
    {
        "role": "user",
        "content": [
            {"type": "image", "image": image_path}
        ] + [{"type": "text", "text": "What kind of cat is this? Answer with one word."}],
    },
]

text = processor.apply_chat_template(messages, add_generation_prompt=True, return_tensors="pt")
inputs = processor(images=images, text=text, return_tensors="pt").to(model.device)
generated_ids = model.generate(**inputs, max_new_tokens=32768, temperature=0.8)
```

## ê¸°ìˆ ì  íŠ¹ì§•

### MoE ì•„í‚¤í…ì²˜ ì¥ì 

- **íš¨ìœ¨ì ì¸ ë§¤ê°œë³€ìˆ˜ í™œìš©**: 16.4B ë§¤ê°œë³€ìˆ˜ì´ì§€ë§Œ í™œì„±í™”ë˜ëŠ” ë§¤ê°œë³€ìˆ˜ëŠ” ì¼ë¶€ë§Œ ì‚¬ìš©
- **í™•ì¥ ê°€ëŠ¥ì„±**: ì¶”ê°€ Expert ëª¨ë“ˆì„ í†µí•œ ì„±ëŠ¥ í–¥ìƒ ê°€ëŠ¥
- **ì¶”ë¡  íš¨ìœ¨ì„±**: ì „ì²´ ëª¨ë¸ì„ í™œì„±í™”í•˜ì§€ ì•Šì•„ë„ ë†’ì€ ì„±ëŠ¥ ë‹¬ì„±

### Thinking ë©”ì»¤ë‹ˆì¦˜

ëª¨ë¸ì´ ë‹µë³€í•˜ê¸° ì „ì— **ë‚´ë¶€ì  ì‚¬ê³  ê³¼ì •**ì„ ê±°ì¹˜ëŠ” êµ¬ì¡°:

```
â—thinkâ–·
[ë‚´ë¶€ ì¶”ë¡  ê³¼ì •]
â—/thinkâ–·
[ìµœì¢… ë‹µë³€]
```

ì´ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ë” ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

## í™œìš© ë¶„ì•¼

### ğŸ”¬ ì—°êµ¬ ë° ê°œë°œ
- ë©€í‹°ëª¨ë‹¬ AI ì—°êµ¬
- ì‹œê°ì  ì¶”ë¡  ì‹œìŠ¤í…œ ê°œë°œ
- êµìœ¡ìš© AI ì–´ì‹œìŠ¤í„´íŠ¸

### ğŸ¢ ë¹„ì¦ˆë‹ˆìŠ¤ ì• í”Œë¦¬ì¼€ì´ì…˜
- ë¬¸ì„œ ë¶„ì„ ë° OCR
- ìŠ¤í¬ë¦°ìƒ· ê¸°ë°˜ ìë™í™”
- ë¹„ë””ì˜¤ ì½˜í…ì¸  ë¶„ì„

### ğŸ¤– ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ
- OS ìë™í™” ì—ì´ì „íŠ¸
- ì›¹ ë¸Œë¼ìš°ì € ìë™í™”
- GUI í…ŒìŠ¤íŒ… ìë™í™”

## ì„±ëŠ¥ ìµœì í™” íŒ

### ë©”ëª¨ë¦¬ ê´€ë¦¬
- **Flash Attention í•„ìˆ˜**: CUDA OOM ë°©ì§€ë¥¼ ìœ„í•´ ë°˜ë“œì‹œ ì„¤ì¹˜
- **ë°°ì¹˜ í¬ê¸° ì¡°ì •**: `max_num_seqs` ë§¤ê°œë³€ìˆ˜ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°ì ˆ

### ì¶”ë¡  ì„¤ì •
- **ì˜¨ë„ ì„¤ì •**: 0.8 ê¶Œì¥ (ì°½ì˜ì  ë‹µë³€ê³¼ ì¼ê´€ì„± ê· í˜•)
- **ìµœëŒ€ í† í°**: 32Kê¹Œì§€ ê°€ëŠ¥í•˜ì§€ë§Œ ìš©ë„ì— ë§ê²Œ ì¡°ì •

## í•œê³„ì  ë° ê³ ë ¤ì‚¬í•­

### ğŸ’¾ ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­
- **GPU ë©”ëª¨ë¦¬**: ìµœì†Œ 24GB ì´ìƒ ê¶Œì¥
- **ì¶”ë¡  ì‹œê°„**: Thinking ê³¼ì •ìœ¼ë¡œ ì¸í•œ ì§€ì—° ì‹œê°„ ì¡´ì¬

### ğŸ”§ ê¸°ìˆ ì  ì œì•½
- **ì»¤ìŠ¤í…€ ì½”ë“œ**: `trust_remote_code=True` í•„ìš”
- **VLLM ì˜ì¡´ì„±**: ìµœì  ì„±ëŠ¥ì„ ìœ„í•´ VLLM 0.9.1 ì´ìƒ í•„ìš”

## ê²°ë¡ 

Kimi-VL-A3B-Thinking-2506ì€ **íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ì„ ëª¨ë‘ ê°–ì¶˜** ì°¨ì„¸ëŒ€ Vision-Language ëª¨ë¸ì…ë‹ˆë‹¤. íŠ¹íˆ **ìˆ˜í•™ì  ì¶”ë¡ **, **ì—ì´ì „íŠ¸ ì‘ì—…**, **ê³ í•´ìƒë„ ì´ë¯¸ì§€ ì²˜ë¦¬**ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ë©°, ë™ì‹œì— í† í° ì†Œë¹„ëŸ‰ì„ 20% ì¤„ì¸ ê²ƒì´ ì¸ìƒì ì…ë‹ˆë‹¤.

MIT ë¼ì´ì„ ìŠ¤ë¡œ ì œê³µë˜ì–´ ìƒìš© í”„ë¡œì íŠ¸ì—ì„œë„ ììœ ë¡­ê²Œ í™œìš©í•  ìˆ˜ ìˆìœ¼ë©°, VLLMê³¼ì˜ í˜¸í™˜ì„±ìœ¼ë¡œ ì‹¤ì œ ì„œë¹„ìŠ¤ ë°°í¬ì—ë„ ì í•©í•©ë‹ˆë‹¤.

## ì¶”ê°€ ìë£Œ

- [Hugging Face ëª¨ë¸ í˜ì´ì§€](https://huggingface.co/moonshotai/Kimi-VL-A3B-Thinking-2506)
- [ê¸°ìˆ  ë¸”ë¡œê·¸](https://kimi.moonshot.cn/blog)
- [GitHub ë¦¬í¬ì§€í† ë¦¬](https://github.com/moonshotai)
- [ì•„ì¹´ì´ë¸Œ ë…¼ë¬¸](https://arxiv.org/abs/2504.07491) 