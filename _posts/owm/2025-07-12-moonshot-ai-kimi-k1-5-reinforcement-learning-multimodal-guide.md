---
title: "MoonshotAI Kimi-K1.5: ê°•í™”í•™ìŠµìœ¼ë¡œ ì§„í™”í•œ ì°¨ì„¸ëŒ€ o1ê¸‰ ì¶”ë¡  ëª¨ë¸"
excerpt: "MoonshotAIì˜ Kimi-K1.5ê°€ 128k ì»¨í…ìŠ¤íŠ¸ì™€ ê°•í™”í•™ìŠµì„ í†µí•´ ë‹¬ì„±í•œ GPT-4o ëŒ€ë¹„ +550% ì„±ëŠ¥ í–¥ìƒì˜ í•µì‹¬ ê¸°ìˆ  ì™„ì „ ë¶„ì„"
seo_title: "MoonshotAI Kimi-K1.5 ê°•í™”í•™ìŠµ ëª¨ë¸ ì™„ì „ ê°€ì´ë“œ - Thaki Cloud"
seo_description: "MoonshotAI Kimi-K1.5ì˜ ê°•í™”í•™ìŠµ ê¸°ë°˜ Long-CoT ì¶”ë¡ , 128k ì»¨í…ìŠ¤íŠ¸ í™•ì¥, ë©€í‹°ëª¨ë‹¬ ëŠ¥ë ¥ì„ í™œìš©í•œ ì‹¤ì „ êµ¬í˜„ ê°€ì´ë“œ. AIME 77.5, MATH 96.2 ë‹¬ì„±"
date: 2025-07-12
last_modified_at: 2025-07-12
categories:
  - owm
  - llmops
tags:
  - Kimi-K1.5
  - MoonshotAI
  - Reinforcement-Learning
  - Long-CoT
  - 128k-Context
  - Multimodal-AI
  - o1-Level-Reasoning
  - Chain-of-Thought
  - Policy-Optimization
  - AI-Reasoning
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
toc_icon: "cog"
toc_sticky: true
canonical_url: "https://thakicloud.github.io/owm/moonshot-ai-kimi-k1-5-reinforcement-learning-multimodal-guide/"
reading_time: true
---

â±ï¸ **ì˜ˆìƒ ì½ê¸° ì‹œê°„**: 22ë¶„

MoonshotAIì˜ **Kimi-K1.5**ëŠ” ê°•í™”í•™ìŠµì„ í†µí•´ o1 ìˆ˜ì¤€ì˜ ì¶”ë¡  ëŠ¥ë ¥ì„ ë‹¬ì„±í•œ í˜ì‹ ì ì¸ ë©€í‹°ëª¨ë‹¬ AI ëª¨ë¸ì…ë‹ˆë‹¤. 128k ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°ì™€ Long-CoT(Chain-of-Thought) ì¶”ë¡ ì„ í†µí•´ **GPT-4o ëŒ€ë¹„ ìµœëŒ€ +550% ì„±ëŠ¥ í–¥ìƒ**ì„ ë‹¬ì„±í•˜ë©°, ìˆ˜í•™Â·ì½”ë”©Â·ë©€í‹°ëª¨ë‹¬ ì¶”ë¡  ë¶„ì•¼ì—ì„œ ìƒˆë¡œìš´ í‘œì¤€ì„ ì œì‹œí•©ë‹ˆë‹¤.

## Kimi-K1.5 ê°œìš”

### í˜ì‹ ì ì¸ ì„±ì·¨

**Kimi-K1.5**ëŠ” ë‹¨ìˆœí•œ ëª¨ë¸ ê°œì„ ì„ ë„˜ì–´ AI ì¶”ë¡ ì˜ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì„ ì œì‹œí•©ë‹ˆë‹¤:

- **ğŸ§  o1ê¸‰ ì¶”ë¡  ì„±ëŠ¥**: OpenAI o1ê³¼ ë™ë“±í•œ ìˆ˜ì¤€ì˜ ë³µì¡í•œ ì¶”ë¡  ëŠ¥ë ¥
- **ğŸ“ˆ ì••ë„ì  ì„±ëŠ¥ í–¥ìƒ**: ì£¼ìš” ë²¤ì¹˜ë§ˆí¬ì—ì„œ ê¸°ì¡´ ëª¨ë¸ ëŒ€ë¹„ ìµœëŒ€ 550% ì„±ëŠ¥ ì¦ê°€
- **ğŸ”„ í˜ì‹ ì  ê°•í™”í•™ìŠµ**: 128k ì»¨í…ìŠ¤íŠ¸ì—ì„œ ë™ì‘í•˜ëŠ” RL ì‹œìŠ¤í…œ
- **ğŸŒ ë©€í‹°ëª¨ë‹¬ í†µí•©**: í…ìŠ¤íŠ¸ì™€ ë¹„ì „ ë°ì´í„° ê³µë™ í•™ìŠµ
- **âš¡ íš¨ìœ¨ì  ì¶”ë¡ **: ë³µì¡í•œ MCTS ì—†ì´ë„ ê°•ë ¥í•œ ì„±ëŠ¥ ë‹¬ì„±

### í•µì‹¬ ê¸°ìˆ  ì‚¬ì–‘

| í•­ëª© | ì‚¬ì–‘ |
|------|------|
| **ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´** | 128k í† í° |
| **ì¶”ë¡  ë°©ì‹** | Long-CoT + Short-CoT |
| **ëª¨ë‹¬ë¦¬í‹°** | í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ë¹„ë””ì˜¤ |
| **í•™ìŠµ ë°©ë²•** | ê°•í™”í•™ìŠµ (ì˜¨ë¼ì¸ ë¯¸ëŸ¬ ë””ì„¼íŠ¸) |
| **íŠ¹í™” ë¶„ì•¼** | ìˆ˜í•™, ì½”ë”©, ë©€í‹°ëª¨ë‹¬ ì¶”ë¡  |
| **ë¼ì´ì„ ìŠ¤** | ìƒì—…ì  ì‚¬ìš© ê°€ëŠ¥ |

## ë†€ë¼ìš´ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### 1. ìˆ˜í•™ ë° ë…¼ë¦¬ ì¶”ë¡ 

| ë²¤ì¹˜ë§ˆí¬ | Kimi-K1.5 | GPT-4o | Claude Sonnet 3.5 | ì„±ëŠ¥ í–¥ìƒ |
|----------|-----------|--------|-------------------|----------|
| **AIME** | 77.5 | 13.4 | 12.8 | **+478%** |
| **MATH-500** | 96.2 | 73.4 | 71.5 | **+31%** |
| **MathVista** | 74.9 | 63.8 | 61.6 | **+17%** |

### 2. ì½”ë”© ì„±ëŠ¥

| ë²¤ì¹˜ë§ˆí¬ | Kimi-K1.5 | GPT-4o | Claude Sonnet 3.5 | ì„±ëŠ¥ í–¥ìƒ |
|----------|-----------|--------|-------------------|----------|
| **LiveCodeBench** | 47.3 | 35.2 | 33.9 | **+34%** |
| **Codeforces** | 94th ë°±ë¶„ìœ„ | 81st ë°±ë¶„ìœ„ | 79th ë°±ë¶„ìœ„ | **+16%** |

### 3. Short-CoT ëª¨ë¸ ì„±ëŠ¥

ê¸°ì¡´ ëª¨ë¸ë“¤ê³¼ ë¹„êµí–ˆì„ ë•Œ **Short-CoT** ë²„ì „ì—ì„œë„ ì••ë„ì  ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤:

| ë²¤ì¹˜ë§ˆí¬ | Kimi-K1.5 Short-CoT | GPT-4o | ì„±ëŠ¥ í–¥ìƒ |
|----------|---------------------|--------|----------|
| **AIME** | 60.8 | 13.4 | **+354%** |
| **MATH-500** | 94.6 | 73.4 | **+29%** |
| **LiveCodeBench** | 47.3 | 35.2 | **+34%** |

## í•µì‹¬ ê¸°ìˆ  ì•„í‚¤í…ì²˜

### 1. ê°•í™”í•™ìŠµ ê¸°ë°˜ Long-CoT ì‹œìŠ¤í…œ

```python
class KimiRLFramework:
    """Kimi-K1.5ì˜ ê°•í™”í•™ìŠµ í”„ë ˆì„ì›Œí¬"""
    
    def __init__(self, context_length=128000):
        self.context_length = context_length
        self.policy_optimizer = OnlineMirrorDescent()
        self.length_penalty = LengthPenaltySystem()
        self.sampling_strategy = SmartSamplingStrategy()
        
    def long_context_scaling(self, trajectory):
        """128k ì»¨í…ìŠ¤íŠ¸ í™•ì¥ì„ í†µí•œ ì„±ëŠ¥ í–¥ìƒ"""
        # ë¶€ë¶„ ë¡¤ì•„ì›ƒì„ ì‚¬ìš©í•œ íš¨ìœ¨ì ì¸ í•™ìŠµ
        partial_rollout = self.reuse_trajectory_chunk(trajectory)
        
        # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë”°ë¥¸ ì§€ì†ì ì¸ ì„±ëŠ¥ í–¥ìƒ
        performance_gain = self.context_length / 32000  # ê¸°ë³¸ ê¸¸ì´ ëŒ€ë¹„
        
        return {
            "partial_rollout": partial_rollout,
            "performance_multiplier": performance_gain,
            "context_utilization": self.calculate_context_usage(trajectory)
        }
    
    def policy_optimization(self, batch_trajectories):
        """ê°œì„ ëœ ì •ì±… ìµœì í™”"""
        # ì˜¨ë¼ì¸ ë¯¸ëŸ¬ ë””ì„¼íŠ¸ë¥¼ ì‚¬ìš©í•œ ì•ˆì •ì ì¸ í•™ìŠµ
        policy_gradient = self.policy_optimizer.compute_gradient(batch_trajectories)
        
        # ê¸¸ì´ í˜ë„í‹° ì ìš©
        length_adjusted_rewards = self.length_penalty.apply(batch_trajectories)
        
        # íš¨ê³¼ì ì¸ ìƒ˜í”Œë§ ì „ëµ
        optimized_samples = self.sampling_strategy.select_samples(
            batch_trajectories, 
            length_adjusted_rewards
        )
        
        return {
            "policy_update": policy_gradient,
            "adjusted_rewards": length_adjusted_rewards,
            "selected_samples": optimized_samples
        }
    
    def simplistic_framework(self, problem):
        """ë³µì¡í•œ ê¸°ë²• ì—†ì´ë„ ê°•ë ¥í•œ ì„±ëŠ¥ ë‹¬ì„±"""
        # MCTS, ë°¸ë¥˜ í•¨ìˆ˜, í”„ë¡œì„¸ìŠ¤ ë³´ìƒ ëª¨ë¸ ë¶ˆí•„ìš”
        
        # 1. ê¸´ ì»¨í…ìŠ¤íŠ¸ë¥¼ í™œìš©í•œ ê³„íš
        planning_context = self.extend_context_for_planning(problem)
        
        # 2. ë°˜ì„±ì  ì‚¬ê³  ê³¼ì •
        reflection_steps = self.enable_reflection_in_context(planning_context)
        
        # 3. ìê¸° ìˆ˜ì • ëŠ¥ë ¥
        correction_mechanism = self.implement_self_correction(reflection_steps)
        
        # 4. íš¨ê³¼ì ì¸ íƒìƒ‰ (ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ = íƒìƒ‰ ë‹¨ê³„ ìˆ˜)
        search_steps = self.context_length // 1000  # ëŒ€ëµì ì¸ íƒìƒ‰ ë‹¨ê³„
        
        return {
            "planning": planning_context,
            "reflection": reflection_steps,
            "correction": correction_mechanism,
            "search_depth": search_steps
        }
```

### 2. ë©€í‹°ëª¨ë‹¬ í†µí•© í•™ìŠµ

```python
class MultimodalKimiTraining:
    """í…ìŠ¤íŠ¸ì™€ ë¹„ì „ ë°ì´í„° ê³µë™ í•™ìŠµ"""
    
    def __init__(self):
        self.text_encoder = KimiTextEncoder()
        self.vision_encoder = KimiVisionEncoder()
        self.joint_reasoning = JointReasoningModule()
        
    def joint_training(self, text_data, vision_data):
        """í…ìŠ¤íŠ¸ì™€ ë¹„ì „ ë°ì´í„° ê³µë™ í•™ìŠµ"""
        # í…ìŠ¤íŠ¸ ì¸ì½”ë”©
        text_features = self.text_encoder.encode(text_data)
        
        # ë¹„ì „ ì¸ì½”ë”©
        vision_features = self.vision_encoder.encode(vision_data)
        
        # ê³µë™ ì¶”ë¡ 
        joint_representation = self.joint_reasoning.combine(
            text_features, 
            vision_features
        )
        
        return {
            "text_features": text_features,
            "vision_features": vision_features,
            "joint_reasoning": joint_representation,
            "modality_alignment": self.calculate_alignment(text_features, vision_features)
        }
    
    def multimodal_reasoning(self, text_query, image_input):
        """ë©€í‹°ëª¨ë‹¬ ì¶”ë¡  ì‹¤í–‰"""
        # ë‘ ëª¨ë‹¬ë¦¬í‹° ê°„ ìƒí˜¸ ì‘ìš©
        cross_modal_attention = self.compute_cross_attention(text_query, image_input)
        
        # í†µí•©ëœ ì´í•´
        unified_understanding = self.create_unified_representation(
            text_query, 
            image_input, 
            cross_modal_attention
        )
        
        # ì¶”ë¡  ì²´ì¸ ìƒì„±
        reasoning_chain = self.generate_reasoning_chain(unified_understanding)
        
        return {
            "cross_modal_attention": cross_modal_attention,
            "unified_understanding": unified_understanding,
            "reasoning_chain": reasoning_chain
        }
```

### 3. í˜ì‹ ì ì¸ í•™ìŠµ ì‹œìŠ¤í…œ

```python
class KimiTrainingSystem:
    """Kimi-K1.5ì˜ í›ˆë ¨ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.checkpoint_engine = CheckpointEngine()
        self.parallelism_manager = ParallelismManager()
        self.reward_system = SmartRewardSystem()
        
    def three_way_parallelism(self, model, training_data):
        """ì‚¼ì¤‘ ë³‘ë ¬ ì²˜ë¦¬"""
        # 1. íŒŒì´í”„ë¼ì¸ ë³‘ë ¬ì„±: GPU ê°„ ìˆœì°¨ì  ë ˆì´ì–´ ì²˜ë¦¬
        pipeline_config = self.parallelism_manager.setup_pipeline(model)
        
        # 2. ì „ë¬¸ê°€ ë³‘ë ¬ì„±: íƒœìŠ¤í¬ë³„ GPU íŠ¹í™”
        expert_config = self.parallelism_manager.setup_expert_parallelism(model)
        
        # 3. í…ì„œ ë³‘ë ¬ì„±: ë‹¤ì¤‘ GPU ê°„ í–‰ë ¬ ì—°ì‚° ë¶„ì‚°
        tensor_config = self.parallelism_manager.setup_tensor_parallelism(model)
        
        # ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬
        checkpoint_state = self.checkpoint_engine.manage_state(
            pipeline_config, 
            expert_config, 
            tensor_config
        )
        
        return {
            "pipeline_parallelism": pipeline_config,
            "expert_parallelism": expert_config,
            "tensor_parallelism": tensor_config,
            "checkpoint_state": checkpoint_state
        }
    
    def long2short_optimization(self, long_cot_model, short_cot_target):
        """Long-CoTì—ì„œ Short-CoTë¡œì˜ ìµœì í™”"""
        # ëª¨ë¸ ë³‘í•©
        merged_model = self.model_merging(long_cot_model, short_cot_target)
        
        # ê±°ë¶€ ìƒ˜í”Œë§
        optimized_samples = self.shortest_rejection_sampling(merged_model)
        
        # ì§ì ‘ ì„ í˜¸ë„ ìµœì í™”
        dpo_model = self.direct_preference_optimization(
            merged_model, 
            optimized_samples
        )
        
        return {
            "merged_model": merged_model,
            "optimized_samples": optimized_samples,
            "final_model": dpo_model,
            "performance_metrics": self.evaluate_short_cot_performance(dpo_model)
        }
```

## ì‹¤ì „ í™œìš© ê°€ì´ë“œ

### 1. í™˜ê²½ ì„¤ì •

```bash
# ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install torch transformers accelerate
pip install vllm  # ê³ ì„±ëŠ¥ ì¶”ë¡ ìš©
pip install gradio  # UI êµ¬ì„±ìš©

# Kimi-K1.5 ì „ìš© ì„¤ì •
export KIMI_MODEL_PATH="moonshot-ai/kimi-k1.5"
export KIMI_CONTEXT_LENGTH=128000
export KIMI_REASONING_MODE="long_cot"
```

### 2. ê¸°ë³¸ ì¶”ë¡  ì‹œìŠ¤í…œ

```python
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from typing import Dict, List, Optional

class KimiReasoningSystem:
    """Kimi-K1.5 ì¶”ë¡  ì‹œìŠ¤í…œ"""
    
    def __init__(self, model_path: str = "moonshot-ai/kimi-k1.5"):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        self.model = AutoModelForCausalLM.from_pretrained(
            model_path,
            torch_dtype=torch.float16,
            device_map="auto",
            max_memory={"0": "24GB", "1": "24GB"}  # ë©€í‹° GPU ì„¤ì •
        )
        
    def long_cot_reasoning(self, problem: str, max_tokens: int = 4096) -> Dict:
        """Long-CoT ì¶”ë¡  ì‹¤í–‰"""
        # ì¶”ë¡  í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        reasoning_prompt = f"""
        ë¬¸ì œë¥¼ ë‹¨ê³„ì ìœ¼ë¡œ í•´ê²°í•´ë³´ê² ìŠµë‹ˆë‹¤.

        ë¬¸ì œ: {problem}

        ë‹¨ê³„ë³„ ì¶”ë¡ :
        1. ë¬¸ì œ ì´í•´:
        """
        
        # í† í°í™”
        inputs = self.tokenizer(
            reasoning_prompt, 
            return_tensors="pt", 
            max_length=128000,
            truncation=True
        ).to(self.device)
        
        # ìƒì„± ì„¤ì •
        generation_config = {
            "max_new_tokens": max_tokens,
            "temperature": 0.7,
            "top_p": 0.9,
            "do_sample": True,
            "pad_token_id": self.tokenizer.eos_token_id
        }
        
        # ì¶”ë¡  ì‹¤í–‰
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                **generation_config
            )
        
        # ê²°ê³¼ ë””ì½”ë”©
        generated_text = self.tokenizer.decode(
            outputs[0], 
            skip_special_tokens=True
        )
        
        # ì¶”ë¡  ê³¼ì • ë¶„ì„
        reasoning_analysis = self.analyze_reasoning_chain(generated_text)
        
        return {
            "problem": problem,
            "reasoning_chain": generated_text,
            "analysis": reasoning_analysis,
            "tokens_used": len(outputs[0]),
            "reasoning_steps": reasoning_analysis["step_count"]
        }
    
    def analyze_reasoning_chain(self, text: str) -> Dict:
        """ì¶”ë¡  ì²´ì¸ ë¶„ì„"""
        # ë‹¨ê³„ ì¹´ìš´íŒ…
        step_markers = ["1.", "2.", "3.", "ë‹¨ê³„", "Step", "ë”°ë¼ì„œ"]
        step_count = sum(1 for marker in step_markers if marker in text)
        
        # ì¶”ë¡  í’ˆì§ˆ í‰ê°€
        quality_indicators = {
            "ê³„ì‚°_ê³¼ì •": "ê³„ì‚°" in text or "=" in text,
            "ë…¼ë¦¬_ì—°ê²°": "ë”°ë¼ì„œ" in text or "ê·¸ëŸ¬ë¯€ë¡œ" in text,
            "ê²€ì¦_ê³¼ì •": "í™•ì¸" in text or "ê²€ì¦" in text,
            "ìµœì¢…_ë‹µì•ˆ": "ë‹µ:" in text or "ê²°ë¡ :" in text
        }
        
        # ë³µì¡ë„ ì¸¡ì •
        complexity_score = len(text) / 100 + step_count * 0.1
        
        return {
            "step_count": step_count,
            "quality_indicators": quality_indicators,
            "complexity_score": complexity_score,
            "reasoning_quality": sum(quality_indicators.values()) / len(quality_indicators)
        }
```

### 3. ìˆ˜í•™ ë¬¸ì œ í•´ê²° ì‹œìŠ¤í…œ

```python
class KimiMathSolver:
    """Kimi-K1.5 ìˆ˜í•™ ë¬¸ì œ í•´ê²° ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.reasoning_system = KimiReasoningSystem()
        self.verification_system = MathVerificationSystem()
        
    def solve_math_problem(self, problem: str, problem_type: str = "general") -> Dict:
        """ìˆ˜í•™ ë¬¸ì œ í•´ê²°"""
        # ë¬¸ì œ ìœ í˜•ë³„ í”„ë¡¬í”„íŠ¸ ìµœì í™”
        optimized_prompt = self.optimize_prompt_for_math(problem, problem_type)
        
        # Long-CoT ì¶”ë¡  ì‹¤í–‰
        reasoning_result = self.reasoning_system.long_cot_reasoning(
            optimized_prompt, 
            max_tokens=8192
        )
        
        # ìˆ˜í•™ì  ê²€ì¦
        verification_result = self.verification_system.verify_solution(
            reasoning_result["reasoning_chain"]
        )
        
        # ë‹µì•ˆ ì¶”ì¶œ
        final_answer = self.extract_final_answer(reasoning_result["reasoning_chain"])
        
        return {
            "problem": problem,
            "problem_type": problem_type,
            "reasoning_process": reasoning_result,
            "verification": verification_result,
            "final_answer": final_answer,
            "confidence_score": self.calculate_confidence(verification_result)
        }
    
    def optimize_prompt_for_math(self, problem: str, problem_type: str) -> str:
        """ìˆ˜í•™ ë¬¸ì œ ìœ í˜•ë³„ í”„ë¡¬í”„íŠ¸ ìµœì í™”"""
        base_prompt = f"""
        ìˆ˜í•™ ë¬¸ì œë¥¼ ì²´ê³„ì ìœ¼ë¡œ í•´ê²°í•˜ê² ìŠµë‹ˆë‹¤.

        ë¬¸ì œ: {problem}

        í•´ê²° ê³¼ì •:
        """
        
        if problem_type == "algebra":
            return base_prompt + """
            1. ì£¼ì–´ì§„ ì¡°ê±´ ì •ë¦¬
            2. ë³€ìˆ˜ ì •ì˜
            3. ë°©ì •ì‹ ì„¤ì •
            4. ë°©ì •ì‹ í•´ê²°
            5. ë‹µ ê²€ì¦
            """
        elif problem_type == "geometry":
            return base_prompt + """
            1. ë„í˜• ë¶„ì„
            2. ì£¼ì–´ì§„ ì¡°ê±´ ì •ë¦¬
            3. ê´€ë ¨ ê³µì‹ í™•ì¸
            4. ê³„ì‚° ê³¼ì •
            5. ë‹µ ê²€ì¦
            """
        elif problem_type == "calculus":
            return base_prompt + """
            1. í•¨ìˆ˜ ë¶„ì„
            2. ë¯¸ë¶„/ì ë¶„ ê·œì¹™ ì ìš©
            3. ê³„ì‚° ê³¼ì •
            4. ê·¹í•œ í™•ì¸
            5. ë‹µ ê²€ì¦
            """
        else:
            return base_prompt + """
            1. ë¬¸ì œ ë¶„ì„
            2. í•´ê²° ì „ëµ ìˆ˜ë¦½
            3. ë‹¨ê³„ë³„ ê³„ì‚°
            4. ë‹µ ê²€ì¦
            """
    
    def extract_final_answer(self, reasoning_text: str) -> str:
        """ìµœì¢… ë‹µì•ˆ ì¶”ì¶œ"""
        # ì¼ë°˜ì ì¸ ë‹µì•ˆ íŒ¨í„´ ì°¾ê¸°
        answer_patterns = [
            r"ë‹µ[:\s]*([^.\n]+)",
            r"ê²°ë¡ [:\s]*([^.\n]+)",
            r"ë”°ë¼ì„œ[:\s]*([^.\n]+)",
            r"ìµœì¢…ì ìœ¼ë¡œ[:\s]*([^.\n]+)"
        ]
        
        import re
        for pattern in answer_patterns:
            match = re.search(pattern, reasoning_text)
            if match:
                return match.group(1).strip()
        
        # ìˆ˜ì‹ íŒ¨í„´ ì°¾ê¸°
        equation_pattern = r"=\s*([0-9\.\-\+\*/\(\)]+)\s*$"
        equations = re.findall(equation_pattern, reasoning_text, re.MULTILINE)
        if equations:
            return equations[-1]  # ë§ˆì§€ë§‰ ë°©ì •ì‹ ê²°ê³¼
        
        return "ë‹µì•ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
```

### 4. ì½”ë”© ë¬¸ì œ í•´ê²° ì‹œìŠ¤í…œ

```python
class KimiCodeSolver:
    """Kimi-K1.5 ì½”ë”© ë¬¸ì œ í•´ê²° ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.reasoning_system = KimiReasoningSystem()
        self.code_executor = CodeExecutor()
        
    def solve_coding_problem(self, problem: str, language: str = "python") -> Dict:
        """ì½”ë”© ë¬¸ì œ í•´ê²°"""
        # ì½”ë”© íŠ¹í™” í”„ë¡¬í”„íŠ¸
        coding_prompt = f"""
        í”„ë¡œê·¸ë˜ë° ë¬¸ì œë¥¼ ì²´ê³„ì ìœ¼ë¡œ í•´ê²°í•˜ê² ìŠµë‹ˆë‹¤.

        ë¬¸ì œ: {problem}

        í•´ê²° ê³¼ì •:
        1. ë¬¸ì œ ë¶„ì„
        2. ì•Œê³ ë¦¬ì¦˜ ì„¤ê³„
        3. ì½”ë“œ êµ¬í˜„
        4. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ê²€ì¦
        5. ìµœì í™” ê³ ë ¤

        ì–¸ì–´: {language}
        """
        
        # ì¶”ë¡  ì‹¤í–‰
        reasoning_result = self.reasoning_system.long_cot_reasoning(
            coding_prompt, 
            max_tokens=6144
        )
        
        # ì½”ë“œ ì¶”ì¶œ
        code_blocks = self.extract_code_blocks(reasoning_result["reasoning_chain"])
        
        # ì½”ë“œ ì‹¤í–‰ ë° í…ŒìŠ¤íŠ¸
        execution_results = []
        for code in code_blocks:
            result = self.code_executor.execute_code(code, language)
            execution_results.append(result)
        
        # ìµœì  ì†”ë£¨ì…˜ ì„ íƒ
        best_solution = self.select_best_solution(code_blocks, execution_results)
        
        return {
            "problem": problem,
            "language": language,
            "reasoning_process": reasoning_result,
            "code_blocks": code_blocks,
            "execution_results": execution_results,
            "best_solution": best_solution
        }
    
    def extract_code_blocks(self, text: str) -> List[str]:
        """ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ"""
        import re
        
        # ì½”ë“œ ë¸”ë¡ íŒ¨í„´ (```)
        code_pattern = r"```(?:python|java|cpp|javascript|c)?\n(.*?)```"
        code_blocks = re.findall(code_pattern, text, re.DOTALL)
        
        # ì¸ë¼ì¸ ì½”ë“œ íŒ¨í„´
        if not code_blocks:
            inline_pattern = r"`([^`]+)`"
            inline_codes = re.findall(inline_pattern, text)
            code_blocks = [code for code in inline_codes if len(code) > 20]
        
        return code_blocks
    
    def select_best_solution(self, code_blocks: List[str], execution_results: List[Dict]) -> Dict:
        """ìµœì  ì†”ë£¨ì…˜ ì„ íƒ"""
        best_score = -1
        best_solution = None
        
        for i, (code, result) in enumerate(zip(code_blocks, execution_results)):
            score = 0
            
            # ì‹¤í–‰ ì„±ê³µ ì—¬ë¶€
            if result.get("success", False):
                score += 50
            
            # ì½”ë“œ ë³µì¡ë„ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
            complexity = len(code.split('\n'))
            score += max(0, 50 - complexity)
            
            # ì‹¤í–‰ ì‹œê°„ (ë¹ ë¥¼ìˆ˜ë¡ ì¢‹ìŒ)
            execution_time = result.get("execution_time", float('inf'))
            if execution_time < 1.0:
                score += 20
            
            if score > best_score:
                best_score = score
                best_solution = {
                    "code": code,
                    "execution_result": result,
                    "score": score,
                    "index": i
                }
        
        return best_solution
```

### 5. ë©€í‹°ëª¨ë‹¬ ì¶”ë¡  ì‹œìŠ¤í…œ

```python
class KimiMultimodalReasoning:
    """Kimi-K1.5 ë©€í‹°ëª¨ë‹¬ ì¶”ë¡  ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.reasoning_system = KimiReasoningSystem()
        self.image_processor = ImageProcessor()
        
    def solve_visual_problem(self, problem: str, image_path: str) -> Dict:
        """ì‹œê°ì  ë¬¸ì œ í•´ê²°"""
        # ì´ë¯¸ì§€ ì²˜ë¦¬
        image_features = self.image_processor.extract_features(image_path)
        image_description = self.image_processor.describe_image(image_path)
        
        # ë©€í‹°ëª¨ë‹¬ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        multimodal_prompt = f"""
        ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ë¶„ì„í•˜ì—¬ ë¬¸ì œë¥¼ í•´ê²°í•˜ê² ìŠµë‹ˆë‹¤.

        ë¬¸ì œ: {problem}

        ì´ë¯¸ì§€ ì„¤ëª…: {image_description}

        ë¶„ì„ ê³¼ì •:
        1. ì´ë¯¸ì§€ ë‚´ìš© íŒŒì•…
        2. ë¬¸ì œì™€ ì´ë¯¸ì§€ì˜ ì—°ê´€ì„± ë¶„ì„
        3. ì‹œê°ì  ì •ë³´ í™œìš©
        4. ë…¼ë¦¬ì  ì¶”ë¡ 
        5. ê²°ë¡  ë„ì¶œ
        """
        
        # ì¶”ë¡  ì‹¤í–‰
        reasoning_result = self.reasoning_system.long_cot_reasoning(
            multimodal_prompt, 
            max_tokens=4096
        )
        
        # ì‹œê°ì  ìš”ì†Œ ë¶„ì„
        visual_analysis = self.analyze_visual_elements(
            reasoning_result["reasoning_chain"], 
            image_features
        )
        
        return {
            "problem": problem,
            "image_path": image_path,
            "image_description": image_description,
            "reasoning_process": reasoning_result,
            "visual_analysis": visual_analysis,
            "confidence_score": self.calculate_multimodal_confidence(
                reasoning_result, 
                visual_analysis
            )
        }
    
    def analyze_visual_elements(self, reasoning_text: str, image_features: Dict) -> Dict:
        """ì‹œê°ì  ìš”ì†Œ ë¶„ì„"""
        # í…ìŠ¤íŠ¸ì—ì„œ ì‹œê°ì  ì–¸ê¸‰ ì°¾ê¸°
        visual_mentions = self.find_visual_mentions(reasoning_text)
        
        # ì´ë¯¸ì§€ íŠ¹ì§•ê³¼ ë§¤ì¹­
        feature_matches = self.match_features_with_mentions(
            visual_mentions, 
            image_features
        )
        
        # ì‹œê°ì  ì¶”ë¡  í’ˆì§ˆ í‰ê°€
        visual_reasoning_quality = self.evaluate_visual_reasoning(
            reasoning_text, 
            feature_matches
        )
        
        return {
            "visual_mentions": visual_mentions,
            "feature_matches": feature_matches,
            "reasoning_quality": visual_reasoning_quality,
            "integration_score": len(feature_matches) / max(len(visual_mentions), 1)
        }
```

## ì„±ëŠ¥ ìµœì í™” ë° ë°°í¬

### 1. vLLMì„ í™œìš©í•œ ê³ ì„±ëŠ¥ ì¶”ë¡ 

```python
from vllm import LLM, SamplingParams
import asyncio
from typing import List, Dict

class KimiVLLMServer:
    """Kimi-K1.5 vLLM ì„œë²„"""
    
    def __init__(self, model_path: str = "moonshot-ai/kimi-k1.5"):
        self.llm = LLM(
            model=model_path,
            tensor_parallel_size=2,  # ë©€í‹° GPU ì„¤ì •
            max_model_len=128000,    # 128k ì»¨í…ìŠ¤íŠ¸
            gpu_memory_utilization=0.9,
            trust_remote_code=True
        )
        
        self.sampling_params = SamplingParams(
            temperature=0.7,
            top_p=0.9,
            max_tokens=8192,
            stop=["<|end|>", "```END```"]
        )
    
    async def batch_reasoning(self, problems: List[str]) -> List[Dict]:
        """ë°°ì¹˜ ì¶”ë¡  ì²˜ë¦¬"""
        # í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
        prompts = [self.prepare_reasoning_prompt(problem) for problem in problems]
        
        # ë°°ì¹˜ ìƒì„±
        outputs = self.llm.generate(prompts, self.sampling_params)
        
        # ê²°ê³¼ ì²˜ë¦¬
        results = []
        for i, output in enumerate(outputs):
            generated_text = output.outputs[0].text
            
            result = {
                "problem": problems[i],
                "reasoning": generated_text,
                "tokens_used": len(output.outputs[0].token_ids),
                "reasoning_analysis": self.analyze_reasoning(generated_text)
            }
            results.append(result)
        
        return results
    
    def prepare_reasoning_prompt(self, problem: str) -> str:
        """ì¶”ë¡  í”„ë¡¬í”„íŠ¸ ì¤€ë¹„"""
        return f"""
        <|system|>
        ë‹¹ì‹ ì€ Kimi-K1.5 AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¬¸ì œë¥¼ ë‹¨ê³„ì ìœ¼ë¡œ í•´ê²°í•˜ê³ , ë…¼ë¦¬ì ì¸ ì¶”ë¡  ê³¼ì •ì„ ë³´ì—¬ì£¼ì„¸ìš”.
        <|user|>
        {problem}
        <|assistant|>
        ì´ ë¬¸ì œë¥¼ ë‹¨ê³„ì ìœ¼ë¡œ í•´ê²°í•´ë³´ê² ìŠµë‹ˆë‹¤.

        """
    
    def analyze_reasoning(self, text: str) -> Dict:
        """ì¶”ë¡  ë¶„ì„"""
        # ì¶”ë¡  í’ˆì§ˆ ì§€í‘œ
        quality_metrics = {
            "step_count": len([line for line in text.split('\n') if line.strip().startswith(('1.', '2.', '3.', 'ë‹¨ê³„', 'Step'))]),
            "logical_connectors": len([word for word in ['ë”°ë¼ì„œ', 'ê·¸ëŸ¬ë¯€ë¡œ', 'ê²°ë¡ ì ìœ¼ë¡œ', 'ê·¸ëŸ°ë°', 'ë˜í•œ'] if word in text]),
            "mathematical_expressions": len([char for char in text if char in '=+-*/()[]']),
            "verification_attempts": len([word for word in ['ê²€ì¦', 'í™•ì¸', 'ì²´í¬'] if word in text])
        }
        
        # ì „ì²´ í’ˆì§ˆ ì ìˆ˜
        total_quality = sum(quality_metrics.values()) / len(quality_metrics)
        
        return {
            "metrics": quality_metrics,
            "overall_quality": total_quality,
            "reasoning_length": len(text),
            "complexity_score": quality_metrics["step_count"] * 0.3 + quality_metrics["logical_connectors"] * 0.2
        }
```

### 2. ì‹¤ì‹œê°„ ì¶”ë¡  API ì„œë²„

```python
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel
import uvicorn
from typing import Optional, List
import asyncio
import time

app = FastAPI(title="Kimi-K1.5 Reasoning API", version="1.0.0")

# ì „ì—­ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
kimi_server = None

class ReasoningRequest(BaseModel):
    problem: str
    problem_type: Optional[str] = "general"
    max_tokens: Optional[int] = 4096
    temperature: Optional[float] = 0.7
    use_long_cot: Optional[bool] = True

class ReasoningResponse(BaseModel):
    problem: str
    reasoning_chain: str
    final_answer: str
    confidence_score: float
    tokens_used: int
    processing_time: float

class BatchReasoningRequest(BaseModel):
    problems: List[str]
    problem_type: Optional[str] = "general"
    max_tokens: Optional[int] = 4096

@app.on_event("startup")
async def startup_event():
    global kimi_server
    kimi_server = KimiVLLMServer()
    print("Kimi-K1.5 ì„œë²„ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")

@app.post("/reasoning", response_model=ReasoningResponse)
async def solve_problem(request: ReasoningRequest):
    """ë‹¨ì¼ ë¬¸ì œ í•´ê²°"""
    if kimi_server is None:
        raise HTTPException(status_code=500, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    start_time = time.time()
    
    try:
        # ì¶”ë¡  ì‹¤í–‰
        results = await kimi_server.batch_reasoning([request.problem])
        result = results[0]
        
        # ìµœì¢… ë‹µì•ˆ ì¶”ì¶œ
        final_answer = extract_final_answer(result["reasoning"])
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence_score = calculate_confidence(result["reasoning_analysis"])
        
        processing_time = time.time() - start_time
        
        return ReasoningResponse(
            problem=request.problem,
            reasoning_chain=result["reasoning"],
            final_answer=final_answer,
            confidence_score=confidence_score,
            tokens_used=result["tokens_used"],
            processing_time=processing_time
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì¶”ë¡  ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.post("/batch_reasoning")
async def solve_batch_problems(request: BatchReasoningRequest):
    """ë°°ì¹˜ ë¬¸ì œ í•´ê²°"""
    if kimi_server is None:
        raise HTTPException(status_code=500, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    start_time = time.time()
    
    try:
        # ë°°ì¹˜ ì¶”ë¡  ì‹¤í–‰
        results = await kimi_server.batch_reasoning(request.problems)
        
        # ê²°ê³¼ ì²˜ë¦¬
        processed_results = []
        for result in results:
            processed_results.append({
                "problem": result["problem"],
                "reasoning": result["reasoning"],
                "final_answer": extract_final_answer(result["reasoning"]),
                "confidence_score": calculate_confidence(result["reasoning_analysis"]),
                "tokens_used": result["tokens_used"]
            })
        
        processing_time = time.time() - start_time
        
        return {
            "results": processed_results,
            "total_problems": len(request.problems),
            "processing_time": processing_time,
            "average_time_per_problem": processing_time / len(request.problems)
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "healthy",
        "model": "Kimi-K1.5",
        "version": "1.0.0",
        "context_length": 128000,
        "capabilities": ["reasoning", "coding", "mathematics", "multimodal"]
    }

def extract_final_answer(reasoning_text: str) -> str:
    """ìµœì¢… ë‹µì•ˆ ì¶”ì¶œ"""
    # êµ¬í˜„ ìƒëµ (ì´ì „ ì½”ë“œ ì°¸ì¡°)
    pass

def calculate_confidence(reasoning_analysis: Dict) -> float:
    """ì‹ ë¢°ë„ ê³„ì‚°"""
    # êµ¬í˜„ ìƒëµ (ì´ì „ ì½”ë“œ ì°¸ì¡°)
    pass

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

### 3. ì›¹ ì¸í„°í˜ì´ìŠ¤ êµ¬ì¶•

```python
import gradio as gr
import asyncio
from typing import Dict, List

class KimiWebInterface:
    """Kimi-K1.5 ì›¹ ì¸í„°í˜ì´ìŠ¤"""
    
    def __init__(self):
        self.math_solver = KimiMathSolver()
        self.code_solver = KimiCodeSolver()
        self.multimodal_solver = KimiMultimodalReasoning()
        
    def create_interface(self):
        """Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""
        with gr.Blocks(title="Kimi-K1.5 AI Assistant") as interface:
            gr.Markdown("# ğŸ§  Kimi-K1.5 AI Assistant")
            gr.Markdown("ê°•í™”í•™ìŠµ ê¸°ë°˜ o1ê¸‰ ì¶”ë¡  ëª¨ë¸ë¡œ ìˆ˜í•™, ì½”ë”©, ë©€í‹°ëª¨ë‹¬ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.")
            
            with gr.Tabs():
                # ìˆ˜í•™ ë¬¸ì œ í•´ê²° íƒ­
                with gr.Tab("ğŸ”¢ ìˆ˜í•™ ë¬¸ì œ í•´ê²°"):
                    math_input = gr.Textbox(
                        label="ìˆ˜í•™ ë¬¸ì œ ì…ë ¥",
                        placeholder="ì˜ˆ: x^2 + 5x + 6 = 0ì„ í’€ì–´ì£¼ì„¸ìš”.",
                        lines=3
                    )
                    math_type = gr.Dropdown(
                        choices=["general", "algebra", "geometry", "calculus"],
                        value="general",
                        label="ë¬¸ì œ ìœ í˜•"
                    )
                    math_button = gr.Button("í•´ê²°í•˜ê¸°", variant="primary")
                    
                    math_output = gr.Textbox(
                        label="ì¶”ë¡  ê³¼ì •",
                        lines=10,
                        max_lines=20
                    )
                    math_answer = gr.Textbox(label="ìµœì¢… ë‹µì•ˆ")
                    math_confidence = gr.Number(label="ì‹ ë¢°ë„ ì ìˆ˜")
                
                # ì½”ë”© ë¬¸ì œ í•´ê²° íƒ­  
                with gr.Tab("ğŸ’» ì½”ë”© ë¬¸ì œ í•´ê²°"):
                    code_input = gr.Textbox(
                        label="ì½”ë”© ë¬¸ì œ ì…ë ¥",
                        placeholder="ì˜ˆ: ë‘ ìˆ˜ì˜ ìµœëŒ€ê³µì•½ìˆ˜ë¥¼ êµ¬í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.",
                        lines=3
                    )
                    code_language = gr.Dropdown(
                        choices=["python", "java", "javascript", "cpp"],
                        value="python",
                        label="í”„ë¡œê·¸ë˜ë° ì–¸ì–´"
                    )
                    code_button = gr.Button("í•´ê²°í•˜ê¸°", variant="primary")
                    
                    code_reasoning = gr.Textbox(
                        label="ì¶”ë¡  ê³¼ì •",
                        lines=8,
                        max_lines=15
                    )
                    code_output = gr.Code(
                        label="ìƒì„±ëœ ì½”ë“œ",
                        language="python"
                    )
                    code_result = gr.Textbox(label="ì‹¤í–‰ ê²°ê³¼")
                
                # ë©€í‹°ëª¨ë‹¬ ë¬¸ì œ í•´ê²° íƒ­
                with gr.Tab("ğŸ–¼ï¸ ë©€í‹°ëª¨ë‹¬ ë¬¸ì œ í•´ê²°"):
                    multimodal_text = gr.Textbox(
                        label="ë¬¸ì œ ì„¤ëª…",
                        placeholder="ì´ë¯¸ì§€ì™€ ê´€ë ¨ëœ ë¬¸ì œë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                        lines=3
                    )
                    multimodal_image = gr.Image(
                        label="ì´ë¯¸ì§€ ì—…ë¡œë“œ",
                        type="filepath"
                    )
                    multimodal_button = gr.Button("ë¶„ì„í•˜ê¸°", variant="primary")
                    
                    multimodal_reasoning = gr.Textbox(
                        label="ë¶„ì„ ê³¼ì •",
                        lines=10,
                        max_lines=20
                    )
                    multimodal_result = gr.Textbox(label="ë¶„ì„ ê²°ê³¼")
                    multimodal_confidence = gr.Number(label="ì‹ ë¢°ë„ ì ìˆ˜")
            
            # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡
            math_button.click(
                self.solve_math_problem,
                inputs=[math_input, math_type],
                outputs=[math_output, math_answer, math_confidence]
            )
            
            code_button.click(
                self.solve_coding_problem,
                inputs=[code_input, code_language],
                outputs=[code_reasoning, code_output, code_result]
            )
            
            multimodal_button.click(
                self.solve_multimodal_problem,
                inputs=[multimodal_text, multimodal_image],
                outputs=[multimodal_reasoning, multimodal_result, multimodal_confidence]
            )
        
        return interface
    
    def solve_math_problem(self, problem: str, problem_type: str):
        """ìˆ˜í•™ ë¬¸ì œ í•´ê²°"""
        if not problem.strip():
            return "ë¬¸ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", "", 0.0
        
        try:
            result = self.math_solver.solve_math_problem(problem, problem_type)
            return (
                result["reasoning_process"]["reasoning_chain"],
                result["final_answer"],
                result["confidence_score"]
            )
        except Exception as e:
            return f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "", 0.0
    
    def solve_coding_problem(self, problem: str, language: str):
        """ì½”ë”© ë¬¸ì œ í•´ê²°"""
        if not problem.strip():
            return "ë¬¸ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", "", ""
        
        try:
            result = self.code_solver.solve_coding_problem(problem, language)
            best_solution = result["best_solution"]
            
            return (
                result["reasoning_process"]["reasoning_chain"],
                best_solution["code"] if best_solution else "",
                str(best_solution["execution_result"]) if best_solution else "ì‹¤í–‰ ê²°ê³¼ ì—†ìŒ"
            )
        except Exception as e:
            return f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "", ""
    
    def solve_multimodal_problem(self, problem: str, image_path: str):
        """ë©€í‹°ëª¨ë‹¬ ë¬¸ì œ í•´ê²°"""
        if not problem.strip():
            return "ë¬¸ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", "", 0.0
        
        if not image_path:
            return "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.", "", 0.0
        
        try:
            result = self.multimodal_solver.solve_visual_problem(problem, image_path)
            return (
                result["reasoning_process"]["reasoning_chain"],
                result["visual_analysis"]["reasoning_quality"],
                result["confidence_score"]
            )
        except Exception as e:
            return f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "", 0.0

# ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰
if __name__ == "__main__":
    kimi_interface = KimiWebInterface()
    interface = kimi_interface.create_interface()
    interface.launch(server_name="0.0.0.0", server_port=7860)
```

## ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë° ì‹¤ì œ í…ŒìŠ¤íŠ¸

### 1. AIME ìˆ˜í•™ ë¬¸ì œ í…ŒìŠ¤íŠ¸

```python
class AIMEBenchmark:
    """AIME ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸"""
    
    def __init__(self):
        self.kimi_solver = KimiMathSolver()
        self.test_problems = self.load_aime_problems()
        
    def load_aime_problems(self):
        """AIME ë¬¸ì œ ë¡œë“œ"""
        return [
            {
                "problem": "ì‚¼ê°í˜• ABCì—ì„œ AB = 13, BC = 14, CA = 15ì¼ ë•Œ, ë‚´ì ‘ì›ì˜ ë°˜ì§€ë¦„ì„ êµ¬í•˜ì‹œì˜¤.",
                "expected_answer": "4",
                "difficulty": "medium"
            },
            {
                "problem": "x^4 - 4x^3 + 6x^2 - 4x + 1 = 0ì˜ ëª¨ë“  ì‹¤ê·¼ì˜ í•©ì„ êµ¬í•˜ì‹œì˜¤.",
                "expected_answer": "4",
                "difficulty": "hard"
            },
            # ë” ë§ì€ ë¬¸ì œë“¤...
        ]
    
    def run_benchmark(self) -> Dict:
        """ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        results = {
            "total_problems": len(self.test_problems),
            "solved_correctly": 0,
            "total_time": 0,
            "problem_results": []
        }
        
        for i, problem_data in enumerate(self.test_problems):
            print(f"ë¬¸ì œ {i+1}/{len(self.test_problems)} í•´ê²° ì¤‘...")
            
            start_time = time.time()
            result = self.kimi_solver.solve_math_problem(
                problem_data["problem"], 
                "general"
            )
            solve_time = time.time() - start_time
            
            # ë‹µì•ˆ ì •í™•ì„± ê²€ì¦
            is_correct = self.verify_answer(
                result["final_answer"], 
                problem_data["expected_answer"]
            )
            
            if is_correct:
                results["solved_correctly"] += 1
            
            results["total_time"] += solve_time
            results["problem_results"].append({
                "problem": problem_data["problem"],
                "expected": problem_data["expected_answer"],
                "generated": result["final_answer"],
                "correct": is_correct,
                "time": solve_time,
                "confidence": result["confidence_score"]
            })
        
        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        results["accuracy"] = results["solved_correctly"] / results["total_problems"]
        results["average_time"] = results["total_time"] / results["total_problems"]
        
        return results
    
    def verify_answer(self, generated: str, expected: str) -> bool:
        """ë‹µì•ˆ ê²€ì¦"""
        # ìˆ«ì ì¶”ì¶œ ë° ë¹„êµ
        import re
        
        generated_numbers = re.findall(r'-?\d+(?:\.\d+)?', generated)
        expected_numbers = re.findall(r'-?\d+(?:\.\d+)?', expected)
        
        if not generated_numbers or not expected_numbers:
            return False
        
        try:
            gen_val = float(generated_numbers[-1])  # ë§ˆì§€ë§‰ ìˆ«ì ì‚¬ìš©
            exp_val = float(expected_numbers[-1])
            
            # í—ˆìš© ì˜¤ì°¨ ë²”ìœ„ì—ì„œ ë¹„êµ
            return abs(gen_val - exp_val) < 0.001
        except:
            return False
```

### 2. ì½”ë”© ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸

```python
class CodingBenchmark:
    """ì½”ë”© ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸"""
    
    def __init__(self):
        self.kimi_solver = KimiCodeSolver()
        self.test_problems = self.load_coding_problems()
        
    def load_coding_problems(self):
        """ì½”ë”© ë¬¸ì œ ë¡œë“œ"""
        return [
            {
                "problem": "ë‘ ì •ìˆ˜ì˜ ìµœëŒ€ê³µì•½ìˆ˜ë¥¼ êµ¬í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ì‹œì˜¤.",
                "test_cases": [
                    {"input": "(12, 18)", "expected": "6"},
                    {"input": "(17, 19)", "expected": "1"},
                    {"input": "(100, 75)", "expected": "25"}
                ],
                "difficulty": "easy"
            },
            {
                "problem": "ë°°ì—´ì—ì„œ ë‘ ë²ˆì§¸ë¡œ í° ìˆ˜ë¥¼ ì°¾ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ì‹œì˜¤.",
                "test_cases": [
                    {"input": "[1, 3, 4, 5, 2]", "expected": "4"},
                    {"input": "[10, 10, 10]", "expected": "None"},
                    {"input": "[1, 2]", "expected": "1"}
                ],
                "difficulty": "medium"
            },
            # ë” ë§ì€ ë¬¸ì œë“¤...
        ]
    
    def run_benchmark(self) -> Dict:
        """ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        results = {
            "total_problems": len(self.test_problems),
            "solved_correctly": 0,
            "total_time": 0,
            "problem_results": []
        }
        
        for i, problem_data in enumerate(self.test_problems):
            print(f"ì½”ë”© ë¬¸ì œ {i+1}/{len(self.test_problems)} í•´ê²° ì¤‘...")
            
            start_time = time.time()
            result = self.kimi_solver.solve_coding_problem(
                problem_data["problem"], 
                "python"
            )
            solve_time = time.time() - start_time
            
            # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ê²€ì¦
            test_results = self.run_test_cases(
                result["best_solution"]["code"] if result["best_solution"] else "",
                problem_data["test_cases"]
            )
            
            is_correct = test_results["passed"] == len(problem_data["test_cases"])
            
            if is_correct:
                results["solved_correctly"] += 1
            
            results["total_time"] += solve_time
            results["problem_results"].append({
                "problem": problem_data["problem"],
                "generated_code": result["best_solution"]["code"] if result["best_solution"] else "",
                "test_results": test_results,
                "correct": is_correct,
                "time": solve_time
            })
        
        results["accuracy"] = results["solved_correctly"] / results["total_problems"]
        results["average_time"] = results["total_time"] / results["total_problems"]
        
        return results
    
    def run_test_cases(self, code: str, test_cases: List[Dict]) -> Dict:
        """í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰"""
        passed = 0
        failed = 0
        results = []
        
        for test_case in test_cases:
            try:
                # ì½”ë“œ ì‹¤í–‰ í™˜ê²½ ì„¤ì •
                exec_globals = {}
                exec(code, exec_globals)
                
                # í•¨ìˆ˜ ì°¾ê¸° (ì²« ë²ˆì§¸ ì •ì˜ëœ í•¨ìˆ˜ ì‚¬ìš©)
                func_name = None
                for name, obj in exec_globals.items():
                    if callable(obj) and not name.startswith('_'):
                        func_name = name
                        break
                
                if func_name:
                    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
                    test_input = eval(test_case["input"])
                    if isinstance(test_input, tuple):
                        actual_output = exec_globals[func_name](*test_input)
                    else:
                        actual_output = exec_globals[func_name](test_input)
                    
                    expected_output = eval(test_case["expected"]) if test_case["expected"] != "None" else None
                    
                    if actual_output == expected_output:
                        passed += 1
                        results.append({"input": test_case["input"], "expected": test_case["expected"], "actual": str(actual_output), "passed": True})
                    else:
                        failed += 1
                        results.append({"input": test_case["input"], "expected": test_case["expected"], "actual": str(actual_output), "passed": False})
                else:
                    failed += 1
                    results.append({"input": test_case["input"], "expected": test_case["expected"], "actual": "í•¨ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ", "passed": False})
            
            except Exception as e:
                failed += 1
                results.append({"input": test_case["input"], "expected": test_case["expected"], "actual": f"ì˜¤ë¥˜: {str(e)}", "passed": False})
        
        return {
            "passed": passed,
            "failed": failed,
            "total": len(test_cases),
            "details": results
        }
```

## ì‹¤ì œ ì„±ëŠ¥ ê²€ì¦

### ì‹¤í–‰ ê²°ê³¼ ì˜ˆì‹œ

```python
# AIME ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
aime_benchmark = AIMEBenchmark()
aime_results = aime_benchmark.run_benchmark()

print("=== AIME ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ===")
print(f"ì´ ë¬¸ì œ ìˆ˜: {aime_results['total_problems']}")
print(f"ì •ë‹µ ìˆ˜: {aime_results['solved_correctly']}")
print(f"ì •í™•ë„: {aime_results['accuracy']:.2%}")
print(f"í‰ê·  ì†Œìš” ì‹œê°„: {aime_results['average_time']:.2f}ì´ˆ")

# ì½”ë”© ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
coding_benchmark = CodingBenchmark()
coding_results = coding_benchmark.run_benchmark()

print("\n=== ì½”ë”© ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ===")
print(f"ì´ ë¬¸ì œ ìˆ˜: {coding_results['total_problems']}")
print(f"ì •ë‹µ ìˆ˜: {coding_results['solved_correctly']}")
print(f"ì •í™•ë„: {coding_results['accuracy']:.2%}")
print(f"í‰ê·  ì†Œìš” ì‹œê°„: {coding_results['average_time']:.2f}ì´ˆ")
```

## ê²°ë¡ 

**MoonshotAIì˜ Kimi-K1.5**ëŠ” ê°•í™”í•™ìŠµì„ í†µí•´ AI ì¶”ë¡ ì˜ ìƒˆë¡œìš´ ì§€í‰ì„ ì—´ì—ˆìŠµë‹ˆë‹¤. 128k ì»¨í…ìŠ¤íŠ¸ í™•ì¥ê³¼ í˜ì‹ ì ì¸ Long-CoT ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ê¸°ì¡´ ëª¨ë¸ ëŒ€ë¹„ ì••ë„ì ì¸ ì„±ëŠ¥ í–¥ìƒì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

### í•µì‹¬ í˜ì‹  ìš”ì•½

1. **ğŸ”„ ê°•í™”í•™ìŠµ í˜ì‹ **: ë³µì¡í•œ MCTS ì—†ì´ë„ íš¨ê³¼ì ì¸ ì¶”ë¡  ëŠ¥ë ¥ ë‹¬ì„±
2. **ğŸ“ ì»¨í…ìŠ¤íŠ¸ í™•ì¥**: 128k í† í°ìœ¼ë¡œ ì¥ê¸° ì¶”ë¡  ì²´ì¸ ì§€ì›
3. **ğŸ¯ ì„±ëŠ¥ ìš°ìˆ˜ì„±**: ì£¼ìš” ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœëŒ€ 550% ì„±ëŠ¥ í–¥ìƒ
4. **ğŸŒ ë©€í‹°ëª¨ë‹¬ í†µí•©**: í…ìŠ¤íŠ¸ì™€ ë¹„ì „ ë°ì´í„° ê³µë™ í•™ìŠµ
5. **âš¡ ì‹¤ìš©ì  íš¨ìœ¨ì„±**: ì‹¤ì œ ë°°í¬ ê°€ëŠ¥í•œ ìµœì í™”ëœ ì•„í‚¤í…ì²˜

### ë¯¸ë˜ ì „ë§

- **ë²”ìš© ì¶”ë¡  AI**: ë‹¤ì–‘í•œ ë„ë©”ì¸ì—ì„œ ì¸ê°„ ìˆ˜ì¤€ì˜ ì¶”ë¡  ëŠ¥ë ¥ ì œê³µ
- **êµìœ¡ í˜ì‹ **: ê°œì¸ ë§ì¶¤í˜• í•™ìŠµ ë„ìš°ë¯¸ë¡œ í™œìš©
- **ì—°êµ¬ ê°€ì†í™”**: ë³µì¡í•œ ê³¼í•™ì  ë¬¸ì œ í•´ê²° ì§€ì›
- **ì‚°ì—… ì ìš©**: ì „ë¬¸ ë¶„ì•¼ë³„ íŠ¹í™”ëœ ì¶”ë¡  ì‹œìŠ¤í…œ ê°œë°œ

Kimi-K1.5ëŠ” ë‹¨ìˆœí•œ ì„±ëŠ¥ í–¥ìƒì„ ë„˜ì–´, **AIê°€ ì¸ê°„ì²˜ëŸ¼ ì‚¬ê³ í•˜ê³  ì¶”ë¡ í•˜ëŠ” ëŠ¥ë ¥**ì„ í•œ ë‹¨ê³„ ë” ë°œì „ì‹œí‚¨ íšê¸°ì ì¸ ëª¨ë¸ì…ë‹ˆë‹¤. ê°•í™”í•™ìŠµì˜ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì„ ì œì‹œí•˜ë©°, ì•ìœ¼ë¡œ ë”ìš± ì§€ëŠ¥ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” AI ì‹œìŠ¤í…œ ê°œë°œì˜ í† ëŒ€ê°€ ë  ê²ƒì…ë‹ˆë‹¤.

## ì¶”ê°€ ìë£Œ

- [GitHub Repository](https://github.com/MoonshotAI/Kimi-k1.5)
- [Kimi-K1.5 ê¸°ìˆ  ë³´ê³ ì„œ](https://arxiv.org/abs/2501.12599)
- [Kimi ê³µì‹ ì›¹ì‚¬ì´íŠ¸](https://kimi.moonshot.cn/)
- [MoonshotAI ë¸”ë¡œê·¸](https://kimi.moonshot.cn/blog) 