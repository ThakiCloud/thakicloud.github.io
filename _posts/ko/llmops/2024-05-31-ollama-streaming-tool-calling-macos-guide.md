---
title: "Ollama ìŠ¤íŠ¸ë¦¬ë° íˆ´ ì½œë§ ì™„ì „ ê°€ì´ë“œ: macOSì—ì„œ ì‹¤ì‹œê°„ AI ì—ì´ì „íŠ¸ êµ¬ì¶•í•˜ê¸°"
date: 2024-05-31
categories: 
  - llmops
tags: 
  - Ollama
  - íˆ´ì½œë§
  - ìŠ¤íŠ¸ë¦¬ë°
  - macOS
  - ë¡œì»¬AI
  - ì—ì´ì „íŠ¸
  - Python
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
---

Ollamaì˜ ìµœì‹  ì—…ë°ì´íŠ¸ë¡œ ìŠ¤íŠ¸ë¦¬ë°ê³¼ íˆ´ ì½œë§ì´ ë™ì‹œì— ê°€ëŠ¥í•´ì¡ŒìŠµë‹ˆë‹¤. ì´ì œ macOSì—ì„œ ì™„ì „íˆ ë¡œì»¬ í™˜ê²½ìœ¼ë¡œ ì‹¤ì‹œê°„ ëŒ€í™”í˜• AI ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë²ˆ ê¸€ì—ì„œëŠ” ìƒˆë¡œìš´ ê¸°ëŠ¥ë“¤ì„ ì‚´í´ë³´ê³ , ì‹¤ì œ ê°œë°œ í™˜ê²½ì„ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ì•ˆë‚´í•˜ê² ìŠµë‹ˆë‹¤.

## 1. ê¸°ëŠ¥ ì—…ë°ì´íŠ¸ í•œëˆˆì— ë³´ê¸°

### ë¦´ë¦¬ìŠ¤ ì¼ì‹œ

**2025-05-28**

### ì£¼ìš” ë³€í™”

1. **ìŠ¤íŠ¸ë¦¬ë° + íˆ´ ì½œë§**: ì˜¤í”„ë‹ í† í°ë¶€í„° ì‹¤ì‹œê°„ìœ¼ë¡œ í™”ë©´ì— ë‚´ë³´ë‚´ë©´ì„œë„, ì¤‘ê°„ì— ë“±ì¥í•˜ëŠ” JSON íˆ´ ì½œì„ ì¦‰ì‹œ ë¶„ë¦¬í•´ ì²˜ë¦¬í•©ë‹ˆë‹¤. ë” ì´ìƒ "ì‘ë‹µ ëê¹Œì§€ ëŒ€ê¸° â†’ JSON íŒŒì‹± â†’ í•¨ìˆ˜ ì‹¤í–‰" ê°™ì€ ì§€ì—°ì´ ì—†ìŠµë‹ˆë‹¤. ([Ollama Blog](https://ollama.com/blog/streaming-tool))

2. **ì¦ë¶„ íŒŒì„œ**(incremental parser): ëª¨ë¸ì´ íˆ´ ì „ìš© í† í°ì„ ê°–ê³  ìˆë“  ì—†ë“ , ë¶€ë¶„ ì ‘ë‘ì‚¬Â·ìˆœìˆ˜ JSON ë“± ì—¬ëŸ¬ íŒ¨í„´ì„ ì¸ì‹í•´ **ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹¨ì¼ íˆ´ ì½œ**ë¡œ ì¬êµ¬ì„±í•©ë‹ˆë‹¤. ë•ë¶„ì— ìŠ¤íŠ¸ë¦¬ë°ê³¼ íˆ´ ì½œì´ ë‘˜ ë‹¤ ê¹¨ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤. ([Apidog Guide](https://apidog.com/blog/ollama-streaming-responses-and-tool-calling/))

3. **ì§€ì› ëª¨ë¸**: Qwen 3, Devstral, Qwen 2.5 (ë° coder), Llama 3.1, Llama 4 ë“±â€”íˆ´ ì¹´í…Œê³ ë¦¬ë¡œ ë°°í¬ë˜ëŠ” ëª¨ë¸ì€ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

4. **ëŒ€ìš©ëŸ‰ ì»¨í…ìŠ¤íŠ¸** `num_ctx`: 32kê¹Œì§€ ì‹¤í—˜ ì§€ì›â€”ëŒ€ì‹  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë¹„ë¡€í•´ ì¦ê°€í•©ë‹ˆë‹¤.

---

## 2. macOS (M-ì‹œë¦¬ì¦ˆ MacBook) ë¡œì»¬ í™˜ê²½ êµ¬ì¶•

| ë‹¨ê³„     | ëª…ë ¹ / ì‘ì—…                           | ì°¸ê³  ë§í¬                    | ë¹„ê³                                         |
| ------ | --------------------------------- | ------------------------ | ----------------------------------------- |
| ì„¤ì¹˜     | `brew install ollama`             | [Homebrew Formulae](https://formulae.brew.sh/formula/ollama) | Homebrew ë³‘ íŒ¨í‚¤ì§€, Apple Silicon/Intel ëª¨ë‘ ì§€ì› |
| ì„œë¹„ìŠ¤ ì‹œì‘ | `brew services start ollama`      | [Chenzhang Guide](https://chenzhang.org/notes/developer/ollama-macos/) | ë¡œê·¸ì¸ ì‹œ ìë™ ì‹¤í–‰ ê°€ëŠ¥                            |
| ëª¨ë¸ ë°›ê¸°  | `ollama pull llama3.1`            | â€”                        | ì²« ì‹¤í–‰ ì‹œ ìë™ pull ê°€ëŠ¥                         |
| API ì‚¬ìš© | `http://localhost:11434/api/chat` | [Apidog Guide](https://apidog.com/blog/ollama-streaming-responses-and-tool-calling/) | OpenAI í˜¸í™˜ ì—”ë“œí¬ì¸íŠ¸ ì œê³µ                        |

> **í•˜ë“œì›¨ì–´ ê°€ì†**: Apple Metal APIê°€ ê¸°ë³¸ í™œì„±í™”ë˜ì–´ M1~M4 GPUÂ·Neural Engineì„ ìë™ í™œìš©í•©ë‹ˆë‹¤â€”ì¶”ê°€ ì„¤ì • ë¶ˆí•„ìš”. ([Hugging Face Guide](https://huggingface.co/blog/lynn-mikami/how-to-use-ollama))

---

## 3. "ë¡œì»¬ íˆ´ ì½œë§"ìœ¼ë¡œ í•  ìˆ˜ ìˆëŠ” ì¼

| ì‹œë‚˜ë¦¬ì˜¤            | ìš”ì•½                                                                          |
| --------------- | --------------------------------------------------------------------------- |
| **CLI/ì‹œìŠ¤í…œ ìë™í™”** | ë¡œì»¬ Python í•¨ìˆ˜ ë˜ëŠ” shell scriptë¥¼ íˆ´ë¡œ ë…¸ì¶œ â†’ ëª¨ë¸ì´ íŒŒì¼ ì •ë¦¬Â·Git ì»¤ë°‹Â·í™ˆ ì˜¤í† ë©”ì´ì…˜ ê°™ì€ ëª…ë ¹ì„ ì§ì ‘ ì‹¤í–‰ |
| **VS Code í™•ì¥**  | Ollama APIë¥¼ ìµìŠ¤í…ì…˜ì—ì„œ í˜¸ì¶œí•´ LLM-ì½”íŒŒì¼ëŸ¿ êµ¬í˜„ + ë¡œì»¬ í•¨ìˆ˜(ì˜ˆ: AST ë¦¬íŒ©í„°) ì—°ë™                   |
| **í”„ë¼ì´ë¹— RAG**    | MacBook SSDì— ìˆëŠ” PDF/CSVë¥¼ Python íˆ´ë¡œ ë¡œë“œ â†’ LLMì´ ì¦‰ì‹œ ê²€ìƒ‰Â·ìš”ì•½â€”í´ë¼ìš°ë“œ ì—…ë¡œë“œ ç„¡            |
| **ì›¹/ëª¨ë°”ì¼ í”„ë¡œí† íƒ€ì…** | Next.jsÂ·Electron ì•±ì—ì„œ WebSocket + íˆ´ ì½œ ì‚¬ìš© â†’ ì‚¬ìš©ìì—ê²Œ ì‹¤ì‹œê°„ í† í° ìŠ¤íŠ¸ë¦¼ & ë¶€ë¶„ UI ì¦‰ì‹œ ì—…ë°ì´íŠ¸  |
| **ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œ**   | ë‹¤ì¤‘ íˆ´(ì›¹ ìŠ¤í¬ë˜í•‘, ê³„ì‚°ê¸°, DB ì¿¼ë¦¬)ì„ ë“±ë¡ â†’ ëª¨ë¸ì´ ê³„íš-ì‹¤í–‰-í”¼ë“œë°± ë£¨í”„ë¥¼ ì „ë¶€ ë¡œì»¬ì—ì„œ ìˆ˜í–‰                 |

---

## 4. ê°œë°œì ê´€ì  ì£¼ìš” ì´ë“

| í•­ëª©         | ë³€í™” ì „                            | ë³€í™” í›„                                   |
| ---------- | ------------------------------- | -------------------------------------- |
| **ì‘ë‹µ ì§€ì—°**  | íˆ´ ì½œ í¬í•¨ ë©”ì‹œì§€ëŠ” ì „ì²´ JSON íŒŒì‹± ì™„ë£Œê¹Œì§€ ë¸”ë¡œí‚¹ | í† í° ìŠ¤íŠ¸ë¦¼ ì¦‰ì‹œ ì¶œë ¥, íˆ´ ì½œë§Œ ë¶„ë¦¬ë˜ì–´ ë³„ë„ íŠ¸ë¦¬ê±°         |
| **ìƒíƒœ ê´€ë¦¬**  | "íˆ´ ì½œì¸ì§€, ì¼ë°˜ í…ìŠ¤íŠ¸ì¸ì§€" í›„ì²˜ë¦¬ í•„ìš”        | íŒŒì„œê°€ **tool_calls í•„ë“œ**ë¡œ ë°˜í™˜ â†’ ì½”ë“œ ë‹¨ìˆœí™”    |
| **ëª¨ë¸ í˜¸í™˜ì„±** | íˆ´ ì½œ ë¯¸í•™ìŠµ ëª¨ë¸ì€ ì‹¤íŒ¨í•˜ê±°ë‚˜ JSON ê¹¨ì§       | íŒŒì„œê°€ JSONë§Œ ë³´ê³ ë„ ì¸ì‹ â†’ ë” ë§ì€ ì˜¤í”ˆëª¨ë¸ ì‚¬ìš©       |
| **ë§¥ë¶ ë¦¬ì†ŒìŠ¤** | ê¸´ ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš© ì œì•½                    | `num_ctx=32000` ê°€ëŠ¥(ë©”ëª¨ë¦¬â†‘) â†’ RAG ê¸´ ë¬¸ì„œ ì²˜ë¦¬ |

---

## 5. ì‹¤ë¬´ TIP

### 1. ë©”ëª¨ë¦¬ ìµœì í™”

32k ì»¨í…ìŠ¤íŠ¸ëŠ” 7B ëª¨ë¸ë„ 12GB+ RAMì„ ìš”êµ¬í•©ë‹ˆë‹¤. í•„ìš” ì‹œ 16kë‚˜ 8kë¡œ ì¡°ì •í•˜ì„¸ìš”.

### 2. íˆ´ ë²„ì „ ê´€ë¦¬

Python/JS í•¨ìˆ˜ ì„œëª…ì„ ë²„ì „ ì»¨íŠ¸ë¡¤ì— ì €ì¥í•´ ëª¨ë¸ ì—…ê·¸ë ˆì´ë“œ ì‹œ í˜¸í™˜ì„±ì„ ì²´í¬í•˜ì„¸ìš”.

### 3. ë³´ì•ˆ

ë¡œì»¬ í•¨ìˆ˜ê°€ íŒŒì¼ ì‚­ì œÂ·ë„¤íŠ¸ì›Œí¬ í˜¸ì¶œì„ í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì¸ìˆ˜ ê²€ì¦Â·ê¶Œí•œ ê²©ë¦¬ê°€ í•„ìˆ˜ì…ë‹ˆë‹¤.

### 4. ë©€í‹°-GPU/Metal

Dockerì—ì„œëŠ” Metal íŒ¨ìŠ¤-ìŠ¤ë£¨ê°€ ì œí•œì â€”ë„¤ì´í‹°ë¸Œ ì‹¤í–‰ì„ ê¶Œì¥í•©ë‹ˆë‹¤. ([Chariot Solutions](https://chariotsolutions.com/blog/post/apple-silicon-gpus-docker-and-ollama-pick-two/))

---

## 6. ì•ìœ¼ë¡œ ê¸°ëŒ€í•  ì  (ê´€ì¸¡Â·ì¶”ì •)

- **íˆ´ ë§ˆì¼“í”Œë ˆì´ìŠ¤**: ëª…ë ¹ì–´-ì„œëª…ë§Œ ê³µìœ í•´ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ "ë¡œì»¬ í”ŒëŸ¬ê·¸ì¸" ìƒíƒœê³„ê°€ ë¹ ë¥´ê²Œ í™•ëŒ€ë  ê°€ëŠ¥ì„±
- **ìŠ¤íŠ¸ë¦¬ë° UI ì»´í¬ë„ŒíŠ¸**: React/SwiftUIì—ì„œ í† í° ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¼ì„ í‘œì‹œí•˜ëŠ” OSS ì»´í¬ë„ŒíŠ¸ê°€ í‘œì¤€í™”ë  ì „ë§
- **Agent í”„ë ˆì„ì›Œí¬**: LangChain-JS, CrewAI ë“±ì´ `ollama://` í”„ë¡œí† ì½œì„ ì§€ì›í•˜ì—¬ ì™„ì „ ì˜¤í”„ë¼ì¸ ì—ì´ì „íŠ¸ êµ¬ì¶•ì´ ì‰¬ì›Œì§ˆ ê²ƒ

---

## ì‹¤ì „ ì˜ˆì œ: 10ë¶„ ë§Œì— ì™„ì„±í•˜ëŠ” ìŠ¤íŠ¸ë¦¬ë° AI ì—ì´ì „íŠ¸

ì•„ë˜ ì˜ˆì‹œëŠ” **"MacBook í•˜ë‚˜ë§Œìœ¼ë¡œ ì‹¤ì‹œê°„ ëŒ€í™” + ì‹¤ì‹œê°„ í•¨ìˆ˜ í˜¸ì¶œ"**ì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆëŠ” **ê°€ì¥ ì‹¤ì „-ì§€í–¥ì ì¸ ìµœì†Œ ì˜ˆì œ**ì…ë‹ˆë‹¤. *10ë¶„ ë‚´ì— ë¡œì»¬ì—ì„œ ëŒì•„ê°€ëŠ” í’€ìŠ¤íƒ LLM ì‹¤í—˜ í™˜ê²½*ì´ ì™„ì„±ë©ë‹ˆë‹¤.

### 1. ì‚¬ì „ ì¤€ë¹„

```bash
# 1) Ollama ì„¤ì¹˜ (Homebrew)
brew install ollama
brew services start ollama     # ë°±ê·¸ë¼ìš´ë“œ ì„œë¹„ìŠ¤ ë“±ë¡

# 2) Python íŒ¨í‚¤ì§€
python -m venv .venv && source .venv/bin/activate
pip install -U ollama rich
```

> **ëª¨ë¸ ë‹¤ìš´ë¡œë“œ**
>
> ```bash
> ollama pull qwen3     # ì˜ˆì‹œ; llama3.1, devstral ë“± ì§€ì› ëª¨ë¸ì´ë©´ ì•„ë¬´ê±°ë‚˜ ê°€ëŠ¥
> ```

### 2. "ê°œë°œìì—ê²Œ ê°€ì¥ ìœ ìš©í•œ" íŒŒì´ì¬ íˆ´: **repo_stats**

- **ë¬´ì—‡ì„ í•˜ë‚˜ìš”?**
  ì§€ì •í•œ ë””ë ‰í„°ë¦¬(ê¸°ë³¸: í˜„ì¬ Git ë¦¬í¬ì§€í† ë¦¬)ë¥¼ ìŠ¤ìº”í•´ **ì–¸ì–´ë³„ ì½”ë“œ ë¼ì¸ ìˆ˜** í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
- **ì™œ ìœ ìš©í•œê°€ìš”?**
  LLMì´ ë‚´ í”„ë¡œì íŠ¸ ê·œëª¨Â·ì–¸ì–´ ë¹„ì¤‘ì„ ì‹¤ì‹œê°„ íŒŒì•…â†’ì»¨ë²¤ì…˜ ì¶”ì²œ, ë¹Œë“œ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±, ë¦¬íŒ©í„°ë§ ê³„íš ë“± ì˜ì‚¬ê²°ì •ì— ë°”ë¡œ í™œìš©.

### 3. ì „ì²´ ì½”ë“œ (`llm_agent.py`)

```python
#!/usr/bin/env python
"""
ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° + íˆ´ ì½œë§ ë°ëª¨ (MacBook ì „ìš©, Ollama + Python SDK)
"""
import os, pathlib, subprocess, json, sys
from typing import Dict
from ollama import chat, ChatResponse
from rich import print

# --------------------------- íˆ´ ì •ì˜ --------------------------- #
def repo_stats(path: str = ".") -> Dict[str, int]:
    """
    Scan a directory recurisvely and return lines-of-code per extension.

    Args:
        path (str): directory to scan, default '.'

    Returns:
        dict: {'.py': 1234, '.js': 567, ...}
    """
    path = pathlib.Path(path).expanduser().resolve()
    if not path.is_dir():
        raise FileNotFoundError(f"{path} is not a directory")

    stats: Dict[str, int] = {}
    for p in path.rglob("*"):
        if p.is_file():
            ext = p.suffix.lower()
            try:
                lines = sum(1 for _ in p.open("r", errors="ignore"))
            except Exception:
                continue
            stats[ext] = stats.get(ext, 0) + lines
    return stats

# ------------------------ ëŒ€í™” ë£¨í”„ --------------------------- #
SYSTEM = "You are a senior software engineer. You call tools when helpful."

def main():
    print("[bold green]ğŸ¦™  LLM + Tool streaming demo (Ctrl-C to quit)[/bold green]")
    messages = [{"role": "system", "content": SYSTEM}]

    while True:
        user_input = input("\n[USER] â€º  ")
        messages.append({"role": "user", "content": user_input})

        # ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ
        response: ChatResponse = chat(
            model="qwen3",
            messages=messages,
            tools=[repo_stats],   # í•¨ìˆ˜ ê°ì²´ ê·¸ëŒ€ë¡œ ì „ë‹¬
            stream=True,
        )

        tool_results = {}
        for chunk in response:
            # â‘  ëª¨ë¸ì´ í…ìŠ¤íŠ¸ ìƒì„± ì¤‘ì´ë©´ ë°”ë¡œ ì¶œë ¥
            if chunk.message.content:
                print(chunk.message.content, end="", flush=True)

            # â‘¡ tool_calls í•„ë“œê°€ ìˆìœ¼ë©´ ì¦‰ì‹œ ì‹¤í–‰
            for call in chunk.message.tool_calls or []:
                func_name = call.function.name
                args = call.function.arguments or {}
                if func_name == "repo_stats":
                    try:
                        result = repo_stats(**args)
                        # ê²°ê³¼ë¥¼ LLMì—ê²Œ í”¼ë“œë°±
                        messages.append({
                            "role": "tool",
                            "name": func_name,
                            "content": json.dumps(result)
                        })
                        tool_results[func_name] = result
                    except Exception as e:
                        messages.append({
                            "role": "tool",
                            "name": func_name,
                            "content": str(e)
                        })
        print()  # ì¤„ë°”ê¿ˆ
        if tool_results:
            print(f"[italic]â†³ repo_stats returned:[/italic] {tool_results['repo_stats']}")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n[bold red]Session ended.[/bold red]")
```

### ì‹¤í–‰

```bash
python llm_agent.py
```

1. **í”„ë¡¬í”„íŠ¸ ì…ë ¥**:
   `ìš°ë¦¬ ì½”ë“œë² ì´ìŠ¤ ì–¼ë§ˆë‚˜ í°ì§€ ì•Œë ¤ì¤˜. ì–¸ì–´ë³„ í†µê³„ë¥¼ ë³´ê³  ì‹¶ì–´.`
2. **ìŠ¤íŠ¸ë¦¼**:
   - ëª¨ë¸ í† í°ì´ ì¦‰ì‹œ ì½˜ì†”ì— íë¥´ê³ 
   - ì¤‘ê°„ì— `[ToolCall] repo_stats {"path": "."}` ê°€ ê°ì§€ë˜ë©´ íŒŒì´ì¬ í•¨ìˆ˜ ì¦‰ì‹œ ì‹¤í–‰
3. **ê²°ê³¼ í”¼ë“œë°±**:
   - `repo_stats` ê²°ê³¼ JSONì„ ë‹¤ì‹œ ëª¨ë¸ì—ê²Œ ë„˜ê²¨ ë‹¤ìŒ ì‘ë‹µì— í™œìš©
   - ëª¨ë¸ì´ "Python 68%, JavaScript 20%, ê¸°íƒ€ 12%â€¦" ì‹ìœ¼ë¡œ í•´ì„í•´ ì•ˆë‚´

---

## í™•ì¥ ì•„ì´ë””ì–´

| ê¸°ëŠ¥             | ê°„ë‹¨ ë°©ë²•                                                            |
| -------------- | ---------------------------------------------------------------- |
| **CI ìë™í™”**     | `run_tests()` ë‚˜ `build_docker()` í•¨ìˆ˜ë¥¼ íˆ´ë¡œ ë…¸ì¶œ                       |
| **í”„ë¼ì´ë¹— RAG**   | `lookup_file(path:str, query:str)` ë¡œ PDF/MD ê²€ìƒ‰Â·ìš”ì•½                |
| **ì½”ë“œ ë³€í™˜Â·ë¦¬íŒ©í„°ë§** | `apply_patch(file:str, diff:str)` ë¡œ ëª¨ë¸ì´ ì§ì ‘ `git apply`           |
| **GUI/Web**    | FastAPI + `async for chunk in chat(stream=True)` â†’ SSE/WebSocket |

---

## ì„±ëŠ¥Â·ë³´ì•ˆ íŒ

### 1. ë©”ëª¨ë¦¬ ì¡°ì ˆ

`OLLAMA_NUM_CTX` í™˜ê²½ë³€ìˆ˜(ë˜ëŠ” `options={"num_ctx": 16000}`)ë¡œ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ íŠœë‹.

### 2. ê¶Œí•œ ê²©ë¦¬

ìœ„í—˜ ëª…ë ¹ì€ wrapper í•¨ìˆ˜ì—ì„œ *í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸*ë§Œ í—ˆìš©.

### 3. ë©”íƒˆ ê°€ì† í™•ì¸

`ollama --version` ì¶œë ¥ì— `metal: enabled` í‘œì‹œ â†’ GPUÂ·Neural Engine ì‚¬ìš© ì¤‘.

### 4. íŒ¨í‚¤ì§€ ê´€ë¦¬

íˆ´ í•¨ìˆ˜ëŠ” **ë²„ì „ ê´€ë¦¬**(git) & **íƒ€ì´í•‘** í•„ìˆ˜â€”LLMì´ ì‹œê·¸ë‹ˆì²˜ë¥¼ ì‹ ë¢°.

---

## ë§ˆë¬´ë¦¬

**ìš”ì•½** â€” ì´ë²ˆ ì—…ë°ì´íŠ¸ë¡œ MacBook í•˜ë‚˜ë§Œìœ¼ë¡œë„ "ì‹¤ì‹œê°„ ëŒ€í™” + ì‹¤ì‹œê°„ í•¨ìˆ˜ í˜¸ì¶œ"ì´ ê°€ëŠ¥í•œ í’€ìŠ¤íƒ LLM ì‹¤í—˜ í™˜ê²½ì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. Homebrew í•œ ì¤„ë¡œ ì„¤ì¹˜í•˜ê³ , Python í˜¹ì€ JavaScriptì—ì„œ í•¨ìˆ˜ë§Œ ì •ì˜í•˜ë©´ ê³§ë°”ë¡œ **ìŠ¤íŠ¸ë¦¬ë° ëŒ€í™”í˜• ì—ì´ì „íŠ¸**ë¥¼ ë¡œì»¬ì—ì„œ êµ¬ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ìœ„ `llm_agent.py` í•˜ë‚˜ë©´ **"í† í° ìŠ¤íŠ¸ë¦¬ë° â†” íŒŒì´ì¬ í•¨ìˆ˜ í˜¸ì¶œ â†” ê²°ê³¼ í”¼ë“œë°±"** ì „ì²´ ì‚¬ì´í´ì„ ë§¥ë¶ ë¡œì»¬ì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ì²´í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•„ìš”ì— ë”°ë¼ í•¨ìˆ˜ë§Œ ì¶”ê°€í•´ ë‚˜ê°€ë©´, ê³§ë°”ë¡œ ê°œë°œ ì›Œí¬í”Œë¡œ ì „ì²´ë¥¼ LLM-ì—ì´ì „íŠ¸í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¦ê±°ìš´ ì‹¤í—˜ ë˜ì„¸ìš”! ğŸ‰
