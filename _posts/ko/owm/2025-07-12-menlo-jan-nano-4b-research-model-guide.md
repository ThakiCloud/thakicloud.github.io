---
title: "Menlo Jan-nano 4B: MCP í†µí•© íŠ¹í™” ì—°êµ¬ ëª¨ë¸ ì™„ì „ ê°€ì´ë“œ"
excerpt: "Model Context Protocol ì„œë²„ í†µí•©ì— ìµœì í™”ëœ 4B íŒŒë¼ë¯¸í„° Jan-nano ëª¨ë¸ì˜ ì—°êµ¬ í™œìš©ë²•ê³¼ ë¡œì»¬ ë°°í¬ ê°€ì´ë“œ"
seo_title: "Menlo Jan-nano 4B MCP í†µí•© ì—°êµ¬ ëª¨ë¸ ê°€ì´ë“œ - Thaki Cloud"
seo_description: "MCP ì„œë²„ í†µí•©ê³¼ ì—°êµ¬ ì‘ì—…ì— íŠ¹í™”ëœ Jan-nano 4B ëª¨ë¸ì˜ ì™„ì „í•œ êµ¬í˜„ ê°€ì´ë“œì™€ SimpleQA ë²¤ì¹˜ë§ˆí¬ ì„±ëŠ¥ ë¶„ì„"
date: 2025-07-12
last_modified_at: 2025-07-12
categories:
  - owm
tags:
  - Menlo
  - Jan-nano
  - 4B-ëª¨ë¸
  - MCP
  - ì—°êµ¬-ëª¨ë¸
  - SimpleQA
  - ë¡œì»¬-ë°°í¬
  - ì»´íŒ©íŠ¸-ëª¨ë¸
  - ì—°êµ¬-ë„êµ¬
  - íš¨ìœ¨ì„±
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
toc_icon: "cog"
toc_sticky: true
canonical_url: "https://thakicloud.github.io/owm/menlo-jan-nano-4b-research-model-guide/"
reading_time: true
---

â±ï¸ **ì˜ˆìƒ ì½ê¸° ì‹œê°„**: 18ë¶„

## ì„œë¡ 

**Menloì˜ Jan-nano**ëŠ” 4B íŒŒë¼ë¯¸í„°ì˜ ì»´íŒ©íŠ¸í•œ ì–¸ì–´ ëª¨ë¸ë¡œ, **ê¹Šì´ ìˆëŠ” ì—°êµ¬ ì‘ì—…**ê³¼ **Model Context Protocol(MCP) ì„œë²„ í†µí•©**ì— íŠ¹í™”ë˜ì–´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. Qwen3-4Bë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ íš¨ìœ¨ì ì¸ ì—°êµ¬ í™˜ê²½ì„ ì œê³µí•˜ë©°, **SimpleQA ë²¤ì¹˜ë§ˆí¬**ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

## í•µì‹¬ íŠ¹ì§•

### 1. ì—°êµ¬ íŠ¹í™” ì„¤ê³„

**ì£¼ìš” ì„±ëŠ¥ ì§€í‘œ:**
- **ëª¨ë¸ í¬ê¸°**: 4B íŒŒë¼ë¯¸í„° (ì»´íŒ©íŠ¸ ì„¤ê³„)
- **ê¸°ë°˜ ëª¨ë¸**: Qwen3-4B-Base
- **íŠ¹í™” ë¶„ì•¼**: ê¹Šì´ ìˆëŠ” ì—°êµ¬ ì‘ì—…
- **í†µí•© ê¸°ëŠ¥**: MCP ì„œë²„ ë„¤ì´í‹°ë¸Œ ì§€ì›

### 2. MCP ì„œë²„ í†µí•© ìµœì í™”

```python
# Jan-nano MCP í†µí•© ê¸°ë³¸ ì„¤ì •
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
import json

class JanNanoMCPModel:
    def __init__(self, model_path="Menlo/Jan-nano"):
        self.model_path = model_path
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.mcp_config = {
            "enabled": True,
            "servers": [],
            "tool_integration": True
        }
        self.load_model()
        
    def load_model(self):
        """ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ"""
        self.model = AutoModelForCausalLM.from_pretrained(
            self.model_path,
            torch_dtype=torch.bfloat16,
            device_map="auto"
        )
        
        self.tokenizer = AutoTokenizer.from_pretrained(
            self.model_path
        )
        
        # MCP ì„œë²„ ì´ˆê¸°í™”
        self.initialize_mcp_servers()
        
    def initialize_mcp_servers(self):
        """MCP ì„œë²„ ì´ˆê¸°í™”"""
        self.mcp_servers = {
            "research_tools": {
                "enabled": True,
                "endpoints": [
                    "arxiv_search",
                    "paper_analysis",
                    "citation_tracking"
                ]
            },
            "data_sources": {
                "enabled": True,
                "endpoints": [
                    "dataset_search",
                    "data_validation",
                    "statistical_analysis"
                ]
            }
        }
        
    def generate_research_response(self, query, max_tokens=512, temperature=0.7):
        """ì—°êµ¬ íŠ¹í™” ì‘ë‹µ ìƒì„±"""
        # ì—°êµ¬ ì»¨í…ìŠ¤íŠ¸ ìµœì í™”ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = """You are a specialized research assistant optimized for deep research tasks. 
        You have access to various research tools and data sources through MCP servers. 
        Provide thorough, well-researched responses with proper citations and analysis."""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": query}
        ]
        
        # ì±„íŒ… í…œí”Œë¦¿ ì ìš©
        text = self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )
        
        # ì…ë ¥ í† í°í™”
        model_inputs = self.tokenizer([text], return_tensors="pt").to(self.device)
        
        # ì¶”ë¡  ì‹¤í–‰
        with torch.no_grad():
            generated_ids = self.model.generate(
                **model_inputs,
                max_new_tokens=max_tokens,
                temperature=temperature,
                top_p=0.8,
                top_k=20,
                do_sample=True,
                pad_token_id=self.tokenizer.eos_token_id
            )
        
        # ì‘ë‹µ ë””ì½”ë”©
        generated_ids = [
            output_ids[len(input_ids):] 
            for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
        ]
        
        response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
        return response
```

### 3. SimpleQA ë²¤ì¹˜ë§ˆí¬ ì„±ëŠ¥

Jan-nanoëŠ” **SimpleQA ë²¤ì¹˜ë§ˆí¬**ì—ì„œ MCP ê¸°ë°˜ í‰ê°€ ë°©ë²•ë¡ ì„ í†µí•´ ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤:

```python
class SimpleQABenchmark:
    def __init__(self, jan_nano_model):
        self.model = jan_nano_model
        self.benchmark_tasks = [
            "factual_accuracy",
            "reasoning_capability", 
            "research_integration",
            "tool_usage_efficiency"
        ]
        
    def run_benchmark(self, test_cases):
        """SimpleQA ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        results = {
            "total_tasks": len(test_cases),
            "completed_tasks": 0,
            "accuracy_scores": [],
            "reasoning_scores": [],
            "tool_integration_scores": []
        }
        
        for case in test_cases:
            try:
                # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰
                response = self.model.generate_research_response(
                    case["query"],
                    max_tokens=case.get("max_tokens", 512)
                )
                
                # ì ìˆ˜ ê³„ì‚°
                accuracy = self.evaluate_accuracy(response, case["expected"])
                reasoning = self.evaluate_reasoning(response, case["complexity"])
                tool_usage = self.evaluate_tool_integration(response)
                
                results["accuracy_scores"].append(accuracy)
                results["reasoning_scores"].append(reasoning)
                results["tool_integration_scores"].append(tool_usage)
                results["completed_tasks"] += 1
                
            except Exception as e:
                print(f"í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                
        # í‰ê·  ì ìˆ˜ ê³„ì‚°
        results["average_accuracy"] = sum(results["accuracy_scores"]) / len(results["accuracy_scores"])
        results["average_reasoning"] = sum(results["reasoning_scores"]) / len(results["reasoning_scores"])
        results["average_tool_integration"] = sum(results["tool_integration_scores"]) / len(results["tool_integration_scores"])
        
        return results
    
    def evaluate_accuracy(self, response, expected):
        """ì •í™•ë„ í‰ê°€"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ì •êµí•œ í‰ê°€ ë¡œì§ í•„ìš”
        common_words = set(response.lower().split()) & set(expected.lower().split())
        return len(common_words) / len(set(expected.lower().split()))
    
    def evaluate_reasoning(self, response, complexity_level):
        """ì¶”ë¡  ëŠ¥ë ¥ í‰ê°€"""
        reasoning_indicators = [
            "because", "therefore", "however", "analysis", "conclude",
            "evidence", "based on", "considering", "according to"
        ]
        
        reasoning_count = sum(1 for indicator in reasoning_indicators if indicator in response.lower())
        return min(reasoning_count / complexity_level, 1.0)
    
    def evaluate_tool_integration(self, response):
        """ë„êµ¬ í†µí•© í‰ê°€"""
        tool_indicators = [
            "research", "data", "source", "reference", "study",
            "analysis", "findings", "according to"
        ]
        
        tool_count = sum(1 for indicator in tool_indicators if indicator in response.lower())
        return min(tool_count / 5, 1.0)
```

## MCP ì„œë²„ í†µí•© ì‹œìŠ¤í…œ

### 1. ì—°êµ¬ ë„êµ¬ í†µí•©

```python
class ResearchToolsIntegration:
    def __init__(self, jan_nano_model):
        self.model = jan_nano_model
        self.research_tools = {
            "arxiv": ArxivSearchTool(),
            "google_scholar": GoogleScholarTool(),
            "semantic_scholar": SemanticScholarTool(),
            "pubmed": PubMedTool()
        }
        
    def search_papers(self, query, max_results=10):
        """ë…¼ë¬¸ ê²€ìƒ‰"""
        all_results = []
        
        for tool_name, tool in self.research_tools.items():
            try:
                results = tool.search(query, max_results=max_results//len(self.research_tools))
                for result in results:
                    result["source"] = tool_name
                all_results.extend(results)
            except Exception as e:
                print(f"{tool_name} ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                
        return all_results
    
    def analyze_paper(self, paper_url):
        """ë…¼ë¬¸ ë¶„ì„"""
        analysis_prompt = f"""
        ë‹¤ìŒ ë…¼ë¬¸ì„ ë¶„ì„í•´ì£¼ì„¸ìš”: {paper_url}
        
        ë¶„ì„ í•­ëª©:
        1. ì£¼ìš” ê¸°ì—¬ë„
        2. ë°©ë²•ë¡  ìš”ì•½
        3. ì‹¤í—˜ ê²°ê³¼
        4. í•œê³„ì 
        5. í–¥í›„ ì—°êµ¬ ë°©í–¥
        """
        
        analysis = self.model.generate_research_response(
            analysis_prompt,
            max_tokens=1000,
            temperature=0.3
        )
        
        return {
            "paper_url": paper_url,
            "analysis": analysis,
            "timestamp": datetime.now().isoformat()
        }
    
    def generate_literature_review(self, topic, papers_list):
        """ë¬¸í—Œ ë¦¬ë·° ìƒì„±"""
        papers_summary = "\n".join([
            f"- {paper['title']} ({paper['authors']}, {paper['year']}): {paper['abstract'][:200]}..."
            for paper in papers_list
        ])
        
        review_prompt = f"""
        ì£¼ì œ: {topic}
        
        ê´€ë ¨ ë…¼ë¬¸ë“¤:
        {papers_summary}
        
        ì´ ë…¼ë¬¸ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ í¬ê´„ì ì¸ ë¬¸í—Œ ë¦¬ë·°ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
        í¬í•¨ ì‚¬í•­:
        1. ì—°êµ¬ ë¶„ì•¼ í˜„í™©
        2. ì£¼ìš” ë°©ë²•ë¡ ë“¤
        3. íŠ¸ë Œë“œ ë¶„ì„
        4. ì—°êµ¬ ê³µë°± ë° í–¥í›„ ë°©í–¥
        """
        
        review = self.model.generate_research_response(
            review_prompt,
            max_tokens=1500,
            temperature=0.4
        )
        
        return review

class ArxivSearchTool:
    def __init__(self):
        self.base_url = "http://export.arxiv.org/api/query"
        
    def search(self, query, max_results=10):
        """ArXiv ê²€ìƒ‰"""
        import urllib.parse
        import urllib.request
        import xml.etree.ElementTree as ET
        
        # ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
        search_query = urllib.parse.quote(query)
        url = f"{self.base_url}?search_query=all:{search_query}&max_results={max_results}"
        
        try:
            with urllib.request.urlopen(url) as response:
                xml_data = response.read()
                
            root = ET.fromstring(xml_data)
            results = []
            
            for entry in root.findall('.//{http://www.w3.org/2005/Atom}entry'):
                title = entry.find('{http://www.w3.org/2005/Atom}title').text
                authors = [author.find('{http://www.w3.org/2005/Atom}name').text 
                          for author in entry.findall('.//{http://www.w3.org/2005/Atom}author')]
                abstract = entry.find('{http://www.w3.org/2005/Atom}summary').text
                url = entry.find('{http://www.w3.org/2005/Atom}id').text
                
                results.append({
                    "title": title.strip(),
                    "authors": authors,
                    "abstract": abstract.strip(),
                    "url": url,
                    "source": "arxiv"
                })
                
            return results
            
        except Exception as e:
            print(f"ArXiv ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
```

### 2. ë°ì´í„° ì†ŒìŠ¤ í†µí•©

```python
class DataSourceIntegration:
    def __init__(self, jan_nano_model):
        self.model = jan_nano_model
        self.data_sources = {
            "huggingface": HuggingFaceDatasets(),
            "kaggle": KaggleDatasets(),
            "github": GitHubDatasets(),
            "academic": AcademicDatasets()
        }
        
    def search_datasets(self, query, domain=None):
        """ë°ì´í„°ì…‹ ê²€ìƒ‰"""
        all_datasets = []
        
        for source_name, source in self.data_sources.items():
            try:
                if domain and not source.supports_domain(domain):
                    continue
                    
                datasets = source.search(query)
                for dataset in datasets:
                    dataset["source"] = source_name
                all_datasets.extend(datasets)
                
            except Exception as e:
                print(f"{source_name} ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                
        return all_datasets
    
    def analyze_dataset(self, dataset_info):
        """ë°ì´í„°ì…‹ ë¶„ì„"""
        analysis_prompt = f"""
        ë‹¤ìŒ ë°ì´í„°ì…‹ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
        
        ì´ë¦„: {dataset_info['name']}
        ì„¤ëª…: {dataset_info['description']}
        í¬ê¸°: {dataset_info.get('size', 'Unknown')}
        í˜•ì‹: {dataset_info.get('format', 'Unknown')}
        
        ë¶„ì„ í•­ëª©:
        1. ë°ì´í„°ì…‹ í’ˆì§ˆ í‰ê°€
        2. ì—°êµ¬ í™œìš© ê°€ëŠ¥ì„±
        3. ì „ì²˜ë¦¬ í•„ìš”ì‚¬í•­
        4. ì ì¬ì  í¸í–¥ì„±
        5. ì‚¬ìš© ì‹œ ì£¼ì˜ì‚¬í•­
        """
        
        analysis = self.model.generate_research_response(
            analysis_prompt,
            max_tokens=800,
            temperature=0.3
        )
        
        return {
            "dataset_info": dataset_info,
            "analysis": analysis,
            "timestamp": datetime.now().isoformat()
        }
    
    def recommend_datasets(self, research_topic):
        """ì—°êµ¬ ì£¼ì œì— ë§ëŠ” ë°ì´í„°ì…‹ ì¶”ì²œ"""
        recommendation_prompt = f"""
        ì—°êµ¬ ì£¼ì œ: {research_topic}
        
        ì´ ì—°êµ¬ ì£¼ì œì— ì í•©í•œ ë°ì´í„°ì…‹ ìœ í˜•ê³¼ íŠ¹ì„±ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.
        í¬í•¨ ì‚¬í•­:
        1. í•„ìš”í•œ ë°ì´í„° ìœ í˜•
        2. ë°ì´í„° í¬ê¸° ìš”êµ¬ì‚¬í•­
        3. í’ˆì§ˆ ê¸°ì¤€
        4. ë¼ì´ì„ ìŠ¤ ê³ ë ¤ì‚¬í•­
        5. êµ¬ì²´ì ì¸ ë°ì´í„°ì…‹ ì¶”ì²œ
        """
        
        recommendations = self.model.generate_research_response(
            recommendation_prompt,
            max_tokens=1000,
            temperature=0.4
        )
        
        return recommendations
```

## ì‹¤ì „ ì—°êµ¬ í™œìš© ì˜ˆì œ

### 1. ì¢…í•© ì—°êµ¬ íŒŒì´í”„ë¼ì¸

```python
import datetime
import json

class ComprehensiveResearchPipeline:
    def __init__(self):
        self.jan_nano = JanNanoMCPModel()
        self.research_tools = ResearchToolsIntegration(self.jan_nano)
        self.data_sources = DataSourceIntegration(self.jan_nano)
        self.benchmark = SimpleQABenchmark(self.jan_nano)
        
    def conduct_research(self, research_topic, depth_level="comprehensive"):
        """ì¢…í•© ì—°êµ¬ ìˆ˜í–‰"""
        print(f"ğŸ” ì—°êµ¬ ì£¼ì œ: {research_topic}")
        print(f"ğŸ“Š ì—°êµ¬ ê¹Šì´: {depth_level}")
        
        research_results = {
            "topic": research_topic,
            "timestamp": datetime.datetime.now().isoformat(),
            "depth_level": depth_level,
            "results": {}
        }
        
        # 1. ë¬¸í—Œ ê²€ìƒ‰
        print("ğŸ“š ë¬¸í—Œ ê²€ìƒ‰ ì¤‘...")
        papers = self.research_tools.search_papers(research_topic, max_results=20)
        research_results["results"]["papers"] = papers
        
        # 2. ë°ì´í„°ì…‹ ê²€ìƒ‰
        print("ğŸ—„ï¸ ë°ì´í„°ì…‹ ê²€ìƒ‰ ì¤‘...")
        datasets = self.data_sources.search_datasets(research_topic)
        research_results["results"]["datasets"] = datasets
        
        # 3. ë¬¸í—Œ ë¦¬ë·° ìƒì„±
        print("ğŸ“ ë¬¸í—Œ ë¦¬ë·° ìƒì„± ì¤‘...")
        literature_review = self.research_tools.generate_literature_review(
            research_topic, 
            papers[:10]  # ìƒìœ„ 10ê°œ ë…¼ë¬¸ ì‚¬ìš©
        )
        research_results["results"]["literature_review"] = literature_review
        
        # 4. ì—°êµ¬ ê³„íš ìƒì„±
        print("ğŸ¯ ì—°êµ¬ ê³„íš ìƒì„± ì¤‘...")
        research_plan = self.generate_research_plan(research_topic, papers, datasets)
        research_results["results"]["research_plan"] = research_plan
        
        # 5. ê²°ê³¼ ìš”ì•½
        print("ğŸ“‹ ê²°ê³¼ ìš”ì•½ ì¤‘...")
        summary = self.generate_research_summary(research_results)
        research_results["results"]["summary"] = summary
        
        return research_results
    
    def generate_research_plan(self, topic, papers, datasets):
        """ì—°êµ¬ ê³„íš ìƒì„±"""
        papers_summary = "\n".join([
            f"- {paper['title']}" for paper in papers[:5]
        ])
        
        datasets_summary = "\n".join([
            f"- {dataset['name']}: {dataset.get('description', '')[:100]}..." 
            for dataset in datasets[:3]
        ])
        
        plan_prompt = f"""
        ì—°êµ¬ ì£¼ì œ: {topic}
        
        ê´€ë ¨ ë…¼ë¬¸ë“¤:
        {papers_summary}
        
        ê´€ë ¨ ë°ì´í„°ì…‹ë“¤:
        {datasets_summary}
        
        ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ ì—°êµ¬ ê³„íšì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
        í¬í•¨ ì‚¬í•­:
        1. ì—°êµ¬ ëª©í‘œ ë° ê°€ì„¤
        2. ì—°êµ¬ ë°©ë²•ë¡ 
        3. ì‹¤í—˜ ì„¤ê³„
        4. ì˜ˆìƒ ê²°ê³¼
        5. ì¼ì • ë° ë§ˆì¼ìŠ¤í†¤
        6. í•„ìš”í•œ ë¦¬ì†ŒìŠ¤
        """
        
        plan = self.jan_nano.generate_research_response(
            plan_prompt,
            max_tokens=1200,
            temperature=0.3
        )
        
        return plan
    
    def generate_research_summary(self, research_results):
        """ì—°êµ¬ ìš”ì•½ ìƒì„±"""
        summary_prompt = f"""
        ë‹¤ìŒ ì—°êµ¬ ê²°ê³¼ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”:
        
        ì£¼ì œ: {research_results['topic']}
        ë…¼ë¬¸ ìˆ˜: {len(research_results['results']['papers'])}
        ë°ì´í„°ì…‹ ìˆ˜: {len(research_results['results']['datasets'])}
        
        ìš”ì•½ í•­ëª©:
        1. ì—°êµ¬ ì£¼ì œ ê°œìš”
        2. ì£¼ìš” ë°œê²¬ì‚¬í•­
        3. ì—°êµ¬ ê³µë°±
        4. í–¥í›„ ì—°êµ¬ ë°©í–¥
        5. ì‹¤ìš©ì  ì‹œì‚¬ì 
        """
        
        summary = self.jan_nano.generate_research_response(
            summary_prompt,
            max_tokens=800,
            temperature=0.4
        )
        
        return summary

# ì‚¬ìš© ì˜ˆì‹œ
def research_pipeline_demo():
    """ì—°êµ¬ íŒŒì´í”„ë¼ì¸ ë°ëª¨"""
    pipeline = ComprehensiveResearchPipeline()
    
    # ì—°êµ¬ ì£¼ì œ ì„¤ì •
    research_topic = "Large Language Models for Code Generation"
    
    # ì¢…í•© ì—°êµ¬ ìˆ˜í–‰
    results = pipeline.conduct_research(research_topic)
    
    print("ğŸ‰ ì—°êµ¬ ì™„ë£Œ!")
    print(f"ğŸ“Š ìš”ì•½: {results['results']['summary']}")
    
    # ê²°ê³¼ ì €ì¥
    with open(f"research_results_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json", 'w') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    return results

if __name__ == "__main__":
    research_pipeline_demo()
```

### 2. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ ë„êµ¬

```python
class PerformanceBenchmark:
    def __init__(self):
        self.jan_nano = JanNanoMCPModel()
        self.test_cases = self.load_test_cases()
        
    def load_test_cases(self):
        """í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ë¡œë“œ"""
        return [
            {
                "query": "What are the key differences between transformer and RNN architectures?",
                "expected": "transformer attention mechanism parallel processing RNN sequential recurrent",
                "complexity": 3,
                "max_tokens": 400
            },
            {
                "query": "Explain the concept of few-shot learning in machine learning.",
                "expected": "few-shot learning small dataset examples meta-learning adaptation",
                "complexity": 4,
                "max_tokens": 500
            },
            {
                "query": "What are the ethical implications of AI in healthcare?",
                "expected": "privacy bias accountability transparency fairness patient safety",
                "complexity": 5,
                "max_tokens": 600
            }
        ]
    
    def run_comprehensive_benchmark(self):
        """ì¢…í•© ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        print("ğŸš€ Jan-nano ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘...")
        
        # SimpleQA ë²¤ì¹˜ë§ˆí¬
        simpleqa_benchmark = SimpleQABenchmark(self.jan_nano)
        simpleqa_results = simpleqa_benchmark.run_benchmark(self.test_cases)
        
        # ì‘ë‹µ ì‹œê°„ ì¸¡ì •
        response_times = []
        for case in self.test_cases:
            start_time = time.time()
            response = self.jan_nano.generate_research_response(case["query"])
            end_time = time.time()
            response_times.append(end_time - start_time)
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
        memory_usage = self.measure_memory_usage()
        
        # ê²°ê³¼ ì¢…í•©
        benchmark_results = {
            "simpleqa_results": simpleqa_results,
            "performance_metrics": {
                "average_response_time": sum(response_times) / len(response_times),
                "memory_usage_mb": memory_usage,
                "throughput_queries_per_second": len(self.test_cases) / sum(response_times)
            },
            "timestamp": datetime.datetime.now().isoformat()
        }
        
        print("ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼:")
        print(f"  í‰ê·  ì •í™•ë„: {simpleqa_results['average_accuracy']:.3f}")
        print(f"  í‰ê·  ì¶”ë¡  ì ìˆ˜: {simpleqa_results['average_reasoning']:.3f}")
        print(f"  ë„êµ¬ í†µí•© ì ìˆ˜: {simpleqa_results['average_tool_integration']:.3f}")
        print(f"  í‰ê·  ì‘ë‹µ ì‹œê°„: {benchmark_results['performance_metrics']['average_response_time']:.2f}ì´ˆ")
        print(f"  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_usage:.1f}MB")
        
        return benchmark_results
    
    def measure_memory_usage(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •"""
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        memory_info = process.memory_info()
        return memory_info.rss / 1024 / 1024  # MB ë‹¨ìœ„
```

## ë¡œì»¬ ë°°í¬ ê°€ì´ë“œ

### 1. Jan ì•± í†µí•© ë°°í¬

```python
class JanAppDeployment:
    def __init__(self):
        self.jan_config = {
            "model_path": "Menlo/Jan-nano",
            "local_inference": True,
            "privacy_mode": True,
            "mcp_enabled": True
        }
        
    def setup_jan_environment(self):
        """Jan í™˜ê²½ ì„¤ì •"""
        print("ğŸ”§ Jan í™˜ê²½ ì„¤ì • ì¤‘...")
        
        # Jan ì„¤ì • íŒŒì¼ ìƒì„±
        jan_config = {
            "models": [
                {
                    "id": "jan-nano",
                    "name": "Jan-nano Research Model",
                    "path": "Menlo/Jan-nano",
                    "engine": "nitro",
                    "settings": {
                        "temperature": 0.7,
                        "top_p": 0.8,
                        "top_k": 20,
                        "max_tokens": 1024
                    }
                }
            ],
            "mcp_servers": [
                {
                    "name": "research_tools",
                    "enabled": True,
                    "endpoints": ["arxiv", "scholar", "pubmed"]
                }
            ]
        }
        
        # ì„¤ì • ì €ì¥
        with open("jan_config.json", "w") as f:
            json.dump(jan_config, f, indent=2)
            
        print("âœ… Jan í™˜ê²½ ì„¤ì • ì™„ë£Œ")
        
    def deploy_local_server(self, port=8080):
        """ë¡œì»¬ ì„œë²„ ë°°í¬"""
        from flask import Flask, request, jsonify
        
        app = Flask(__name__)
        jan_nano = JanNanoMCPModel()
        
        @app.route('/health', methods=['GET'])
        def health_check():
            return jsonify({
                "status": "healthy",
                "model": "Jan-nano",
                "mcp_enabled": True
            })
        
        @app.route('/research', methods=['POST'])
        def research_query():
            data = request.json
            query = data.get('query', '')
            
            if not query:
                return jsonify({"error": "Query is required"}), 400
            
            response = jan_nano.generate_research_response(query)
            
            return jsonify({
                "query": query,
                "response": response,
                "timestamp": datetime.datetime.now().isoformat()
            })
        
        print(f"ğŸš€ Jan-nano ì„œë²„ ì‹œì‘: http://localhost:{port}")
        app.run(host='0.0.0.0', port=port, debug=False)
```

### 2. vLLM ë°°í¬

```bash
# vLLM ì„œë²„ ì‹¤í–‰ ëª…ë ¹
vllm serve Menlo/Jan-nano \
    --host 0.0.0.0 \
    --port 1234 \
    --enable-auto-tool-choice \
    --tool-call-parser hermes \
    --chat-template ./qwen3_nonthinking.jinja
```

```python
class VLLMDeployment:
    def __init__(self):
        self.server_config = {
            "model": "Menlo/Jan-nano",
            "host": "0.0.0.0",
            "port": 1234,
            "gpu_memory_utilization": 0.8,
            "max_model_len": 4096
        }
        
    def start_vllm_server(self):
        """vLLM ì„œë²„ ì‹œì‘"""
        import subprocess
        
        cmd = [
            "vllm", "serve", self.server_config["model"],
            "--host", self.server_config["host"],
            "--port", str(self.server_config["port"]),
            "--enable-auto-tool-choice",
            "--tool-call-parser", "hermes",
            "--gpu-memory-utilization", str(self.server_config["gpu_memory_utilization"]),
            "--max-model-len", str(self.server_config["max_model_len"])
        ]
        
        print(f"ğŸš€ vLLM ì„œë²„ ì‹œì‘: {' '.join(cmd)}")
        process = subprocess.Popen(cmd)
        
        return process
    
    def test_vllm_connection(self):
        """vLLM ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸"""
        import requests
        
        url = f"http://{self.server_config['host']}:{self.server_config['port']}/v1/chat/completions"
        
        payload = {
            "model": "Menlo/Jan-nano",
            "messages": [
                {"role": "user", "content": "Hello, how are you?"}
            ],
            "max_tokens": 100
        }
        
        try:
            response = requests.post(url, json=payload)
            if response.status_code == 200:
                print("âœ… vLLM ì„œë²„ ì—°ê²° ì„±ê³µ")
                return True
            else:
                print(f"âŒ vLLM ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {response.status_code}")
                return False
        except Exception as e:
            print(f"âŒ vLLM ì„œë²„ ì—°ê²° ì˜¤ë¥˜: {e}")
            return False
```

## ì„±ëŠ¥ ìµœì í™” ë° ëª¨ë‹ˆí„°ë§

### 1. ì¶”ë¡  ìµœì í™”

```python
class InferenceOptimizer:
    def __init__(self, jan_nano_model):
        self.model = jan_nano_model
        
    def optimize_for_research(self):
        """ì—°êµ¬ ì‘ì—… ìµœì í™”"""
        # ê¶Œì¥ ìƒ˜í”Œë§ íŒŒë¼ë¯¸í„°
        self.optimal_params = {
            "temperature": 0.7,
            "top_p": 0.8,
            "top_k": 20,
            "min_p": 0.0,
            "repetition_penalty": 1.1
        }
        
        # ëª¨ë¸ ìµœì í™”
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
        
        # ë©”ëª¨ë¦¬ ìµœì í™”
        if hasattr(self.model.model, 'gradient_checkpointing_enable'):
            self.model.model.gradient_checkpointing_enable()
            
        return self.optimal_params
    
    def benchmark_inference_speed(self, test_queries):
        """ì¶”ë¡  ì†ë„ ë²¤ì¹˜ë§ˆí¬"""
        times = []
        
        for query in test_queries:
            start_time = time.time()
            response = self.model.generate_research_response(query)
            end_time = time.time()
            times.append(end_time - start_time)
        
        return {
            "average_time": sum(times) / len(times),
            "min_time": min(times),
            "max_time": max(times),
            "total_queries": len(test_queries)
        }
```

## ê²°ë¡ 

**Menloì˜ Jan-nano**ëŠ” 4B íŒŒë¼ë¯¸í„°ì˜ íš¨ìœ¨ì ì¸ í¬ê¸°ë¡œ **ê¹Šì´ ìˆëŠ” ì—°êµ¬ ì‘ì—…**ê³¼ **MCP ì„œë²„ í†µí•©**ì„ ì§€ì›í•˜ëŠ” íŠ¹í™” ëª¨ë¸ì…ë‹ˆë‹¤. **ì»´íŒ©íŠ¸í•œ ì„¤ê³„**ì™€ **ë¡œì»¬ ë°°í¬ ìµœì í™”**ë¡œ ê°œì¸ ì—°êµ¬ìì™€ ì†Œê·œëª¨ íŒ€ì—ê²Œ ì´ìƒì ì¸ ì„ íƒì…ë‹ˆë‹¤.

### í•µì‹¬ ì¥ì 

1. **íš¨ìœ¨ì„±**: 4B íŒŒë¼ë¯¸í„°ë¡œ ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì  ìš´ì˜
2. **MCP í†µí•©**: ë„¤ì´í‹°ë¸Œ MCP ì„œë²„ ì§€ì›ìœ¼ë¡œ ì—°êµ¬ ë„êµ¬ í†µí•© ìš©ì´
3. **ì—°êµ¬ íŠ¹í™”**: ê¹Šì´ ìˆëŠ” ì—°êµ¬ ì‘ì—…ì— ìµœì í™”ëœ ì„¤ê³„
4. **ë¡œì»¬ ë°°í¬**: ì™„ì „í•œ í”„ë¼ì´ë²„ì‹œì™€ ì œì–´ ê°€ëŠ¥í•œ ë¡œì»¬ ì‹¤í–‰
5. **Jan ì•± ì§€ì›**: ì‚¬ìš©ì ì¹œí™”ì ì¸ ì¸í„°í˜ì´ìŠ¤ ì œê³µ

### í™œìš© ë¶„ì•¼

- **í•™ìˆ  ì—°êµ¬**: ë¬¸í—Œ ë¦¬ë·°, ë°ì´í„° ë¶„ì„, ì—°êµ¬ ê³„íš ìˆ˜ë¦½
- **ê°œì¸ ì—°êµ¬**: ì†Œê·œëª¨ í”„ë¡œì íŠ¸, í•™ìŠµ ëª©ì  ì—°êµ¬
- **êµìœ¡**: ì—°êµ¬ ë°©ë²•ë¡  êµìœ¡, í•™ìƒ ì—°êµ¬ ì§€ì›
- **í”„ë¡œí† íƒ€ì´í•‘**: ì—°êµ¬ ì•„ì´ë””ì–´ ê²€ì¦, ê°œë… ì¦ëª…

Jan-nanoë¥¼ í†µí•´ íš¨ìœ¨ì ì´ê³  í”„ë¼ì´ë²„ì‹œë¥¼ ë³´ì¥ë°›ëŠ” ì—°êµ¬ í™˜ê²½ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ì°¸ê³  ìë£Œ:**
- [Jan-nano ëª¨ë¸ í˜ì´ì§€](https://huggingface.co/Menlo/Jan-nano)
- [Jan ì•± ê³µì‹ ì‚¬ì´íŠ¸](https://jan.ai)
- [MCP í”„ë¡œí† ì½œ ë¬¸ì„œ](https://modelcontextprotocol.io)
- [vLLM ë°°í¬ ê°€ì´ë“œ](https://docs.vllm.ai) 