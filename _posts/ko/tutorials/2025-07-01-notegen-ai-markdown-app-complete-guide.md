---
title: "NoteGen AI ë§ˆí¬ë‹¤ìš´ ì•± ì™„ì „ ê°€ì´ë“œ - ì†ŒìŠ¤ ì»´íŒŒì¼ë¶€í„° Dockerê¹Œì§€"
excerpt: "AI ê¸°ë°˜ í¬ë¡œìŠ¤í”Œë«í¼ ë§ˆí¬ë‹¤ìš´ ë…¸íŠ¸ ì•± NoteGenì„ ì†ŒìŠ¤ì—ì„œ ì»´íŒŒì¼í•˜ê³  ë„ì»¤ë¼ì´ì§•í•˜ëŠ” ì™„ì „ ê°€ì´ë“œ. RAG, ì„ë² ë”©, ë‹¤ì¤‘ AI ëª¨ë¸ ì§€ì› ê¸°ëŠ¥ê¹Œì§€ ìƒì„¸íˆ ë‹¤ë£¹ë‹ˆë‹¤."
seo_title: "NoteGen AI ë§ˆí¬ë‹¤ìš´ ì•± ì™„ì „ ê°€ì´ë“œ - ì†ŒìŠ¤ ì»´íŒŒì¼ Docker ì„¤ì • - Thaki Cloud"
seo_description: "AI ê¸°ë°˜ í¬ë¡œìŠ¤í”Œë«í¼ ë§ˆí¬ë‹¤ìš´ ë…¸íŠ¸ ì•± NoteGen ì†ŒìŠ¤ ì»´íŒŒì¼, Docker ì„¤ì •, AI LLM ê¸°ëŠ¥ ì™„ì „ ê°€ì´ë“œ. Tauri Next.js ê¸°ë°˜ ì•± ê°œë°œ íŠœí† ë¦¬ì–¼"
date: 2025-07-01
last_modified_at: 2025-07-01
categories:
  - tutorials
tags:
  - notegen
  - ai
  - markdown
  - tauri
  - nextjs
  - docker
  - rag
  - embedding
  - llm
  - chatgpt
  - ollama
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
toc_icon: "cog"
toc_sticky: true
canonical_url: "https://thakicloud.github.io/tutorials/notegen-ai-markdown-app-complete-guide/"
reading_time: true
---

â±ï¸ **ì˜ˆìƒ ì½ê¸° ì‹œê°„**: 15ë¶„

## ì„œë¡ 

[NoteGen](https://github.com/codexu/note-gen)ì€ AIë¥¼ í™œìš©í•œ í˜ì‹ ì ì¸ í¬ë¡œìŠ¤í”Œë«í¼ ë§ˆí¬ë‹¤ìš´ ë…¸íŠ¸ ì•±ì…ë‹ˆë‹¤. Tauri2ì™€ Next.js ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ë˜ì–´ ë°ìŠ¤í¬í†±ê³¼ ëª¨ë°”ì¼ì„ ëª¨ë‘ ì§€ì›í•˜ë©°, ChatGPT, Gemini, Ollama ë“± ë‹¤ì–‘í•œ AI ëª¨ë¸ê³¼ RAG(Retrieval-Augmented Generation) ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

ì´ ê°€ì´ë“œì—ì„œëŠ” NoteGenì„ ì†ŒìŠ¤ì—ì„œ ì»´íŒŒì¼í•˜ê³ , Docker í™˜ê²½ì„ êµ¬ì„±í•˜ë©°, AI ê¸°ëŠ¥ì„ ìƒì„¸íˆ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

## í”„ë¡œì íŠ¸ ê°œìš”

### ì£¼ìš” íŠ¹ì§•

- **ê²½ëŸ‰**: 20MB ë¯¸ë§Œì˜ ì„¤ì¹˜ íŒŒì¼
- **í¬ë¡œìŠ¤í”Œë«í¼**: Windows, macOS, Linux, iOS, Android ì§€ì›
- **AI í†µí•©**: ë‹¤ì¤‘ AI ëª¨ë¸ ì§€ì› (ChatGPT, Gemini, Grok, Ollama, LM Studio ë“±)
- **RAG ê¸°ëŠ¥**: ì„ë² ë”© ëª¨ë¸ê³¼ ë¦¬ë­í‚¹ ëª¨ë¸ ì§€ì›
- **ì˜¤í”„ë¼ì¸**: ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œ ê¸°ë°˜
- **ë™ê¸°í™”**: GitHub, Gitee, WebDAV ì§€ì›

### ê¸°ìˆ  ìŠ¤íƒ

- **Frontend**: Next.js 15, React 19, TypeScript
- **Backend**: Tauri 2 (Rust)
- **UI**: Radix UI, Tailwind CSS
- **AI**: OpenAI SDK, ë‹¤ì¤‘ í”„ë¡œë°”ì´ë” ì§€ì›
- **Database**: SQLite (ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤)

## ê°œë°œ í™˜ê²½ ì„¤ì •

### í•„ìˆ˜ ìš”êµ¬ì‚¬í•­

**macOS í™˜ê²½ ê¸°ì¤€:**

```bash
# Node.js ë° pnpm ë²„ì „ í™•ì¸
node --version  # v22.16.0+
pnpm --version  # v10.12.1+
```

**ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­:**

- Node.js 22.16.0 ì´ìƒ
- Rust 1.70 ì´ìƒ
- pnpm (íŒ¨í‚¤ì§€ ë§¤ë‹ˆì €)

### Rust ì„¤ì¹˜

```bash
# Rust ì„¤ì¹˜
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source ~/.zshrc

# ë²„ì „ í™•ì¸
rustc --version
cargo --version
```

### Tauri CLI ì„¤ì¹˜

```bash
# Tauri CLI ì „ì—­ ì„¤ì¹˜
cargo install tauri-cli

# ë˜ëŠ” pnpmìœ¼ë¡œ ì„¤ì¹˜
pnpm add -g @tauri-apps/cli
```

## ì†ŒìŠ¤ ì»´íŒŒì¼ ê°€ì´ë“œ

### 1. ì €ì¥ì†Œ í´ë¡ 

```bash
# í”„ë¡œì íŠ¸ í´ë¡ 
git clone https://github.com/codexu/note-gen.git
cd note-gen

# ë¸Œëœì¹˜ í™•ì¸ (dev ë¸Œëœì¹˜ ì‚¬ìš©)
git checkout dev
```

### 2. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
# pnpmìœ¼ë¡œ ì˜ì¡´ì„± ì„¤ì¹˜ (npmë³´ë‹¤ ê¶Œì¥)
pnpm install

# build scripts ìŠ¹ì¸ (í•„ìš”ì‹œ)
pnpm approve-builds
```

### 3. ê°œë°œ ì„œë²„ ì‹¤í–‰

```bash
# Next.js ê°œë°œ ì„œë²„ (ì›¹ ë²„ì „)
pnpm dev

# Tauri ê°œë°œ ì•± ì‹¤í–‰ (ë°ìŠ¤í¬í†± ë²„ì „)
pnpm tauri dev
```

### 4. í”„ë¡œë•ì…˜ ë¹Œë“œ

```bash
# ì›¹ ë¹Œë“œ
pnpm build

# ë°ìŠ¤í¬í†± ì•± ë¹Œë“œ
pnpm tauri build
```

## Docker ì„¤ì •

NoteGenì€ ê¸°ë³¸ì ìœ¼ë¡œ Dockerfileì„ ì œê³µí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ì›¹ ë²„ì „ìš© Docker ì„¤ì •ì„ ì§ì ‘ êµ¬ì„±í•´ë³´ê² ìŠµë‹ˆë‹¤.

### Dockerfile ìƒì„±

```dockerfile
# ë©€í‹°ìŠ¤í…Œì´ì§€ ë¹Œë“œ
FROM node:22-alpine AS builder

# pnpm ì„¤ì¹˜
RUN npm install -g pnpm

WORKDIR /app

# íŒ¨í‚¤ì§€ íŒŒì¼ ë³µì‚¬
COPY package.json pnpm-lock.yaml ./

# ì˜ì¡´ì„± ì„¤ì¹˜
RUN pnpm install --frozen-lockfile

# ì†ŒìŠ¤ ì½”ë“œ ë³µì‚¬
COPY . .

# ë¹Œë“œ
RUN pnpm build

# í”„ë¡œë•ì…˜ ìŠ¤í…Œì´ì§€
FROM node:22-alpine AS runner

RUN npm install -g pnpm serve

WORKDIR /app

# í”„ë¡œë•ì…˜ ì˜ì¡´ì„± ì„¤ì¹˜
# COPY package.json pnpm-lock.yaml ./
# RUN pnpm install --prod --frozen-lockfile

# ë¹Œë“œ ê²°ê³¼ë¬¼ ë³µì‚¬
# COPY --from=builder /app/.next ./.next
# COPY --from=builder /app/public ./public
# COPY --from=builder /app/next.config.ts ./

# ì •ì  íŒŒì¼ ì„œë¹™ì„ ìœ„í•œ ë¹Œë“œ ê²°ê³¼ë¬¼ ë³µì‚¬
COPY --from=builder /app/out ./

# í¬íŠ¸ ì„¤ì •
EXPOSE 3456

# ì„œë²„ ì‹œì‘
# CMD ["pnpm", "start"]

# ì •ì  íŒŒì¼ ì„œë²„ ì‹œì‘
CMD ["serve", "-s", ".", "-p", "3456"] 
```

### Docker Compose ì„¤ì •

```yaml
# docker-compose.yml
version: '3.8'

services:
  notegen:
    build: .
    ports:
      - "3456:3456"
    environment:
      - NODE_ENV=production
    volumes:
      # ë…¸íŠ¸ ë°ì´í„° ì˜ì†í™”
      - notegen_data:/app/data
    restart: unless-stopped

volumes:
  notegen_data:
```

### Docker ì‹¤í–‰

```bash
# ì´ë¯¸ì§€ ë¹Œë“œ ë° ì‹¤í–‰
docker-compose up -d

# ë˜ëŠ” ì§ì ‘ ë¹Œë“œ
docker build -t notegen .
docker run -p 3456:3456 -v notegen_data:/app/data notegen
```

## AI ê¸°ëŠ¥ ìƒì„¸ ë¶„ì„

### ì§€ì› AI ëª¨ë¸

NoteGenì€ ë‹¤ì–‘í•œ AI í”„ë¡œë°”ì´ë”ë¥¼ ì§€ì›í•©ë‹ˆë‹¤:

#### 1. í´ë¼ìš°ë“œ AI ì„œë¹„ìŠ¤

```typescript
// src/app/core/setting/config.tsxì—ì„œ í™•ì¸
const aiProviders = [
  {
    key: 'chatgpt',
    title: 'ChatGPT',
    baseURL: 'https://api.openai.com/v1',
    apiKeyUrl: 'https://platform.openai.com/api-keys'
  },
  {
    key: 'gemini',
    title: 'Gemini',
    baseURL: 'https://generativelanguage.googleapis.com/v1beta/openai',
    apiKeyUrl: 'https://aistudio.google.com/app/apikey'
  },
  {
    key: 'grok',
    title: 'Grok',
    baseURL: 'https://api.x.ai/v1',
    apiKeyUrl: 'https://console.x.ai/'
  },
  {
    key: 'deepseek',
    title: 'DeepSeek',
    baseURL: 'https://api.deepseek.com',
    apiKeyUrl: 'https://platform.deepseek.com/api_keys'
  }
]
```

#### 2. ë¡œì»¬ AI ì„œë¹„ìŠ¤

```typescript
const localProviders = [
  {
    key: 'ollama',
    title: 'Ollama',
    baseURL: 'http://localhost:11434/v1'
  },
  {
    key: 'lmstudio',
    title: 'LM Studio',
    baseURL: 'http://localhost:1234/v1'
  }
]
```

### AI í´ë¼ì´ì–¸íŠ¸ ìƒì„±

```typescript
// src/lib/ai.ts
export async function createOpenAIClient(aiConfig?: AiConfig) {
  const config = aiConfig || await getAISettings()
  if (!config) throw new Error('AI ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤')
  
  const { baseURL, apiKey, temperature = 0.7, topP = 1 } = config
  
  return new OpenAI({
    baseURL,
    apiKey,
    defaultQuery: { temperature, top_p: topP },
    dangerouslyAllowBrowser: true
  })
}
```

### ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬

```typescript
export async function fetchAiStream(
  text: string, 
  onUpdate: (content: string) => void, 
  abortSignal?: AbortSignal
): Promise<string> {
  const { messages } = await prepareMessages(text)
  const openai = await createOpenAIClient()
  
  const stream = await openai.chat.completions.create({
    messages,
    stream: true,
    signal: abortSignal
  })
  
  let fullContent = ''
  
  for await (const chunk of stream) {
    const content = chunk.choices[0]?.delta?.content || ''
    fullContent += content
    onUpdate(fullContent)
  }
  
  return fullContent
}
```

## RAG (Retrieval-Augmented Generation) ê¸°ëŠ¥

### ë²¡í„° ì„ë² ë”©

```typescript
// src/lib/rag.ts
export async function processMarkdownFile(
  filePath: string, 
  fileContent?: string
): Promise<boolean> {
  try {
    const content = fileContent || await readTextFile(filePath)
    
    // í…ìŠ¤íŠ¸ ì²­í‚¹
    const chunks = chunkText(content, 1000, 200)
    const filename = filePath.split('/').pop() || filePath
    
    // ê¸°ì¡´ ë²¡í„° ì‚­ì œ
    await deleteVectorDocumentsByFilename(filename)
    
    // ê° ì²­í¬ì— ëŒ€í•´ ì„ë² ë”© ìƒì„±
    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i]
      const embedding = await fetchEmbedding(chunk)
      
      if (embedding) {
        await upsertVectorDocument({
          filename,
          chunk_id: i,
          content: chunk,
          embedding: JSON.stringify(embedding),
          updated_at: Date.now()
        })
      }
    }
    
    return true
  } catch (error) {
    console.error(`íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: ${filePath}`, error)
    return false
  }
}
```

### í…ìŠ¤íŠ¸ ì²­í‚¹ ì•Œê³ ë¦¬ì¦˜

```typescript
export function chunkText(
  text: string, 
  chunkSize: number = 1000, 
  chunkOverlap: number = 200
): string[] {
  const chunks: string[] = []
  
  if (text.length <= chunkSize) {
    chunks.push(text)
    return chunks
  }
  
  // ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ë¶„í• 
  const paragraphs = text.split('\n\n')
  let currentChunk = ''
  
  for (const paragraph of paragraphs) {
    if (currentChunk.length + paragraph.length + 2 > chunkSize) {
      if (currentChunk.length > 0) {
        chunks.push(currentChunk)
        
        // ì˜¤ë²„ë© ë¶€ë¶„ ê³„ì‚°
        const overlapLength = Math.min(chunkOverlap, currentChunk.length)
        const lastChunkParts = currentChunk.split('\n\n')
        const overlapParts = []
        let currentLength = 0
        
        for (let i = lastChunkParts.length - 1; i >= 0; i--) {
          const part = lastChunkParts[i]
          if (currentLength + part.length + 2 <= overlapLength) {
            overlapParts.unshift(part)
            currentLength += part.length + 2
          } else {
            break
          }
        }
        
        currentChunk = overlapParts.join('\n\n')
      }
      currentChunk += paragraph + '\n\n'
    } else {
      currentChunk += paragraph + '\n\n'
    }
  }
  
  if (currentChunk.trim()) {
    chunks.push(currentChunk.trim())
  }
  
  return chunks
}
```

### ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰

```typescript
export async function getContextForQuery(query: string): Promise<string> {
  try {
    // ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
    const queryEmbedding = await fetchEmbedding(query)
    if (!queryEmbedding) return ''
    
    // ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
    const similarDocs = await getSimilarDocuments(queryEmbedding, 5)
    
    // ë¦¬ë­í‚¹ ì ìš© (ê°€ëŠ¥í•œ ê²½ìš°)
    const rerankModelAvailable = await checkRerankModelAvailable()
    let finalDocs = similarDocs
    
    if (rerankModelAvailable && similarDocs.length > 0) {
      finalDocs = await rerankDocuments(query, similarDocs)
    }
    
    // ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ ìƒì„±
    return finalDocs
      .map(doc => `íŒŒì¼: ${doc.filename}\në‚´ìš©: ${doc.content}`)
      .join('\n\n---\n\n')
  } catch (error) {
    console.error('ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹¤íŒ¨:', error)
    return ''
  }
}
```

### ë¦¬ë­í‚¹ ëª¨ë¸

```typescript
export async function rerankDocuments(
  query: string,
  documents: {id: number, filename: string, content: string, similarity: number}[]
): Promise<{id: number, filename: string, content: string, similarity: number}[]> {
  try {
    const modelInfo = await getRerankModelInfo()
    if (!modelInfo) return documents
    
    const { baseURL, apiKey, model } = modelInfo
    const response = await fetch(baseURL + '/rerank', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify({
        model,
        query,
        documents: documents.map(doc => doc.content)
      })
    })
    
    if (!response.ok) return documents
    
    const data = await response.json()
    
    // ë¦¬ë­í‚¹ ê²°ê³¼ì— ë”°ë¼ ë¬¸ì„œ ì¬ì •ë ¬
    return data.results
      .map((result: any) => ({
        ...documents[result.index],
        similarity: result.relevance_score
      }))
      .sort((a: any, b: any) => b.similarity - a.similarity)
  } catch (error) {
    console.error('ë¦¬ë­í‚¹ ì‹¤íŒ¨:', error)
    return documents
  }
}
```

## ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ

### AI ì„¤ì •

1. **ì„¤ì • í˜ì´ì§€ ì ‘ê·¼**: ì•± ì‹¤í–‰ í›„ ì„¤ì • ë²„íŠ¼ í´ë¦­
2. **AI ëª¨ë¸ êµ¬ì„±**: 
   - API í‚¤ ì…ë ¥ (OpenAI, Anthropic ë“±)
   - ë¡œì»¬ ëª¨ë¸ URL ì„¤ì • (Ollama, LM Studio)
   - ëª¨ë¸ëª… ì§€ì •

```bash
# Ollama ë¡œì»¬ ì‹¤í–‰ ì˜ˆì‹œ
ollama serve
ollama pull llama3.1:8b
```

### ë…¹ìŒ ë° AI ëŒ€í™”

1. **ë…¹ìŒ í˜ì´ì§€**: ìŠ¤í¬ë¦°ìƒ·, í…ìŠ¤íŠ¸, íŒŒì¼ ë“± ë‹¤ì–‘í•œ í˜•íƒœë¡œ ì •ë³´ ìˆ˜ì§‘
2. **AI ì–´ì‹œìŠ¤í„´íŠ¸**: ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ AIì™€ ëŒ€í™”
3. **ë…¸íŠ¸ ìƒì„±**: ëŒ€í™” ë‚´ìš©ì„ ì •ë¦¬í•˜ì—¬ ë§ˆí¬ë‹¤ìš´ ë…¸íŠ¸ë¡œ ë³€í™˜

### RAG í™œìš©

1. **ë¬¸ì„œ ì¸ë±ì‹±**: ê¸°ì¡´ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë“¤ì„ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
2. **ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰**: ì§ˆë¬¸ ì‹œ ê´€ë ¨ ë¬¸ì„œ ìë™ ê²€ìƒ‰
3. **ì§€ëŠ¥í˜• ë‹µë³€**: ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ë‹µë³€ ìƒì„±

## ìë™í™” ìŠ¤í¬ë¦½íŠ¸

### ë¹Œë“œ ìë™í™”

```bash
#!/bin/bash
# build-notegen.sh

echo "ğŸš€ NoteGen ë¹Œë“œ ì‹œì‘..."

# ì˜ì¡´ì„± ì—…ë°ì´íŠ¸
echo "ğŸ“¦ ì˜ì¡´ì„± ì„¤ì¹˜..."
pnpm install

# íƒ€ì… ì²´í¬
echo "ğŸ” íƒ€ì… ì²´í¬..."
pnpm run lint

# ë¹Œë“œ ì‹¤í–‰
echo "ğŸ—ï¸  ë¹Œë“œ ì‹¤í–‰..."
if [ "$1" == "desktop" ]; then
    echo "ğŸ–¥ï¸  ë°ìŠ¤í¬í†± ì•± ë¹Œë“œ..."
    pnpm tauri build
else
    echo "ğŸŒ ì›¹ ì•± ë¹Œë“œ..."
    pnpm build
fi

echo "âœ… ë¹Œë“œ ì™„ë£Œ!"
```

### ê°œë°œ í™˜ê²½ ì„¤ì •

```bash
#!/bin/bash
# setup-dev.sh

echo "ğŸ› ï¸  NoteGen ê°œë°œ í™˜ê²½ ì„¤ì •..."

# Rust ì„¤ì¹˜ í™•ì¸
if ! command -v rustc &> /dev/null; then
    echo "ğŸ“¥ Rust ì„¤ì¹˜ ì¤‘..."
    curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
    source ~/.zshrc
fi

# pnpm ì„¤ì¹˜ í™•ì¸
if ! command -v pnpm &> /dev/null; then
    echo "ğŸ“¥ pnpm ì„¤ì¹˜ ì¤‘..."
    npm install -g pnpm
fi

# Tauri CLI ì„¤ì¹˜
echo "ğŸ“¥ Tauri CLI ì„¤ì¹˜ ì¤‘..."
cargo install tauri-cli

echo "âœ… ê°œë°œ í™˜ê²½ ì„¤ì • ì™„ë£Œ!"
echo "ğŸ¯ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ê°œë°œ ì„œë²„ë¥¼ ì‹œì‘í•˜ì„¸ìš”:"
echo "   pnpm dev      # ì›¹ ë²„ì „"
echo "   pnpm tauri dev # ë°ìŠ¤í¬í†± ë²„ì „"
```

### zshrc Aliases

```bash
# ~/.zshrcì— ì¶”ê°€
export NOTEGEN_DIR="$HOME/projects/note-gen"

# NoteGen ê´€ë ¨ alias
alias ng="cd $NOTEGEN_DIR"
alias ngdev="cd $NOTEGEN_DIR && pnpm dev"
alias ngtauri="cd $NOTEGEN_DIR && pnpm tauri dev"
alias ngbuild="cd $NOTEGEN_DIR && pnpm build"
alias ngdocker="cd $NOTEGEN_DIR && docker-compose up -d"

# ê°œë°œ ë„êµ¬ í™•ì¸
alias checkdev="node --version && pnpm --version && rustc --version"
```

## ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ì˜¤ë¥˜

#### 1. ì˜ì¡´ì„± ì¶©ëŒ

```bash
# npm ëŒ€ì‹  pnpm ì‚¬ìš©
rm -rf node_modules package-lock.json
pnpm install
```

#### 2. Rust ì»´íŒŒì¼ ì˜¤ë¥˜

```bash
# Rust íˆ´ì²´ì¸ ì—…ë°ì´íŠ¸
rustup update
cargo clean
```

#### 3. Tauri ë¹Œë“œ ì‹¤íŒ¨

```bash
# Tauri ì˜ì¡´ì„± ì¬ì„¤ì¹˜
cargo install tauri-cli --force
pnpm tauri info
```

### ì„±ëŠ¥ ìµœì í™”

#### ì²­í‚¹ íŒŒë¼ë¯¸í„° ì¡°ì •

```typescript
// í° ë¬¸ì„œìš©
const chunks = chunkText(content, 2000, 400)

// ì •ë°€í•œ ê²€ìƒ‰ìš©
const chunks = chunkText(content, 500, 100)
```

#### ì„ë² ë”© ë°°ì¹˜ ì²˜ë¦¬

```typescript
async function batchProcessFiles(files: string[]) {
  const batchSize = 5
  for (let i = 0; i < files.length; i += batchSize) {
    const batch = files.slice(i, i + batchSize)
    await Promise.all(batch.map(processMarkdownFile))
    
    // API ë ˆì´íŠ¸ ë¦¬ë°‹ ê³ ë ¤
    await new Promise(resolve => setTimeout(resolve, 1000))
  }
}
```

## ê²°ë¡ 

NoteGenì€ AI ê¸°ë°˜ ë§ˆí¬ë‹¤ìš´ ë…¸íŠ¸ ì•±ì˜ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì„ ì œì‹œí•©ë‹ˆë‹¤. Tauriì™€ Next.jsì˜ ì¡°í•©ìœ¼ë¡œ ë›°ì–´ë‚œ ì„±ëŠ¥ê³¼ í¬ë¡œìŠ¤í”Œë«í¼ í˜¸í™˜ì„±ì„ ì œê³µí•˜ë©°, ë‹¤ì–‘í•œ AI ëª¨ë¸ê³¼ RAG ê¸°ëŠ¥ìœ¼ë¡œ ì§€ëŠ¥í˜• ë…¸íŠ¸ ì‘ì„±ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

### ì£¼ìš” ì¥ì 

- **ê²½ëŸ‰í™”**: 20MB ë¯¸ë§Œì˜ ì„¤ì¹˜ íŒŒì¼
- **ìœ ì—°ì„±**: ë‹¤ì¤‘ AI í”„ë¡œë°”ì´ë” ì§€ì›
- **í™•ì¥ì„±**: í”ŒëŸ¬ê·¸ì¸ ì•„í‚¤í…ì²˜
- **í”„ë¼ì´ë²„ì‹œ**: ë¡œì»¬ ë°ì´í„° ì €ì¥

### ì¶”ì²œ ì‚¬ìš© ì‚¬ë¡€

- **ì—°êµ¬ ë…¸íŠ¸**: ë…¼ë¬¸ê³¼ ìë£Œë¥¼ AIë¡œ ë¶„ì„í•˜ê³  ì •ë¦¬
- **ê°œë°œ ë¬¸ì„œ**: ì½”ë“œì™€ ë¬¸ì„œë¥¼ ì—°ê²°í•œ ì§€ì‹ ê´€ë¦¬
- **í•™ìŠµ ë…¸íŠ¸**: AI íŠœí„°ì™€ í•¨ê»˜í•˜ëŠ” ìŠ¤ë§ˆíŠ¸ í•™ìŠµ
- **íšŒì˜ë¡**: ìŒì„±ê³¼ í…ìŠ¤íŠ¸ë¥¼ í†µí•©í•œ íšŒì˜ ê¸°ë¡

NoteGenì€ ë‹¨ìˆœí•œ ë…¸íŠ¸ ì•±ì„ ë„˜ì–´ AI ì‹œëŒ€ì˜ ì§€ì‹ ê´€ë¦¬ ë„êµ¬ë¡œ ìë¦¬ì¡ì„ ì ì¬ë ¥ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ë¡œì„œ ì»¤ë®¤ë‹ˆí‹°ì˜ ê¸°ì—¬ë¥¼ í†µí•´ ì§€ì†ì ìœ¼ë¡œ ë°œì „í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤. 