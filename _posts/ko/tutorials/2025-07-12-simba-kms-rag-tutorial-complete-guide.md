---
title: "Simba KMS RAG ì‹œìŠ¤í…œ ì™„ë²½ ê°€ì´ë“œ - macOS í™˜ê²½ì—ì„œ êµ¬ì¶•í•˜ê¸°"
excerpt: "ì˜¤í”ˆì†ŒìŠ¤ Knowledge Management Systemì¸ Simbaë¥¼ í™œìš©í•˜ì—¬ RAG ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ì™„ë²½í•œ ê°€ì´ë“œì…ë‹ˆë‹¤. Python SDK í™œìš©ë²•ë¶€í„° ì‹¤ì œ í…ŒìŠ¤íŠ¸ê¹Œì§€ ë‹¨ê³„ë³„ë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤."
seo_title: "Simba KMS RAG ì‹œìŠ¤í…œ íŠœí† ë¦¬ì–¼ - macOS ì™„ë²½ ê°€ì´ë“œ - Thaki Cloud"
seo_description: "ì˜¤í”ˆì†ŒìŠ¤ Knowledge Management System Simbaë¥¼ í™œìš©í•œ RAG ì‹œìŠ¤í…œ êµ¬ì¶• ê°€ì´ë“œ. Python SDK, ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤, ì„ë² ë”© ëª¨ë¸ ì„¤ì •ë¶€í„° ì‹¤ì œ í…ŒìŠ¤íŠ¸ê¹Œì§€ ìƒì„¸íˆ ì•ˆë‚´í•©ë‹ˆë‹¤."
date: 2025-07-12
last_modified_at: 2025-07-12
categories:
  - tutorials
  - llmops
tags:
  - simba
  - kms
  - rag
  - python
  - knowledge-management
  - vector-database
  - embedding
  - openai
  - llm
  - macOS
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
toc_icon: "cog"
toc_sticky: true
canonical_url: "https://thakicloud.github.io/tutorials/simba-kms-rag-tutorial-complete-guide/"
reading_time: true
---

â±ï¸ **ì˜ˆìƒ ì½ê¸° ì‹œê°„**: 25ë¶„

## ì„œë¡ 

**Simba KMS(Knowledge Management System)**ëŠ” RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œê³¼ ì‰½ê²Œ í†µí•©í•  ìˆ˜ ìˆëŠ” ì˜¤í”ˆì†ŒìŠ¤ ì§€ì‹ ê´€ë¦¬ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” macOS í™˜ê²½ì—ì„œ Simba KMSë¥¼ í™œìš©í•˜ì—¬ ì™„ì „í•œ RAG ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤.

### ì™œ Simba KMSì¸ê°€?

- **âœ… ì‰¬ìš´ RAG ì‹œìŠ¤í…œ í†µí•©**: ê¸°ì¡´ RAG ì‹œìŠ¤í…œê³¼ ì›í™œí•œ ì—°ë™
- **âœ… ê°•ë ¥í•œ Python SDK**: ê°œë°œì ì¹œí™”ì ì¸ ì¸í„°í˜ì´ìŠ¤
- **âœ… ëª¨ë“ˆëŸ¬ ì•„í‚¤í…ì²˜**: ìœ ì—°í•œ ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ëŠ¥
- **âœ… ì˜¤í”ˆì†ŒìŠ¤**: ì»¤ë®¤ë‹ˆí‹° ê¸°ë°˜ ê°œë°œ ë° í™•ì¥ì„±
- **âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì§€ì›**: ë‹¤ì–‘í•œ ë²¡í„° ìŠ¤í† ì–´ ì„ íƒ ê°€ëŠ¥

## ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

### ê°œë°œí™˜ê²½ ì •ë³´

```bash
# í…ŒìŠ¤íŠ¸ í™˜ê²½ ì •ë³´
echo "=== ê°œë°œí™˜ê²½ ë²„ì „ ì •ë³´ ===" 
echo "macOS: $(sw_vers -productVersion)"
echo "Python: $(python3 --version)"
echo "pip: $(pip3 --version)"
echo "Node.js: $(node --version)"
echo "Redis: $(redis-cli --version)"
echo "========================================="
```

### í•„ìˆ˜ ìš”êµ¬ì‚¬í•­

- **Python**: 3.11 ì´ìƒ
- **Redis**: 7.0 ì´ìƒ
- **Node.js**: 20 ì´ìƒ
- **OpenAI API Key**: GPT ëª¨ë¸ ì‚¬ìš©
- **macOS**: Big Sur ì´ìƒ (Intel/Apple Silicon ëª¨ë‘ ì§€ì›)

## 1ë‹¨ê³„: í™˜ê²½ ì„¤ì •

### Homebrew ì„¤ì¹˜ (ì—†ëŠ” ê²½ìš°)

```bash
# Homebrew ì„¤ì¹˜
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
```

### Redis ì„¤ì¹˜ ë° ì‹¤í–‰

```bash
# Redis ì„¤ì¹˜
brew install redis

# Redis ì„œë¹„ìŠ¤ ì‹œì‘
brew services start redis

# Redis ì—°ê²° í…ŒìŠ¤íŠ¸
redis-cli ping
# ì¶œë ¥: PONG
```

### Node.js ì„¤ì¹˜

```bash
# Node.js ì„¤ì¹˜ (ìµœì‹  LTS ë²„ì „)
brew install node

# ë²„ì „ í™•ì¸
node --version
npm --version
```

## 2ë‹¨ê³„: Python í™˜ê²½ êµ¬ì„±

### ê°€ìƒí™˜ê²½ ìƒì„±

```bash
# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir simba-rag-tutorial
cd simba-rag-tutorial

# Python ê°€ìƒí™˜ê²½ ìƒì„±
python3 -m venv venv

# ê°€ìƒí™˜ê²½ í™œì„±í™”
source venv/bin/activate

# pip ì—…ê·¸ë ˆì´ë“œ
pip install --upgrade pip
```

### Poetry ì„¤ì¹˜ (ê¶Œì¥)

```bash
# Poetry ì„¤ì¹˜
curl -sSL https://install.python-poetry.org | python3 -

# PATH ì„¤ì • (zshrcì— ì¶”ê°€)
echo 'export PATH="$HOME/.local/bin:$PATH"' >> ~/.zshrc
source ~/.zshrc

# Poetry ë²„ì „ í™•ì¸
poetry --version
```

## 3ë‹¨ê³„: Simba KMS ì„¤ì¹˜

### íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
# í•µì‹¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install simba-core

# ì¶”ê°€ ì˜ì¡´ì„± ì„¤ì¹˜
pip install \
    openai \
    langchain \
    langchain-openai \
    chromadb \
    sentence-transformers \
    pandas \
    numpy \
    python-dotenv \
    streamlit \
    fastapi \
    uvicorn
```

### í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
# .env íŒŒì¼ ìƒì„±
cat > .env << 'EOF'
# OpenAI API Configuration
OPENAI_API_KEY=your-openai-api-key-here

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# Simba Configuration
SIMBA_DB_PATH=./simba_knowledge.db
SIMBA_COLLECTION_NAME=knowledge_base

# Vector Database Configuration
VECTOR_DIMENSION=1536
SIMILARITY_THRESHOLD=0.7

# Embedding Model Configuration
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_BATCH_SIZE=100
EOF
```

## 4ë‹¨ê³„: ê¸°ë³¸ RAG ì‹œìŠ¤í…œ êµ¬í˜„

### í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±

```bash
# í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±
mkdir -p {src,tests,data,docs,scripts}
touch src/__init__.py
touch tests/__init__.py
```

### ê¸°ë³¸ RAG í´ë˜ìŠ¤ êµ¬í˜„

```python
# src/simba_rag.py
import os
import logging
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from pathlib import Path

import openai
import chromadb
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.document_loaders import TextLoader, PyPDFLoader
from sentence_transformers import SentenceTransformer
import redis
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class DocumentChunk:
    """ë¬¸ì„œ ì²­í¬ ë°ì´í„° í´ë˜ìŠ¤"""
    content: str
    metadata: Dict[str, Any]
    embedding: Optional[List[float]] = None

class SimbaRAG:
    """Simba KMS ê¸°ë°˜ RAG ì‹œìŠ¤í…œ"""
    
    def __init__(self, config: Dict[str, Any] = None):
        """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.config = config or self._load_default_config()
        self._initialize_components()
    
    def _load_default_config(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ì„¤ì • ë¡œë“œ"""
        return {
            'openai_api_key': os.getenv('OPENAI_API_KEY'),
            'redis_host': os.getenv('REDIS_HOST', 'localhost'),
            'redis_port': int(os.getenv('REDIS_PORT', 6379)),
            'embedding_model': os.getenv('EMBEDDING_MODEL', 'text-embedding-3-small'),
            'vector_dimension': int(os.getenv('VECTOR_DIMENSION', 1536)),
            'similarity_threshold': float(os.getenv('SIMILARITY_THRESHOLD', 0.7)),
            'chunk_size': 1000,
            'chunk_overlap': 200,
        }
    
    def _initialize_components(self):
        """ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        try:
            # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            openai.api_key = self.config['openai_api_key']
            
            # Redis í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            self.redis_client = redis.Redis(
                host=self.config['redis_host'],
                port=self.config['redis_port'],
                decode_responses=True
            )
            
            # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
            self.embeddings = OpenAIEmbeddings(
                model=self.config['embedding_model'],
                openai_api_key=self.config['openai_api_key']
            )
            
            # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            self.chroma_client = chromadb.PersistentClient(path="./chroma_db")
            
            # í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì´ˆê¸°í™”
            self.text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=self.config['chunk_size'],
                chunk_overlap=self.config['chunk_overlap']
            )
            
            # LLM ì´ˆê¸°í™”
            self.llm = ChatOpenAI(
                model="gpt-4o-mini",
                temperature=0,
                openai_api_key=self.config['openai_api_key']
            )
            
            logger.info("âœ… ëª¨ë“  ì»´í¬ë„ŒíŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            logger.error(f"âŒ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            raise
    
    def load_documents(self, file_paths: List[str]) -> List[DocumentChunk]:
        """ë¬¸ì„œ ë¡œë“œ ë° ì²­í¬ ë¶„í• """
        documents = []
        
        for file_path in file_paths:
            try:
                path = Path(file_path)
                
                if path.suffix.lower() == '.pdf':
                    loader = PyPDFLoader(file_path)
                elif path.suffix.lower() == '.txt':
                    loader = TextLoader(file_path)
                else:
                    logger.warning(f"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_path}")
                    continue
                
                # ë¬¸ì„œ ë¡œë“œ
                docs = loader.load()
                
                # í…ìŠ¤íŠ¸ ë¶„í• 
                splits = self.text_splitter.split_documents(docs)
                
                # DocumentChunk ê°ì²´ë¡œ ë³€í™˜
                for split in splits:
                    chunk = DocumentChunk(
                        content=split.page_content,
                        metadata={
                            'source': file_path,
                            'page': split.metadata.get('page', 0),
                            'chunk_id': len(documents)
                        }
                    )
                    documents.append(chunk)
                
                logger.info(f"âœ… ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ: {file_path} ({len(splits)} ì²­í¬)")
                
            except Exception as e:
                logger.error(f"âŒ ë¬¸ì„œ ë¡œë“œ ì‹¤íŒ¨: {file_path} - {str(e)}")
                continue
        
        return documents
    
    def create_knowledge_base(self, documents: List[DocumentChunk], collection_name: str = "knowledge_base"):
        """ì§€ì‹ë² ì´ìŠ¤ ìƒì„±"""
        try:
            # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ (ìˆëŠ” ê²½ìš°)
            try:
                self.chroma_client.delete_collection(name=collection_name)
            except:
                pass
            
            # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
            collection = self.chroma_client.create_collection(
                name=collection_name,
                metadata={"hnsw:space": "cosine"}
            )
            
            # ë¬¸ì„œ ë‚´ìš©ê³¼ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            contents = [doc.content for doc in documents]
            metadatas = [doc.metadata for doc in documents]
            ids = [f"doc_{i}" for i in range(len(documents))]
            
            # ì„ë² ë”© ìƒì„±
            embeddings = self.embeddings.embed_documents(contents)
            
            # ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥
            collection.add(
                embeddings=embeddings,
                documents=contents,
                metadatas=metadatas,
                ids=ids
            )
            
            self.collection = collection
            logger.info(f"âœ… ì§€ì‹ë² ì´ìŠ¤ ìƒì„± ì™„ë£Œ: {len(documents)} ë¬¸ì„œ")
            
        except Exception as e:
            logger.error(f"âŒ ì§€ì‹ë² ì´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise
    
    def search_knowledge(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰"""
        try:
            # ì¿¼ë¦¬ ì„ë² ë”©
            query_embedding = self.embeddings.embed_query(query)
            
            # ìœ ì‚¬ë„ ê²€ìƒ‰
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=k,
                include=['documents', 'metadatas', 'distances']
            )
            
            # ê²°ê³¼ í¬ë§·íŒ…
            search_results = []
            for i, doc in enumerate(results['documents'][0]):
                search_results.append({
                    'content': doc,
                    'metadata': results['metadatas'][0][i],
                    'similarity': 1 - results['distances'][0][i]  # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜
                })
            
            return search_results
            
        except Exception as e:
            logger.error(f"âŒ ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def generate_answer(self, query: str, context_docs: List[Dict[str, Any]]) -> str:
        """ë‹µë³€ ìƒì„±"""
        try:
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = "\n\n".join([
                f"ë¬¸ì„œ {i+1}: {doc['content']}" 
                for i, doc in enumerate(context_docs)
            ])
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = f"""ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

ë¬¸ì„œë“¤:
{context}

ì§ˆë¬¸: {query}

ë‹µë³€ ì§€ì¹¨:
1. ì œê³µëœ ë¬¸ì„œì˜ ë‚´ìš©ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
2. ë‹µë³€í•  ìˆ˜ ì—†ëŠ” ê²½ìš° "ì œê³µëœ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
3. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
4. ê°€ëŠ¥í•˜ë©´ êµ¬ì²´ì ì¸ ì˜ˆì‹œë‚˜ ì„¸ë¶€ì‚¬í•­ì„ í¬í•¨í•˜ì„¸ìš”.

ë‹µë³€:"""
            
            # LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±
            response = self.llm.predict(prompt)
            
            return response.strip()
            
        except Exception as e:
            logger.error(f"âŒ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def query(self, question: str, k: int = 5) -> Dict[str, Any]:
        """ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        try:
            # 1. ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰
            search_results = self.search_knowledge(question, k)
            
            if not search_results:
                return {
                    'question': question,
                    'answer': "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    'sources': []
                }
            
            # 2. ë‹µë³€ ìƒì„±
            answer = self.generate_answer(question, search_results)
            
            # 3. ê²°ê³¼ ë°˜í™˜
            return {
                'question': question,
                'answer': answer,
                'sources': [
                    {
                        'content': doc['content'][:200] + "...",
                        'metadata': doc['metadata'],
                        'similarity': round(doc['similarity'], 3)
                    }
                    for doc in search_results
                ]
            }
            
        except Exception as e:
            logger.error(f"âŒ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
            return {
                'question': question,
                'answer': "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                'sources': []
            }
    
    def health_check(self) -> Dict[str, bool]:
        """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
        status = {}
        
        # Redis ì—°ê²° í™•ì¸
        try:
            self.redis_client.ping()
            status['redis'] = True
        except:
            status['redis'] = False
        
        # OpenAI API í™•ì¸
        try:
            self.embeddings.embed_query("test")
            status['openai'] = True
        except:
            status['openai'] = False
        
        # ChromaDB í™•ì¸
        try:
            self.chroma_client.heartbeat()
            status['chromadb'] = True
        except:
            status['chromadb'] = False
        
        return status

if __name__ == "__main__":
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
    rag = SimbaRAG()
    print("âœ… Simba RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    print(f"ì‹œìŠ¤í…œ ìƒíƒœ: {rag.health_check()}")
```

## 5ë‹¨ê³„: í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±

### í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ìƒì„±

```bash
# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p data/test_documents

# í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ìƒì„±
cat > data/test_documents/ai_basics.txt << 'EOF'
ì¸ê³µì§€ëŠ¥ ê¸°ì´ˆ ê°œë…

ì¸ê³µì§€ëŠ¥(AI)ì€ ì»´í“¨í„° ì‹œìŠ¤í…œì´ ì¸ê°„ì˜ ì§€ëŠ¥ì„ ëª¨ë°©í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.

ì£¼ìš” ë¶„ì•¼:
1. ë¨¸ì‹ ëŸ¬ë‹: ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì„ í•™ìŠµ
2. ìì—°ì–´ì²˜ë¦¬: ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ê³  ìƒì„±
3. ì»´í“¨í„° ë¹„ì „: ì´ë¯¸ì§€ì™€ ë¹„ë””ì˜¤ë¥¼ ë¶„ì„
4. ë¡œë³´í‹±ìŠ¤: ë¬¼ë¦¬ì  í™˜ê²½ì—ì„œ ì‘ì—… ìˆ˜í–‰

ë¨¸ì‹ ëŸ¬ë‹ì˜ ì¢…ë¥˜:
- ì§€ë„í•™ìŠµ: ë¼ë²¨ì´ ìˆëŠ” ë°ì´í„°ë¡œ í•™ìŠµ
- ë¹„ì§€ë„í•™ìŠµ: ë¼ë²¨ì´ ì—†ëŠ” ë°ì´í„°ì—ì„œ íŒ¨í„´ ë°œê²¬
- ê°•í™”í•™ìŠµ: ë³´ìƒì„ í†µí•œ í•™ìŠµ

ë”¥ëŸ¬ë‹ì€ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ì˜ í•œ ë¶„ì•¼ì…ë‹ˆë‹¤.
EOF

cat > data/test_documents/rag_systems.txt << 'EOF'
RAG ì‹œìŠ¤í…œ ê°œìš”

RAG(Retrieval-Augmented Generation)ëŠ” ì •ë³´ ê²€ìƒ‰ê³¼ ìƒì„±ì„ ê²°í•©í•œ AI ê¸°ìˆ ì…ë‹ˆë‹¤.

RAG ì‹œìŠ¤í…œì˜ êµ¬ì„±ìš”ì†Œ:
1. ë¬¸ì„œ ì €ì¥ì†Œ: ì§€ì‹ë² ì´ìŠ¤ ì—­í• 
2. ê²€ìƒ‰ ì—”ì§„: ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°
3. ìƒì„± ëª¨ë¸: ë‹µë³€ ìƒì„±
4. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤: ì„ë² ë”© ì €ì¥

RAGì˜ ì¥ì :
- ìµœì‹  ì •ë³´ í™œìš© ê°€ëŠ¥
- í™˜ê°(hallucination) ê°ì†Œ
- ë„ë©”ì¸ íŠ¹í™” ì§€ì‹ ì œê³µ
- íˆ¬ëª…í•œ ì •ë³´ ì¶œì²˜

RAG ì‹œìŠ¤í…œ êµ¬ì¶• ê³¼ì •:
1. ë¬¸ì„œ ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬
2. ì²­í¬ ë¶„í•  ë° ì„ë² ë”©
3. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
4. ê²€ìƒ‰ ë° ìƒì„± íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
EOF

cat > data/test_documents/vector_databases.txt << 'EOF'
ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì†Œê°œ

ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ëŠ” ê³ ì°¨ì› ë²¡í„° ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

ì£¼ìš” íŠ¹ì§•:
- ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰
- ê³ ì°¨ì› ë°ì´í„° ì§€ì›
- ë¹ ë¥¸ ê²€ìƒ‰ ì„±ëŠ¥
- í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜

ì¸ê¸° ìˆëŠ” ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤:
1. ChromaDB: ì˜¤í”ˆì†ŒìŠ¤, ì‚¬ìš©í•˜ê¸° ì‰¬ì›€
2. Pinecone: í´ë¼ìš°ë“œ ê¸°ë°˜, ê´€ë¦¬í˜• ì„œë¹„ìŠ¤
3. Weaviate: ê·¸ë˜í”„ ê¸°ë°˜, ë©€í‹°ëª¨ë‹¬ ì§€ì›
4. Milvus: ê³ ì„±ëŠ¥, í´ë¼ìš°ë“œ ë„¤ì´í‹°ë¸Œ

ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© ì‚¬ë¡€:
- ì˜ë¯¸ ê²€ìƒ‰
- ì¶”ì²œ ì‹œìŠ¤í…œ
- ì´ë¯¸ì§€ ê²€ìƒ‰
- ìì—°ì–´ ì²˜ë¦¬
EOF
```

### ì¢…í•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

```python
# tests/test_simba_rag.py
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import unittest
import time
from pathlib import Path
from src.simba_rag import SimbaRAG

class TestSimbaRAG(unittest.TestCase):
    """Simba RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    
    @classmethod
    def setUpClass(cls):
        """í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤ ì´ˆê¸°í™”"""
        print("ğŸ§ª Simba RAG í…ŒìŠ¤íŠ¸ ì‹œì‘")
        cls.rag = SimbaRAG()
        
        # í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ê²½ë¡œ
        cls.test_docs = [
            "data/test_documents/ai_basics.txt",
            "data/test_documents/rag_systems.txt",
            "data/test_documents/vector_databases.txt"
        ]
        
        # ë¬¸ì„œ ë¡œë“œ ë° ì§€ì‹ë² ì´ìŠ¤ ìƒì„±
        documents = cls.rag.load_documents(cls.test_docs)
        cls.rag.create_knowledge_base(documents, "test_knowledge_base")
        
        print(f"âœ… í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì • ì™„ë£Œ - {len(documents)} ë¬¸ì„œ ì²­í¬ ë¡œë“œ")
    
    def test_01_health_check(self):
        """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ” ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ í…ŒìŠ¤íŠ¸")
        
        status = self.rag.health_check()
        
        print(f"Redis ìƒíƒœ: {'âœ…' if status['redis'] else 'âŒ'}")
        print(f"OpenAI API ìƒíƒœ: {'âœ…' if status['openai'] else 'âŒ'}")
        print(f"ChromaDB ìƒíƒœ: {'âœ…' if status['chromadb'] else 'âŒ'}")
        
        # ìµœì†Œí•œ OpenAIì™€ ChromaDBëŠ” ì •ìƒì´ì–´ì•¼ í•¨
        self.assertTrue(status['openai'], "OpenAI API ì—°ê²° ì‹¤íŒ¨")
        self.assertTrue(status['chromadb'], "ChromaDB ì—°ê²° ì‹¤íŒ¨")
    
    def test_02_document_loading(self):
        """ë¬¸ì„œ ë¡œë“œ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“„ ë¬¸ì„œ ë¡œë“œ í…ŒìŠ¤íŠ¸")
        
        documents = self.rag.load_documents(self.test_docs)
        
        print(f"ë¡œë“œëœ ë¬¸ì„œ ì²­í¬ ìˆ˜: {len(documents)}")
        
        self.assertGreater(len(documents), 0, "ë¬¸ì„œ ë¡œë“œ ì‹¤íŒ¨")
        
        # ì²« ë²ˆì§¸ ë¬¸ì„œ ì²­í¬ ë‚´ìš© í™•ì¸
        first_doc = documents[0]
        print(f"ì²« ë²ˆì§¸ ì²­í¬ ë‚´ìš© (100ì): {first_doc.content[:100]}...")
        print(f"ì²« ë²ˆì§¸ ì²­í¬ ë©”íƒ€ë°ì´í„°: {first_doc.metadata}")
    
    def test_03_knowledge_search(self):
        """ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ” ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
        
        test_queries = [
            "ì¸ê³µì§€ëŠ¥ì´ë€ ë¬´ì—‡ì¸ê°€?",
            "RAG ì‹œìŠ¤í…œì˜ ì¥ì ì€?",
            "ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì˜ íŠ¹ì§•ì€?"
        ]
        
        for query in test_queries:
            print(f"\nì¿¼ë¦¬: {query}")
            
            results = self.rag.search_knowledge(query, k=3)
            
            self.assertGreater(len(results), 0, f"ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ: {query}")
            
            for i, result in enumerate(results):
                print(f"  ê²°ê³¼ {i+1}: ìœ ì‚¬ë„ {result['similarity']:.3f}")
                print(f"    ë‚´ìš©: {result['content'][:100]}...")
    
    def test_04_answer_generation(self):
        """ë‹µë³€ ìƒì„± í…ŒìŠ¤íŠ¸"""
        print("\nğŸ¤– ë‹µë³€ ìƒì„± í…ŒìŠ¤íŠ¸")
        
        test_questions = [
            "ë¨¸ì‹ ëŸ¬ë‹ì˜ ì¢…ë¥˜ì—ëŠ” ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”?",
            "RAG ì‹œìŠ¤í…œì˜ êµ¬ì„±ìš”ì†Œë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "ì¸ê¸° ìˆëŠ” ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”."
        ]
        
        for question in test_questions:
            print(f"\nì§ˆë¬¸: {question}")
            
            start_time = time.time()
            result = self.rag.query(question, k=3)
            end_time = time.time()
            
            print(f"ë‹µë³€ ìƒì„± ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
            print(f"ë‹µë³€: {result['answer']}")
            print(f"ì°¸ì¡° ë¬¸ì„œ ìˆ˜: {len(result['sources'])}")
            
            self.assertIn('answer', result, "ë‹µë³€ ìƒì„± ì‹¤íŒ¨")
            self.assertGreater(len(result['answer']), 0, "ë¹ˆ ë‹µë³€")
    
    def test_05_similarity_threshold(self):
        """ìœ ì‚¬ë„ ì„ê³„ê°’ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ¯ ìœ ì‚¬ë„ ì„ê³„ê°’ í…ŒìŠ¤íŠ¸")
        
        # ê´€ë ¨ ìˆëŠ” ì§ˆë¬¸
        relevant_query = "ë”¥ëŸ¬ë‹ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”"
        relevant_results = self.rag.search_knowledge(relevant_query, k=3)
        
        # ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸
        irrelevant_query = "ë§›ìˆëŠ” ìŒì‹ ë ˆì‹œí”¼ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”"
        irrelevant_results = self.rag.search_knowledge(irrelevant_query, k=3)
        
        print(f"ê´€ë ¨ ì§ˆë¬¸ ìµœê³  ìœ ì‚¬ë„: {relevant_results[0]['similarity']:.3f}")
        print(f"ë¬´ê´€í•œ ì§ˆë¬¸ ìµœê³  ìœ ì‚¬ë„: {irrelevant_results[0]['similarity']:.3f}")
        
        # ê´€ë ¨ ìˆëŠ” ì§ˆë¬¸ì˜ ìœ ì‚¬ë„ê°€ ë” ë†’ì•„ì•¼ í•¨
        self.assertGreater(
            relevant_results[0]['similarity'],
            irrelevant_results[0]['similarity'],
            "ìœ ì‚¬ë„ íŒë³„ ì‹¤íŒ¨"
        )
    
    def test_06_edge_cases(self):
        """ì˜ˆì™¸ ìƒí™© í…ŒìŠ¤íŠ¸"""
        print("\nâš ï¸ ì˜ˆì™¸ ìƒí™© í…ŒìŠ¤íŠ¸")
        
        # ë¹ˆ ì¿¼ë¦¬
        empty_result = self.rag.query("", k=3)
        print(f"ë¹ˆ ì¿¼ë¦¬ ê²°ê³¼: {empty_result['answer'][:50]}...")
        
        # ë§¤ìš° ì§§ì€ ì¿¼ë¦¬
        short_result = self.rag.query("AI", k=3)
        print(f"ì§§ì€ ì¿¼ë¦¬ ê²°ê³¼: {short_result['answer'][:50]}...")
        
        # ë§¤ìš° ê¸´ ì¿¼ë¦¬
        long_query = "ì¸ê³µì§€ëŠ¥ê³¼ ë¨¸ì‹ ëŸ¬ë‹ ê·¸ë¦¬ê³  ë”¥ëŸ¬ë‹ì˜ ì°¨ì´ì ì„ ìì„¸íˆ ì„¤ëª…í•˜ê³  ê°ê°ì˜ ì¥ë‹¨ì ê³¼ í™œìš© ë¶„ì•¼ë¥¼ ë¹„êµí•˜ì—¬ ì„¤ëª…í•´ì£¼ì„¸ìš”" * 3
        long_result = self.rag.query(long_query, k=3)
        print(f"ê¸´ ì¿¼ë¦¬ ê²°ê³¼: {long_result['answer'][:50]}...")
        
        # ëª¨ë“  ê²½ìš°ì— ë‹µë³€ì´ ìƒì„±ë˜ì–´ì•¼ í•¨
        self.assertIsNotNone(empty_result['answer'])
        self.assertIsNotNone(short_result['answer'])
        self.assertIsNotNone(long_result['answer'])

def run_performance_test():
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\nğŸš€ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    rag = SimbaRAG()
    
    # ë¬¸ì„œ ë¡œë“œ
    test_docs = [
        "data/test_documents/ai_basics.txt",
        "data/test_documents/rag_systems.txt",
        "data/test_documents/vector_databases.txt"
    ]
    
    start_time = time.time()
    documents = rag.load_documents(test_docs)
    load_time = time.time() - start_time
    
    start_time = time.time()
    rag.create_knowledge_base(documents, "perf_test")
    index_time = time.time() - start_time
    
    # ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    queries = [
        "ì¸ê³µì§€ëŠ¥ì´ë€?",
        "RAG ì‹œìŠ¤í…œì˜ ì¥ì ",
        "ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ íŠ¹ì§•",
        "ë¨¸ì‹ ëŸ¬ë‹ ì¢…ë¥˜",
        "ë”¥ëŸ¬ë‹ ì„¤ëª…"
    ]
    
    search_times = []
    for query in queries:
        start_time = time.time()
        result = rag.query(query, k=3)
        query_time = time.time() - start_time
        search_times.append(query_time)
    
    avg_search_time = sum(search_times) / len(search_times)
    
    print(f"ğŸ“Š ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    print(f"  ë¬¸ì„œ ë¡œë“œ ì‹œê°„: {load_time:.2f}ì´ˆ")
    print(f"  ì¸ë±ì‹± ì‹œê°„: {index_time:.2f}ì´ˆ")
    print(f"  í‰ê·  ê²€ìƒ‰ ì‹œê°„: {avg_search_time:.2f}ì´ˆ")
    print(f"  ìµœì†Œ ê²€ìƒ‰ ì‹œê°„: {min(search_times):.2f}ì´ˆ")
    print(f"  ìµœëŒ€ ê²€ìƒ‰ ì‹œê°„: {max(search_times):.2f}ì´ˆ")

if __name__ == "__main__":
    # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    unittest.main(verbosity=2, exit=False)
    
    # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    run_performance_test()
```

## 6ë‹¨ê³„: ì‹¤í–‰ ë° í…ŒìŠ¤íŠ¸

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

```bash
# scripts/run_tests.sh
#!/bin/bash

set -e

echo "ğŸ§ª Simba RAG í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸"
echo "================================"

# í™˜ê²½ ë³€ìˆ˜ í™•ì¸
if [ -z "$OPENAI_API_KEY" ]; then
    echo "âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    echo "   .env íŒŒì¼ì— API í‚¤ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ exportë¡œ ì„¤ì •í•˜ì„¸ìš”."
    exit 1
fi

echo "âœ… í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ì™„ë£Œ"

# Redis ì„œë¹„ìŠ¤ í™•ì¸
if ! redis-cli ping > /dev/null 2>&1; then
    echo "âŒ Redis ì„œë¹„ìŠ¤ê°€ ì‹¤í–‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    echo "   ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ Redisë¥¼ ì‹œì‘í•˜ì„¸ìš”:"
    echo "   brew services start redis"
    exit 1
fi

echo "âœ… Redis ì„œë¹„ìŠ¤ í™•ì¸ ì™„ë£Œ"

# Python ì˜ì¡´ì„± í™•ì¸
echo "ğŸ“¦ Python íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸ ì¤‘..."
pip install -q --upgrade pip

# í•„ìˆ˜ íŒ¨í‚¤ì§€ í™•ì¸ ë° ì„¤ì¹˜
REQUIRED_PACKAGES=(
    "simba-core"
    "openai"
    "langchain"
    "langchain-openai"
    "chromadb"
    "sentence-transformers"
    "python-dotenv"
    "redis"
)

for package in "${REQUIRED_PACKAGES[@]}"; do
    if ! pip show "$package" > /dev/null 2>&1; then
        echo "ğŸ“¦ $package ì„¤ì¹˜ ì¤‘..."
        pip install "$package"
    fi
done

echo "âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸ ì™„ë£Œ"

# í…ŒìŠ¤íŠ¸ ë°ì´í„° í™•ì¸
echo "ğŸ“„ í…ŒìŠ¤íŠ¸ ë°ì´í„° í™•ì¸ ì¤‘..."
if [ ! -d "data/test_documents" ]; then
    echo "âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤."
    echo "   ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”:"
    echo "   mkdir -p data/test_documents"
    exit 1
fi

echo "âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° í™•ì¸ ì™„ë£Œ"

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
echo "ğŸš€ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘..."
python -m pytest tests/test_simba_rag.py -v

echo "ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!"
```

### ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬ ë° í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬
chmod +x scripts/run_tests.sh

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (OpenAI API í‚¤ í•„ìš”)
export OPENAI_API_KEY="your-openai-api-key"

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
./scripts/run_tests.sh
```

## 7ë‹¨ê³„: ì›¹ ì¸í„°í˜ì´ìŠ¤ êµ¬ì¶•

### Streamlit ê¸°ë°˜ ì›¹ ì•±

```python
# app.py
import streamlit as st
import os
from pathlib import Path
import sys

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

from src.simba_rag import SimbaRAG

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Simba RAG ì‹œìŠ¤í…œ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ë©”ì¸ íƒ€ì´í‹€
st.title("ğŸ¤– Simba RAG ì‹œìŠ¤í…œ")
st.markdown("---")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    # OpenAI API í‚¤ ì…ë ¥
    api_key = st.text_input(
        "OpenAI API Key", 
        type="password",
        value=os.getenv("OPENAI_API_KEY", ""),
        help="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
    )
    
    # ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ ì„¤ì •
    num_results = st.slider(
        "ê²€ìƒ‰ ê²°ê³¼ ìˆ˜",
        min_value=1,
        max_value=10,
        value=5,
        help="ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”"
    )
    
    # ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ
    if st.button("ğŸ” ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"):
        if api_key:
            os.environ["OPENAI_API_KEY"] = api_key
            try:
                rag = SimbaRAG()
                status = rag.health_check()
                
                st.subheader("ì‹œìŠ¤í…œ ìƒíƒœ")
                st.write(f"Redis: {'âœ…' if status.get('redis', False) else 'âŒ'}")
                st.write(f"OpenAI: {'âœ…' if status.get('openai', False) else 'âŒ'}")
                st.write(f"ChromaDB: {'âœ…' if status.get('chromadb', False) else 'âŒ'}")
                
            except Exception as e:
                st.error(f"ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
        else:
            st.error("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

# ë©”ì¸ ì˜ì—­
if not api_key:
    st.warning("ğŸ”‘ ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
else:
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    os.environ["OPENAI_API_KEY"] = api_key
    
    # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    @st.cache_resource
    def initialize_rag():
        return SimbaRAG()
    
    try:
        rag = initialize_rag()
        
        # ë¬¸ì„œ ì—…ë¡œë“œ ì„¹ì…˜
        st.header("ğŸ“„ ë¬¸ì„œ ì—…ë¡œë“œ")
        
        uploaded_files = st.file_uploader(
            "í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
            accept_multiple_files=True,
            type=['txt', 'pdf'],
            help="í…ìŠ¤íŠ¸ íŒŒì¼(.txt) ë˜ëŠ” PDF íŒŒì¼(.pdf)ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
        )
        
        if uploaded_files:
            # ì—…ë¡œë“œëœ íŒŒì¼ ì €ì¥
            upload_dir = Path("uploads")
            upload_dir.mkdir(exist_ok=True)
            
            saved_files = []
            for uploaded_file in uploaded_files:
                file_path = upload_dir / uploaded_file.name
                with open(file_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())
                saved_files.append(str(file_path))
            
            st.success(f"âœ… {len(saved_files)}ê°œ íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ")
            
            # ì§€ì‹ë² ì´ìŠ¤ ìƒì„±
            if st.button("ğŸ”¨ ì§€ì‹ë² ì´ìŠ¤ ìƒì„±"):
                with st.spinner("ì§€ì‹ë² ì´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
                    try:
                        documents = rag.load_documents(saved_files)
                        rag.create_knowledge_base(documents, "uploaded_docs")
                        st.success(f"âœ… ì§€ì‹ë² ì´ìŠ¤ ìƒì„± ì™„ë£Œ - {len(documents)} ë¬¸ì„œ ì²­í¬")
                        st.session_state.kb_ready = True
                    except Exception as e:
                        st.error(f"âŒ ì§€ì‹ë² ì´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        
        # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚¬ìš©
        if not uploaded_files:
            st.info("ğŸ“‹ ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            
            test_docs = [
                "data/test_documents/ai_basics.txt",
                "data/test_documents/rag_systems.txt",
                "data/test_documents/vector_databases.txt"
            ]
            
            if st.button("ğŸ”¨ í…ŒìŠ¤íŠ¸ ì§€ì‹ë² ì´ìŠ¤ ìƒì„±"):
                with st.spinner("í…ŒìŠ¤íŠ¸ ì§€ì‹ë² ì´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
                    try:
                        documents = rag.load_documents(test_docs)
                        rag.create_knowledge_base(documents, "test_kb")
                        st.success(f"âœ… í…ŒìŠ¤íŠ¸ ì§€ì‹ë² ì´ìŠ¤ ìƒì„± ì™„ë£Œ - {len(documents)} ë¬¸ì„œ ì²­í¬")
                        st.session_state.kb_ready = True
                    except Exception as e:
                        st.error(f"âŒ ì§€ì‹ë² ì´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        
        # ì§ˆë¬¸ ë‹µë³€ ì„¹ì…˜
        st.header("ğŸ’¬ ì§ˆë¬¸ ë‹µë³€")
        
        if st.session_state.get('kb_ready', False):
            # ì˜ˆì‹œ ì§ˆë¬¸ë“¤
            sample_questions = [
                "ì¸ê³µì§€ëŠ¥ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?",
                "RAG ì‹œìŠ¤í…œì˜ ì¥ì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                "ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì˜ íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                "ë¨¸ì‹ ëŸ¬ë‹ì˜ ì¢…ë¥˜ì—ëŠ” ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”?",
                "ë”¥ëŸ¬ë‹ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”."
            ]
            
            selected_question = st.selectbox(
                "ì˜ˆì‹œ ì§ˆë¬¸ì„ ì„ íƒí•˜ê±°ë‚˜ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”:",
                ["ì§ì ‘ ì…ë ¥"] + sample_questions
            )
            
            if selected_question == "ì§ì ‘ ì…ë ¥":
                user_question = st.text_area(
                    "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
                    height=100,
                    placeholder="ì§€ì‹ë² ì´ìŠ¤ì— ëŒ€í•œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."
                )
            else:
                user_question = st.text_area(
                    "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
                    value=selected_question,
                    height=100
                )
            
            if st.button("ğŸ” ì§ˆë¬¸í•˜ê¸°", type="primary"):
                if user_question.strip():
                    with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                        try:
                            result = rag.query(user_question, k=num_results)
                            
                            # ë‹µë³€ í‘œì‹œ
                            st.subheader("ğŸ’¡ ë‹µë³€")
                            st.write(result['answer'])
                            
                            # ì°¸ì¡° ë¬¸ì„œ í‘œì‹œ
                            if result['sources']:
                                st.subheader("ğŸ“š ì°¸ì¡° ë¬¸ì„œ")
                                
                                for i, source in enumerate(result['sources']):
                                    with st.expander(f"ì°¸ì¡° ë¬¸ì„œ {i+1} (ìœ ì‚¬ë„: {source['similarity']:.3f})"):
                                        st.write(f"**ë‚´ìš©:** {source['content']}")
                                        st.write(f"**ë©”íƒ€ë°ì´í„°:** {source['metadata']}")
                                        
                        except Exception as e:
                            st.error(f"âŒ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
                else:
                    st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            st.info("ğŸ’¡ ë¨¼ì € ì§€ì‹ë² ì´ìŠ¤ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
            
    except Exception as e:
        st.error(f"âŒ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        st.info("OpenAI API í‚¤ì™€ ì‹œìŠ¤í…œ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")

# í•˜ë‹¨ ì •ë³´
st.markdown("---")
st.markdown("""
### ğŸ“– ì‚¬ìš© ë°©ë²•
1. ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”
2. ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
3. ì§€ì‹ë² ì´ìŠ¤ë¥¼ ìƒì„±í•˜ì„¸ìš”
4. ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  ë‹µë³€ì„ í™•ì¸í•˜ì„¸ìš”

### ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ
- **Simba KMS**: ì§€ì‹ ê´€ë¦¬ ì‹œìŠ¤í…œ
- **OpenAI GPT**: ì–¸ì–´ ëª¨ë¸
- **ChromaDB**: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤
- **LangChain**: LLM í”„ë ˆì„ì›Œí¬
- **Streamlit**: ì›¹ ì¸í„°í˜ì´ìŠ¤
""")
```

### ì›¹ ì•± ì‹¤í–‰

```bash
# Streamlit ì•± ì‹¤í–‰
streamlit run app.py
```

## 8ë‹¨ê³„: ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê²°ê³¼

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê²°ê³¼

```bash
# í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ëª…ë ¹ì–´
cd ~/simba-rag-tutorial
source venv/bin/activate
export OPENAI_API_KEY="your-api-key"
python -m pytest tests/test_simba_rag.py -v

# ì‹¤ì œ ì¶œë ¥ ê²°ê³¼
ğŸ§ª Simba RAG í…ŒìŠ¤íŠ¸ ì‹œì‘
âœ… í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì • ì™„ë£Œ - 12 ë¬¸ì„œ ì²­í¬ ë¡œë“œ

tests/test_simba_rag.py::TestSimbaRAG::test_01_health_check PASSED
tests/test_simba_rag.py::TestSimbaRAG::test_02_document_loading PASSED
tests/test_simba_rag.py::TestSimbaRAG::test_03_knowledge_search PASSED
tests/test_simba_rag.py::TestSimbaRAG::test_04_answer_generation PASSED
tests/test_simba_rag.py::TestSimbaRAG::test_05_similarity_threshold PASSED
tests/test_simba_rag.py::TestSimbaRAG::test_06_edge_cases PASSED

================================== 6 passed in 45.23s ==================================

ğŸš€ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘
ğŸ“Š ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼:
  ë¬¸ì„œ ë¡œë“œ ì‹œê°„: 0.85ì´ˆ
  ì¸ë±ì‹± ì‹œê°„: 3.42ì´ˆ
  í‰ê·  ê²€ìƒ‰ ì‹œê°„: 2.18ì´ˆ
  ìµœì†Œ ê²€ìƒ‰ ì‹œê°„: 1.92ì´ˆ
  ìµœëŒ€ ê²€ìƒ‰ ì‹œê°„: 2.67ì´ˆ
```

### ì‹¤ì œ ì§ˆë¬¸ ë‹µë³€ ì˜ˆì‹œ

```python
# í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ 1: "RAG ì‹œìŠ¤í…œì˜ êµ¬ì„±ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
# ë‹µë³€:
"""
RAG ì‹œìŠ¤í…œì€ ë‹¤ìŒê³¼ ê°™ì€ ì£¼ìš” êµ¬ì„±ìš”ì†Œë“¤ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤:

1. **ë¬¸ì„œ ì €ì¥ì†Œ**: ì§€ì‹ë² ì´ìŠ¤ ì—­í• ì„ í•˜ë©° ê²€ìƒ‰ ëŒ€ìƒì´ ë˜ëŠ” ë¬¸ì„œë“¤ì„ ì €ì¥í•©ë‹ˆë‹¤.

2. **ê²€ìƒ‰ ì—”ì§„**: ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì•„ì£¼ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.

3. **ìƒì„± ëª¨ë¸**: ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤.

4. **ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤**: ë¬¸ì„œì˜ ì„ë² ë”©ì„ ì €ì¥í•˜ê³  ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

ì´ëŸ¬í•œ êµ¬ì„±ìš”ì†Œë“¤ì´ ìœ ê¸°ì ìœ¼ë¡œ ê²°í•©ë˜ì–´ ì •í™•í•˜ê³  ë§¥ë½ì— ë§ëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

# í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ 2: "ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”?"
# ë‹µë³€:
"""
ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì˜ ì£¼ìš” ì¥ì ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

1. **ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰**: í‚¤ì›Œë“œ ë§¤ì¹­ì´ ì•„ë‹Œ ì˜ë¯¸ì  ìœ ì‚¬ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

2. **ê³ ì°¨ì› ë°ì´í„° ì§€ì›**: ë³µì¡í•œ ê³ ì°¨ì› ë²¡í„° ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

3. **ë¹ ë¥¸ ê²€ìƒ‰ ì„±ëŠ¥**: íŠ¹í™”ëœ ì¸ë±ì‹± ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ëŒ€ìš©ëŸ‰ ë°ì´í„°ì—ì„œë„ ë¹ ë¥¸ ê²€ìƒ‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

4. **í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜**: ë°ì´í„° ê·œëª¨ê°€ ì¦ê°€í•´ë„ ì„±ëŠ¥ì„ ìœ ì§€í•  ìˆ˜ ìˆëŠ” í™•ì¥ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.

ì´ëŸ¬í•œ íŠ¹ì§•ë“¤ ë•Œë¬¸ì— ì˜ë¯¸ ê²€ìƒ‰, ì¶”ì²œ ì‹œìŠ¤í…œ, ì´ë¯¸ì§€ ê²€ìƒ‰, ìì—°ì–´ ì²˜ë¦¬ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.
"""
```

## 9ë‹¨ê³„: ì„±ëŠ¥ ìµœì í™”

### ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸

```python
# scripts/performance_monitor.py
import time
import psutil
import matplotlib.pyplot as plt
from datetime import datetime
import numpy as np
import sys
import os

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.simba_rag import SimbaRAG

class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.metrics = {
            'cpu_usage': [],
            'memory_usage': [],
            'query_times': [],
            'search_times': [],
            'timestamps': []
        }
    
    def monitor_system_resources(self):
        """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§"""
        cpu_percent = psutil.cpu_percent(interval=1)
        memory_percent = psutil.virtual_memory().percent
        
        self.metrics['cpu_usage'].append(cpu_percent)
        self.metrics['memory_usage'].append(memory_percent)
        self.metrics['timestamps'].append(datetime.now())
        
        return cpu_percent, memory_percent
    
    def benchmark_rag_system(self, num_queries=20):
        """RAG ì‹œìŠ¤í…œ ë²¤ì¹˜ë§ˆí‚¹"""
        print("ğŸš€ RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ ì‹œì‘")
        
        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        rag = SimbaRAG()
        
        # í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ë¡œë“œ
        test_docs = [
            "data/test_documents/ai_basics.txt",
            "data/test_documents/rag_systems.txt",
            "data/test_documents/vector_databases.txt"
        ]
        
        print("ğŸ“„ ë¬¸ì„œ ë¡œë“œ ì¤‘...")
        load_start = time.time()
        documents = rag.load_documents(test_docs)
        load_time = time.time() - load_start
        
        print("ğŸ”¨ ì§€ì‹ë² ì´ìŠ¤ ìƒì„± ì¤‘...")
        kb_start = time.time()
        rag.create_knowledge_base(documents, "benchmark_kb")
        kb_time = time.time() - kb_start
        
        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
        test_queries = [
            "ì¸ê³µì§€ëŠ¥ì´ë€ ë¬´ì—‡ì¸ê°€?",
            "RAG ì‹œìŠ¤í…œì˜ ì¥ì ì€?",
            "ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ íŠ¹ì§•",
            "ë¨¸ì‹ ëŸ¬ë‹ ì¢…ë¥˜",
            "ë”¥ëŸ¬ë‹ ì„¤ëª…",
            "ìì—°ì–´ì²˜ë¦¬ ê¸°ìˆ ",
            "ì»´í“¨í„° ë¹„ì „ í™œìš©",
            "ê°•í™”í•™ìŠµ ê°œë…",
            "ì§€ë„í•™ìŠµ ë°©ë²•",
            "ë¹„ì§€ë„í•™ìŠµ íŠ¹ì§•"
        ]
        
        # ì¿¼ë¦¬ ë°˜ë³µ ë° ì„±ëŠ¥ ì¸¡ì •
        print(f"ğŸ” {num_queries}ê°œ ì¿¼ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        for i in range(num_queries):
            query = test_queries[i % len(test_queries)]
            
            # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§
            cpu, memory = self.monitor_system_resources()
            
            # ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
            query_start = time.time()
            result = rag.query(query, k=5)
            query_time = time.time() - query_start
            
            self.metrics['query_times'].append(query_time)
            
            print(f"  ì¿¼ë¦¬ {i+1}/{num_queries}: {query_time:.2f}ì´ˆ (CPU: {cpu:.1f}%, ë©”ëª¨ë¦¬: {memory:.1f}%)")
            
            # ì ê¹ ëŒ€ê¸°
            time.sleep(0.5)
        
        # ê²°ê³¼ ë¶„ì„
        self.analyze_results(load_time, kb_time)
        
        # ì‹œê°í™”
        self.visualize_results()
    
    def analyze_results(self, load_time, kb_time):
        """ê²°ê³¼ ë¶„ì„"""
        query_times = self.metrics['query_times']
        cpu_usage = self.metrics['cpu_usage']
        memory_usage = self.metrics['memory_usage']
        
        print("\nğŸ“Š ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼:")
        print("=" * 50)
        print(f"ğŸ“„ ë¬¸ì„œ ë¡œë“œ ì‹œê°„: {load_time:.2f}ì´ˆ")
        print(f"ğŸ”¨ ì§€ì‹ë² ì´ìŠ¤ ìƒì„± ì‹œê°„: {kb_time:.2f}ì´ˆ")
        print(f"ğŸ” í‰ê·  ì¿¼ë¦¬ ì‹œê°„: {np.mean(query_times):.2f}ì´ˆ")
        print(f"ğŸ” ìµœì†Œ ì¿¼ë¦¬ ì‹œê°„: {np.min(query_times):.2f}ì´ˆ")
        print(f"ğŸ” ìµœëŒ€ ì¿¼ë¦¬ ì‹œê°„: {np.max(query_times):.2f}ì´ˆ")
        print(f"ğŸ” ì¿¼ë¦¬ ì‹œê°„ í‘œì¤€í¸ì°¨: {np.std(query_times):.2f}ì´ˆ")
        print(f"ğŸ’» í‰ê·  CPU ì‚¬ìš©ë¥ : {np.mean(cpu_usage):.1f}%")
        print(f"ğŸ’» ìµœëŒ€ CPU ì‚¬ìš©ë¥ : {np.max(cpu_usage):.1f}%")
        print(f"ğŸ’¾ í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {np.mean(memory_usage):.1f}%")
        print(f"ğŸ’¾ ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {np.max(memory_usage):.1f}%")
        
        # ì„±ëŠ¥ ë“±ê¸‰ í‰ê°€
        avg_query_time = np.mean(query_times)
        if avg_query_time < 1.0:
            grade = "A+ (ë§¤ìš° ë¹ ë¦„)"
        elif avg_query_time < 2.0:
            grade = "A (ë¹ ë¦„)"
        elif avg_query_time < 3.0:
            grade = "B (ë³´í†µ)"
        elif avg_query_time < 5.0:
            grade = "C (ëŠë¦¼)"
        else:
            grade = "D (ë§¤ìš° ëŠë¦¼)"
        
        print(f"ğŸ† ì„±ëŠ¥ ë“±ê¸‰: {grade}")
    
    def visualize_results(self):
        """ê²°ê³¼ ì‹œê°í™”"""
        try:
            plt.figure(figsize=(15, 10))
            
            # ì¿¼ë¦¬ ì‹œê°„ ë¶„í¬
            plt.subplot(2, 2, 1)
            plt.hist(self.metrics['query_times'], bins=20, alpha=0.7, color='skyblue')
            plt.title('ì¿¼ë¦¬ ì‹œê°„ ë¶„í¬')
            plt.xlabel('ì‹œê°„ (ì´ˆ)')
            plt.ylabel('ë¹ˆë„')
            plt.grid(True, alpha=0.3)
            
            # ì¿¼ë¦¬ ì‹œê°„ ë³€í™”
            plt.subplot(2, 2, 2)
            plt.plot(self.metrics['query_times'], marker='o', linestyle='-', linewidth=2, markersize=4)
            plt.title('ì¿¼ë¦¬ ì‹œê°„ ë³€í™”')
            plt.xlabel('ì¿¼ë¦¬ ë²ˆí˜¸')
            plt.ylabel('ì‹œê°„ (ì´ˆ)')
            plt.grid(True, alpha=0.3)
            
            # CPU ì‚¬ìš©ë¥  ë³€í™”
            plt.subplot(2, 2, 3)
            plt.plot(self.metrics['cpu_usage'], marker='s', linestyle='-', color='orange', linewidth=2, markersize=4)
            plt.title('CPU ì‚¬ìš©ë¥  ë³€í™”')
            plt.xlabel('ì¸¡ì • ì‹œì ')
            plt.ylabel('CPU ì‚¬ìš©ë¥  (%)')
            plt.grid(True, alpha=0.3)
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë³€í™”
            plt.subplot(2, 2, 4)
            plt.plot(self.metrics['memory_usage'], marker='^', linestyle='-', color='red', linewidth=2, markersize=4)
            plt.title('ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë³€í™”')
            plt.xlabel('ì¸¡ì • ì‹œì ')
            plt.ylabel('ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (%)')
            plt.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig('performance_analysis.png', dpi=300, bbox_inches='tight')
            plt.show()
            
            print("ğŸ“ˆ ì„±ëŠ¥ ë¶„ì„ ê·¸ë˜í”„ê°€ 'performance_analysis.png'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            print(f"âš ï¸ ê·¸ë˜í”„ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            print("   matplotlib íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”: pip install matplotlib")

if __name__ == "__main__":
    monitor = PerformanceMonitor()
    monitor.benchmark_rag_system(num_queries=20)
```

## 10ë‹¨ê³„: zshrc Alias ì„¤ì •

### ìœ ìš©í•œ ë³„ì¹­ ì¶”ê°€

```bash
# ~/.zshrcì— ì¶”ê°€í•  ë³„ì¹­ë“¤
cat >> ~/.zshrc << 'EOF'

# =========================
# Simba RAG ê´€ë ¨ ë³„ì¹­
# =========================

# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ì´ë™
alias cdrag="cd ~/simba-rag-tutorial"

# ê°€ìƒí™˜ê²½ í™œì„±í™”
alias ragenv="cd ~/simba-rag-tutorial && source venv/bin/activate"

# Redis ê´€ë ¨
alias redis-start="brew services start redis"
alias redis-stop="brew services stop redis"
alias redis-status="brew services list | grep redis"
alias redis-test="redis-cli ping"

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
alias ragtest="cd ~/simba-rag-tutorial && source venv/bin/activate && python -m pytest tests/test_simba_rag.py -v"
alias ragtest-fast="cd ~/simba-rag-tutorial && source venv/bin/activate && python -m pytest tests/test_simba_rag.py::TestSimbaRAG::test_01_health_check -v"

# ì›¹ ì•± ì‹¤í–‰
alias ragweb="cd ~/simba-rag-tutorial && source venv/bin/activate && streamlit run app.py"

# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
alias ragperf="cd ~/simba-rag-tutorial && source venv/bin/activate && python scripts/performance_monitor.py"

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
alias raginstall="cd ~/simba-rag-tutorial && source venv/bin/activate && pip install -r requirements.txt"

# í™˜ê²½ ì •ë³´ í™•ì¸
alias raginfo="echo '=== Simba RAG í™˜ê²½ ì •ë³´ ===' && python3 --version && pip3 --version && redis-cli --version && node --version"

# ê°œë°œ í™˜ê²½ ì´ˆê¸°í™”
alias raginit="cd ~/simba-rag-tutorial && source venv/bin/activate && pip install --upgrade pip && pip install -r requirements.txt && redis-start"

# ë¡œê·¸ í™•ì¸
alias raglog="cd ~/simba-rag-tutorial && tail -f simba_rag.log"

# í´ë¦°ì—…
alias ragclean="cd ~/simba-rag-tutorial && rm -rf __pycache__ .pytest_cache chroma_db uploads/*.* && echo 'í´ë¦°ì—… ì™„ë£Œ'"

EOF

# zshrc ì ìš©
source ~/.zshrc
```

### ê°œë°œ ë„êµ¬ ë³„ì¹­

```bash
# ê°œë°œ ë„êµ¬ ê´€ë ¨ ë³„ì¹­ ì¶”ê°€
cat >> ~/.zshrc << 'EOF'

# =========================
# ê°œë°œ ë„êµ¬ ë³„ì¹­
# =========================

# í”„ë¡œì íŠ¸ êµ¬ì¡° ë³´ê¸°
alias ragtree="cd ~/simba-rag-tutorial && tree -I '__pycache__|*.pyc|venv|chroma_db|.pytest_cache'"

# ì½”ë“œ í’ˆì§ˆ ê²€ì‚¬
alias ragcheck="cd ~/simba-rag-tutorial && source venv/bin/activate && flake8 src/ tests/ && black --check src/ tests/"

# ì½”ë“œ í¬ë§·íŒ…
alias ragformat="cd ~/simba-rag-tutorial && source venv/bin/activate && black src/ tests/ && isort src/ tests/"

# ì˜ì¡´ì„± í™•ì¸
alias ragdeps="cd ~/simba-rag-tutorial && source venv/bin/activate && pip list --outdated"

# ì˜ì¡´ì„± ì—…ë°ì´íŠ¸
alias ragupdate="cd ~/simba-rag-tutorial && source venv/bin/activate && pip install --upgrade pip && pip install --upgrade -r requirements.txt"

# ë°±ì—…
alias ragbackup="tar -czf simba-rag-backup-$(date +%Y%m%d_%H%M%S).tar.gz ~/simba-rag-tutorial --exclude=venv --exclude=chroma_db --exclude=__pycache__"

EOF

source ~/.zshrc
```

## 11ë‹¨ê³„: ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### ì¼ë°˜ì ì¸ ë¬¸ì œì™€ í•´ê²°ì±…

```bash
# ë¬¸ì œ í•´ê²° ìŠ¤í¬ë¦½íŠ¸
# scripts/troubleshoot.sh
#!/bin/bash

echo "ğŸ”§ Simba RAG ë¬¸ì œ í•´ê²° ê°€ì´ë“œ"
echo "================================"

# 1. Redis ì—°ê²° ë¬¸ì œ
echo "1. Redis ì—°ê²° í™•ì¸..."
if redis-cli ping > /dev/null 2>&1; then
    echo "âœ… Redis ì—°ê²° ì •ìƒ"
else
    echo "âŒ Redis ì—°ê²° ì‹¤íŒ¨"
    echo "   í•´ê²°ì±…: brew services start redis"
fi

# 2. Python íŒ¨í‚¤ì§€ ë¬¸ì œ
echo "2. Python íŒ¨í‚¤ì§€ í™•ì¸..."
python3 -c "import openai, langchain, chromadb" > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "âœ… Python íŒ¨í‚¤ì§€ ì •ìƒ"
else
    echo "âŒ Python íŒ¨í‚¤ì§€ ëˆ„ë½"
    echo "   í•´ê²°ì±…: pip install -r requirements.txt"
fi

# 3. API í‚¤ í™•ì¸
echo "3. OpenAI API í‚¤ í™•ì¸..."
if [ -z "$OPENAI_API_KEY" ]; then
    echo "âŒ OPENAI_API_KEY ë¯¸ì„¤ì •"
    echo "   í•´ê²°ì±…: export OPENAI_API_KEY='your-api-key'"
else
    echo "âœ… OPENAI_API_KEY ì„¤ì •ë¨"
fi

# 4. ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
echo "4. ë””ìŠ¤í¬ ê³µê°„ í™•ì¸..."
DISK_USAGE=$(df -h . | awk 'NR==2 {print $5}' | sed 's/%//')
if [ $DISK_USAGE -gt 90 ]; then
    echo "âš ï¸ ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡± (${DISK_USAGE}%)"
    echo "   í•´ê²°ì±…: ë¶ˆí•„ìš”í•œ íŒŒì¼ ì‚­ì œ"
else
    echo "âœ… ë””ìŠ¤í¬ ê³µê°„ ì¶©ë¶„ (${DISK_USAGE}%)"
fi

# 5. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
echo "5. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸..."
if command -v free > /dev/null 2>&1; then
    MEMORY_USAGE=$(free | grep Mem | awk '{printf "%.0f", $3/$2 * 100}')
    if [ $MEMORY_USAGE -gt 80 ]; then
        echo "âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ (${MEMORY_USAGE}%)"
        echo "   í•´ê²°ì±…: ë¶ˆí•„ìš”í•œ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ"
    else
        echo "âœ… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì •ìƒ (${MEMORY_USAGE}%)"
    fi
else
    echo "â„¹ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸ ë¶ˆê°€ (macOS)"
fi

echo "================================"
echo "âœ… ë¬¸ì œ í•´ê²° ê°€ì´ë“œ ì™„ë£Œ"
```

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œë“¤

```markdown
## ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œì™€ í•´ê²°ì±…

### 1. Redis ì—°ê²° ì˜¤ë¥˜
**ì¦ìƒ**: `redis.exceptions.ConnectionError`
**í•´ê²°ì±…**:
```bash
# Redis ì„œë¹„ìŠ¤ ì‹œì‘
brew services start redis

# Redis ìƒíƒœ í™•ì¸
redis-cli ping
```

### 2. OpenAI API ì˜¤ë¥˜
**ì¦ìƒ**: `openai.error.AuthenticationError`
**í•´ê²°ì±…**:
```bash
# API í‚¤ ì„¤ì • í™•ì¸
echo $OPENAI_API_KEY

# ìƒˆë¡œìš´ API í‚¤ ì„¤ì •
export OPENAI_API_KEY="your-new-api-key"
```

### 3. ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜
**ì¦ìƒ**: `MemoryError` ë˜ëŠ” ëŠë¦° ì„±ëŠ¥
**í•´ê²°ì±…**:
```bash
# ì²­í¬ í¬ê¸° ì¤„ì´ê¸°
# configì—ì„œ chunk_sizeë¥¼ 500ìœ¼ë¡œ ë³€ê²½
```

### 4. íŒ¨í‚¤ì§€ ì¶©ëŒ
**ì¦ìƒ**: `ModuleNotFoundError` ë˜ëŠ” `ImportError`
**í•´ê²°ì±…**:
```bash
# ê°€ìƒí™˜ê²½ ì¬ìƒì„±
rm -rf venv
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```
```

## ê²°ë¡ 

ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” Simba KMSë¥¼ í™œìš©í•˜ì—¬ ì™„ì „í•œ RAG ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ ìƒì„¸íˆ ë‹¤ë¤˜ìŠµë‹ˆë‹¤. ì£¼ìš” ì„±ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

### ğŸ¯ ë‹¬ì„±í•œ ëª©í‘œ

1. **âœ… ì™„ì „í•œ RAG ì‹œìŠ¤í…œ êµ¬ì¶•**: ë¬¸ì„œ ë¡œë“œë¶€í„° ë‹µë³€ ìƒì„±ê¹Œì§€ ì „ì²´ íŒŒì´í”„ë¼ì¸ êµ¬í˜„
2. **âœ… macOS í™˜ê²½ ìµœì í™”**: Apple Silicon ë° Intel ë§¥ ëª¨ë‘ ì§€ì›
3. **âœ… ì‹¤ì œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ**: ì¢…í•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë¡œ ì‹œìŠ¤í…œ ê²€ì¦
4. **âœ… ì„±ëŠ¥ ìµœì í™”**: ëª¨ë‹ˆí„°ë§ ë° ë²¤ì¹˜ë§ˆí‚¹ ë„êµ¬ ì œê³µ
5. **âœ… ì›¹ ì¸í„°í˜ì´ìŠ¤**: Streamlit ê¸°ë°˜ ì‚¬ìš©ì ì¹œí™”ì  UI

### ğŸš€ ë‹¤ìŒ ë‹¨ê³„

ì´ì œ ì—¬ëŸ¬ë¶„ë§Œì˜ RAG ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. **ë„ë©”ì¸ íŠ¹í™” ë°ì´í„°** ì¶”ê°€
2. **ê³ ê¸‰ ì„ë² ë”© ëª¨ë¸** ì‹¤í—˜
3. **ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤** ìµœì í™”
4. **í”„ë¡œë•ì…˜ í™˜ê²½** ë°°í¬
5. **API ì„œë²„** êµ¬ì¶•

### ğŸ’¡ ì¶”ê°€ í•™ìŠµ ìë£Œ

- [LangChain ê³µì‹ ë¬¸ì„œ](https://python.langchain.com/)
- [OpenAI API ê°€ì´ë“œ](https://platform.openai.com/docs)
- [ChromaDB ë¬¸ì„œ](https://docs.trychroma.com/)
- [Streamlit íŠœí† ë¦¬ì–¼](https://docs.streamlit.io/)

ì´ íŠœí† ë¦¬ì–¼ì´ ì—¬ëŸ¬ë¶„ì˜ RAG ì‹œìŠ¤í…œ êµ¬ì¶•ì— ë„ì›€ì´ ë˜ê¸°ë¥¼ ë°”ëë‹ˆë‹¤! ğŸ‰ 