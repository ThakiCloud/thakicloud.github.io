---
title: "Open Deep Research ì™„ì „ ê°€ì´ë“œ - LangChain AI ì—ì´ì „íŠ¸ë¡œ êµ¬ì¶•í•˜ëŠ” ì°¨ì„¸ëŒ€ ì—°êµ¬ ìë™í™” ì‹œìŠ¤í…œ"
excerpt: "LangChain AIì˜ Open Deep Researchë¡œ ê³ ê¸‰ AI ì—°êµ¬ ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•˜ì„¸ìš”. LangGraph ê¸°ë°˜ì˜ ì„¤ì • ê°€ëŠ¥í•œ ì˜¤í”ˆì†ŒìŠ¤ ì†”ë£¨ì…˜ìœ¼ë¡œ ë‹¤ì¤‘ ëª¨ë¸, MCP ì„œë²„, í‰ê°€ ì‹œìŠ¤í…œê¹Œì§€ ì™„ë²½ êµ¬í˜„ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤."
seo_title: "Open Deep Research LangChain AI ì—ì´ì „íŠ¸ íŠœí† ë¦¬ì–¼ - ì—°êµ¬ ìë™í™” ì™„ì „ ê°€ì´ë“œ - Thaki Cloud"
seo_description: "LangChain AI Open Deep Research ì—ì´ì „íŠ¸ ì™„ì „ ì„¤ì¹˜ ë° í™œìš© ê°€ì´ë“œ. LangGraph Studio, MCP ì„œë²„ ì—°ë™, ë‹¤ì¤‘ ëª¨ë¸ ì„¤ì •, í‰ê°€ ì‹œìŠ¤í…œê¹Œì§€ AI ì—°êµ¬ ìë™í™”ì˜ ëª¨ë“  ê²ƒì„ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤."
date: 2025-08-01
last_modified_at: 2025-08-01
categories:
  - tutorials
  - ai-agents
tags:
  - Open-Deep-Research
  - LangChain-AI
  - LangGraph
  - AI-Agents
  - Research-Automation
  - MCP-Server
  - Multi-Agent
  - AI-Research
  - Python
  - OpenAI
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
toc_icon: "cog"
toc_sticky: true
canonical_url: "https://thakicloud.github.io/tutorials/open-deep-research-langchain-ai-agent-complete-guide/"
reading_time: true
---

â±ï¸ **ì˜ˆìƒ ì½ê¸° ì‹œê°„**: 20ë¶„

## ì„œë¡ : Open Deep Researchê°€ ë°”ê¾¸ëŠ” AI ì—°êµ¬ì˜ ë¯¸ë˜

AI ì—°êµ¬ ë¶„ì•¼ì—ì„œ ê°€ì¥ í˜ì‹ ì ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì¤‘ í•˜ë‚˜ì¸ **ë”¥ ë¦¬ì„œì¹˜(Deep Research)**ê°€ ìƒˆë¡œìš´ ì „í™˜ì ì„ ë§ê³  ìˆìŠµë‹ˆë‹¤. [LangChain AIì˜ Open Deep Research](https://github.com/langchain-ai/open_deep_research)ëŠ” ì´ëŸ¬í•œ ë³€í™”ë¥¼ ì£¼ë„í•˜ëŠ” ì™„ì „ ì˜¤í”ˆì†ŒìŠ¤ ì—°êµ¬ ìë™í™” ì—ì´ì „íŠ¸ë¡œ, ë³µì¡í•œ ì—°êµ¬ ê³¼ì •ì„ AIê°€ ìë™ìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.

### Open Deep Researchì˜ í˜ì‹ ì„±

**ì™„ì „í•œ ì˜¤í”ˆì†ŒìŠ¤ ìƒíƒœê³„**:
- ğŸ”“ **MIT ë¼ì´ì„ ìŠ¤**: ìƒì—…ì  ì‚¬ìš© í¬í•¨ ì™„ì „ ììœ 
- ğŸŒŸ **ì»¤ë®¤ë‹ˆí‹° ê²€ì¦**: GitHub 6.8k stars, 913 forksì˜ ì‹ ë¢°ì„±
- ğŸ”§ **ë¬´ì œí•œ ì»¤ìŠ¤í„°ë§ˆì´ì§•**: ì†ŒìŠ¤ì½”ë“œ ë ˆë²¨ì—ì„œ ììœ ë¡œìš´ ìˆ˜ì •
- ğŸ“š **íˆ¬ëª…í•œ ê°œë°œ**: ëª¨ë“  êµ¬í˜„ ë¡œì§ ê³µê°œ

**ì°¨ì„¸ëŒ€ ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜**:
- ğŸ—ï¸ **LangGraph ê¸°ë°˜**: ìµœì‹  AI ì›Œí¬í”Œë¡œìš° ì—”ì§„ í™œìš©
- ğŸ¤– **ë‹¤ì¤‘ ì—ì´ì „íŠ¸**: í˜‘ì—…í•˜ëŠ” AI ì—°êµ¬ì›ë“¤ì˜ ì‹œìŠ¤í…œ
- ğŸ”„ **ë°˜ì„±ì  ì‚¬ê³ **: ì—°êµ¬ ê²°ê³¼ë¥¼ ìŠ¤ìŠ¤ë¡œ ê²€ì¦í•˜ê³  ê°œì„ 
- âš¡ **ë³‘ë ¬ ì²˜ë¦¬**: ë™ì‹œ ë‹¤ë°œì  ì—°êµ¬ ìˆ˜í–‰ìœ¼ë¡œ ì†ë„ ê·¹ëŒ€í™”

**ë²”ìš©ì  í˜¸í™˜ì„±**:
- ğŸ¯ **ë‹¤ì¤‘ ëª¨ë¸ ì§€ì›**: OpenAI, Anthropic, Google Vertex AI ë“±
- ğŸ” **ë‹¤ì–‘í•œ ê²€ìƒ‰ API**: Tavily, OpenAI Native, Anthropic Native
- ğŸ”Œ **MCP ì„œë²„ ì—°ë™**: Model Context Protocolë¡œ ë¬´í•œ í™•ì¥
- ğŸ“Š **í¬ê´„ì  í‰ê°€**: ë‹¤ì°¨ì› ì„±ëŠ¥ ë¶„ì„ ì‹œìŠ¤í…œ

### ì´ ê°€ì´ë“œì—ì„œ ë°°ìš¸ ë‚´ìš©

1. **Open Deep Research í•µì‹¬ ì•„í‚¤í…ì²˜ ì´í•´**
2. **ë¡œì»¬ í™˜ê²½ ì„¤ì • ë° ë¹ ë¥¸ ì‹œì‘**
3. **LangGraph Studio í™œìš© ë°©ë²•**
4. **ë‹¤ì¤‘ ëª¨ë¸ ì„¤ì • ë° ìµœì í™”**
5. **MCP ì„œë²„ ì—°ë™ ë° í™•ì¥**
6. **ì—°êµ¬ ì›Œí¬í”Œë¡œìš° ì»¤ìŠ¤í„°ë§ˆì´ì§•**
7. **í‰ê°€ ì‹œìŠ¤í…œ êµ¬ì¶• ë° í™œìš©**
8. **í”„ë¡œë•ì…˜ ë°°í¬ ì „ëµ**
9. **ì‹¤ì „ ì—°êµ¬ í”„ë¡œì íŠ¸ êµ¬í˜„**

## Open Deep Research í•µì‹¬ ì•„í‚¤í…ì²˜

### ì „ì²´ ì‹œìŠ¤í…œ êµ¬ì¡°

**Multi-Agent Research Architecture**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Research Supervisor                       â”‚
â”‚              (ì—°êµ¬ ì´ê´„ ê´€ë¦¬ ì—ì´ì „íŠ¸)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚         â”‚         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Researcher  â”‚ â”‚ Search â”‚ â”‚Compression â”‚
â”‚   Agent 1   â”‚ â”‚ Agent  â”‚ â”‚   Agent    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                         â”‚
        â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
        â””â”€â”€â”€â”€â–º Research    â—„â”€â”€â”€â”€â”€â”€â”˜
             â”‚ Results     â”‚
             â”‚ Database    â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ì£¼ìš” êµ¬ì„± ìš”ì†Œ ë¶„ì„

**1. Research Supervisor (ì—°êµ¬ ê°ë…ì)**
- **ì—­í• **: ì „ì²´ ì—°êµ¬ í”„ë¡œì„¸ìŠ¤ ì¡°ìœ¨ ë° ê´€ë¦¬
- **ê¸°ëŠ¥**: ì—°êµ¬ ê³„íš ìˆ˜ë¦½, í•˜ìœ„ ì—ì´ì „íŠ¸ ê´€ë¦¬, í’ˆì§ˆ ê²€ì¦
- **ëª¨ë¸**: GPT-4o ë“± ê³ ì„±ëŠ¥ ëª¨ë¸ ê¶Œì¥

**2. Sub-Research Agents (ì—°êµ¬ ì—ì´ì „íŠ¸ë“¤)**
- **ì—­í• **: íŠ¹ì • ì£¼ì œì— ëŒ€í•œ ì‹¬í™” ì—°êµ¬ ìˆ˜í–‰
- **ê¸°ëŠ¥**: ì •ë³´ ìˆ˜ì§‘, ë¶„ì„, ì¤‘ê°„ ë³´ê³ ì„œ ì‘ì„±
- **íŠ¹ì§•**: ë³‘ë ¬ ì‹¤í–‰ìœ¼ë¡œ ì—°êµ¬ ì†ë„ í–¥ìƒ

**3. Search Integration Layer**
- **Tavily API**: ëª¨ë“  ëª¨ë¸ê³¼ í˜¸í™˜ë˜ëŠ” ë²”ìš© ê²€ìƒ‰
- **Native Search**: OpenAI/Anthropic ì „ìš© ê³ ê¸‰ ê²€ìƒ‰
- **Custom Search**: ì‚¬ìš©ì ì •ì˜ ê²€ìƒ‰ ì—”ì§„ ì—°ë™

**4. MCP (Model Context Protocol) System**
- **ë¡œì»¬ MCP**: íŒŒì¼ì‹œìŠ¤í…œ, ë°ì´í„°ë² ì´ìŠ¤ ì ‘ê·¼
- **ì›ê²© MCP**: í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤, API ì—°ë™
- **í™•ì¥ì„±**: ë¬´ì œí•œ ë„êµ¬ ë° ì„œë¹„ìŠ¤ ì—°ê²°

## ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ (Quickstart)

### í™˜ê²½ ì¤€ë¹„ ë° ì„¤ì¹˜

**1ë‹¨ê³„: ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸**

```bash
# Python 3.11+ í•„ìˆ˜
python --version

# uv íŒ¨í‚¤ì§€ ë§¤ë‹ˆì € ì„¤ì¹˜ (ê¶Œì¥)
curl -LsSf https://astral.sh/uv/install.sh | sh

# ë˜ëŠ” pip ì„¤ì¹˜
pip install uv
```

**2ë‹¨ê³„: í”„ë¡œì íŠ¸ í´ë¡  ë° í™˜ê²½ ì„¤ì •**

```bash
# GitHubì—ì„œ í”„ë¡œì íŠ¸ í´ë¡ 
git clone https://github.com/langchain-ai/open_deep_research.git
cd open_deep_research

# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
uv venv
source .venv/bin/activate  # macOS/Linux
# .venv\Scripts\activate  # Windows

# ì˜ì¡´ì„± ì„¤ì¹˜
uv pip install -r pyproject.toml
```

**3ë‹¨ê³„: í™˜ê²½ ë³€ìˆ˜ ì„¤ì •**

```bash
# í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ ìƒì„±
cp .env.example .env

# .env íŒŒì¼ í¸ì§‘
nano .env
```

**í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •**:

```env
# OpenAI API ì„¤ì •
OPENAI_API_KEY=sk-your-openai-api-key

# Tavily Search API (ë¬´ë£Œ ê³„ì •ìœ¼ë¡œ ì‹œì‘ ê°€ëŠ¥)
TAVILY_API_KEY=tvly-your-tavily-api-key

# LangSmith ì¶”ì  (ì„ íƒì )
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=ls__your-langsmith-api-key
LANGCHAIN_PROJECT=open-deep-research

# Anthropic API (ì„ íƒì )
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key

# Google Vertex AI (ì„ íƒì )
GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json
```

### LangGraph Studio ì‹¤í–‰

**4ë‹¨ê³„: ê°œë°œ ì„œë²„ ì‹œì‘**

```bash
# LangGraph ê°œë°œ ì„œë²„ ì‹¤í–‰
uvx --refresh --from "langgraph-cli[inmem]" --with-editable . --python 3.11 langgraph dev --allow-blocking
```

**ì„±ê³µì  ì‹¤í–‰ í™•ì¸**:

```
ğŸš€ API: http://127.0.0.1:2024
ğŸ¨ Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024
ğŸ“š API Docs: http://127.0.0.1:2024/docs
```

**5ë‹¨ê³„: LangGraph Studio ì‚¬ìš©**

1. **Studio UI ì ‘ì†**: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024
2. **Graph ì„ íƒ**: open_deep_research ê·¸ë˜í”„ ì„ íƒ
3. **ì²« ì—°êµ¬ ì‹¤í–‰**:
   - `messages` ì…ë ¥ í•„ë“œì— ì—°êµ¬ ì§ˆë¬¸ ì…ë ¥
   - ì˜ˆì‹œ: "Explain the latest developments in quantum computing"
   - `Submit` ë²„íŠ¼ í´ë¦­

### ì²« ì—°êµ¬ í”„ë¡œì íŠ¸ ì‹¤í–‰

**ê°„ë‹¨í•œ ì—°êµ¬ ì§ˆë¬¸ ì˜ˆì œ**:

```python
# examples/simple_research.py
from src.research_assistant import research_assistant

async def run_simple_research():
    # ì—°êµ¬ ì§ˆë¬¸ ì •ì˜
    question = "What are the latest breakthroughs in AI safety research in 2024?"
    
    # ì—°êµ¬ ì‹¤í–‰
    result = await research_assistant.ainvoke({
        "messages": [{"role": "user", "content": question}]
    })
    
    # ê²°ê³¼ ì¶œë ¥
    print("ì—°êµ¬ ê²°ê³¼:")
    print(result["messages"][-1]["content"])

# ì‹¤í–‰
import asyncio
asyncio.run(run_simple_research())
```

**ì‹¤í–‰ ê²°ê³¼ ì˜ˆì œ**:

```
ì—°êµ¬ ê²°ê³¼:
# AI Safety Research: 2024ë…„ ì£¼ìš” ëŒíŒŒêµ¬

## 1. Constitutional AI ë°œì „
- Anthropicì˜ Claude 3.5 Sonnetì—ì„œ ê°œì„ ëœ í—Œë²•ì  AI êµ¬í˜„
- ë” ë‚˜ì€ ê°€ì¹˜ ì •ë ¬ê³¼ í•´ì•… ë°©ì§€ ë©”ì»¤ë‹ˆì¦˜

## 2. Scalable Oversight
- OpenAIì˜ ìŠˆí¼ì •ë ¬ íŒ€ ì—°êµ¬ ê²°ê³¼
- ì¸ê°„ë³´ë‹¤ ë›°ì–´ë‚œ AI ì‹œìŠ¤í…œì˜ ê°ë… ë°©ë²•ë¡ 

## 3. Interpretability Tools
- Anthropicì˜ Dictionary Learning for SAEs
- ì‹ ê²½ë§ ë‚´ë¶€ í‘œí˜„ì˜ í•´ì„ ê°€ëŠ¥ì„± í–¥ìƒ

[ìƒì„¸í•œ ì—°êµ¬ ê²°ê³¼ ê³„ì†...]
```

## ê³ ê¸‰ ì„¤ì • ë° êµ¬ì„± ì˜µì…˜

### ì—°êµ¬ ë™ì‘ ì„¤ì •

**í•µì‹¬ ì„¤ì • íŒŒë¼ë¯¸í„°**:

```python
# src/config/research_config.py
from dataclasses import dataclass
from typing import Optional

@dataclass
class ResearchConfig:
    # ì¼ë°˜ ì„¤ì •
    max_structured_output_retries: int = 3
    allow_clarification: bool = True
    max_concurrent_research_units: int = 5
    
    # ì—°êµ¬ í”„ë¡œì„¸ìŠ¤ ì„¤ì •  
    search_api: str = "tavily"  # tavily, openai_native, anthropic_native
    max_researcher_iterations: int = 3
    max_react_tool_calls: int = 5
    
    # ëª¨ë¸ ì„¤ì •
    summarization_model: str = "openai:gpt-4o-mini"
    research_model: str = "openai:gpt-4o"
    compression_model: str = "openai:gpt-4o-mini"
    final_report_model: str = "openai:gpt-4o"
```

### ëª¨ë¸ ì„ íƒ ë° ìµœì í™”

**ëª¨ë¸ë³„ íŠ¹ì„± ë° ê¶Œì¥ ì‚¬ìš©**:

```python
# src/models/model_selector.py
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_vertexai import ChatVertexAI

class ModelSelector:
    def __init__(self):
        self.model_configs = {
            # OpenAI ëª¨ë¸ë“¤
            "openai:gpt-4o": {
                "class": ChatOpenAI,
                "model": "gpt-4o",
                "temperature": 0.1,
                "max_tokens": 4000,
                "supports_structured_output": True,
                "cost_per_1k_tokens": 0.03,
                "best_for": ["research", "final_report"]
            },
            "openai:gpt-4o-mini": {
                "class": ChatOpenAI,
                "model": "gpt-4o-mini", 
                "temperature": 0.1,
                "max_tokens": 2000,
                "supports_structured_output": True,
                "cost_per_1k_tokens": 0.005,
                "best_for": ["summarization", "compression"]
            },
            
            # Anthropic ëª¨ë¸ë“¤
            "anthropic:claude-3-5-sonnet": {
                "class": ChatAnthropic,
                "model": "claude-3-5-sonnet-20241022",
                "temperature": 0.1,
                "max_tokens": 4000,
                "supports_structured_output": True,
                "cost_per_1k_tokens": 0.03,
                "best_for": ["research", "analysis"]
            },
            
            # Google ëª¨ë¸ë“¤
            "vertex:gemini-pro": {
                "class": ChatVertexAI,
                "model": "gemini-pro",
                "temperature": 0.1,
                "max_output_tokens": 2048,
                "supports_structured_output": True,
                "cost_per_1k_tokens": 0.0025,
                "best_for": ["summarization", "compression"]
            }
        }
    
    def get_optimized_model(self, task_type: str, budget_level: str = "standard"):
        """íƒœìŠ¤í¬ ìœ í˜•ê³¼ ì˜ˆì‚°ì— ë”°ë¥¸ ìµœì  ëª¨ë¸ ì„ íƒ"""
        if budget_level == "premium":
            if task_type in ["research", "final_report"]:
                return "anthropic:claude-3-5-sonnet"
            else:
                return "openai:gpt-4o-mini"
                
        elif budget_level == "budget":
            return "openai:gpt-4o-mini"
            
        else:  # standard
            if task_type in ["research", "final_report"]:
                return "openai:gpt-4o"
            else:
                return "openai:gpt-4o-mini"
```

### ê²€ìƒ‰ API ì„¤ì • ë° ë¹„êµ

**ë‹¤ì–‘í•œ ê²€ìƒ‰ ì˜µì…˜ ì„¤ì •**:

```python
# src/search/search_manager.py
from typing import Dict, Any
import os

class SearchManager:
    def __init__(self):
        self.search_configs = {
            "tavily": {
                "api_key": os.getenv("TAVILY_API_KEY"),
                "max_results": 10,
                "search_depth": "advanced",
                "include_images": False,
                "include_answer": True,
                "compatibility": "all_models",
                "cost": "low"
            },
            
            "openai_native": {
                "requires_model": "openai",
                "web_search_enabled": True,
                "real_time_data": True,
                "accuracy": "high",
                "cost": "medium"
            },
            
            "anthropic_native": {
                "requires_model": "anthropic",
                "web_search_enabled": True,
                "real_time_data": True,
                "accuracy": "high",  
                "cost": "medium"
            }
        }
    
    def configure_search(self, search_type: str, custom_config: Dict[str, Any] = None):
        """ê²€ìƒ‰ ì—”ì§„ ì„¤ì •"""
        base_config = self.search_configs.get(search_type, {})
        if custom_config:
            base_config.update(custom_config)
        return base_config

# ì‚¬ìš© ì˜ˆì œ
search_manager = SearchManager()

# Tavily ì„¤ì • (ê°€ì¥ ë²”ìš©ì )
tavily_config = search_manager.configure_search("tavily", {
    "max_results": 15,
    "search_depth": "advanced",
    "include_domain_filter": ["arxiv.org", "nature.com", "science.org"]
})
```

## MCP (Model Context Protocol) ì„œë²„ ì—°ë™

### ë¡œì»¬ MCP ì„œë²„ ì„¤ì •

**íŒŒì¼ì‹œìŠ¤í…œ MCP ì„œë²„ êµ¬ì„±**:

```python
# src/mcp/filesystem_mcp.py
import json
import subprocess
from pathlib import Path

class FilesystemMCP:
    def __init__(self, allowed_dirs: list):
        self.allowed_dirs = [Path(d).resolve() for d in allowed_dirs]
        self.server_process = None
    
    def start_server(self):
        """íŒŒì¼ì‹œìŠ¤í…œ MCP ì„œë²„ ì‹œì‘"""
        cmd = [
            "mcp-server-filesystem",
            *[str(d) for d in self.allowed_dirs]
        ]
        
        self.server_process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        
        return self.server_process
    
    def configure_security(self):
        """ë³´ì•ˆ ì„¤ì • êµ¬ì„±"""
        return {
            "allowed_operations": [
                "read_file",
                "write_file", 
                "list_directory",
                "create_directory",
                "search_files"
            ],
            "restricted_patterns": [
                "*.exe",
                "*.sh",
                "/etc/*",
                "/sys/*"
            ],
            "max_file_size": "10MB",
            "max_depth": 10
        }

# ì‚¬ìš© ì˜ˆì œ
filesystem_mcp = FilesystemMCP([
    "/Users/researcher/documents",
    "/Users/researcher/projects", 
    "/tmp/research_workspace"
])

security_config = filesystem_mcp.configure_security()
server = filesystem_mcp.start_server()
```

**SQLite ë°ì´í„°ë² ì´ìŠ¤ MCP ì—°ë™**:

```python
# src/mcp/database_mcp.py
import sqlite3
import json
from typing import Dict, Any

class DatabaseMCP:
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.connection = None
    
    def setup_research_db(self):
        """ì—°êµ¬ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì„¤ì •"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ì—°êµ¬ í”„ë¡œì íŠ¸ í…Œì´ë¸”
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS research_projects (
                id INTEGER PRIMARY KEY,
                title TEXT NOT NULL,
                description TEXT,
                status TEXT DEFAULT 'active',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # ì—°êµ¬ ê²°ê³¼ í…Œì´ë¸”
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS research_results (
                id INTEGER PRIMARY KEY,
                project_id INTEGER,
                query TEXT NOT NULL,
                result_text TEXT,
                sources JSON,
                confidence_score REAL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (project_id) REFERENCES research_projects (id)
            )
        """)
        
        # ì¸ë±ìŠ¤ ìƒì„±
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_results_project ON research_results(project_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_results_created ON research_results(created_at)")
        
        conn.commit()
        conn.close()
    
    def save_research_result(self, project_id: int, query: str, result: Dict[str, Any]):
        """ì—°êµ¬ ê²°ê³¼ ì €ì¥"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO research_results 
            (project_id, query, result_text, sources, confidence_score)
            VALUES (?, ?, ?, ?, ?)
        """, (
            project_id,
            query,
            result.get('text', ''),
            json.dumps(result.get('sources', [])),
            result.get('confidence', 0.0)
        ))
        
        conn.commit()
        conn.close()

# ì‚¬ìš© ì˜ˆì œ
db_mcp = DatabaseMCP("/path/to/research.db")
db_mcp.setup_research_db()
```

### ì›ê²© MCP ì„œë²„ ì—°ë™

**Arcade MCP ì„œë²„ ì„¤ì • (ì—¬í–‰ ê´€ë ¨ ì—°êµ¬)**:

```python
# src/mcp/remote_mcp.py
import httpx
import json
from typing import Dict, Any

class RemoteMCP:
    def __init__(self, server_config: Dict[str, Any]):
        self.url = server_config["url"]
        self.tools = server_config.get("tools", [])
        self.auth_token = server_config.get("auth_token")
        self.client = httpx.AsyncClient()
    
    async def setup_arcade_travel_research(self):
        """Arcade ì—¬í–‰ ì—°êµ¬ MCP ì„¤ì •"""
        config = {
            "url": "https://api.arcade.dev/v1/mcps/ms_0ujssxh0cECutqzMgbtXSGnjorm",
            "tools": [
                "Search_SearchHotels",
                "Search_SearchOneWayFlights", 
                "Search_SearchRoundtripFlights"
            ],
            "auth_required": True
        }
        
        return config
    
    async def call_mcp_tool(self, tool_name: str, parameters: Dict[str, Any]):
        """ì›ê²© MCP ë„êµ¬ í˜¸ì¶œ"""
        headers = {"Content-Type": "application/json"}
        if self.auth_token:
            headers["Authorization"] = f"Bearer {self.auth_token}"
        
        payload = {
            "tool": tool_name,
            "parameters": parameters
        }
        
        response = await self.client.post(
            f"{self.url}/call_tool",
            json=payload,
            headers=headers
        )
        
        return response.json()

# ì‹¤ì œ ì‚¬ìš© ì˜ˆì œ
async def research_travel_options():
    """ì—¬í–‰ ì˜µì…˜ ì—°êµ¬ ì˜ˆì œ"""
    arcade_config = {
        "url": "https://api.arcade.dev/v1/mcps/ms_0ujssxh0cECutqzMgbtXSGnjorm",
        "tools": ["Search_SearchHotels", "Search_SearchRoundtripFlights"]
    }
    
    remote_mcp = RemoteMCP(arcade_config)
    
    # í˜¸í…” ê²€ìƒ‰
    hotel_results = await remote_mcp.call_mcp_tool("Search_SearchHotels", {
        "destination": "Tokyo",
        "check_in": "2024-03-15",
        "check_out": "2024-03-20", 
        "guests": 2
    })
    
    # í•­ê³µí¸ ê²€ìƒ‰
    flight_results = await remote_mcp.call_mcp_tool("Search_SearchRoundtripFlights", {
        "origin": "JFK",
        "destination": "NRT",
        "departure_date": "2024-03-15",
        "return_date": "2024-03-20",
        "passengers": 2
    })
    
    return {
        "hotels": hotel_results,
        "flights": flight_results
    }
```

## í‰ê°€ ì‹œìŠ¤í…œ êµ¬ì¶• ë° í™œìš©

### ë‹¤ì°¨ì› í‰ê°€ í”„ë ˆì„ì›Œí¬

**í‰ê°€ ì§€í‘œ ì„¤ê³„**:

```python
# tests/evaluators.py
from typing import Dict, Any, List
from dataclasses import dataclass

@dataclass
class EvaluationResult:
    accuracy: float  # 0-1 scale
    completeness: float  # 0-1 scale  
    relevance: float  # 0-1 scale
    clarity: float  # 0-1 scale
    source_quality: float  # 0-1 scale
    overall_score: float  # weighted average
    feedback: str

class ResearchEvaluator:
    def __init__(self):
        self.weights = {
            "accuracy": 0.3,
            "completeness": 0.25,
            "relevance": 0.2,
            "clarity": 0.15,
            "source_quality": 0.1
        }
    
    def evaluate_research_output(self, 
                                research_result: str, 
                                reference_answer: str,
                                sources: List[Dict[str, Any]]) -> EvaluationResult:
        """ì—°êµ¬ ê²°ê³¼ ì¢…í•© í‰ê°€"""
        
        # ì •í™•ì„± í‰ê°€
        accuracy = self._evaluate_accuracy(research_result, reference_answer)
        
        # ì™„ì„±ë„ í‰ê°€
        completeness = self._evaluate_completeness(research_result, reference_answer)
        
        # ê´€ë ¨ì„± í‰ê°€
        relevance = self._evaluate_relevance(research_result, reference_answer)
        
        # ëª…í™•ì„± í‰ê°€
        clarity = self._evaluate_clarity(research_result)
        
        # ì†ŒìŠ¤ í’ˆì§ˆ í‰ê°€
        source_quality = self._evaluate_source_quality(sources)
        
        # ì „ì²´ ì ìˆ˜ ê³„ì‚°
        overall_score = (
            accuracy * self.weights["accuracy"] +
            completeness * self.weights["completeness"] +
            relevance * self.weights["relevance"] + 
            clarity * self.weights["clarity"] +
            source_quality * self.weights["source_quality"]
        )
        
        # í”¼ë“œë°± ìƒì„±
        feedback = self._generate_feedback(accuracy, completeness, relevance, clarity, source_quality)
        
        return EvaluationResult(
            accuracy=accuracy,
            completeness=completeness,
            relevance=relevance,
            clarity=clarity,
            source_quality=source_quality,
            overall_score=overall_score,
            feedback=feedback
        )
    
    def _evaluate_accuracy(self, result: str, reference: str) -> float:
        """ì •í™•ì„± í‰ê°€ - ì‚¬ì‹¤ í™•ì¸"""
        # LLM ê¸°ë°˜ íŒ©íŠ¸ ì²´í‚¹
        prompt = f"""
        Research Result: {result}
        Reference Answer: {reference}
        
        Rate the factual accuracy of the research result compared to the reference on a scale of 0.0 to 1.0.
        Consider:
        - Factual correctness
        - No misinformation
        - Proper context
        
        Return only the numerical score.
        """
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” LLM í˜¸ì¶œ
        return 0.85  # ì˜ˆì‹œ ì ìˆ˜
    
    def _evaluate_completeness(self, result: str, reference: str) -> float:
        """ì™„ì„±ë„ í‰ê°€ - í•„ìš”í•œ ì •ë³´ í¬í•¨ ì—¬ë¶€"""
        prompt = f"""
        Research Result: {result}
        Reference Answer: {reference}
        
        Rate how completely the research result covers the topic compared to the reference on a scale of 0.0 to 1.0.
        Consider:
        - Coverage of key points
        - Depth of information
        - Missing important aspects
        
        Return only the numerical score.
        """
        return 0.78  # ì˜ˆì‹œ ì ìˆ˜
```

### ë°°ì¹˜ í‰ê°€ ì‹œìŠ¤í…œ

**ëŒ€ê·œëª¨ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ í‰ê°€**:

```python
# tests/run_evaluate.py
import asyncio
import json
from typing import List, Dict
from pathlib import Path

class BatchEvaluator:
    def __init__(self, evaluator: ResearchEvaluator):
        self.evaluator = evaluator
        self.results = []
    
    async def run_batch_evaluation(self, test_dataset: List[Dict[str, Any]]):
        """ë°°ì¹˜ í‰ê°€ ì‹¤í–‰"""
        
        print(f"Starting batch evaluation with {len(test_dataset)} test cases...")
        
        for i, test_case in enumerate(test_dataset):
            print(f"Processing test case {i+1}/{len(test_dataset)}: {test_case['question'][:50]}...")
            
            # ì—°êµ¬ ì‹¤í–‰
            research_result = await self._run_research(test_case["question"])
            
            # í‰ê°€ ìˆ˜í–‰
            evaluation = self.evaluator.evaluate_research_output(
                research_result["content"],
                test_case["reference_answer"],
                research_result["sources"]
            )
            
            # ê²°ê³¼ ì €ì¥
            result = {
                "test_case_id": test_case["id"],
                "question": test_case["question"],
                "research_result": research_result["content"],
                "evaluation": evaluation.__dict__,
                "execution_time": research_result["execution_time"]
            }
            
            self.results.append(result)
            
            print(f"  Overall Score: {evaluation.overall_score:.3f}")
        
        return self.results
    
    def generate_evaluation_report(self) -> Dict[str, Any]:
        """í‰ê°€ ë¦¬í¬íŠ¸ ìƒì„±"""
        if not self.results:
            return {"error": "No evaluation results available"}
        
        # í†µê³„ ê³„ì‚°
        scores = [r["evaluation"]["overall_score"] for r in self.results]
        
        report = {
            "summary": {
                "total_cases": len(self.results),
                "average_score": sum(scores) / len(scores),
                "max_score": max(scores),
                "min_score": min(scores),
                "median_score": sorted(scores)[len(scores)//2]
            },
            "dimension_breakdown": {
                "accuracy": sum(r["evaluation"]["accuracy"] for r in self.results) / len(self.results),
                "completeness": sum(r["evaluation"]["completeness"] for r in self.results) / len(self.results),
                "relevance": sum(r["evaluation"]["relevance"] for r in self.results) / len(self.results),
                "clarity": sum(r["evaluation"]["clarity"] for r in self.results) / len(self.results),
                "source_quality": sum(r["evaluation"]["source_quality"] for r in self.results) / len(self.results)
            },
            "performance_analysis": {
                "avg_execution_time": sum(r["execution_time"] for r in self.results) / len(self.results),
                "cases_above_threshold": len([s for s in scores if s >= 0.8]),
                "improvement_areas": self._identify_improvement_areas()
            },
            "detailed_results": self.results
        }
        
        return report
    
    def _identify_improvement_areas(self) -> List[str]:
        """ê°œì„  ì˜ì—­ ì‹ë³„"""
        dimension_scores = {
            "accuracy": sum(r["evaluation"]["accuracy"] for r in self.results) / len(self.results),
            "completeness": sum(r["evaluation"]["completeness"] for r in self.results) / len(self.results),
            "relevance": sum(r["evaluation"]["relevance"] for r in self.results) / len(self.results),
            "clarity": sum(r["evaluation"]["clarity"] for r in self.results) / len(self.results),
            "source_quality": sum(r["evaluation"]["source_quality"] for r in self.results) / len(self.results)
        }
        
        # í‰ê·  ì´í•˜ ì„±ëŠ¥ ì˜ì—­ ì‹ë³„
        avg_score = sum(dimension_scores.values()) / len(dimension_scores)
        improvement_areas = [
            dimension for dimension, score in dimension_scores.items() 
            if score < avg_score - 0.05
        ]
        
        return improvement_areas

# ì‚¬ìš© ì˜ˆì œ
async def run_comprehensive_evaluation():
    """ì¢…í•© í‰ê°€ ì‹¤í–‰"""
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¡œë“œ
    test_dataset = [
        {
            "id": "ai_safety_001",
            "question": "What are the latest developments in AI safety research?",
            "reference_answer": "Recent developments include constitutional AI, scalable oversight, and interpretability tools..."
        },
        {
            "id": "quantum_001", 
            "question": "Explain quantum error correction breakthroughs in 2024",
            "reference_answer": "Major breakthroughs include surface code improvements, logical qubit demonstrations..."
        }
        # ... ë” ë§ì€ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
    ]
    
    # í‰ê°€ ì‹¤í–‰
    evaluator = ResearchEvaluator()
    batch_evaluator = BatchEvaluator(evaluator)
    
    results = await batch_evaluator.run_batch_evaluation(test_dataset)
    report = batch_evaluator.generate_evaluation_report()
    
    # ê²°ê³¼ ì €ì¥
    with open("evaluation_report.json", "w") as f:
        json.dump(report, f, indent=2)
    
    print(f"Evaluation completed. Average score: {report['summary']['average_score']:.3f}")
    return report

# ì‹¤í–‰
# asyncio.run(run_comprehensive_evaluation())
```

## í”„ë¡œë•ì…˜ ë°°í¬ ë° í™•ì¥ ì „ëµ

### Docker ì»¨í…Œì´ë„ˆí™”

**ìµœì í™”ëœ Dockerfile**:

```dockerfile
# Dockerfile
FROM python:3.11-slim

# ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    git \
    curl \
    && rm -rf /var/lib/apt/lists/*

# uv ì„¤ì¹˜
RUN pip install uv

# ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •
WORKDIR /app

# ì˜ì¡´ì„± íŒŒì¼ ë³µì‚¬
COPY pyproject.toml uv.lock ./

# ì˜ì¡´ì„± ì„¤ì¹˜
RUN uv pip install --system -r pyproject.toml

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬
COPY . .

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
ENV PYTHONPATH=/app
ENV LANGCHAIN_TRACING_V2=true

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8000

# í—¬ìŠ¤ì²´í¬ ì¶”ê°€
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
CMD ["uvx", "--from", "langgraph-cli[inmem]", "--with-editable", ".", "langgraph", "start", "--host", "0.0.0.0", "--port", "8000"]
```

**Docker Compose ì„¤ì •**:

```yaml
# docker-compose.yml
version: '3.8'

services:
  open-deep-research:
    build: .
    ports:
      - "8000:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - TAVILY_API_KEY=${TAVILY_API_KEY}
      - LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY}
      - LANGCHAIN_PROJECT=open-deep-research-prod
      - REDIS_URL=redis://redis:6379
    depends_on:
      - redis
      - postgres
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    restart: unless-stopped

  postgres:
    image: postgres:15
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=research_db
      - POSTGRES_USER=researcher
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - open-deep-research
    restart: unless-stopped

volumes:
  redis_data:
  postgres_data:
```

### Kubernetes ë°°í¬

**Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸**:

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: open-deep-research
  labels:
    app: open-deep-research
spec:
  replicas: 3
  selector:
    matchLabels:
      app: open-deep-research
  template:
    metadata:
      labels:
        app: open-deep-research
    spec:
      containers:
      - name: open-deep-research
        image: your-registry/open-deep-research:latest
        ports:
        - containerPort: 8000
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: api-secrets
              key: openai-api-key
        - name: TAVILY_API_KEY
          valueFrom:
            secretKeyRef:
              name: api-secrets
              key: tavily-api-key
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: open-deep-research-service
spec:
  selector:
    app: open-deep-research
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: ClusterIP

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: open-deep-research-ingress
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  tls:
  - hosts:
    - research-api.yourdomain.com
    secretName: research-api-tls
  rules:
  - host: research-api.yourdomain.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: open-deep-research-service
            port:
              number: 80
```

## ì‹¤ì „ ì—°êµ¬ í”„ë¡œì íŠ¸ êµ¬í˜„

### ë³µí•© ì—°êµ¬ ì›Œí¬í”Œë¡œìš°

**ë‹¤ë‹¨ê³„ ì—°êµ¬ í”„ë¡œì„¸ìŠ¤ ì„¤ê³„**:

```python
# src/workflows/complex_research.py
from typing import List, Dict, Any
from dataclasses import dataclass
import asyncio

@dataclass
class ResearchPhase:
    name: str
    description: str
    agents_required: int
    max_duration: int  # seconds
    dependencies: List[str]

class ComplexResearchWorkflow:
    def __init__(self):
        self.phases = {
            "literature_review": ResearchPhase(
                name="Literature Review",
                description="Comprehensive review of existing literature",
                agents_required=2,
                max_duration=300,
                dependencies=[]
            ),
            "data_collection": ResearchPhase(
                name="Data Collection", 
                description="Gather relevant data and statistics",
                agents_required=3,
                max_duration=600,
                dependencies=["literature_review"]
            ),
            "analysis": ResearchPhase(
                name="Analysis",
                description="Deep analysis of collected information",
                agents_required=2,
                max_duration=400,
                dependencies=["literature_review", "data_collection"]
            ),
            "synthesis": ResearchPhase(
                name="Synthesis",
                description="Synthesize findings into coherent insights",
                agents_required=1,
                max_duration=300,
                dependencies=["analysis"]
            ),
            "validation": ResearchPhase(
                name="Validation",
                description="Validate findings and check for consistency",
                agents_required=1,
                max_duration=200,
                dependencies=["synthesis"]
            )
        }
    
    async def execute_research_pipeline(self, research_question: str) -> Dict[str, Any]:
        """ë³µí•© ì—°êµ¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        
        results = {}
        execution_order = self._determine_execution_order()
        
        print(f"Starting complex research pipeline for: {research_question}")
        
        for phase_name in execution_order:
            phase = self.phases[phase_name]
            print(f"\nğŸ”¬ Executing Phase: {phase.name}")
            print(f"   Description: {phase.description}")
            print(f"   Agents: {phase.agents_required}, Max Duration: {phase.max_duration}s")
            
            # ì˜ì¡´ì„± í™•ì¸
            dependencies_met = all(dep in results for dep in phase.dependencies)
            if not dependencies_met:
                missing = [dep for dep in phase.dependencies if dep not in results]
                raise Exception(f"Dependencies not met for {phase_name}: {missing}")
            
            # ë‹¨ê³„ë³„ ì—°êµ¬ ì‹¤í–‰
            phase_result = await self._execute_phase(
                phase_name, 
                research_question, 
                results,
                phase
            )
            
            results[phase_name] = phase_result
            print(f"   âœ… Phase completed: {len(phase_result.get('findings', []))} findings")
        
        # ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
        final_report = await self._generate_final_report(research_question, results)
        
        return {
            "research_question": research_question,
            "phase_results": results,
            "final_report": final_report,
            "execution_summary": self._create_execution_summary(results)
        }
    
    async def _execute_phase(self, 
                           phase_name: str,
                           research_question: str, 
                           previous_results: Dict[str, Any],
                           phase: ResearchPhase) -> Dict[str, Any]:
        """ê°œë³„ ì—°êµ¬ ë‹¨ê³„ ì‹¤í–‰"""
        
        # ë‹¨ê³„ë³„ ë§ì¶¤í˜• í”„ë¡¬í”„íŠ¸ ìƒì„±
        phase_prompt = self._generate_phase_prompt(
            phase_name, 
            research_question, 
            previous_results
        )
        
        # ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ë³‘ë ¬ ì‹¤í–‰
        agent_tasks = []
        for i in range(phase.agents_required):
            task = self._run_phase_agent(
                f"agent_{i}",
                phase_prompt,
                research_question,
                previous_results
            )
            agent_tasks.append(task)
        
        # ê²°ê³¼ ìˆ˜ì§‘ ë° í†µí•©
        agent_results = await asyncio.gather(*agent_tasks)
        
        # ê²°ê³¼ í†µí•© ë° ì •ì œ
        integrated_result = await self._integrate_agent_results(
            phase_name,
            agent_results
        )
        
        return integrated_result
    
    def _generate_phase_prompt(self, 
                             phase_name: str,
                             research_question: str,
                             previous_results: Dict[str, Any]) -> str:
        """ë‹¨ê³„ë³„ ë§ì¶¤í˜• í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        phase_prompts = {
            "literature_review": f"""
            Conduct a comprehensive literature review for the research question: "{research_question}"
            
            Focus on:
            1. Recent academic papers and publications
            2. Established theories and frameworks
            3. Key researchers and institutions
            4. Research gaps and controversies
            
            Provide citations and assess credibility of sources.
            """,
            
            "data_collection": f"""
            Collect relevant data and statistics for: "{research_question}"
            
            Previous literature review findings: {previous_results.get('literature_review', {}).get('summary', 'None')}
            
            Focus on:
            1. Quantitative data and statistics
            2. Recent surveys and reports
            3. Government and institutional data
            4. Industry reports and market research
            
            Ensure data is current and from reliable sources.
            """,
            
            "analysis": f"""
            Conduct deep analysis based on collected information for: "{research_question}"
            
            Previous findings:
            - Literature: {previous_results.get('literature_review', {}).get('summary', 'None')}
            - Data: {previous_results.get('data_collection', {}).get('summary', 'None')}
            
            Focus on:
            1. Pattern identification and trends
            2. Cause-effect relationships
            3. Comparative analysis
            4. Critical evaluation of findings
            """,
            
            "synthesis": f"""
            Synthesize all research findings into coherent insights for: "{research_question}"
            
            Integration of:
            - Literature insights: {previous_results.get('literature_review', {}).get('key_findings', [])}
            - Data insights: {previous_results.get('data_collection', {}).get('key_findings', [])}
            - Analysis results: {previous_results.get('analysis', {}).get('key_findings', [])}
            
            Create unified conclusions and actionable insights.
            """,
            
            "validation": f"""
            Validate and verify the research findings for: "{research_question}"
            
            Synthesized insights: {previous_results.get('synthesis', {}).get('summary', 'None')}
            
            Focus on:
            1. Fact-checking key claims
            2. Consistency verification
            3. Bias detection
            4. Reliability assessment
            """
        }
        
        return phase_prompts.get(phase_name, f"Research the topic: {research_question}")

# ì‹¤ì œ ì‚¬ìš© ì˜ˆì œ
async def run_complex_ai_safety_research():
    """AI ì•ˆì „ì„±ì— ëŒ€í•œ ë³µí•© ì—°êµ¬ ì‹¤í–‰"""
    
    workflow = ComplexResearchWorkflow()
    
    research_question = """
    What are the most critical challenges in AI safety for large language models, 
    and what are the most promising approaches to address them in 2024?
    """
    
    result = await workflow.execute_research_pipeline(research_question)
    
    print("\n" + "="*80)
    print("ğŸ¯ FINAL RESEARCH REPORT")
    print("="*80)
    print(result["final_report"])
    
    print("\n" + "="*80)
    print("ğŸ“Š EXECUTION SUMMARY")
    print("="*80)
    for phase, summary in result["execution_summary"].items():
        print(f"{phase}: {summary}")
    
    return result

# ì‹¤í–‰ 
# asyncio.run(run_complex_ai_safety_research())
```

## ê²°ë¡ : Open Deep Researchì˜ ë¬´í•œí•œ ê°€ëŠ¥ì„±

### Open Deep Researchê°€ ì œê³µí•˜ëŠ” í˜ì‹ 

**ì—°êµ¬ íŒ¨ëŸ¬ë‹¤ì„ì˜ ì „í™˜**:
- ğŸ¤– **AI í˜‘ì—… ì—°êµ¬**: ì¸ê°„ê³¼ AIê°€ í•¨ê»˜í•˜ëŠ” ìƒˆë¡œìš´ ì—°êµ¬ ë°©ì‹
- âš¡ **ì†ë„ì˜ í˜ëª…**: ëª‡ ì£¼ ê±¸ë¦¬ë˜ ì—°êµ¬ë¥¼ ëª‡ ì‹œê°„ìœ¼ë¡œ ë‹¨ì¶•
- ğŸ¯ **ì •í™•ì„± í–¥ìƒ**: ë‹¤ì¤‘ ê²€ì¦ê³¼ ë°˜ì„±ì  ì‚¬ê³ ë¡œ ë” ë†’ì€ ì‹ ë¢°ì„±
- ğŸŒ **ì ‘ê·¼ì„± í™•ëŒ€**: ê³ ê¸‰ ì—°êµ¬ ë„êµ¬ì˜ ë¯¼ì£¼í™”

**ì‹¤ë¬´ ì ìš© ê°€ëŠ¥ì„±**:
- ğŸ“Š **ì‹œì¥ ì¡°ì‚¬**: ê²½ìŸì‚¬ ë¶„ì„, íŠ¸ë Œë“œ ì˜ˆì¸¡, ì†Œë¹„ì í–‰ë™ ì—°êµ¬
- ğŸ”¬ **í•™ìˆ  ì—°êµ¬**: ë¬¸í—Œ ë¦¬ë·°, ë°ì´í„° ë¶„ì„, ê°€ì„¤ ê²€ì¦
- ğŸ’¼ **ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ**: ì‚°ì—… ë¶„ì„, ë¦¬ìŠ¤í¬ í‰ê°€, ê¸°íšŒ íƒìƒ‰
- ğŸ›ï¸ **ì •ì±… ì—°êµ¬**: ì‚¬íšŒ ë¬¸ì œ ë¶„ì„, ì •ì±… íš¨ê³¼ ì˜ˆì¸¡

### ë‹¤ìŒ ë‹¨ê³„ ë° ë°œì „ ë°©í–¥

**ì¦‰ì‹œ í™œìš© ê°€ëŠ¥í•œ í”„ë¡œì íŠ¸**:
1. **ê°œì¸ ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸**: ì¼ìƒì ì¸ ì§ˆë¬¸ê³¼ ì¡°ì‚¬ ìë™í™”
2. **ì—…ë¬´ ë¦¬ì„œì¹˜ ë„êµ¬**: íšŒì‚¬ ë‚´ ì‹œì¥ ì¡°ì‚¬ ë° ê²½ìŸ ë¶„ì„
3. **í•™ìŠµ ë„ìš°ë¯¸**: ìƒˆë¡œìš´ ê¸°ìˆ ì´ë‚˜ ë„ë©”ì¸ í•™ìŠµ ì§€ì›
4. **ì½˜í…ì¸  ì œì‘**: ë¸”ë¡œê·¸, ë¦¬í¬íŠ¸, í”„ë ˆì  í…Œì´ì…˜ ìë£Œ ìƒì„±

**ê³ ê¸‰ í™•ì¥ ë°©í–¥**:
1. **ë„ë©”ì¸ íŠ¹í™”**: ì˜ë£Œ, ë²•ë¥ , ê¸ˆìœµ ë“± ì „ë¬¸ ë¶„ì•¼ ë§ì¶¤í™”
2. **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: ì§€ì†ì ì¸ ì •ë³´ ì¶”ì ê³¼ ì•Œë¦¼ ì‹œìŠ¤í…œ
3. **í˜‘ì—… í”Œë«í¼**: íŒ€ ë‹¨ìœ„ ì—°êµ¬ í”„ë¡œì íŠ¸ ê´€ë¦¬
4. **ì§€ì‹ ë² ì´ìŠ¤**: ì¡°ì§ ë‚´ ì¶•ì ëœ ì—°êµ¬ ìì‚° í™œìš©

### ì»¤ë®¤ë‹ˆí‹°ì™€ ê¸°ì—¬

**ì˜¤í”ˆì†ŒìŠ¤ ìƒíƒœê³„ ì°¸ì—¬**:
- ğŸ› ï¸ **GitHub ê¸°ì—¬**: [í”„ë¡œì íŠ¸ ê°œì„  ë° ë²„ê·¸ ë¦¬í¬íŠ¸](https://github.com/langchain-ai/open_deep_research)
- ğŸ’¡ **ì•„ì´ë””ì–´ ì œì•ˆ**: ìƒˆë¡œìš´ ê¸°ëŠ¥ ë° ì‚¬ìš© ì‚¬ë¡€ ê³µìœ 
- ğŸ“– **ë¬¸ì„œí™”**: ì‚¬ìš© ê°€ì´ë“œ ë° íŠœí† ë¦¬ì–¼ ì‘ì„±
- ğŸ“ **êµìœ¡ ì½˜í…ì¸ **: ì›Œí¬ìƒµ, ê°•ì˜, ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì œì‘

**ì§€ì†ì ì¸ í•™ìŠµê³¼ ë°œì „**:
- ğŸ“š ìƒˆë¡œìš´ ëª¨ë¸ê³¼ API ì¶œì‹œ ë™í–¥ íŒŒì•…
- ğŸ”„ ì›Œí¬í”Œë¡œìš° ìµœì í™” ë° ì„±ëŠ¥ íŠœë‹
- ğŸ“Š í‰ê°€ ì§€í‘œ ê°œì„  ë° ë²¤ì¹˜ë§ˆí¬ êµ¬ì¶•
- ğŸŒŸ ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€ ê³µìœ  ë° ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ ê°œë°œ

Open Deep ResearchëŠ” ë‹¨ìˆœí•œ ë„êµ¬ë¥¼ ë„˜ì–´ì„œ **ì—°êµ¬ì™€ ì§€ì‹ íƒêµ¬ì˜ ìƒˆë¡œìš´ ê°€ëŠ¥ì„±**ì„ ì—´ì–´ì£¼ëŠ” í”Œë«í¼ì…ë‹ˆë‹¤. ì´ ê°€ì´ë“œë¥¼ í†µí•´ êµ¬ì¶•í•œ ì‹œìŠ¤í…œì„ ë°”íƒ•ìœ¼ë¡œ ë”ìš± í˜ì‹ ì ì´ê³  íš¨ê³¼ì ì¸ ì—°êµ¬ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.

ğŸš€ **ì§€ê¸ˆ ë°”ë¡œ ì‹œì‘í•˜ì„¸ìš”**: [GitHubì—ì„œ í”„ë¡œì íŠ¸ë¥¼ í´ë¡ ](https://github.com/langchain-ai/open_deep_research)í•˜ê³  ì²« ë²ˆì§¸ AI ì—°êµ¬ ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•´ë³´ì„¸ìš”!

**"ë¯¸ë˜ì˜ ì—°êµ¬ëŠ” AIì™€ í•¨ê»˜í•©ë‹ˆë‹¤. Open Deep Researchë¡œ ê·¸ ë¯¸ë˜ë¥¼ ì§€ê¸ˆ ê²½í—˜í•˜ì„¸ìš”."**