---
title: "Unsloth Dockerë¡œ LLM íŒŒì¸íŠœë‹ ì™„ë²½ ê°€ì´ë“œ: ì„¤ì¹˜ë¶€í„° ì‹¤ì „ê¹Œì§€"
excerpt: "Unsloth Docker ì»¨í…Œì´ë„ˆë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ íš¨ìœ¨ì ìœ¼ë¡œ íŒŒì¸íŠœë‹í•˜ëŠ” ë°©ë²•ì„ ë°°ì›Œë³´ì„¸ìš”. ì„¤ì¹˜, ì„¤ì •, ì‹¤ìŠµ ì˜ˆì œê¹Œì§€ í¬í•¨í•œ ì¢…í•© íŠœí† ë¦¬ì–¼ì…ë‹ˆë‹¤."
seo_title: "Unsloth Docker LLM íŒŒì¸íŠœë‹ íŠœí† ë¦¬ì–¼ - ì™„ë²½ ê°€ì´ë“œ 2025"
seo_description: "Unsloth Dockerë¡œ LLM íŒŒì¸íŠœë‹ì„ ë§ˆìŠ¤í„°í•˜ì„¸ìš”. ì„¤ì¹˜, GPU ì„¤ì •, Jupyter Lab ì ‘ê·¼, ì‹¤ì „ í›ˆë ¨ ì˜ˆì œë¥¼ í¬í•¨í•œ ë‹¨ê³„ë³„ íŠœí† ë¦¬ì–¼ë¡œ íš¨ìœ¨ì ì¸ ëª¨ë¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•ì„ ë°°ì›Œë³´ì„¸ìš”."
date: 2025-10-03
categories:
  - tutorials
tags:
  - unsloth
  - docker
  - llm
  - fine-tuning
  - machine-learning
  - gpu
  - jupyter
  - nvidia
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
lang: ko
permalink: /ko/tutorials/unsloth-docker-llm-training-tutorial/
canonical_url: "https://thakicloud.github.io/ko/tutorials/unsloth-docker-llm-training-tutorial/"
---

â±ï¸ **ì˜ˆìƒ ì½ê¸° ì‹œê°„**: 12ë¶„

## ì†Œê°œ

ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM) íŒŒì¸íŠœë‹ì€ íŠ¹í™”ëœ AI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“œëŠ” ë° ì ì  ë” ì¤‘ìš”í•´ì§€ê³  ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ LLM í›ˆë ¨ì„ ìœ„í•œ ì ì ˆí•œ í™˜ê²½ì„ ì„¤ì •í•˜ëŠ” ê²ƒì€ ë³µì¡í•œ ì˜ì¡´ì„±ê³¼ ì ì¬ì  ì¶©ëŒë¡œ ì¸í•´ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Unslothì˜ Docker ì†”ë£¨ì…˜ì€ íš¨ìœ¨ì ì¸ LLM íŒŒì¸íŠœë‹ì„ ìœ„í•œ ì‚¬ì „ êµ¬ì„±ëœ ì•ˆì •ì ì¸ í™˜ê²½ì„ ì œê³µí•˜ì—¬ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.

ì´ ì¢…í•© íŠœí† ë¦¬ì–¼ì—ì„œëŠ” Unslothì˜ Docker ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œì»¬ì—ì„œ LLMì„ íŒŒì¸íŠœë‹í•˜ëŠ” ë°©ë²•ì„ ì´ˆê¸° ì„¤ì •ë¶€í„° ì‹¤ì „ í›ˆë ¨ ì˜ˆì œê¹Œì§€ ëª¨ë“  ê²ƒì„ ë‹¤ë£¨ì–´ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

## Unslothë€ ë¬´ì—‡ì¸ê°€?

UnslothëŠ” ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ë©´ì„œ LLM íŒŒì¸íŠœë‹ì„ ê°€ì†í™”í•˜ë„ë¡ ì„¤ê³„ëœ ê°•ë ¥í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ê¸°ì¡´ íŒŒì¸íŠœë‹ ë°©ë²•ë³´ë‹¤ ìƒë‹¹í•œ ì„±ëŠ¥ í–¥ìƒì„ ì œê³µí•˜ì—¬ ì†Œë¹„ììš© í•˜ë“œì›¨ì–´ì—ì„œë„ ë” í° ëª¨ë¸ì„ í›ˆë ¨í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.

### Unsloth Dockerì˜ ì£¼ìš” ì¥ì 

- **ì˜ì¡´ì„± ê´€ë¦¬**: ì™„ì „íˆ ê²©ë¦¬ëœ í™˜ê²½ìœ¼ë¡œ "ì˜ì¡´ì„± ì§€ì˜¥" ì œê±°
- **ì‹œìŠ¤í…œ ì•ˆì „ì„±**: ë£¨íŠ¸ ê¶Œí•œ ì—†ì´ ì‹¤í–‰ë˜ì–´ ì‹œìŠ¤í…œì„ ê¹¨ë—í•˜ê²Œ ìœ ì§€
- **ì´ì‹ì„±**: ë‹¤ì–‘í•œ í”Œë«í¼ê³¼ ì„¤ì •ì—ì„œ ì¼ê´€ë˜ê²Œ ì‘ë™
- **ì‚¬ì „ êµ¬ì„±ëœ í™˜ê²½**: í•„ìš”í•œ ëª¨ë“  ë„êµ¬ì™€ ë¼ì´ë¸ŒëŸ¬ë¦¬ í¬í•¨
- **ì •ê¸° ì—…ë°ì´íŠ¸**: ìµœì‹  ê°œì„ ì‚¬í•­ìœ¼ë¡œ ìì£¼ ì—…ë°ì´íŠ¸

## ì‚¬ì „ ìš”êµ¬ì‚¬í•­

ì‹œì‘í•˜ê¸° ì „ì— ë‹¤ìŒ ì‚¬í•­ì„ í™•ì¸í•˜ì„¸ìš”:

- **NVIDIA GPU**: íš¨ìœ¨ì ì¸ í›ˆë ¨ì„ ìœ„í•´ í•„ìš” (RTX 3060 ì´ìƒ ê¶Œì¥)
- **Docker**: ì‹œìŠ¤í…œì— ì„¤ì¹˜ë˜ê³  ì‹¤í–‰ ì¤‘
- **NVIDIA Container Toolkit**: ì»¨í…Œì´ë„ˆ ë‚´ GPU ì ‘ê·¼ì„ ìœ„í•´ í•„ìš”
- **ì¶©ë¶„í•œ ì €ì¥ê³µê°„**: ëª¨ë¸ê³¼ ë°ì´í„°ë¥¼ ìœ„í•´ ìµœì†Œ 50GB ì—¬ìœ  ê³µê°„
- **RAM**: 16GB ì´ìƒ ê¶Œì¥

## 1ë‹¨ê³„: Docker ë° NVIDIA Container Toolkit ì„¤ì¹˜

### Docker ì„¤ì¹˜

Linux ì‹œìŠ¤í…œì˜ ê²½ìš°:
```bash
# íŒ¨í‚¤ì§€ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
sudo apt-get update

# Docker ì„¤ì¹˜
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# ì‚¬ìš©ìë¥¼ docker ê·¸ë£¹ì— ì¶”ê°€
sudo usermod -aG docker $USER
newgrp docker
```

ë‹¤ë¥¸ ì‹œìŠ¤í…œì˜ ê²½ìš° [ê³µì‹ Docker ì„¤ì¹˜ ê°€ì´ë“œ](https://docs.docker.com/get-docker/)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

### NVIDIA Container Toolkit ì„¤ì¹˜

NVIDIA Container Toolkitì€ Docker ì»¨í…Œì´ë„ˆ ë‚´ì—ì„œ GPU ì ‘ê·¼ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤:

```bash
# ë²„ì „ ì„¤ì • (ìµœì‹  ì•ˆì • ë²„ì „ ì‚¬ìš©)
export NVIDIA_CONTAINER_TOOLKIT_VERSION=1.17.8-1

# NVIDIA Container Toolkit ì„¤ì¹˜
sudo apt-get update && sudo apt-get install -y \
  nvidia-container-toolkit=${NVIDIA_CONTAINER_TOOLKIT_VERSION} \
  nvidia-container-toolkit-base=${NVIDIA_CONTAINER_TOOLKIT_VERSION} \
  libnvidia-container-tools=${NVIDIA_CONTAINER_TOOLKIT_VERSION} \
  libnvidia-container1=${NVIDIA_CONTAINER_TOOLKIT_VERSION}

# Docker ë°ëª¬ ì¬ì‹œì‘
sudo systemctl restart docker
```

### ì„¤ì¹˜ í™•ì¸

GPU ì ‘ê·¼ì„ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”:
```bash
# NVIDIA Docker í†µí•© í…ŒìŠ¤íŠ¸
docker run --rm --gpus all nvidia/cuda:11.8-base-ubuntu20.04 nvidia-smi
```

## 2ë‹¨ê³„: Unsloth Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰

### ê¸°ë³¸ ì»¨í…Œì´ë„ˆ ì„¤ì •

ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ ë§Œë“¤ê³  ì»¨í…Œì´ë„ˆë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:

```bash
# ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p ~/unsloth-workspace
cd ~/unsloth-workspace

# ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ Unsloth ì»¨í…Œì´ë„ˆ ì‹¤í–‰
docker run -d \
  --name unsloth-training \
  -e JUPYTER_PASSWORD="mypassword" \
  -p 8888:8888 \
  -p 2222:22 \
  -v $(pwd)/work:/workspace/work \
  --gpus all \
  unsloth/unsloth
```

### ê³ ê¸‰ ì„¤ì •

í”„ë¡œë•ì…˜ ì‚¬ìš©ì„ ìœ„í•œ í–¥ìƒëœ ì„¤ì •:

```bash
# ë³´ì•ˆ ì ‘ê·¼ì„ ìœ„í•œ SSH í‚¤ ìƒì„±
ssh-keygen -t rsa -b 4096 -f ~/.ssh/unsloth_key

# ê³ ê¸‰ ì„¤ì •ìœ¼ë¡œ ì»¨í…Œì´ë„ˆ ì‹¤í–‰
docker run -d \
  --name unsloth-production \
  -e JUPYTER_PORT=8000 \
  -e JUPYTER_PASSWORD="secure_password_2024" \
  -e "SSH_KEY=$(cat ~/.ssh/unsloth_key.pub)" \
  -e USER_PASSWORD="unsloth2024" \
  -p 8000:8000 \
  -p 2222:22 \
  -v $(pwd)/work:/workspace/work \
  -v $(pwd)/models:/workspace/models \
  -v $(pwd)/datasets:/workspace/datasets \
  --gpus all \
  --restart unless-stopped \
  unsloth/unsloth
```

## 3ë‹¨ê³„: Jupyter Lab ì ‘ê·¼

### ì›¹ ì¸í„°í˜ì´ìŠ¤ ì ‘ê·¼

1. ë¸Œë¼ìš°ì €ë¥¼ ì—´ê³  `http://localhost:8888`ë¡œ ì´ë™
2. ì„¤ì •í•œ ë¹„ë°€ë²ˆí˜¸ ì…ë ¥ (ê¸°ë³¸ê°’: "unsloth")
3. ì‚¬ì „ ë¡œë“œëœ ë…¸íŠ¸ë¶ì´ ìˆëŠ” Jupyter Lab ì¸í„°í˜ì´ìŠ¤ í™•ì¸

### SSH ì ‘ê·¼ (ì„ íƒì‚¬í•­)

ëª…ë ¹ì¤„ ì ‘ê·¼ì„ ìœ„í•´:
```bash
# SSHë¥¼ í†µí•œ ì—°ê²°
ssh -i ~/.ssh/unsloth_key -p 2222 unsloth@localhost
```

## 4ë‹¨ê³„: ì»¨í…Œì´ë„ˆ êµ¬ì¡° ì´í•´

Unsloth ì»¨í…Œì´ë„ˆëŠ” ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

```
/workspace/
â”œâ”€â”€ work/                    # ë§ˆìš´íŠ¸ëœ ì‘ì—… ë””ë ‰í† ë¦¬
â”œâ”€â”€ unsloth-notebooks/       # íŒŒì¸íŠœë‹ ì˜ˆì œ ë…¸íŠ¸ë¶
â”œâ”€â”€ models/                  # ëª¨ë¸ ì €ì¥ì†Œ (ë§ˆìš´íŠ¸ëœ ê²½ìš°)
â””â”€â”€ datasets/               # ë°ì´í„°ì…‹ ì €ì¥ì†Œ (ë§ˆìš´íŠ¸ëœ ê²½ìš°)

/home/unsloth/              # ì‚¬ìš©ì í™ˆ ë””ë ‰í† ë¦¬
```

## 5ë‹¨ê³„: ì²« ë²ˆì§¸ íŒŒì¸íŠœë‹ ì˜ˆì œ

Llama-3ë¥¼ ì‚¬ìš©í•œ ê°„ë‹¨í•œ íŒŒì¸íŠœë‹ ì˜ˆì œë¥¼ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤.

### ìƒˆ ë…¸íŠ¸ë¶ ìƒì„±

1. Jupyter Labì—ì„œ ìƒˆ ë…¸íŠ¸ë¶ ìƒì„±
2. ë‹¤ìŒ ì½”ë“œ ì…€ë“¤ì„ ì¶”ê°€:

```python
# ì…€ 1: ì˜ì¡´ì„± ì„¤ì¹˜ ë° ì„í¬íŠ¸
from unsloth import FastLanguageModel
import torch

# ì…€ 2: ëª¨ë¸ ë¡œë“œ
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name="unsloth/llama-3-8b-bnb-4bit",
    max_seq_length=2048,
    dtype=None,
    load_in_4bit=True,
)

# ì…€ 3: LoRA ì„¤ì •
model = FastLanguageModel.get_peft_model(
    model,
    r=16,
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj",
                    "gate_proj", "up_proj", "down_proj"],
    lora_alpha=16,
    lora_dropout=0,
    bias="none",
    use_gradient_checkpointing="unsloth",
    random_state=3407,
    use_rslora=False,
    loftq_config=None,
)

# ì…€ 4: ë°ì´í„°ì…‹ ì¤€ë¹„
alpaca_prompt = """Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.

### Instruction:
{}

### Input:
{}

### Response:
{}"""

def formatting_prompts_func(examples):
    instructions = examples["instruction"]
    inputs       = examples["input"]
    outputs      = examples["output"]
    texts = []
    for instruction, input, output in zip(instructions, inputs, outputs):
        text = alpaca_prompt.format(instruction, input, output) + tokenizer.eos_token
        texts.append(text)
    return { "text" : texts, }

# ë°ì´í„°ì…‹ ë¡œë“œ
from datasets import load_dataset
dataset = load_dataset("yahma/alpaca-cleaned", split="train")
dataset = dataset.map(formatting_prompts_func, batched=True)

# ì…€ 5: í›ˆë ¨ ì„¤ì •
from trl import SFTTrainer
from transformers import TrainingArguments

trainer = SFTTrainer(
    model=model,
    tokenizer=tokenizer,
    train_dataset=dataset,
    dataset_text_field="text",
    max_seq_length=2048,
    dataset_num_proc=2,
    packing=False,
    args=TrainingArguments(
        per_device_train_batch_size=2,
        gradient_accumulation_steps=4,
        warmup_steps=5,
        max_steps=60,
        learning_rate=2e-4,
        fp16=not torch.cuda.is_bf16_supported(),
        bf16=torch.cuda.is_bf16_supported(),
        logging_steps=1,
        optim="adamw_8bit",
        weight_decay=0.01,
        lr_scheduler_type="linear",
        seed=3407,
        output_dir="outputs",
    ),
)

# ì…€ 6: í›ˆë ¨ ì‹œì‘
trainer_stats = trainer.train()
```

### í›ˆë ¨ ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§

í›ˆë ¨ ê³¼ì •ì—ì„œ ì§„í–‰ë¥  í‘œì‹œì¤„ê³¼ ì†ì‹¤ ë©”íŠ¸ë¦­ì´ í‘œì‹œë©ë‹ˆë‹¤. ì´ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ì—¬ í›ˆë ¨ì´ ì˜¬ë°”ë¥´ê²Œ ì§„í–‰ë˜ê³  ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.

## 6ë‹¨ê³„: íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ì €ì¥ ë° ì‚¬ìš©

### ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥

```python
# Hugging Face í˜•ì‹ìœ¼ë¡œ ì €ì¥
model.save_pretrained("my_finetuned_model")
tokenizer.save_pretrained("my_finetuned_model")

# Ollamaìš© GGUF í˜•ì‹ìœ¼ë¡œ ì €ì¥
model.save_pretrained_gguf("my_model", tokenizer, quantization_method="q4_k_m")

# VLLMìš©ìœ¼ë¡œ ì €ì¥
model.save_pretrained_merged("my_model_vllm", tokenizer, save_method="merged_16bit")
```

### ëª¨ë¸ í…ŒìŠ¤íŠ¸

```python
# ì¶”ë¡  í…ŒìŠ¤íŠ¸
FastLanguageModel.for_inference(model)

inputs = tokenizer(
    [alpaca_prompt.format(
        "í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?",
        "",
        ""
    )], return_tensors="pt").to("cuda")

outputs = model.generate(**inputs, max_new_tokens=64, use_cache=True)
print(tokenizer.batch_decode(outputs))
```

## ê³ ê¸‰ ì„¤ì • ì˜µì…˜

### í™˜ê²½ ë³€ìˆ˜

| ë³€ìˆ˜ | ì„¤ëª… | ê¸°ë³¸ê°’ |
|------|------|--------|
| `JUPYTER_PASSWORD` | Jupyter Lab ë¹„ë°€ë²ˆí˜¸ | `unsloth` |
| `JUPYTER_PORT` | Jupyter Lab í¬íŠ¸ | `8888` |
| `SSH_KEY` | SSH ê³µê°œ í‚¤ | `None` |
| `USER_PASSWORD` | sudoìš© ì‚¬ìš©ì ë¹„ë°€ë²ˆí˜¸ | `unsloth` |

### GPU ë©”ëª¨ë¦¬ ìµœì í™”

GPU ë©”ëª¨ë¦¬ê°€ ì œí•œëœ ì‹œìŠ¤í…œì˜ ê²½ìš°:

```python
# ë” ì‘ì€ ë°°ì¹˜ í¬ê¸° ì‚¬ìš©
per_device_train_batch_size=1
gradient_accumulation_steps=8

# ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ… í™œì„±í™”
use_gradient_checkpointing="unsloth"

# 4ë¹„íŠ¸ ì–‘ìí™” ì‚¬ìš©
load_in_4bit=True
```

### ë©€í‹° GPU í›ˆë ¨

ì—¬ëŸ¬ GPUê°€ ìˆëŠ” ì‹œìŠ¤í…œì˜ ê²½ìš°:

```bash
# ëª¨ë“  GPUë¡œ ì»¨í…Œì´ë„ˆ ì‹¤í–‰
docker run -d \
  --gpus all \
  # ... ê¸°íƒ€ ë§¤ê°œë³€ìˆ˜
  unsloth/unsloth

# í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ DataParallel ì‚¬ìš©
model = torch.nn.DataParallel(model)
```

## ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°

### GPUê°€ ê°ì§€ë˜ì§€ ì•ŠëŠ” ê²½ìš°

```bash
# GPU ê°€ìš©ì„± í™•ì¸
nvidia-smi

# Docker GPU ì ‘ê·¼ í™•ì¸
docker run --rm --gpus all nvidia/cuda:11.8-base-ubuntu20.04 nvidia-smi
```

### ë©”ëª¨ë¦¬ ë¬¸ì œ

- ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
- ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ… í™œì„±í™”
- 4ë¹„íŠ¸ ì–‘ìí™” ì‚¬ìš©
- GPU ìºì‹œ ì •ë¦¬: `torch.cuda.empty_cache()`

### ì»¨í…Œì´ë„ˆ ì ‘ê·¼ ë¬¸ì œ

```bash
# ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
docker ps -a

# ì»¨í…Œì´ë„ˆ ë¡œê·¸ ë³´ê¸°
docker logs unsloth-training

# ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
docker restart unsloth-training
```

## ëª¨ë²” ì‚¬ë¡€

### 1. ë°ì´í„° ê´€ë¦¬

- ì˜êµ¬ ì €ì¥ì„ ìœ„í•´ ë³¼ë¥¨ ë§ˆìš´íŠ¸ ì‚¬ìš©
- ì „ìš© ë””ë ‰í† ë¦¬ì— ë°ì´í„°ì…‹ ì •ë¦¬
- ì¤‘ìš”í•œ ëª¨ë¸ ì •ê¸°ì ìœ¼ë¡œ ë°±ì—…

### 2. ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§

```python
# GPU ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
import GPUtil
GPUtil.showUtilization()

# ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§
import psutil
print(f"CPU: {psutil.cpu_percent()}%")
print(f"RAM: {psutil.virtual_memory().percent}%")
```

### 3. ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

- Jupyter ì ‘ê·¼ì„ ìœ„í•œ ê°•ë ¥í•œ ë¹„ë°€ë²ˆí˜¸ ì‚¬ìš©
- SSH í‚¤ ì¸ì¦ êµ¬í˜„
- ì»¨í…Œì´ë„ˆë¥¼ ë¹„ë£¨íŠ¸ ì‚¬ìš©ìë¡œ ì‹¤í–‰
- Unsloth ì´ë¯¸ì§€ ì •ê¸°ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸

### 4. ì„±ëŠ¥ ìµœì í™”

- GPUì— ì í•©í•œ ë°°ì¹˜ í¬ê¸° ì‚¬ìš©
- í˜¼í•© ì •ë°€ë„ í›ˆë ¨ í™œì„±í™”
- íš¨ê³¼ì ì¸ ë” í° ë°°ì¹˜ í¬ê¸°ë¥¼ ìœ„í•´ ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  í™œìš©
- ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•´ í›ˆë ¨ ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§

## í”„ë¡œë•ì…˜ ë°°í¬

### Docker Compose ì„¤ì •

ë” ì‰¬ìš´ ê´€ë¦¬ë¥¼ ìœ„í•œ `docker-compose.yml` ìƒì„±:

```yaml
version: '3.8'
services:
  unsloth:
    image: unsloth/unsloth
    container_name: unsloth-production
    environment:
      - JUPYTER_PASSWORD=secure_password
      - JUPYTER_PORT=8888
      - USER_PASSWORD=unsloth2024
    ports:
      - "8888:8888"
      - "2222:22"
    volumes:
      - ./work:/workspace/work
      - ./models:/workspace/models
      - ./datasets:/workspace/datasets
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped
```

### ìë™í™”ëœ í›ˆë ¨ íŒŒì´í”„ë¼ì¸

ìë™í™”ëœ ì›Œí¬í”Œë¡œìš°ë¥¼ ìœ„í•œ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±:

```python
#!/usr/bin/env python3
"""
ìë™í™”ëœ Unsloth í›ˆë ¨ íŒŒì´í”„ë¼ì¸
"""
import argparse
import json
from pathlib import Path
from unsloth import FastLanguageModel
from transformers import TrainingArguments
from trl import SFTTrainer

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", required=True, help="í›ˆë ¨ ì„¤ì • JSON íŒŒì¼")
    args = parser.parse_args()
    
    # ì„¤ì • ë¡œë“œ
    with open(args.config) as f:
        config = json.load(f)
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    model, tokenizer = FastLanguageModel.from_pretrained(
        model_name=config["model_name"],
        max_seq_length=config["max_seq_length"],
        load_in_4bit=config.get("load_in_4bit", True)
    )
    
    # LoRA ì„¤ì •
    model = FastLanguageModel.get_peft_model(
        model,
        r=config["lora_r"],
        target_modules=config["target_modules"],
        lora_alpha=config["lora_alpha"],
        lora_dropout=config["lora_dropout"],
        bias="none",
        use_gradient_checkpointing="unsloth"
    )
    
    # í›ˆë ¨ ë¡œì§...
    print("í›ˆë ¨ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    main()
```

## ê²°ë¡ 

Unsloth DockerëŠ” ì„¤ì • ë³µì¡ì„±ì„ ì œê±°í•˜ë©´ì„œ ì„±ëŠ¥ê³¼ ìœ ì—°ì„±ì„ ìœ ì§€í•˜ëŠ” LLM íŒŒì¸íŠœë‹ì„ ìœ„í•œ í›Œë¥­í•œ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ íŠœí† ë¦¬ì–¼ì„ ë”°ë¼í•˜ë©´ ì´ì œ ë‹¤ìŒì„ ê°–ì¶”ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤:

- ì™„ì „íˆ êµ¬ì„±ëœ Unsloth í™˜ê²½
- ê¸°ë³¸ ë° ê³ ê¸‰ ì„¤ì • ì˜µì…˜ì— ëŒ€í•œ ì´í•´
- íŒŒì¸íŠœë‹ ì›Œí¬í”Œë¡œìš°ì— ëŒ€í•œ ì‹¤ì „ ê²½í—˜
- ëª¨ë²” ì‚¬ë¡€ ë° ë¬¸ì œ í•´ê²° ê¸°ë²•ì— ëŒ€í•œ ì§€ì‹

ì»¨í…Œì´ë„ˆí™”ëœ ì ‘ê·¼ ë°©ì‹ì€ ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ë³´ì¥í•˜ê³  ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ íŒŒì¸íŠœë‹ ì‘ì—…ì„ ì‰½ê²Œ í™•ì¥í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.

### ë‹¤ìŒ ë‹¨ê³„

1. **ë‹¤ì–‘í•œ ëª¨ë¸ ì‹¤í—˜**: ë‹¤ì–‘í•œ ëª¨ë¸ ì•„í‚¤í…ì²˜ íŒŒì¸íŠœë‹ ì‹œë„
2. **ê³ ê¸‰ ê¸°ë²• íƒêµ¬**: ê°•í™”í•™ìŠµ ë° DPO í›ˆë ¨ ì¡°ì‚¬
3. **í”„ë¡œë•ì…˜ ìµœì í™”**: ìë™í™”ëœ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ êµ¬í˜„
4. **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: í¬ê´„ì ì¸ ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ì„¤ì •

### ì¶”ê°€ ë¦¬ì†ŒìŠ¤

- [Unsloth ê³µì‹ ë¬¸ì„œ](https://docs.unsloth.ai/)
- [Unsloth GitHub ì €ì¥ì†Œ](https://github.com/unslothai/unsloth)
- [Docker ëª¨ë²” ì‚¬ë¡€](https://docs.docker.com/develop/best-practices/)
- [NVIDIA Container Toolkit ë¬¸ì„œ](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/)

ì¦ê±°ìš´ íŒŒì¸íŠœë‹ ë˜ì„¸ìš”! ğŸš€
