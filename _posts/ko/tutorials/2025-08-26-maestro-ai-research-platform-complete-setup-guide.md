---
title: "MAESTRO: AI ê¸°ë°˜ ì—°êµ¬ í”Œë«í¼ ì™„ì „ ì„¤ì¹˜ ë° í™œìš© ê°€ì´ë“œ"
excerpt: "AI ì—ì´ì „íŠ¸ ê¸°ë°˜ ì—°êµ¬ ìë™í™” í”Œë«í¼ MAESTROì˜ ì„¤ì¹˜ë¶€í„° ê³ ê¸‰ í™œìš©ê¹Œì§€ ë‹¨ê³„ë³„ ì™„ì „ ê°€ì´ë“œ"
seo_title: "MAESTRO AI ì—°êµ¬ í”Œë«í¼ ì„¤ì¹˜ ê°€ì´ë“œ - Docker, GPU ì„¤ì •, ë¡œì»¬ LLM ì—°ë™ - Thaki Cloud"
seo_description: "ì˜¤í”ˆì†ŒìŠ¤ AI ì—°êµ¬ í”Œë«í¼ MAESTRO ì„¤ì¹˜ ë°©ë²•ë¶€í„° GPU ìµœì í™”, SearXNG ê²€ìƒ‰ ì—”ì§„ ì—°ë™, ë¡œì»¬ LLM ì„¤ì •ê¹Œì§€ ì‹¤ë¬´ ì¤‘ì‹¬ íŠœí† ë¦¬ì–¼"
date: 2025-08-26
categories:
  - tutorials
tags:
  - maestro
  - ai-research
  - docker
  - fastapi
  - react
  - postgresql
  - pgvector
  - searxng
  - local-llm
  - gpu
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
canonical_url: "https://thakicloud.github.io/ko/tutorials/maestro-ai-research-platform-complete-setup-guide/"
lang: ko
permalink: /ko/tutorials/maestro-ai-research-platform-complete-setup-guide/
---

â±ï¸ **ì˜ˆìƒ ì½ê¸° ì‹œê°„**: 25ë¶„

## 1. MAESTRO ì†Œê°œ

### MAESTROë€?

MAESTROëŠ” AI ê¸°ë°˜ì˜ ì—°êµ¬ ìë™í™” í”Œë«í¼ìœ¼ë¡œ, ë³µì¡í•œ ì—°êµ¬ ì‘ì—…ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ëœ ì˜¤í”ˆì†ŒìŠ¤ ì• í”Œë¦¬ì¼€ì´ì…˜ì…ë‹ˆë‹¤. AI ì—ì´ì „íŠ¸ë¥¼ í™œìš©í•˜ì—¬ ë¬¸ì„œ ìˆ˜ì§‘, ë¶„ì„, ë³´ê³ ì„œ ìƒì„±ê¹Œì§€ ì „ì²´ ì—°êµ¬ ì›Œí¬í”Œë¡œìš°ë¥¼ ìë™í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì£¼ìš” íŠ¹ì§•

- **AI ì—ì´ì „íŠ¸ ê¸°ë°˜ ì—°êµ¬**: LLMì„ í™œìš©í•œ ìë™í™”ëœ ì—°êµ¬ íŒŒì´í”„ë¼ì¸
- **RAG (Retrieval-Augmented Generation)**: ë²¡í„° ê²€ìƒ‰ ê¸°ë°˜ ë¬¸ì„œ ì²˜ë¦¬
- **ì‹¤ì‹œê°„ ì›¹ì†Œì¼“ í†µì‹ **: ì‘ì—… ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
- **ì™„ì „ ì…€í”„ í˜¸ìŠ¤íŒ…**: ë¡œì»¬ í™˜ê²½ì—ì„œ ì™„ì „í•œ ë…ë¦½ ìš´ì˜ ê°€ëŠ¥
- **ë‹¤ì–‘í•œ LLM ì§€ì›**: OpenAI, ë¡œì»¬ LLM, API í˜¸í™˜ ëª¨ë¸
- **SearXNG í†µí•©**: í”„ë¼ì´ë¹— ë©”íƒ€ ê²€ìƒ‰ ì—”ì§„ ì—°ë™

### ê¸°ìˆ  ìŠ¤íƒ

- **ë°±ì—”ë“œ**: FastAPI, SQLAlchemy, PostgreSQL, pgvector
- **í”„ë¡ íŠ¸ì—”ë“œ**: React, TypeScript, Vite, Tailwind CSS
- **ì¸í”„ë¼**: Docker Compose, WebSocket
- **AI/ML**: ë²¡í„° ì„ë² ë”©, LLM API í†µí•©

## 2. ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

### ìµœì†Œ í•˜ë“œì›¨ì–´ ì‚¬ì–‘

```bash
# CPU ëª¨ë“œ (ìµœì†Œ)
- CPU: 4ì½”ì–´ ì´ìƒ
- RAM: 8GB ì´ìƒ
- ì €ì¥ê³µê°„: 10GB ì´ìƒ
- OS: Linux, macOS, Windows (WSL2)

# GPU ëª¨ë“œ (ê¶Œì¥)
- GPU: NVIDIA GPU (CUDA 11.0 ì´ìƒ)
- VRAM: 8GB ì´ìƒ
- RAM: 16GB ì´ìƒ
- ì €ì¥ê³µê°„: 20GB ì´ìƒ
```

### í•„ìˆ˜ ì†Œí”„íŠ¸ì›¨ì–´

```bash
# ê³µí†µ ìš”êµ¬ì‚¬í•­
- Docker Desktop (ìµœì‹  ë²„ì „)
- Docker Compose v2
- Git

# GPU ì‚¬ìš© ì‹œ ì¶”ê°€ ìš”êµ¬ì‚¬í•­ (Linux)
- nvidia-container-toolkit
- NVIDIA ë“œë¼ì´ë²„ (ìµœì‹  ë²„ì „)

# Windows ì‚¬ìš©ì
- WSL2 (Ubuntu 20.04 ì´ìƒ)
- Windows Terminal (ê¶Œì¥)
```

## 3. ì„¤ì¹˜ ë° ì´ˆê¸° ì„¤ì •

### 3.1 ì €ì¥ì†Œ í´ë¡  ë° ê¸°ë³¸ ì„¤ì •

```bash
# 1. MAESTRO ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/murtaza-nasir/maestro.git
cd maestro

# 2. ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬ (Linux/macOS)
chmod +x start.sh stop.sh detect_gpu.sh maestro-cli.sh

# 3. í™˜ê²½ ì„¤ì • íŒŒì¼ ìƒì„±
cp .env.example .env
```

### 3.2 í™˜ê²½ë³€ìˆ˜ ì„¤ì •

`.env` íŒŒì¼ì„ í¸ì§‘í•˜ì—¬ ê¸°ë³¸ ì„¤ì •ì„ êµ¬ì„±í•©ë‹ˆë‹¤:

```bash
# .env íŒŒì¼ ì£¼ìš” ì„¤ì •
# ===================

# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
POSTGRES_DB=maestro_db
POSTGRES_USER=maestro_user
POSTGRES_PASSWORD=your_secure_password_here

# JWT ë³´ì•ˆ ì„¤ì •
JWT_SECRET_KEY=your_jwt_secret_key_here
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30

# LLM API ì„¤ì • (OpenAI ì‚¬ìš© ì‹œ)
OPENAI_API_KEY=your_openai_api_key_here
LLM_MODEL=gpt-4

# ë¡œì»¬ LLM ì„¤ì • (Ollama ì‚¬ìš© ì‹œ)
LOCAL_LLM_BASE_URL=http://localhost:11434/v1
LOCAL_LLM_MODEL=llama3.1:8b
USE_LOCAL_LLM=true

# ê²€ìƒ‰ ì—”ì§„ ì„¤ì •
SEARCH_ENGINE=searxng
SEARXNG_BASE_URL=http://searxng:8080

# GPU ì„¤ì •
GPU_AVAILABLE=true
BACKEND_GPU_DEVICE=0
DOC_PROCESSOR_GPU_DEVICE=0

# CPU ì „ìš© ëª¨ë“œ (GPU ì—†ëŠ” í™˜ê²½)
FORCE_CPU_MODE=false
```

### 3.3 GPU ì§€ì› í™•ì¸

GPU ì§€ì› ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê³  ìµœì  ì„¤ì •ì„ ì ìš©í•©ë‹ˆë‹¤:

```bash
# GPU ê°ì§€ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
./detect_gpu.sh

# ì¶œë ¥ ì˜ˆì‹œ:
# =========== GPU Detection Results ===========
# Platform: Linux
# GPU Support: Available
# NVIDIA Driver: 525.147.05
# CUDA Version: 12.0
# Recommended Configuration: GPU-enabled
# ===========================================
```

## 4. í”Œë«í¼ë³„ ì„¤ì¹˜ ê°€ì´ë“œ

### 4.1 Linux (Ubuntu/Debian) - GPU ì§€ì›

```bash
# 1. NVIDIA ì»¨í…Œì´ë„ˆ íˆ´í‚· ì„¤ì¹˜
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit

# 2. Docker ì¬ì‹œì‘
sudo systemctl restart docker

# 3. GPU í…ŒìŠ¤íŠ¸
docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi

# 4. MAESTRO ì‹œì‘
./start.sh
```

### 4.2 macOS (Apple Silicon/Intel)

```bash
# 1. Docker Desktop ì„¤ì¹˜ í™•ì¸
docker --version
docker-compose --version

# 2. CPU ìµœì í™” ëª¨ë“œë¡œ ì‹œì‘
docker-compose -f docker-compose.cpu.yml up -d

# ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ ì„¤ì • í›„ ì¼ë°˜ ì‹œì‘
echo "FORCE_CPU_MODE=true" >> .env
./start.sh
```

### 4.3 Windows (WSL2)

PowerShellì„ ê´€ë¦¬ì ê¶Œí•œìœ¼ë¡œ ì‹¤í–‰:

```powershell
# 1. WSL2 ë° Ubuntu ì„¤ì¹˜ í™•ì¸
wsl --list --verbose

# 2. Docker Desktop Windows ì‹¤í–‰ í™•ì¸
docker --version

# 3. ì €ì¥ì†Œ í´ë¡  (WSL2 ë‚´ë¶€)
wsl
cd /mnt/c/
git clone https://github.com/murtaza-nasir/maestro.git
cd maestro

# 4. ê¶Œí•œ ì„¤ì • ë° ì‹œì‘
chmod +x *.sh
./start.sh

# ë˜ëŠ” PowerShell ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©
# .\start.ps1
```

## 5. ì„œë¹„ìŠ¤ êµ¬ì„± ë° ì‹œì‘

### 5.1 ê¸°ë³¸ ì„œë¹„ìŠ¤ ì‹œì‘

```bash
# ìë™ í”Œë«í¼ ê°ì§€ë¡œ ì‹œì‘
./start.sh

# ë˜ëŠ” ìˆ˜ë™ìœ¼ë¡œ Docker Compose ì‹¤í–‰
docker-compose up -d

# CPU ì „ìš© ëª¨ë“œ
docker-compose -f docker-compose.cpu.yml up -d
```

### 5.2 ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸

```bash
# ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
docker-compose ps

# ë¡œê·¸ í™•ì¸
docker-compose logs -f backend
docker-compose logs -f frontend
docker-compose logs -f postgres
docker-compose logs -f searxng

# ì „ì²´ ë¡œê·¸ í™•ì¸
docker-compose logs -f
```

### 5.3 ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”

```bash
# ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸
./maestro-cli.sh reset-db --check

# ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¡°íšŒ
./maestro-cli.sh reset-db --stats

# ë°±ì—…ê³¼ í•¨ê»˜ ë°ì´í„°ë² ì´ìŠ¤ ë¦¬ì…‹ (í•„ìš”ì‹œ)
./maestro-cli.sh reset-db --backup
```

## 6. ì›¹ ì¸í„°í˜ì´ìŠ¤ ì ‘ì† ë° ì´ˆê¸° ì„¤ì •

### 6.1 ì²« ì ‘ì† ë° ê³„ì • ìƒì„±

```bash
# ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†
http://localhost:3000

# ë˜ëŠ” CLIë¡œ ê´€ë¦¬ì ê³„ì • ìƒì„±
./maestro-cli.sh create-user admin securepassword123 --admin
```

### 6.2 ê¸°ë³¸ ì„¤ì • êµ¬ì„±

ì›¹ ì¸í„°í˜ì´ìŠ¤ì—ì„œ `Settings` ë©”ë‰´ë¡œ ì´ë™í•˜ì—¬ ë‹¤ìŒì„ ì„¤ì •í•©ë‹ˆë‹¤:

```yaml
# LLM ì„¤ì •
Model Provider: OpenAI / Local LLM
API Key: [YOUR_API_KEY]
Model Name: gpt-4 / llama3.1:8b
Temperature: 0.7
Max Tokens: 4000

# ê²€ìƒ‰ ì„¤ì •
Search Engine: SearXNG
Categories: 
  - General
  - Science
  - IT
  - News
Results per Query: 10

# ì—°êµ¬ ë§¤ê°œë³€ìˆ˜
Planning Context: 200000
Max Documents: 50
Chunk Size: 1000
Overlap: 200
```

## 7. ë¡œì»¬ LLM ì—°ë™ (Ollama)

### 7.1 Ollama ì„¤ì¹˜ ë° ì„¤ì •

```bash
# Ollama ì„¤ì¹˜ (Linux/macOS)
curl -fsSL https://ollama.ai/install.sh | sh

# Windows (PowerShell)
# Invoke-WebRequest -Uri https://ollama.ai/install.ps1 -OutFile install.ps1; .\install.ps1

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ollama pull llama3.1:8b
ollama pull codellama:7b
ollama pull mistral:7b

# Ollama ì„œë¹„ìŠ¤ ì‹œì‘
ollama serve
```

### 7.2 MAESTROì™€ Ollama ì—°ë™

`.env` íŒŒì¼ì„ ë‹¤ìŒê³¼ ê°™ì´ ìˆ˜ì •:

```bash
# ë¡œì»¬ LLM ì„¤ì •
USE_LOCAL_LLM=true
LOCAL_LLM_BASE_URL=http://host.docker.internal:11434/v1
LOCAL_LLM_MODEL=llama3.1:8b
LOCAL_LLM_API_KEY=ollama

# OpenAI í˜¸í™˜ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
LLM_PROVIDER=local
```

### 7.3 ì—°ë™ í…ŒìŠ¤íŠ¸

```bash
# CLIë¡œ ëª¨ë¸ í…ŒìŠ¤íŠ¸
./maestro-cli.sh test-llm

# ë˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ë¡œ ì§ì ‘ í…ŒìŠ¤íŠ¸
python << EOF
import requests

response = requests.post('http://localhost:11434/v1/chat/completions', 
    json={
        'model': 'llama3.1:8b',
        'messages': [{'role': 'user', 'content': 'Hello, MAESTRO!'}],
        'max_tokens': 100
    }
)
print(response.json())
EOF
```

## 8. SearXNG ê²€ìƒ‰ ì—”ì§„ ì„¤ì •

### 8.1 SearXNG ì»¨í…Œì´ë„ˆ ì„¤ì • í™•ì¸

```bash
# SearXNG ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
docker-compose logs searxng

# ì„¤ì • íŒŒì¼ í™•ì¸
docker-compose exec searxng cat /etc/searxng/settings.yml
```

### 8.2 ê²€ìƒ‰ ì¹´í…Œê³ ë¦¬ ì„¤ì •

SearXNGì˜ `settings.yml` íŒŒì¼ì„ ì»¤ìŠ¤í„°ë§ˆì´ì§•:

```yaml
# searxng/settings.yml
search:
  safe_search: 0
  autocomplete: duckduckgo
  default_lang: ""
  formats:
    - html
    - json  # MAESTRO í†µí•©ì„ ìœ„í•´ í•„ìˆ˜

categories:
  general:
    - google
    - bing
    - duckduckgo
  science:
    - arxiv
    - pubmed
    - semantic scholar
  it:
    - github
    - stackoverflow
    - documentation
  news:
    - google news
    - reuters
    - bbc
```

### 8.3 í”„ë¼ì´ë¹— ê²€ìƒ‰ í…ŒìŠ¤íŠ¸

```bash
# SearXNG API í…ŒìŠ¤íŠ¸
curl "http://localhost:8080/search?q=artificial+intelligence&format=json&category=science"

# MAESTROì—ì„œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
# ì›¹ ì¸í„°í˜ì´ìŠ¤ > Settings > Search > Test Search ë²„íŠ¼ í´ë¦­
```

## 9. ì‹¤ì „ í™œìš© ì‹œë‚˜ë¦¬ì˜¤

### 9.1 ë¬¸ì„œ ìˆ˜ì§‘ ë° ë¶„ì„

```bash
# CLIë¡œ ë¬¸ì„œ ì¼ê´„ ì—…ë¡œë“œ
./maestro-cli.sh ingest username ./research_documents

# ì§€ì› í˜•ì‹
# - PDF, DOCX, TXT, MD
# - ì›¹ URL, arXiv ë…¼ë¬¸
# - JSON, CSV ë°ì´í„°

# ì—…ë¡œë“œ ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
./maestro-cli.sh status username
```

### 9.2 ì—°êµ¬ í”„ë¡œì íŠ¸ ìƒì„±

ì›¹ ì¸í„°í˜ì´ìŠ¤ì—ì„œ ìƒˆ ì—°êµ¬ í”„ë¡œì íŠ¸ ìƒì„±:

```yaml
# ì—°êµ¬ ì„¤ì • ì˜ˆì‹œ
Project Name: "AI Agent Architecture Analysis"
Research Question: "What are the latest trends in AI agent architectures?"
Scope: 
  - Academic papers (2023-2024)
  - Industry reports
  - Technical documentation
Output Format: "Comprehensive report with citations"
```

### 9.3 AI ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰

```bash
# 1. ê³„íš ìˆ˜ë¦½ ë‹¨ê³„
Research Agent -> Planning Context Analysis
              -> Outline Generation
              -> Resource Identification

# 2. ë°ì´í„° ìˆ˜ì§‘ ë‹¨ê³„  
Search Agent -> Web Search (SearXNG)
             -> Document Retrieval
             -> Content Extraction

# 3. ë¶„ì„ ë‹¨ê³„
Analysis Agent -> RAG-based Analysis
               -> Cross-reference Validation
               -> Insight Generation

# 4. ë³´ê³ ì„œ ìƒì„± ë‹¨ê³„
Report Agent -> Content Synthesis
             -> Citation Management
             -> Output Formatting
```

## 10. ê³ ê¸‰ ì„¤ì • ë° ìµœì í™”

### 10.1 GPU ë©”ëª¨ë¦¬ ìµœì í™”

```bash
# GPU ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
nvidia-smi -l 1

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” ì„¤ì •
# .env íŒŒì¼ì— ì¶”ê°€
MAX_GPU_MEMORY=8192  # MB ë‹¨ìœ„
BATCH_SIZE=32
CHUNK_OVERLAP=100
```

### 10.2 ë‹¤ì¤‘ GPU ì„¤ì •

```bash
# ì„œë¹„ìŠ¤ë³„ GPU í• ë‹¹
BACKEND_GPU_DEVICE=0
DOC_PROCESSOR_GPU_DEVICE=1
CLI_GPU_DEVICE=0

# GPU ë¡œë“œ ë°¸ëŸ°ì‹± í™•ì¸
nvidia-smi topo -m
```

### 10.3 ì„±ëŠ¥ íŠœë‹

```bash
# PostgreSQL íŠœë‹
# docker-compose.ymlì—ì„œ postgres ì„œë¹„ìŠ¤ ì„¤ì •
environment:
  - POSTGRES_SHARED_PRELOAD_LIBRARIES=pg_stat_statements,auto_explain
  - POSTGRES_LOG_STATEMENT=all
  - POSTGRES_EFFECTIVE_CACHE_SIZE=4GB
  - POSTGRES_SHARED_BUFFERS=1GB

# pgvector ì¸ë±ìŠ¤ ìµœì í™”
docker-compose exec postgres psql -U maestro_user -d maestro_db
CREATE INDEX CONCURRENTLY idx_embeddings_cosine ON documents 
USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
```

## 11. ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### 11.1 ì¼ë°˜ì ì¸ ì˜¤ë¥˜ ë° í•´ê²°ì±…

```bash
# 1. í¬íŠ¸ ì¶©ëŒ ì˜¤ë¥˜
Error: Port 3000 already in use
í•´ê²°: sudo lsof -i :3000; kill -9 <PID>

# 2. GPU ë©”ëª¨ë¦¬ ë¶€ì¡±
CUDA out of memory
í•´ê²°: FORCE_CPU_MODE=true ì„¤ì • ë˜ëŠ” ë°°ì¹˜ í¬ê¸° ì¡°ì •

# 3. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜
Connection refused to PostgreSQL
í•´ê²°: docker-compose restart postgres

# 4. Ollama ì—°ê²° ì‹¤íŒ¨
Local LLM connection failed
í•´ê²°: host.docker.internal ëŒ€ì‹  ì‹¤ì œ IP ì‚¬ìš©
```

### 11.2 ë””ë²„ê¹… ë„êµ¬ í™œìš©

```bash
# ìƒì„¸ ë¡œê·¸ í™œì„±í™”
export MAESTRO_LOG_LEVEL=DEBUG
docker-compose up -d

# ì»¨í…Œì´ë„ˆ ë‚´ë¶€ ì ‘ê·¼
docker-compose exec backend bash
docker-compose exec postgres psql -U maestro_user -d maestro_db

# ê±´ê°• ìƒíƒœ ê²€ì‚¬
curl http://localhost:8000/health
curl http://localhost:3000/health
```

### 11.3 ë°ì´í„° ë°±ì—… ë° ë³µêµ¬

```bash
# ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
docker-compose exec postgres pg_dump -U maestro_user maestro_db > backup.sql

# ë²¡í„° ë°ì´í„° ë°±ì—… (pgvector í™•ì¥ í¬í•¨)
docker-compose exec postgres pg_dump -U maestro_user -Fc maestro_db > backup.dump

# ë³µêµ¬
docker-compose exec -T postgres psql -U maestro_user -d maestro_db < backup.sql
```

## 12. ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

### 12.1 ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬

```bash
# ê°•ë ¥í•œ JWT ì‹œí¬ë¦¿ ìƒì„±
openssl rand -hex 32

# ì‚¬ìš©ì ê¶Œí•œ ì„¤ì •
./maestro-cli.sh create-user researcher pass123 --role user
./maestro-cli.sh create-user admin admin123 --role admin

# API í‚¤ ë¡œí…Œì´ì…˜
./maestro-cli.sh rotate-keys
```

### 12.2 ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆ

```bash
# ë°©í™”ë²½ ì„¤ì • (Ubuntu/Debian)
sudo ufw allow from 192.168.1.0/24 to any port 3000
sudo ufw allow from 192.168.1.0/24 to any port 8000

# Reverse Proxy ì„¤ì • (Nginx)
# nginx/maestro.conf
server {
    listen 443 ssl;
    server_name maestro.yourdomain.com;
    
    ssl_certificate /path/to/cert.pem;
    ssl_certificate_key /path/to/key.pem;
    
    location / {
        proxy_pass http://localhost:3000;
        proxy_websocket_upgrade on;
    }
    
    location /api {
        proxy_pass http://localhost:8000;
    }
}
```

## 13. ëª¨ë‹ˆí„°ë§ ë° ìœ ì§€ë³´ìˆ˜

### 13.1 ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§

```bash
# ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
docker stats maestro_backend maestro_frontend maestro_postgres

# ë¡œê·¸ ë¡œí…Œì´ì…˜ ì„¤ì •
# docker-compose.ymlì— ì¶”ê°€
logging:
  driver: json-file
  options:
    max-size: "100m"
    max-file: "3"

# ìë™ ê±´ê°• ê²€ì‚¬
# healthcheck.sh
#!/bin/bash
curl -f http://localhost:8000/health || exit 1
curl -f http://localhost:3000/ || exit 1
```

### 13.2 ì •ê¸° ìœ ì§€ë³´ìˆ˜

```bash
# ì£¼ê°„ ìœ ì§€ë³´ìˆ˜ ìŠ¤í¬ë¦½íŠ¸
#!/bin/bash
# weekly_maintenance.sh

# 1. ì»¨í…Œì´ë„ˆ ì—…ë°ì´íŠ¸
docker-compose pull
docker-compose up -d

# 2. ë°ì´í„°ë² ì´ìŠ¤ ì •ë¦¬
./maestro-cli.sh cleanup-orphaned-docs

# 3. ë¡œê·¸ ì••ì¶•
find /var/log/maestro -name "*.log" -mtime +7 -exec gzip {} \;

# 4. ì‹œìŠ¤í…œ ìƒíƒœ ë³´ê³ 
./maestro-cli.sh system-report > /var/log/maestro/weekly_report_$(date +%Y%m%d).txt
```

## 14. í™•ì¥ ë° ì»¤ìŠ¤í„°ë§ˆì´ì§•

### 14.1 ì»¤ìŠ¤í…€ AI ì—ì´ì „íŠ¸ ê°œë°œ

```python
# maestro_backend/agents/custom_agent.py
from maestro_backend.core.agent_base import BaseAgent

class CustomResearchAgent(BaseAgent):
    def __init__(self, config):
        super().__init__(config)
        self.specialty = "domain_specific_research"
    
    async def process_request(self, request):
        """ì»¤ìŠ¤í…€ ì—°êµ¬ ë¡œì§ êµ¬í˜„"""
        results = await self.search_documents(request.query)
        analysis = await self.analyze_with_llm(results)
        return await self.generate_report(analysis)
    
    async def search_documents(self, query):
        """ë„ë©”ì¸ íŠ¹í™” ê²€ìƒ‰ ë¡œì§"""
        # êµ¬í˜„ ë¡œì§
        pass
```

### 14.2 API í™•ì¥

```python
# maestro_backend/api/custom_endpoints.py
from fastapi import APIRouter, Depends
from maestro_backend.core.auth import get_current_user

router = APIRouter(prefix="/api/custom", tags=["custom"])

@router.post("/domain-research")
async def domain_research(
    request: DomainResearchRequest,
    current_user: User = Depends(get_current_user)
):
    """ì»¤ìŠ¤í…€ ë„ë©”ì¸ ì—°êµ¬ ì—”ë“œí¬ì¸íŠ¸"""
    agent = CustomResearchAgent(config)
    results = await agent.process_request(request)
    return {"results": results, "status": "completed"}
```

## 15. íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ì²´í¬ë¦¬ìŠ¤íŠ¸

### 15.1 ì„¤ì¹˜ í›„ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Docker ì»¨í…Œì´ë„ˆ ëª¨ë‘ ì‹¤í–‰ ì¤‘ (`docker-compose ps`)
- [ ] í¬íŠ¸ 3000, 8000, 5432, 8080 ì ‘ê·¼ ê°€ëŠ¥
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì •ìƒ (`./maestro-cli.sh reset-db --check`)
- [ ] LLM API ì—°ê²° í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ì›¹ ì¸í„°í˜ì´ìŠ¤ ë¡œê·¸ì¸ ê°€ëŠ¥
- [ ] ê²€ìƒ‰ ê¸°ëŠ¥ ì •ìƒ ì‘ë™

### 15.2 ì„±ëŠ¥ ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
- [ ] PostgreSQL ì¸ë±ìŠ¤ ìµœì í™”
- [ ] SearXNG ì‘ë‹µ ì†ë„ í™•ì¸
- [ ] ë¬¸ì„œ ì²˜ë¦¬ ë°°ì¹˜ í¬ê¸° ì¡°ì •
- [ ] ìºì‹œ ì„¤ì • í™•ì¸

## 16. ê²°ë¡ 

MAESTROëŠ” AI ê¸°ë°˜ ì—°êµ¬ ìë™í™”ì˜ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì„ ì œì‹œí•˜ëŠ” ê°•ë ¥í•œ í”Œë«í¼ì…ë‹ˆë‹¤. ì´ íŠœí† ë¦¬ì–¼ì„ í†µí•´ ê¸°ë³¸ ì„¤ì¹˜ë¶€í„° ê³ ê¸‰ ì„¤ì •ê¹Œì§€ ì™„ì „íˆ ë§ˆìŠ¤í„°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì£¼ìš” ì„±ê³¼

âœ… **ì™„ì „ ì…€í”„ í˜¸ìŠ¤íŒ… í™˜ê²½ êµ¬ì¶•**  
âœ… **AI ì—ì´ì „íŠ¸ ê¸°ë°˜ ì—°êµ¬ ì›Œí¬í”Œë¡œìš° êµ¬í˜„**  
âœ… **ë¡œì»¬ LLMê³¼ í”„ë¼ì´ë¹— ê²€ìƒ‰ì—”ì§„ í†µí•©**  
âœ… **í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜ ì´í•´**  

### ë‹¤ìŒ ë‹¨ê³„

1. **ê³ ê¸‰ AI ì—ì´ì „íŠ¸ ê°œë°œ**: ë„ë©”ì¸ íŠ¹í™” ì—°êµ¬ ì—ì´ì „íŠ¸ êµ¬í˜„
2. **ê¸°ì—… í™˜ê²½ ë°°í¬**: Kubernetes í´ëŸ¬ìŠ¤í„° ë°°í¬ ê³ ë ¤
3. **API í†µí•©**: ê¸°ì¡´ ì—°êµ¬ ë„êµ¬ì™€ì˜ ì—°ë™ í™•ì¥
4. **ì»¤ë®¤ë‹ˆí‹° ê¸°ì—¬**: MAESTRO ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ ì°¸ì—¬

MAESTROë¥¼ í†µí•´ ì—°êµ¬ ìƒì‚°ì„±ì„ í˜ì‹ ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¤ê³ , AI ì—ì´ì „íŠ¸ì˜ ë¬´í•œí•œ ê°€ëŠ¥ì„±ì„ ê²½í—˜í•´ë³´ì„¸ìš”! ğŸš€

---

**ì°¸ê³  ìë£Œ**
- [MAESTRO GitHub Repository](https://github.com/murtaza-nasir/maestro)
- [Docker Compose ê³µì‹ ë¬¸ì„œ](https://docs.docker.com/compose/)
- [PostgreSQL + pgvector ê°€ì´ë“œ](https://github.com/pgvector/pgvector)
- [SearXNG ì„¤ì • ê°€ì´ë“œ](https://docs.searxng.org/)
