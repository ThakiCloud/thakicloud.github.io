---
title: "WhisperLiveKit: ì´ˆì €ì§€ì—° ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì™„ì „ ê°€ì´ë“œ"
excerpt: "ìµœì²¨ë‹¨ ì—°êµ¬ ê¸°ë°˜ì˜ ì‹¤ì‹œê°„ ìŒì„± ì „ì‚¬ ì‹œìŠ¤í…œ WhisperLiveKitì„ ë§ˆìŠ¤í„°í•˜ì„¸ìš”. SimulStreaming, í™”ì ë¶„ë¦¬, ì›¹ UI í†µí•©ì„ í†µí•œ í”„ë¡œë•ì…˜ ê¸‰ ìŒì„± ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¶• ë°©ë²•ì„ ìƒì„¸íˆ ì•Œì•„ë´…ë‹ˆë‹¤."
seo_title: "WhisperLiveKit ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ íŠœí† ë¦¬ì–¼ - ì™„ì „ ê°€ì´ë“œ - Thaki Cloud"
seo_description: "ì´ˆì €ì§€ì—° ì‹¤ì‹œê°„ ìŒì„± ì „ì‚¬ë¥¼ ìœ„í•œ WhisperLiveKit êµ¬í˜„ ë°©ë²•ì„ í•™ìŠµí•˜ì„¸ìš”. ì„¤ì¹˜, ì„¤ì •, í™”ì ë¶„ë¦¬ ë“± ê³ ê¸‰ ê¸°ëŠ¥ì„ í¬í•¨í•œ ì™„ì „í•œ íŠœí† ë¦¬ì–¼ì„ ì œê³µí•©ë‹ˆë‹¤."
date: 2025-08-31
categories:
  - tutorials
tags:
  - WhisperLiveKit
  - ì‹¤ì‹œê°„ìŒì„±ì¸ì‹
  - ìŒì„±ì „ì‚¬
  - SimulStreaming
  - ìŒì„±í™œë™ê°ì§€
  - í™”ìë¶„ë¦¬
  - WebSocket
  - FastAPI
  - Python
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
canonical_url: "https://thakicloud.github.io/ko/tutorials/whisperlivekit-real-time-speech-recognition-tutorial/"
lang: ko
permalink: /ko/tutorials/whisperlivekit-real-time-speech-recognition-tutorial/
---

â±ï¸ **ì˜ˆìƒ ì½ê¸° ì‹œê°„**: 15ë¶„

## ì„œë¡ 

ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ê¸°ìˆ ì€ ìŠ¤íŠ¸ë¦¬ë° ìµœì í™” ëª¨ë¸ê³¼ ì²¨ë‹¨ ì—°êµ¬ ì„±ê³¼ì˜ ë“±ì¥ìœ¼ë¡œ ê·¹ì ì¸ ë°œì „ì„ ì´ë£¨ì—ˆìŠµë‹ˆë‹¤. **WhisperLiveKit**ì€ SimulStreaming(SOTA 2025), WhisperStreaming(SOTA 2023), ê·¸ë¦¬ê³  ê³ ê¸‰ í™”ì ë¶„ë¦¬ ì‹œìŠ¤í…œì„ ê²°í•©í•œ ì‹¤ì‹œê°„ ìŒì„± ì „ì‚¬ ë¶„ì•¼ì˜ ìµœì²¨ë‹¨ ê¸°ìˆ ì„ ëŒ€í‘œí•©ë‹ˆë‹¤.

ì‹¤ì‹œê°„ ì œì•½ ì¡°ê±´ì—ì„œ ì–´ë ¤ì›€ì„ ê²ªëŠ” ì „í†µì ì¸ ë°°ì¹˜ ì²˜ë¦¬ ë°©ì‹ê³¼ ë‹¬ë¦¬, WhisperLiveKitì€ ì§€ëŠ¥ì  ë²„í¼ë§, ì ì§„ì  ì²˜ë¦¬, ìŒì„± í™œë™ ê°ì§€ë¥¼ í™œìš©í•˜ì—¬ ë¸Œë¼ìš°ì €ë¡œ ì§ì ‘ ì´ˆì €ì§€ì—° ì „ì‚¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

ì´ í¬ê´„ì ì¸ ê°€ì´ë“œëŠ” ê¸°ë³¸ ì„¤ì •ë¶€í„° í™”ì ì‹ë³„ ë° ë‹¤ì¤‘ ì‚¬ìš©ì ì§€ì›ê³¼ ê°™ì€ ê³ ê¸‰ ê¸°ëŠ¥ê¹Œì§€, í”„ë¡œë•ì…˜ ê¸‰ ì‹¤ì‹œê°„ ìŒì„± ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ WhisperLiveKit êµ¬í˜„ ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤.

## í‘œì¤€ Whisper ëŒ€ë¹„ WhisperLiveKitì˜ ì¥ì 

### ì‹¤ì‹œê°„ ì²˜ë¦¬ì˜ ë„ì „ ê³¼ì œ

í‘œì¤€ Whisper ëª¨ë¸ì€ ì™„ì „í•œ ë°œí™”ë¥¼ ìœ„í•´ ì„¤ê³„ë˜ì—ˆìœ¼ë©°, ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì²­í¬ì—ëŠ” ì í•©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì‘ì€ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì²˜ë¦¬í•  ë•Œ ë‹¤ìŒê³¼ ê°™ì€ ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤:

- **ì»¨í…ìŠ¤íŠ¸ ì†ì‹¤**: ëŒ€í™” íë¦„ê³¼ ë¬¸ì¥ ê²½ê³„ ëˆ„ë½
- **ë‹¨ì–´ ë¶„í• **: ìŒì ˆ ì¤‘ê°„ì—ì„œ ë‹¨ì–´ ì ˆë‹¨
- **ì •í™•ë„ ì €í•˜**: ë¶ˆì™„ì „í•œ ì˜¤ë””ì˜¤ì—ì„œ ì „ì‚¬ í’ˆì§ˆ í•˜ë½
- **ë†’ì€ ì§€ì—°ì‹œê°„**: ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì¸í•œ ì§€ì—°

### WhisperLiveKitì˜ í˜ì‹ 

WhisperLiveKitì€ ë‹¤ìŒì„ í†µí•´ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤:

```python
# ì „í†µì  ì ‘ê·¼ë²• (ë¬¸ì œ ë°œìƒ)
def process_audio_chunk(chunk):
    return whisper.transcribe(chunk)  # ì»¨í…ìŠ¤íŠ¸ ì†ì‹¤, í’ˆì§ˆ ì €í•˜

# WhisperLiveKit ì ‘ê·¼ë²• (ìµœì í™”)
def process_streaming_audio(stream):
    # ì»¨í…ìŠ¤íŠ¸ ë³´ì¡´ì„ í†µí•œ ì§€ëŠ¥ì  ë²„í¼ë§
    # íš¨ìœ¨ì„±ì„ ìœ„í•œ ìŒì„± í™œë™ ê°ì§€
    # ì´ˆì €ì§€ì—°ì„ ìœ„í•œ SimulStreaming
    # LocalAgreementë¥¼ í†µí•œ ì ì§„ì  ì²˜ë¦¬
    return optimized_transcription
```

## í•µì‹¬ ê¸°ìˆ  ë° ì•„í‚¤í…ì²˜

### ìµœì²¨ë‹¨ ì—°êµ¬ í†µí•©

**SimulStreaming (SOTA 2025)**:
- AlignAtt ì •ì±…ì„ í†µí•œ ì´ˆì €ì§€ì—° ì „ì‚¬
- ìµœì  ì²˜ë¦¬ íƒ€ì´ë°ì„ ìœ„í•œ í”„ë ˆì„ ìˆ˜ì¤€ ì–´í…ì…˜ ê°€ì´ë“œ
- ê³ ê¸‰ ë¹” ì„œì¹˜ ìµœì í™”

**WhisperStreaming (SOTA 2023)**:
- ì¼ê´€ëœ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ìœ„í•œ LocalAgreement ì •ì±…
- ì§€ëŠ¥ì  ë²„í¼ ê´€ë¦¬ ë° íŠ¸ë¦¬ë° ì „ëµ

**ê³ ê¸‰ í™”ì ë¶„ë¦¬**:
- ì‹¤ì‹œê°„ í™”ì ì‹ë³„ì„ ìœ„í•œ Streaming Sortformer (SOTA 2025)
- í”„ë¡œë•ì…˜ í™˜ê²½ì„ ìœ„í•œ Diart (SOTA 2021) í†µí•©

**ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ VAD**:
- ì •í™•í•œ ìŒì„± í™œë™ ê°ì§€ë¥¼ ìœ„í•œ Silero VAD (2024)
- ë¬´ìŒ êµ¬ê°„ ë™ì•ˆ ê³„ì‚° ì˜¤ë²„í—¤ë“œ ê°ì†Œ

### ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
graph TD
    A[ì˜¤ë””ì˜¤ ì…ë ¥] --> B[ìŒì„± í™œë™ ê°ì§€]
    B --> C[ì˜¤ë””ì˜¤ ë²„í¼ ê´€ë¦¬]
    C --> D[SimulStreaming ì—”ì§„]
    D --> E[í™”ì ë¶„ë¦¬]
    E --> F[WebSocket ì„œë²„]
    F --> G[ì›¹ UI í´ë¼ì´ì–¸íŠ¸]
    
    H[ë‹¤ì¤‘ í´ë¼ì´ì–¸íŠ¸] --> F
    I[ì‹¤ì‹œê°„ ì²˜ë¦¬] --> D
    J[ì»¨í…ìŠ¤íŠ¸ ë³´ì¡´] --> C
```

ì´ ì•„í‚¤í…ì²˜ëŠ” ì§€ëŠ¥ì  ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ì™€ ìŒì„± í™œë™ ê°ì§€ë¥¼ í†µí•´ ì„±ëŠ¥ì„ ìµœì í™”í•˜ë©´ì„œ ë‹¤ì¤‘ ë™ì‹œ ì‚¬ìš©ìë¥¼ ì§€ì›í•©ë‹ˆë‹¤.

## ì„¤ì¹˜ ë° ì„¤ì •

### ì‚¬ì „ ìš”êµ¬ì‚¬í•­

**ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­**:
- Python 3.8+
- FFmpeg (ì˜¤ë””ì˜¤ ì²˜ë¦¬ í•„ìˆ˜)
- 4GB+ RAM (ëŒ€í˜• ëª¨ë¸ì˜ ê²½ìš° 8GB+ ê¶Œì¥)
- ì„ íƒì‚¬í•­: ê°€ì† ì²˜ë¦¬ë¥¼ ìœ„í•œ NVIDIA GPU

### FFmpeg ì„¤ì¹˜

```bash
# macOS
brew install ffmpeg

# Ubuntu/Debian
sudo apt install ffmpeg

# Windows
# https://ffmpeg.org/download.htmlì—ì„œ ë‹¤ìš´ë¡œë“œ í›„ PATHì— ì¶”ê°€
```

### WhisperLiveKit ì„¤ì¹˜

```bash
# ê²©ë¦¬ëœ í™˜ê²½ ìƒì„±
python3 -m venv whisperlivekit-env
source whisperlivekit-env/bin/activate  # Windows: whisperlivekit-env\Scripts\activate

# WhisperLiveKit ì„¤ì¹˜
pip install whisperlivekit

# ì„¤ì¹˜ í™•ì¸
whisperlivekit-server --help
```

## ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ

### ê¸°ë³¸ ì„œë²„ ì‹¤í–‰

```bash
# ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì‹œì‘ (small ëª¨ë¸, ìë™ ì–¸ì–´ ê°ì§€)
whisperlivekit-server --model base --language ko

# ì„œë²„ê°€ http://localhost:8000ì—ì„œ ì‹œì‘ë¨
# ì›¹ UIê°€ ë™ì¼í•œ ì£¼ì†Œì—ì„œ ìë™ìœ¼ë¡œ ì œê³µë¨
```

### ì„¤ì¹˜ í…ŒìŠ¤íŠ¸

1. **ì„œë²„ ì‹œì‘**:
```bash
whisperlivekit-server --model tiny --language ko --host localhost --port 8000
```

2. **ë¸Œë¼ìš°ì € ì—´ê¸°** ë° `http://localhost:8000`ìœ¼ë¡œ ì´ë™

3. **ë§ˆì´í¬ ê¶Œí•œ í—ˆìš©** (ìš”ì²­ ì‹œ)

4. **ë§í•˜ê¸° ì‹œì‘** í›„ ì‹¤ì‹œê°„ ì „ì‚¬ í™•ì¸

### ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

```python
# test_whisperlivekit.py
import asyncio
import websockets
import json
import pyaudio
import wave

async def test_websocket_connection():
    """WhisperLiveKit ì„œë²„ì— ëŒ€í•œ WebSocket ì—°ê²° í…ŒìŠ¤íŠ¸"""
    uri = "ws://localhost:8000/ws"
    
    try:
        async with websockets.connect(uri) as websocket:
            print("âœ… WebSocket ì—°ê²° ì„±ê³µ")
            
            # í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡
            test_message = {
                "type": "audio_chunk",
                "data": "test_audio_data"
            }
            
            await websocket.send(json.dumps(test_message))
            response = await websocket.recv()
            print(f"ğŸ“¨ ì„œë²„ ì‘ë‹µ: {response}")
            
    except Exception as e:
        print(f"âŒ ì—°ê²° ì‹¤íŒ¨: {e}")

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
asyncio.run(test_websocket_connection())
```

## ê³ ê¸‰ ì„¤ì •

### ëª¨ë¸ ì„ íƒ ë° ì„±ëŠ¥

```bash
# ì´ˆê³ ì† ì²˜ë¦¬ (ë‚®ì€ ì •í™•ë„)
whisperlivekit-server --model tiny --language ko

# ê· í˜•ì¡íŒ ì„±ëŠ¥ (ëŒ€ë¶€ë¶„ì˜ ì‚¬ìš© ì‚¬ë¡€ì— ê¶Œì¥)
whisperlivekit-server --model base --language ko

# ë†’ì€ ì •í™•ë„ (ë” ë§ì€ ë¦¬ì†ŒìŠ¤ í•„ìš”)
whisperlivekit-server --model large-v3 --language ko

# ìë™ ê°ì§€ë¥¼ í†µí•œ ë‹¤êµ­ì–´ ì§€ì›
whisperlivekit-server --model base --language auto
```

### ë°±ì—”ë“œ ì„ íƒ

```bash
# SimulStreaming (SOTA 2025) - ì´ˆì €ì§€ì—°
whisperlivekit-server --backend simulstreaming --model base

# Faster-Whisper - ìµœì í™”ëœ ì„±ëŠ¥
whisperlivekit-server --backend faster-whisper --model base

# WhisperStreaming - LocalAgreement ì •ì±…
whisperlivekit-server --backend whisper_timestamped --model base
```

### SimulStreaming ê³ ê¸‰ ì„¤ì •

```bash
# ì§€ì—°ì‹œê°„ vs ì •í™•ë„ ë¯¸ì„¸ ì¡°ì •
whisperlivekit-server \
  --backend simulstreaming \
  --model base \
  --frame-threshold 25 \
  --beams 1 \
  --audio-max-len 30.0 \
  --never-fire
```

**ì£¼ìš” ë§¤ê°œë³€ìˆ˜**:
- `--frame-threshold`: ë‚®ìŒ = ë¹ ë¦„, ë†’ìŒ = ì •í™•í•¨ (ê¸°ë³¸ê°’: 25)
- `--beams`: ë¹” ì„œì¹˜ ë¹” ìˆ˜ (1 = ê·¸ë¦¬ë””, >1 = ë¹” ì„œì¹˜)
- `--audio-max-len`: ìµœëŒ€ ì˜¤ë””ì˜¤ ë²„í¼ ê¸¸ì´(ì´ˆ)
- `--never-fire`: ë¶ˆì™„ì „í•œ ë‹¨ì–´ë¥¼ ì ˆëŒ€ ìë¥´ì§€ ì•ŠìŒ

## í™”ì ë¶„ë¦¬ ì„¤ì •

### ê¸°ë³¸ í™”ì ì‹ë³„

```bash
# Sortformer(SOTA 2025)ë¥¼ ì‚¬ìš©í•œ í™”ì ë¶„ë¦¬ í™œì„±í™”
whisperlivekit-server \
  --model base \
  --language ko \
  --diarization \
  --diarization-backend sortformer
```

### Diartë¥¼ ì‚¬ìš©í•œ ê³ ê¸‰ ë¶„ë¦¬

```bash
# ì‚¬ìš©ì ì •ì˜ ëª¨ë¸ì„ ì‚¬ìš©í•œ Diart ë°±ì—”ë“œ
whisperlivekit-server \
  --model base \
  --language ko \
  --diarization \
  --diarization-backend diart \
  --segmentation-model pyannote/segmentation-3.0 \
  --embedding-model speechbrain/spkrec-ecapa-voxceleb
```

### Pyannoteë¥¼ ìœ„í•œ Hugging Face ì¸ì¦

```bash
# pyannote.audio ëª¨ë¸ì— í•„ìš”
pip install huggingface_hub
huggingface-cli login

# í•„ìš”í•œ ëª¨ë¸ì— ëŒ€í•œ ì‚¬ìš©ì ì¡°ê±´ ìˆ˜ë½:
# 1. pyannote/segmentation
# 2. pyannote/segmentation-3.0  
# 3. pyannote/embedding
```

## í”„ë¡œë•ì…˜ ë°°í¬

### Docker ë°°í¬

**GPU ê°€ì† ì»¨í…Œì´ë„ˆ**:
```dockerfile
# Dockerfile
FROM nvidia/cuda:11.8-runtime-ubuntu20.04

RUN apt-get update && apt-get install -y \
    python3 python3-pip ffmpeg \
    && rm -rf /var/lib/apt/lists/*

RUN pip install whisperlivekit

EXPOSE 8000

CMD ["whisperlivekit-server", "--model", "base", "--language", "ko", "--host", "0.0.0.0"]
```

```bash
# ë¹Œë“œ ë° ì‹¤í–‰
docker build -t whisperlivekit .
docker run --gpus all -p 8000:8000 whisperlivekit
```

**CPU ì „ìš© ì»¨í…Œì´ë„ˆ**:
```bash
# ë¯¸ë¦¬ ë¹Œë“œëœ CPU ì´ë¯¸ì§€ ì‚¬ìš©
docker run -p 8000:8000 whisperlivekit/cpu:latest
```

### í”„ë¡œë•ì…˜ ì„œë²„ ì„¤ì •

```bash
# í”„ë¡œë•ì…˜ ì¤€ë¹„ ì„¤ì •
whisperlivekit-server \
  --model base \
  --language ko \
  --host 0.0.0.0 \
  --port 8000 \
  --ssl-certfile /path/to/cert.pem \
  --ssl-keyfile /path/to/key.pem \
  --diarization \
  --preloaded_model_count 4 \
  --min-chunk-size 1.0 \
  --buffer_trimming sentence
```

### Nginxë¥¼ ì‚¬ìš©í•œ ë¡œë“œ ë°¸ëŸ°ì‹±

```nginx
# /etc/nginx/sites-available/whisperlivekit
upstream whisperlivekit_backend {
    server 127.0.0.1:8000;
    server 127.0.0.1:8001;
    server 127.0.0.1:8002;
    server 127.0.0.1:8003;
}

server {
    listen 80;
    server_name your-domain.com;

    location / {
        proxy_pass http://whisperlivekit_backend;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
}
```

## ì‚¬ìš©ì ì •ì˜ ì›¹ í†µí•©

### ê¸°ë³¸ WebSocket í´ë¼ì´ì–¸íŠ¸

```javascript
// whisperlivekit-client.js
class WhisperLiveKitClient {
    constructor(serverUrl = 'ws://localhost:8000/ws') {
        this.serverUrl = serverUrl;
        this.websocket = null;
        this.mediaRecorder = null;
        this.audioContext = null;
    }

    async connect() {
        try {
            this.websocket = new WebSocket(this.serverUrl);
            
            this.websocket.onopen = () => {
                console.log('âœ… WhisperLiveKitì— ì—°ê²°ë¨');
                this.startAudioCapture();
            };

            this.websocket.onmessage = (event) => {
                const data = JSON.parse(event.data);
                this.handleTranscription(data);
            };

            this.websocket.onerror = (error) => {
                console.error('âŒ WebSocket ì˜¤ë¥˜:', error);
            };

        } catch (error) {
            console.error('ì—°ê²° ì‹¤íŒ¨:', error);
        }
    }

    async startAudioCapture() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ 
                audio: {
                    sampleRate: 16000,
                    channelCount: 1,
                    echoCancellation: true,
                    noiseSuppression: true
                } 
            });

            this.audioContext = new AudioContext({ sampleRate: 16000 });
            const source = this.audioContext.createMediaStreamSource(stream);
            
            // ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì²˜ë¦¬
            this.processAudioStream(source);

        } catch (error) {
            console.error('ë§ˆì´í¬ ì ‘ê·¼ ê±°ë¶€ë¨:', error);
        }
    }

    processAudioStream(source) {
        const processor = this.audioContext.createScriptProcessor(4096, 1, 1);
        
        processor.onaudioprocess = (event) => {
            const audioData = event.inputBuffer.getChannelData(0);
            
            // 16ë¹„íŠ¸ PCMìœ¼ë¡œ ë³€í™˜
            const pcmData = new Int16Array(audioData.length);
            for (let i = 0; i < audioData.length; i++) {
                pcmData[i] = Math.max(-32768, Math.min(32767, audioData[i] * 32768));
            }

            // ì„œë²„ë¡œ ì „ì†¡
            if (this.websocket && this.websocket.readyState === WebSocket.OPEN) {
                this.websocket.send(pcmData.buffer);
            }
        };

        source.connect(processor);
        processor.connect(this.audioContext.destination);
    }

    handleTranscription(data) {
        if (data.type === 'transcription') {
            this.displayTranscription(data.text, data.speaker);
        }
    }

    displayTranscription(text, speaker = null) {
        const transcriptionDiv = document.getElementById('transcription');
        const timestamp = new Date().toLocaleTimeString();
        
        const entry = document.createElement('div');
        entry.className = 'transcription-entry';
        entry.innerHTML = `
            <span class="timestamp">${timestamp}</span>
            ${speaker ? `<span class="speaker">í™”ì ${speaker}:</span>` : ''}
            <span class="text">${text}</span>
        `;
        
        transcriptionDiv.appendChild(entry);
        transcriptionDiv.scrollTop = transcriptionDiv.scrollHeight;
    }
}

// ì‚¬ìš©ë²•
const client = new WhisperLiveKitClient();
client.connect();
```

### React í†µí•©

```jsx
// WhisperLiveKitComponent.jsx
import React, { useState, useEffect, useRef } from 'react';

const WhisperLiveKitComponent = () => {
    const [transcriptions, setTranscriptions] = useState([]);
    const [isConnected, setIsConnected] = useState(false);
    const [isRecording, setIsRecording] = useState(false);
    const websocketRef = useRef(null);
    const mediaRecorderRef = useRef(null);

    useEffect(() => {
        connectToServer();
        return () => {
            if (websocketRef.current) {
                websocketRef.current.close();
            }
        };
    }, []);

    const connectToServer = () => {
        const ws = new WebSocket('ws://localhost:8000/ws');
        
        ws.onopen = () => {
            setIsConnected(true);
            console.log('WhisperLiveKitì— ì—°ê²°ë¨');
        };

        ws.onmessage = (event) => {
            const data = JSON.parse(event.data);
            if (data.type === 'transcription') {
                setTranscriptions(prev => [...prev, {
                    id: Date.now(),
                    text: data.text,
                    speaker: data.speaker,
                    timestamp: new Date().toLocaleTimeString()
                }]);
            }
        };

        ws.onclose = () => {
            setIsConnected(false);
            console.log('WhisperLiveKit ì—°ê²° í•´ì œë¨');
        };

        websocketRef.current = ws;
    };

    const startRecording = async () => {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ 
                audio: {
                    sampleRate: 16000,
                    channelCount: 1,
                    echoCancellation: true,
                    noiseSuppression: true
                }
            });

            const mediaRecorder = new MediaRecorder(stream, {
                mimeType: 'audio/webm;codecs=opus'
            });

            mediaRecorder.ondataavailable = (event) => {
                if (event.data.size > 0 && websocketRef.current?.readyState === WebSocket.OPEN) {
                    websocketRef.current.send(event.data);
                }
            };

            mediaRecorder.start(100); // 100msë§ˆë‹¤ ë°ì´í„° ì „ì†¡
            mediaRecorderRef.current = mediaRecorder;
            setIsRecording(true);

        } catch (error) {
            console.error('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:', error);
        }
    };

    const stopRecording = () => {
        if (mediaRecorderRef.current) {
            mediaRecorderRef.current.stop();
            mediaRecorderRef.current = null;
            setIsRecording(false);
        }
    };

    return (
        <div className="whisperlivekit-container">
            <div className="controls">
                <div className={`status ${isConnected ? 'connected' : 'disconnected'}`}>
                    {isConnected ? 'ğŸŸ¢ ì—°ê²°ë¨' : 'ğŸ”´ ì—°ê²° í•´ì œë¨'}
                </div>
                
                <button 
                    onClick={isRecording ? stopRecording : startRecording}
                    disabled={!isConnected}
                    className={`record-button ${isRecording ? 'recording' : ''}`}
                >
                    {isRecording ? 'â¹ï¸ ë…¹ìŒ ì¤‘ì§€' : 'ğŸ¤ ë…¹ìŒ ì‹œì‘'}
                </button>
            </div>

            <div className="transcriptions">
                <h3>ì‹¤ì‹œê°„ ì „ì‚¬</h3>
                <div className="transcription-list">
                    {transcriptions.map(item => (
                        <div key={item.id} className="transcription-item">
                            <span className="timestamp">{item.timestamp}</span>
                            {item.speaker && <span className="speaker">í™”ì {item.speaker}:</span>}
                            <span className="text">{item.text}</span>
                        </div>
                    ))}
                </div>
            </div>
        </div>
    );
};

export default WhisperLiveKitComponent;
```

## ì„±ëŠ¥ ìµœì í™”

### ëª¨ë¸ ì„ íƒ ì „ëµ

```python
# performance_config.py
PERFORMANCE_CONFIGS = {
    'ultra_fast': {
        'model': 'tiny',
        'backend': 'simulstreaming',
        'frame_threshold': 15,
        'beams': 1,
        'min_chunk_size': 0.5
    },
    'balanced': {
        'model': 'base',
        'backend': 'simulstreaming', 
        'frame_threshold': 25,
        'beams': 1,
        'min_chunk_size': 1.0
    },
    'high_accuracy': {
        'model': 'large-v3',
        'backend': 'faster-whisper',
        'beams': 5,
        'min_chunk_size': 2.0
    }
}

def get_optimal_config(use_case):
    """ì‚¬ìš© ì‚¬ë¡€ì— ë”°ë¥¸ ìµœì  ì„¤ì • ì„ íƒ"""
    if use_case == 'live_streaming':
        return PERFORMANCE_CONFIGS['ultra_fast']
    elif use_case == 'meeting_transcription':
        return PERFORMANCE_CONFIGS['balanced']
    elif use_case == 'legal_documentation':
        return PERFORMANCE_CONFIGS['high_accuracy']
```

### ë¦¬ì†ŒìŠ¤ ê´€ë¦¬

```bash
# ë†’ì€ ë™ì‹œì„±ì„ ìœ„í•œ ë‹¤ì¤‘ ì¸ìŠ¤í„´ìŠ¤ ë°°í¬
# ì¸ìŠ¤í„´ìŠ¤ 1: ì´ˆê³ ì† ì²˜ë¦¬
whisperlivekit-server --model tiny --port 8001 --preloaded_model_count 2

# ì¸ìŠ¤í„´ìŠ¤ 2: ê· í˜•ì¡íŒ ì²˜ë¦¬  
whisperlivekit-server --model base --port 8002 --preloaded_model_count 2

# ì¸ìŠ¤í„´ìŠ¤ 3: ê³ ì •í™•ë„ ì²˜ë¦¬
whisperlivekit-server --model large-v3 --port 8003 --preloaded_model_count 1
```

## ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### ì¼ë°˜ì ì¸ ë¬¸ì œ ë° í•´ê²°ì±…

**1. ì„œë²„ê°€ ì‹œì‘ë˜ì§€ ì•ŠìŒ**
```bash
# FFmpeg ì„¤ì¹˜ í™•ì¸
ffmpeg -version

# Python í™˜ê²½ í™•ì¸
python -c "import whisperlivekit; print('âœ… ì„¤ì¹˜ ì™„ë£Œ')"

# í¬íŠ¸ ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
lsof -i :8000
```

**2. ì „ì‚¬ í’ˆì§ˆ ì €í•˜**
```bash
# ëª¨ë¸ í¬ê¸° ì¦ê°€
whisperlivekit-server --model base  # tiny ëŒ€ì‹ 

# ì²­í¬ í¬ê¸° ì¡°ì •
whisperlivekit-server --min-chunk-size 2.0

# ì‹ ë¢°ë„ ê²€ì¦ í™œì„±í™”
whisperlivekit-server --confidence-validation
```

**3. ë†’ì€ ì§€ì—°ì‹œê°„ ë¬¸ì œ**
```bash
# SimulStreaming ë°±ì—”ë“œ ì‚¬ìš©
whisperlivekit-server --backend simulstreaming --frame-threshold 15

# ì˜¤ë””ì˜¤ ë²„í¼ ê°ì†Œ
whisperlivekit-server --audio-max-len 15.0

# VAD ìµœì í™” í™œì„±í™”
whisperlivekit-server --vac-chunk-size 0.5
```

**4. WebSocket ì—°ê²° ë¬¸ì œ**
```javascript
// ì—°ê²° ì¬ì‹œë„ ë¡œì§ ì¶”ê°€
class RobustWhisperClient {
    constructor(serverUrl) {
        this.serverUrl = serverUrl;
        this.reconnectAttempts = 0;
        this.maxReconnectAttempts = 5;
    }

    connect() {
        this.websocket = new WebSocket(this.serverUrl);
        
        this.websocket.onclose = () => {
            if (this.reconnectAttempts < this.maxReconnectAttempts) {
                setTimeout(() => {
                    this.reconnectAttempts++;
                    this.connect();
                }, 1000 * this.reconnectAttempts);
            }
        };
    }
}
```

### ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```python
# monitoring.py
import psutil
import time
import requests

def monitor_whisperlivekit_performance():
    """WhisperLiveKit ì„œë²„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""
    while True:
        try:
            # ì„œë²„ ìƒíƒœ í™•ì¸
            response = requests.get('http://localhost:8000/health', timeout=5)
            
            # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§
            cpu_percent = psutil.cpu_percent(interval=1)
            memory_percent = psutil.virtual_memory().percent
            
            print(f"ğŸ–¥ï¸  CPU: {cpu_percent}% | ğŸ’¾ ë©”ëª¨ë¦¬: {memory_percent}%")
            
            if cpu_percent > 80:
                print("âš ï¸  ë†’ì€ CPU ì‚¬ìš©ëŸ‰ ê°ì§€")
            
            if memory_percent > 80:
                print("âš ï¸  ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì§€")
                
        except Exception as e:
            print(f"âŒ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
        
        time.sleep(10)

if __name__ == "__main__":
    monitor_whisperlivekit_performance()
```

## ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€

### 1. ì‹¤ì‹œê°„ íšŒì˜ ì „ì‚¬

```python
# meeting_transcriber.py
import asyncio
import websockets
import json
from datetime import datetime

class MeetingTranscriber:
    def __init__(self):
        self.transcriptions = []
        self.meeting_id = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    async def start_meeting_transcription(self):
        uri = "ws://localhost:8000/ws"
        
        async with websockets.connect(uri) as websocket:
            print(f"ğŸ“ íšŒì˜ ì „ì‚¬ ì‹œì‘: {self.meeting_id}")
            
            async for message in websocket:
                data = json.loads(message)
                
                if data['type'] == 'transcription':
                    entry = {
                        'timestamp': datetime.now().isoformat(),
                        'speaker': data.get('speaker', 'ì•Œ ìˆ˜ ì—†ìŒ'),
                        'text': data['text']
                    }
                    
                    self.transcriptions.append(entry)
                    print(f"[{entry['timestamp']}] í™”ì {entry['speaker']}: {entry['text']}")
    
    def export_meeting_notes(self):
        """íšŒì˜ ì „ì‚¬ë¥¼ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        filename = f"meeting_{self.meeting_id}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.transcriptions, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“„ íšŒì˜ë¡ì´ {filename}ìœ¼ë¡œ ë‚´ë³´ë‚´ì§")

# ì‚¬ìš©ë²•
transcriber = MeetingTranscriber()
asyncio.run(transcriber.start_meeting_transcription())
```

### 2. ê³ ê° ì„œë¹„ìŠ¤ í†µí™” ë¶„ì„

```python
# call_analyzer.py
import re
from collections import Counter

class CallAnalyzer:
    def __init__(self):
        self.sentiment_keywords = {
            'positive': ['í›Œë¥­í•œ', 'ì¢‹ì€', 'ë§Œì¡±', 'í–‰ë³µí•œ', 'ê°ì‚¬'],
            'negative': ['ë”ì°í•œ', 'ë‚˜ìœ', 'ì‹¤ë§', 'í™”ë‚œ', 'ë¶ˆë§Œ'],
            'neutral': ['ê´œì°®ì€', 'ë³´í†µ', 'í‰ê· ì ì¸', 'ì¼ë°˜ì ì¸']
        }
    
    def analyze_call_transcription(self, transcriptions):
        """ê³ ê° ì„œë¹„ìŠ¤ í†µí™” ë¶„ì„ì„ ìœ„í•œ ì¸ì‚¬ì´íŠ¸"""
        analysis = {
            'total_duration': len(transcriptions),
            'speaker_distribution': Counter(),
            'sentiment_analysis': {'positive': 0, 'negative': 0, 'neutral': 0},
            'key_topics': [],
            'action_items': []
        }
        
        for entry in transcriptions:
            speaker = entry['speaker']
            text = entry['text'].lower()
            
            # í™”ì ë¶„í¬
            analysis['speaker_distribution'][speaker] += 1
            
            # ê°ì • ë¶„ì„
            for sentiment, keywords in self.sentiment_keywords.items():
                if any(keyword in text for keyword in keywords):
                    analysis['sentiment_analysis'][sentiment] += 1
            
            # ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ
            if any(phrase in text for phrase in ['í›„ì† ì¡°ì¹˜', 'ì „ì†¡í•˜ê² ìŠµë‹ˆë‹¤', 'ë‹¤ì‹œ ì—°ë½']):
                analysis['action_items'].append(entry)
        
        return analysis
    
    def generate_call_summary(self, analysis):
        """í†µí™” ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
        summary = f"""
        ğŸ“ í†µí™” ë¶„ì„ ìš”ì•½
        ================
        ì´ ìƒí˜¸ì‘ìš©: {analysis['total_duration']}
        
        í™”ì ë¶„í¬:
        {dict(analysis['speaker_distribution'])}
        
        ê°ì • ë¶„ì„:
        - ê¸ì •ì : {analysis['sentiment_analysis']['positive']}
        - ë¶€ì •ì : {analysis['sentiment_analysis']['negative']}  
        - ì¤‘ë¦½ì : {analysis['sentiment_analysis']['neutral']}
        
        ì•¡ì…˜ ì•„ì´í…œ: {len(analysis['action_items'])}ê°œ
        """
        
        return summary
```

### 3. ì ‘ê·¼ì„± í†µí•©

```javascript
// accessibility_integration.js
class AccessibilityTranscriber {
    constructor() {
        this.isHighContrast = false;
        this.fontSize = 'medium';
        this.speechRate = 1.0;
    }

    setupAccessibilityFeatures() {
        // ê³ ëŒ€ë¹„ ëª¨ë“œ
        this.addHighContrastToggle();
        
        // ê¸€ê¼´ í¬ê¸° ì¡°ì ˆ
        this.addFontSizeControls();
        
        // ì „ì‚¬ ë‚´ìš© ìŒì„± ì½ê¸°
        this.addTextToSpeech();
        
        // í‚¤ë³´ë“œ íƒìƒ‰
        this.addKeyboardShortcuts();
    }

    addHighContrastToggle() {
        const toggle = document.createElement('button');
        toggle.textContent = 'ğŸ¨ ê³ ëŒ€ë¹„ ëª¨ë“œ';
        toggle.onclick = () => {
            this.isHighContrast = !this.isHighContrast;
            document.body.classList.toggle('high-contrast', this.isHighContrast);
        };
        document.getElementById('accessibility-controls').appendChild(toggle);
    }

    addTextToSpeech() {
        const speakButton = document.createElement('button');
        speakButton.textContent = 'ğŸ”Š ìŒì„± ì½ê¸°';
        speakButton.onclick = () => {
            const transcriptionText = document.getElementById('transcription').textContent;
            const utterance = new SpeechSynthesisUtterance(transcriptionText);
            utterance.rate = this.speechRate;
            utterance.lang = 'ko-KR';
            speechSynthesis.speak(utterance);
        };
        document.getElementById('accessibility-controls').appendChild(speakButton);
    }

    addKeyboardShortcuts() {
        document.addEventListener('keydown', (event) => {
            // Ctrl+R: ë…¹ìŒ ì‹œì‘/ì¤‘ì§€
            if (event.ctrlKey && event.key === 'r') {
                event.preventDefault();
                this.toggleRecording();
            }
            
            // Ctrl+S: ì „ì‚¬ ë‚´ìš© ì €ì¥
            if (event.ctrlKey && event.key === 's') {
                event.preventDefault();
                this.saveTranscription();
            }
            
            // Ctrl+Plus: ê¸€ê¼´ í¬ê¸° ì¦ê°€
            if (event.ctrlKey && event.key === '=') {
                event.preventDefault();
                this.increaseFontSize();
            }
        });
    }
}
```

## ê³ ê¸‰ ê¸°ëŠ¥ ë° ì‚¬ìš©ì ì •ì˜

### ì‚¬ìš©ì ì •ì˜ ì–¸ì–´ ëª¨ë¸

```python
# custom_model_integration.py
from whisperlivekit import WhisperLiveKitServer

class CustomWhisperServer(WhisperLiveKitServer):
    def __init__(self, custom_model_path):
        super().__init__()
        self.custom_model_path = custom_model_path
    
    def load_custom_model(self):
        """ë„ë©”ì¸ë³„ íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ë¡œë“œ"""
        # ì‚¬ìš©ì ì •ì˜ ëª¨ë¸ ë¡œë”© êµ¬í˜„
        pass
    
    def apply_domain_specific_processing(self, transcription):
        """ë„ë©”ì¸ë³„ í›„ì²˜ë¦¬ ì ìš©"""
        # ì˜ë£Œ ìš©ì–´ êµì •
        medical_corrections = {
            'ì‹¬ì¥ë§ˆë¹„': 'ì‹¬ê·¼ê²½ìƒ‰',
            'ê³ í˜ˆì••': 'ê³ í˜ˆì••ì¦'
        }
        
        for term, correction in medical_corrections.items():
            transcription = transcription.replace(term, correction)
        
        return transcription
```

### ì™¸ë¶€ ì„œë¹„ìŠ¤ í†µí•©

```python
# external_integrations.py
import requests
import json

class ExternalServiceIntegrator:
    def __init__(self):
        self.slack_webhook = "YOUR_SLACK_WEBHOOK_URL"
        self.teams_webhook = "YOUR_TEAMS_WEBHOOK_URL"
    
    async def send_to_slack(self, transcription_data):
        """Slack ì±„ë„ë¡œ ì „ì‚¬ ë‚´ìš© ì „ì†¡"""
        message = {
            "text": f"ğŸ¤ ìƒˆë¡œìš´ ì „ì‚¬ ë‚´ìš©",
            "attachments": [{
                "color": "good",
                "fields": [{
                    "title": "í™”ì",
                    "value": transcription_data.get('speaker', 'ì•Œ ìˆ˜ ì—†ìŒ'),
                    "short": True
                }, {
                    "title": "ë‚´ìš©",
                    "value": transcription_data['text'],
                    "short": False
                }]
            }]
        }
        
        response = requests.post(self.slack_webhook, json=message)
        return response.status_code == 200
    
    async def save_to_database(self, transcription_data):
        """ë°ì´í„°ë² ì´ìŠ¤ì— ì „ì‚¬ ë‚´ìš© ì €ì¥"""
        # ë°ì´í„°ë² ì´ìŠ¤ í†µí•© ë¡œì§
        pass
    
    async def trigger_workflow(self, transcription_data):
        """ì „ì‚¬ ë‚´ìš© ê¸°ë°˜ ìë™í™” ì›Œí¬í”Œë¡œìš° íŠ¸ë¦¬ê±°"""
        # ì›Œí¬í”Œë¡œìš° ìë™í™” ë¡œì§
        pass
```

## ê²°ë¡ 

WhisperLiveKitì€ ìµœì²¨ë‹¨ ì—°êµ¬ì™€ ì‹¤ìš©ì ì¸ í”„ë¡œë•ì…˜ ì¤€ë¹„ ê¸°ëŠ¥ì„ ê²°í•©í•œ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ê¸°ìˆ ì˜ ì¤‘ìš”í•œ ë°œì „ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ í¬ê´„ì ì¸ ê°€ì´ë“œë¥¼ í†µí•´ ë‹¤ìŒì„ í•™ìŠµí–ˆìŠµë‹ˆë‹¤:

### ì£¼ìš” ì„±ê³¼

1. **ì‹¤ì‹œê°„ ìŒì„± ì²˜ë¦¬ ë§ˆìŠ¤í„°**: ë°°ì¹˜ì™€ ìŠ¤íŠ¸ë¦¬ë° ìŒì„± ì¸ì‹ì˜ ê·¼ë³¸ì ì¸ ì°¨ì´ì  ì´í•´
2. **í”„ë¡œë•ì…˜ ì‹œìŠ¤í…œ êµ¬í˜„**: í™•ì¥ ê°€ëŠ¥í•œ ë‹¤ì¤‘ ì‚¬ìš©ì ìŒì„± ì „ì‚¬ ì„œë¹„ìŠ¤ ë°°í¬
3. **ê³ ê¸‰ ê¸°ëŠ¥ í†µí•©**: í™”ì ë¶„ë¦¬, ìŒì„± í™œë™ ê°ì§€, ì‚¬ìš©ì ì •ì˜ ë°±ì—”ë“œ í™œìš©
4. **ì„±ëŠ¥ ìµœì í™”**: ìµœì ì˜ ì§€ì—°ì‹œê°„ê³¼ ì •í™•ë„ ê· í˜•ì„ ìœ„í•œ ì‹œìŠ¤í…œ ì„¤ì •
5. **ì‹¤ì œ ì• í”Œë¦¬ì¼€ì´ì…˜**: íšŒì˜ ì „ì‚¬ê¸°, ì ‘ê·¼ì„± ë„êµ¬, ê³ ê° ì„œë¹„ìŠ¤ ë¶„ì„ê¸° êµ¬ì¶•

### ê¸°ìˆ ì  í•˜ì´ë¼ì´íŠ¸

- **ì´ˆì €ì§€ì—°**: í”„ë ˆì„ ìˆ˜ì¤€ ì–´í…ì…˜ ê°€ì´ë“œë¥¼ í†µí•œ SimulStreaming ë°±ì—”ë“œ
- **ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ê¸°ëŠ¥**: ë‹¤ì¤‘ ì‚¬ìš©ì ì§€ì›, í™”ì ì‹ë³„, SSL/TLS ë³´ì•ˆ
- **ìœ ì—°í•œ ì•„í‚¤í…ì²˜**: ì›¹ UI í†µí•©ì„ í†µí•œ WebSocket ê¸°ë°˜ ì‹¤ì‹œê°„ í†µì‹ 
- **í”„ë¡œë•ì…˜ ì¤€ë¹„**: Docker ë°°í¬, ë¡œë“œ ë°¸ëŸ°ì‹±, ëª¨ë‹ˆí„°ë§, ì˜¤ë¥˜ ì²˜ë¦¬

### ë‹¤ìŒ ë‹¨ê³„

ë‹¤ìŒ ê³ ê¸‰ ì£¼ì œë“¤ì„ íƒìƒ‰í•´ë³´ì„¸ìš”:

- **ì‚¬ìš©ì ì •ì˜ ëª¨ë¸ íŒŒì¸íŠœë‹**: ë„ë©”ì¸ë³„ ìš©ì–´ì— ë§ëŠ” ëª¨ë¸ ì ì‘
- **ë©€í‹°ëª¨ë‹¬ í†µí•©**: í¬ê´„ì ì¸ íšŒì˜ ë¶„ì„ì„ ìœ„í•œ ë¹„ë””ì˜¤ ì²˜ë¦¬ì™€ ê²°í•©
- **ì—£ì§€ ë°°í¬**: ëª¨ë°”ì¼ ë° IoT ë””ë°”ì´ìŠ¤ ìµœì í™”
- **ê³ ê¸‰ ë¶„ì„**: ê°ì • ë¶„ì„ ë° ëŒ€í™” ì¸í…”ë¦¬ì „ìŠ¤ êµ¬í˜„

WhisperLiveKitì˜ ìµœì²¨ë‹¨ ì—°êµ¬ì™€ ì‹¤ìš©ì  êµ¬í˜„ì˜ ê²°í•©ì€ ì°¨ì„¸ëŒ€ ìŒì„± ì§€ì› ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¶•ì„ ìœ„í•œ ì´ìƒì ì¸ ì„ íƒì…ë‹ˆë‹¤. ì ‘ê·¼ì„± ë„êµ¬, íšŒì˜ ì „ì‚¬ ì‹œìŠ¤í…œ, ê³ ê° ì„œë¹„ìŠ¤ ë¶„ì„ ë“± ì–´ë–¤ ê²ƒì„ ê°œë°œí•˜ë“ , WhisperLiveKitì€ ì•ˆì •ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•œ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ì˜ ê¸°ë°˜ì„ ì œê³µí•©ë‹ˆë‹¤.

---

**ê´€ë ¨ ë¦¬ì†ŒìŠ¤**:
- [WhisperLiveKit GitHub ì €ì¥ì†Œ](https://github.com/QuentinFuxa/WhisperLiveKit)
- [SimulStreaming ì—°êµ¬ ë…¼ë¬¸](https://arxiv.org/abs/2406.03049)
- [Pyannote.audio ë¬¸ì„œ](https://github.com/pyannote/pyannote-audio)
- [FastAPI WebSocket ê°€ì´ë“œ](https://fastapi.tiangolo.com/advanced/websockets/)
