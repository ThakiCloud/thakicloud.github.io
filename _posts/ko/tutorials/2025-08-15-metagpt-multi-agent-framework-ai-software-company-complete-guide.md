---
title: "MetaGPT: ë©€í‹° ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬ë¡œ AI ì†Œí”„íŠ¸ì›¨ì–´ íšŒì‚¬ êµ¬ì¶•í•˜ê¸° ì™„ì „ ê°€ì´ë“œ"
excerpt: "ìì—°ì–´ í•œ ì¤„ë¡œ ì™„ì „í•œ ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ ê°œë°œí•˜ëŠ” MetaGPT ë©€í‹° ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬. ì„¤ì¹˜ë¶€í„° ì‹¤ì œ í”„ë¡œì íŠ¸ ìƒì„±ê¹Œì§€ ë‹¨ê³„ë³„ íŠœí† ë¦¬ì–¼"
seo_title: "MetaGPT ë©€í‹° ì—ì´ì „íŠ¸ AI ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ íŠœí† ë¦¬ì–¼ - Thaki Cloud"
seo_description: "MetaGPTë¡œ AI ì†Œí”„íŠ¸ì›¨ì–´ íšŒì‚¬ êµ¬ì¶•í•˜ê¸°. Python ì„¤ì¹˜, ì„¤ì •, ì‹¤ì œ í”„ë¡œì íŠ¸ ìƒì„±ê¹Œì§€ í¬í•¨í•œ ì™„ì „ ê°€ì´ë“œ. ìì—°ì–´ í”„ë¡œê·¸ë˜ë°ì˜ í˜ì‹ "
date: 2025-08-15
last_modified_at: 2025-08-15
categories:
  - tutorials
  - llmops
tags:
  - metagpt
  - multi-agent
  - ai-software-company
  - natural-language-programming
  - llm-agents
  - gpt
  - python
  - automation
  - collaborative-ai
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
toc_icon: "cog"
toc_sticky: true
canonical_url: "https://thakicloud.github.io/tutorials/metagpt-multi-agent-framework-ai-software-company-complete-guide/"
reading_time: true
---

â±ï¸ **ì˜ˆìƒ ì½ê¸° ì‹œê°„**: 15ë¶„

## ì„œë¡ 

ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì˜ ë¯¸ë˜ê°€ ë°”ë€Œê³  ìˆìŠµë‹ˆë‹¤. [MetaGPT](https://github.com/FoundationAgents/MetaGPT)ëŠ” **ìì—°ì–´ í•œ ì¤„**ë§Œìœ¼ë¡œ ì™„ì „í•œ ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ ê°œë°œí•  ìˆ˜ ìˆëŠ” í˜ì‹ ì ì¸ ë©€í‹° ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ë§ˆì¹˜ ì‹¤ì œ ì†Œí”„íŠ¸ì›¨ì–´ íšŒì‚¬ì²˜ëŸ¼ **ì œí’ˆ ë§¤ë‹ˆì €, ì•„í‚¤í…íŠ¸, ì—”ì§€ë‹ˆì–´** ì—­í• ì„ í•˜ëŠ” AI ì—ì´ì „íŠ¸ë“¤ì´ í˜‘ì—…í•˜ì—¬ ì½”ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

ì´ í”„ë ˆì„ì›Œí¬ëŠ” **57.9k GitHub ìŠ¤íƒ€**ë¥¼ ê¸°ë¡í•˜ë©°, **ìì—°ì–´ í”„ë¡œê·¸ë˜ë°**ì˜ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì„ ì œì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤. MGX(MetaGPT X)ë¼ëŠ” ìƒìš© ì„œë¹„ìŠ¤ë„ ëŸ°ì¹­í•˜ì—¬ ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ í™˜ê²½ì—ì„œ ê²€ì¦ë°›ê³  ìˆìŠµë‹ˆë‹¤.

### ì´ ê°€ì´ë“œì—ì„œ ë°°ìš¸ ë‚´ìš©

- MetaGPTì˜ ë©€í‹° ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ì™€ SOP(Standard Operating Procedures) ì² í•™
- ì™„ì „í•œ ê°œë°œ í™˜ê²½ ì„¤ì • ë° êµ¬ì„±
- ì‹¤ì œ í”„ë¡œì íŠ¸ ìƒì„±ë¶€í„° ë°°í¬ê¹Œì§€ ì „ì²´ ì›Œí¬í”Œë¡œìš°
- ì»¤ìŠ¤í…€ ì—ì´ì „íŠ¸ ê°œë°œ ë° í™•ì¥ ë°©ë²•
- ë°ì´í„° ë¶„ì„, ë””ë² ì´íŠ¸, ì—°êµ¬ ë“± ë‹¤ì–‘í•œ í™œìš© ì‚¬ë¡€
- í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œì˜ ìµœì í™” ì „ëµ

### ê¸°ìˆ  ìš”êµ¬ì‚¬í•­

- **Python**: 3.9 ì´ìƒ, 3.12 ë¯¸ë§Œ
- **Node.js**: 18+ (í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œìš©)
- **pnpm**: ìµœì‹  ë²„ì „
- **OpenAI API Key** ë˜ëŠ” í˜¸í™˜ LLM
- **ë©”ëª¨ë¦¬**: ìµœì†Œ 8GB RAM
- **ì €ì¥ê³µê°„**: 5GB ì´ìƒ

## MetaGPT í•µì‹¬ ê°œë…

### Code = SOP(Team) ì² í•™

MetaGPTì˜ í•µì‹¬ ì² í•™ì€ **"Code = SOP(Team)"**ì…ë‹ˆë‹¤. ì‹¤ì œ ì†Œí”„íŠ¸ì›¨ì–´ íšŒì‚¬ì˜ í‘œì¤€ ìš´ì˜ ì ˆì°¨(SOP)ë¥¼ AI ì—ì´ì „íŠ¸ íŒ€ì— ì ìš©í•˜ì—¬ ì²´ê³„ì ì¸ ê°œë°œ í”„ë¡œì„¸ìŠ¤ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

```python
# MetaGPTì˜ í•µì‹¬ ì•„í‚¤í…ì²˜
class SoftwareCompany:
    def __init__(self):
        self.roles = {
            "product_manager": ProductManager(),
            "architect": Architect(), 
            "project_manager": ProjectManager(),
            "engineers": [Engineer() for _ in range(3)],
            "qa_engineer": QAEngineer()
        }
        
        self.sop = StandardOperatingProcedures()
    
    def develop_software(self, requirement: str):
        # 1. ì œí’ˆ ë§¤ë‹ˆì €: ìš”êµ¬ì‚¬í•­ ë¶„ì„
        user_stories = self.roles["product_manager"].analyze_requirements(requirement)
        
        # 2. ì•„í‚¤í…íŠ¸: ì‹œìŠ¤í…œ ì„¤ê³„
        architecture = self.roles["architect"].design_system(user_stories)
        
        # 3. í”„ë¡œì íŠ¸ ë§¤ë‹ˆì €: ì‘ì—… ê³„íš
        tasks = self.roles["project_manager"].create_tasks(architecture)
        
        # 4. ì—”ì§€ë‹ˆì–´ë“¤: ì½”ë“œ êµ¬í˜„
        code = self.parallel_development(tasks)
        
        # 5. QA: í’ˆì§ˆ ë³´ì¦
        tested_code = self.roles["qa_engineer"].test_code(code)
        
        return tested_code
```

### ë©€í‹° ì—ì´ì „íŠ¸ í˜‘ì—… ì‹œìŠ¤í…œ

MetaGPTëŠ” ê° ì—­í• ë³„ ì „ë¬¸ ì—ì´ì „íŠ¸ê°€ ë‹¨ê³„ì ìœ¼ë¡œ í˜‘ì—…í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Product        â”‚    â”‚  Architect      â”‚    â”‚  Project        â”‚
â”‚  Manager        â”‚â”€â”€â”€â–¶â”‚                 â”‚â”€â”€â”€â–¶â”‚  Manager        â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Requirements   â”‚    â”‚  System Design  â”‚    â”‚  Task Planning  â”‚
â”‚  â€¢ User Stories â”‚    â”‚  â€¢ Architecture â”‚    â”‚  â€¢ Sprint Plan  â”‚
â”‚  â€¢ Use Cases    â”‚    â”‚  â€¢ APIs         â”‚    â”‚  â€¢ Resource     â”‚
â”‚  â€¢ Acceptance   â”‚    â”‚  â€¢ Database     â”‚    â”‚    Allocation   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Engineering Team                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Frontend     â”‚  â”‚  Backend      â”‚  â”‚  DevOps       â”‚      â”‚
â”‚  â”‚  Engineer     â”‚  â”‚  Engineer     â”‚  â”‚  Engineer     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    QA Engineer                                  â”‚
â”‚  â€¢ Unit Testing    â€¢ Integration Testing    â€¢ Performance      â”‚
â”‚  â€¢ Code Review     â€¢ Security Analysis      â€¢ Documentation    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## í™˜ê²½ ì„¤ì • ë° ì„¤ì¹˜

### 1ë‹¨ê³„: Python í™˜ê²½ ì¤€ë¹„

```bash
# Python ë²„ì „ í™•ì¸
python --version  # 3.9 ì´ìƒ, 3.12 ë¯¸ë§Œì´ì–´ì•¼ í•¨

# Condaë¡œ í™˜ê²½ ìƒì„± (ê¶Œì¥)
conda create -n metagpt python=3.11
conda activate metagpt

# ë˜ëŠ” venv ì‚¬ìš©
python -m venv metagpt-env
source metagpt-env/bin/activate  # Linux/macOS
# metagpt-env\Scripts\activate  # Windows
```

### 2ë‹¨ê³„: MetaGPT ì„¤ì¹˜

```bash
# PyPIì—ì„œ ì„¤ì¹˜ (ê¶Œì¥)
pip install --upgrade metagpt

# ë˜ëŠ” ìµœì‹  ê°œë°œ ë²„ì „
pip install --upgrade git+https://github.com/FoundationAgents/MetaGPT.git

# ë˜ëŠ” ì†ŒìŠ¤ì—ì„œ ì„¤ì¹˜ (ê°œë°œììš©)
git clone https://github.com/FoundationAgents/MetaGPT.git
cd MetaGPT
pip install --upgrade -e .
```

### 3ë‹¨ê³„: Node.js ë° pnpm ì„¤ì¹˜

```bash
# Node.js ì„¤ì¹˜ í™•ì¸ (18+ í•„ìš”)
node --version

# macOS (Homebrew)
brew install node pnpm

# Ubuntu/Debian
curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
sudo apt-get install -y nodejs
npm install -g pnpm

# Windows (Chocolatey)
choco install nodejs pnpm
```

### 4ë‹¨ê³„: ì„¤ì¹˜ í™•ì¸

```python
# test_installation.py
import sys
import subprocess

def test_metagpt_installation():
    print("ğŸ” MetaGPT ì„¤ì¹˜ í™•ì¸ ì¤‘...")
    
    # Python ë²„ì „ í™•ì¸
    python_version = sys.version_info
    print(f"âœ… Python ë²„ì „: {python_version.major}.{python_version.minor}.{python_version.micro}")
    
    if not (3, 9) <= (python_version.major, python_version.minor) < (3, 12):
        print("âŒ Python ë²„ì „ì´ 3.9-3.11 ë²”ìœ„ì— ìˆì§€ ì•ŠìŠµë‹ˆë‹¤")
        return False
    
    # MetaGPT ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸
    try:
        import metagpt
        print(f"âœ… MetaGPT ë²„ì „: {metagpt.__version__}")
    except ImportError as e:
        print(f"âŒ MetaGPT ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
        return False
    
    # Node.js ë° pnpm í™•ì¸
    try:
        node_result = subprocess.run(['node', '--version'], capture_output=True, text=True)
        pnpm_result = subprocess.run(['pnpm', '--version'], capture_output=True, text=True)
        
        print(f"âœ… Node.js: {node_result.stdout.strip()}")
        print(f"âœ… pnpm: {pnpm_result.stdout.strip()}")
        
    except FileNotFoundError as e:
        print(f"âŒ Node.js/pnpm ì„¤ì¹˜ í™•ì¸ ì‹¤íŒ¨: {e}")
        return False
    
    print("ğŸ‰ ëª¨ë“  ì„¤ì¹˜ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    return True

if __name__ == "__main__":
    test_metagpt_installation()
```

## ì„¤ì • ë° êµ¬ì„±

### ì„¤ì • íŒŒì¼ ì´ˆê¸°í™”

```bash
# MetaGPT ì„¤ì • ì´ˆê¸°í™”
metagpt --init-config

# ì„¤ì • íŒŒì¼ ìœ„ì¹˜ í™•ì¸
ls -la ~/.metagpt/config2.yaml
```

### LLM ì œê³µìë³„ ì„¤ì •

#### OpenAI ì„¤ì •

```yaml
# ~/.metagpt/config2.yaml
llm:
  api_type: "openai"
  model: "gpt-4-turbo"  # ë˜ëŠ” gpt-3.5-turbo, gpt-4o
  base_url: "https://api.openai.com/v1"
  api_key: "YOUR_OPENAI_API_KEY"
  
# ê³ ê¸‰ ì„¤ì •
  max_tokens: 4096
  temperature: 0.7
  timeout: 60
```

#### Azure OpenAI ì„¤ì •

```yaml
llm:
  api_type: "azure"
  model: "gpt-4"
  base_url: "https://YOUR_RESOURCE.openai.azure.com/"
  api_key: "YOUR_AZURE_API_KEY"
  api_version: "2024-02-15-preview"
  deployment_name: "gpt-4-deployment"
```

#### Ollama ë¡œì»¬ LLM ì„¤ì •

```bash
# Ollama ì„¤ì¹˜ ë° ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
curl -fsSL https://ollama.ai/install.sh | sh
ollama serve
ollama pull llama2  # ë˜ëŠ” codellama, mistral
```

```yaml
llm:
  api_type: "ollama"
  model: "llama2"
  base_url: "http://localhost:11434"
  # api_keyëŠ” í•„ìš” ì—†ìŒ
```

#### Groq ì„¤ì • (ë¹ ë¥¸ ì¶”ë¡ ìš©)

```yaml
llm:
  api_type: "groq"
  model: "mixtral-8x7b-32768"
  base_url: "https://api.groq.com/openai/v1"
  api_key: "YOUR_GROQ_API_KEY"
```

### í™˜ê²½ë³„ ì„¤ì • ìµœì í™”

```python
# config_optimizer.py
import yaml
import os
from pathlib import Path

class MetaGPTConfigOptimizer:
    def __init__(self):
        self.config_path = Path.home() / ".metagpt" / "config2.yaml"
        
    def create_optimized_config(self, environment="development"):
        """í™˜ê²½ë³„ ìµœì í™”ëœ ì„¤ì • ìƒì„±"""
        
        base_config = {
            "llm": {
                "api_type": "openai",
                "model": "gpt-4-turbo",
                "base_url": "https://api.openai.com/v1",
                "api_key": os.getenv("OPENAI_API_KEY", "YOUR_API_KEY_HERE")
            },
            "workspace": {
                "path": "./workspace"
            },
            "logging": {
                "level": "INFO"
            }
        }
        
        if environment == "development":
            # ê°œë°œ í™˜ê²½: ë¹ ë¥¸ ë°˜ë³µì„ ìœ„í•œ ì„¤ì •
            config = {
                **base_config,
                "llm": {
                    **base_config["llm"],
                    "model": "gpt-3.5-turbo",  # ë¹ ë¥´ê³  ì €ë ´
                    "temperature": 0.3,  # ì¼ê´€ì„± ìˆëŠ” ê²°ê³¼
                    "max_tokens": 2048
                },
                "logging": {
                    "level": "DEBUG"
                }
            }
            
        elif environment == "production":
            # í”„ë¡œë•ì…˜ í™˜ê²½: í’ˆì§ˆ ìš°ì„  ì„¤ì •
            config = {
                **base_config,
                "llm": {
                    **base_config["llm"],
                    "model": "gpt-4-turbo",  # ìµœê³  í’ˆì§ˆ
                    "temperature": 0.7,  # ì°½ì˜ì„±ê³¼ ì¼ê´€ì„± ê· í˜•
                    "max_tokens": 4096,
                    "timeout": 120
                },
                "logging": {
                    "level": "WARNING"
                }
            }
            
        elif environment == "budget":
            # ì˜ˆì‚° ì ˆì•½ í™˜ê²½: ë¹„ìš© ìµœì í™”
            config = {
                **base_config,
                "llm": {
                    **base_config["llm"],
                    "model": "gpt-3.5-turbo",
                    "temperature": 0.5,
                    "max_tokens": 1024
                }
            }
            
        return config
    
    def save_config(self, config):
        """ì„¤ì • íŒŒì¼ ì €ì¥"""
        self.config_path.parent.mkdir(exist_ok=True)
        
        with open(self.config_path, 'w') as f:
            yaml.dump(config, f, default_flow_style=False, indent=2)
        
        print(f"âœ… ì„¤ì • íŒŒì¼ ì €ì¥ë¨: {self.config_path}")
    
    def setup_environment_config(self, environment="development"):
        """í™˜ê²½ë³„ ì„¤ì • ìë™ ìƒì„±"""
        config = self.create_optimized_config(environment)
        self.save_config(config)
        
        print(f"ğŸ”§ {environment} í™˜ê²½ ì„¤ì • ì™„ë£Œ")
        print("ğŸ“ ë‹¤ìŒ ì‚¬í•­ì„ í™•ì¸í•˜ì„¸ìš”:")
        print(f"   1. API í‚¤ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€")
        print(f"   2. ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€")
        print(f"   3. ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì´ ì •ìƒì¸ì§€")

# ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    optimizer = MetaGPTConfigOptimizer()
    
    # ê°œë°œ í™˜ê²½ ì„¤ì •
    optimizer.setup_environment_config("development")
```

## ê¸°ë³¸ ì‚¬ìš©ë²•

### CLIë¥¼ í†µí•œ ê°„ë‹¨í•œ í”„ë¡œì íŠ¸ ìƒì„±

```bash
# ê°„ë‹¨í•œ ê²Œì„ ë§Œë“¤ê¸°
metagpt "Create a 2048 game"

# ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ë§Œë“¤ê¸°
metagpt "Create a todo list web app with React frontend and Python backend"

# ë°ì´í„° ë¶„ì„ ë„êµ¬ ë§Œë“¤ê¸°
metagpt "Create a data visualization dashboard for sales analytics"

# ìƒì„±ëœ í”„ë¡œì íŠ¸ í™•ì¸
ls -la ./workspace/
```

### Python APIë¥¼ í†µí•œ í”„ë¡œê·¸ë˜ë° ë°©ì‹ ì‚¬ìš©

```python
# basic_usage.py
import asyncio
from metagpt.software_company import generate_repo
from metagpt.utils.project_repo import ProjectRepo

async def create_simple_project():
    """ê°„ë‹¨í•œ í”„ë¡œì íŠ¸ ìƒì„± ì˜ˆì œ"""
    
    # ìš”êµ¬ì‚¬í•­ ì •ì˜
    requirement = """
    Create a simple web-based calculator that can:
    1. Perform basic arithmetic operations (+, -, *, /)
    2. Have a clean, responsive UI
    3. Show calculation history
    4. Support keyboard input
    5. Include unit tests
    """
    
    print("ğŸš€ í”„ë¡œì íŠ¸ ìƒì„± ì‹œì‘...")
    print(f"ğŸ“‹ ìš”êµ¬ì‚¬í•­: {requirement}")
    
    # í”„ë¡œì íŠ¸ ìƒì„±
    repo: ProjectRepo = await generate_repo(requirement)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\nğŸ“ ìƒì„±ëœ í”„ë¡œì íŠ¸ êµ¬ì¡°:")
    print(repo)
    
    # ìƒì„±ëœ íŒŒì¼ë“¤ í™•ì¸
    print("\nğŸ“„ ì£¼ìš” íŒŒì¼ë“¤:")
    for file_path in repo.all_files:
        print(f"   {file_path}")
    
    return repo

async def create_advanced_project():
    """ê³ ê¸‰ í”„ë¡œì íŠ¸ ìƒì„± ì˜ˆì œ"""
    
    requirement = """
    Create a microservices-based e-commerce platform with:
    
    Backend Services:
    - User authentication service (JWT-based)
    - Product catalog service with search
    - Shopping cart service
    - Order processing service
    - Payment integration service
    - Email notification service
    
    Frontend:
    - React-based customer portal
    - Admin dashboard for inventory management
    - Mobile-responsive design
    
    Infrastructure:
    - Docker containerization
    - API gateway
    - Database design (PostgreSQL)
    - Redis for caching
    - Message queue for async processing
    
    Quality Assurance:
    - Unit tests for all services
    - Integration tests
    - API documentation (OpenAPI/Swagger)
    - Performance testing setup
    - Security vulnerability scanning
    """
    
    print("ğŸš€ ê³ ê¸‰ í”„ë¡œì íŠ¸ ìƒì„± ì‹œì‘...")
    
    # í”„ë¡œì íŠ¸ ìƒì„±
    repo: ProjectRepo = await generate_repo(requirement)
    
    # í”„ë¡œì íŠ¸ ë¶„ì„
    print(f"\nğŸ“Š í”„ë¡œì íŠ¸ í†µê³„:")
    print(f"   ì´ íŒŒì¼ ìˆ˜: {len(repo.all_files)}")
    
    # íŒŒì¼ ìœ í˜•ë³„ ë¶„ë¥˜
    file_types = {}
    for file_path in repo.all_files:
        ext = file_path.suffix.lower()
        file_types[ext] = file_types.get(ext, 0) + 1
    
    print(f"   íŒŒì¼ ìœ í˜•ë³„ ë¶„í¬:")
    for ext, count in sorted(file_types.items()):
        print(f"     {ext or '(í™•ì¥ì ì—†ìŒ)'}: {count}ê°œ")
    
    return repo

# ì‚¬ìš© ì˜ˆì œ
async def main():
    # ê°„ë‹¨í•œ í”„ë¡œì íŠ¸ ë¨¼ì € í…ŒìŠ¤íŠ¸
    simple_repo = await create_simple_project()
    
    # ê³ ê¸‰ í”„ë¡œì íŠ¸ ìƒì„± (ì‹œê°„ì´ ë” ê±¸ë¦¼)
    # advanced_repo = await create_advanced_project()

if __name__ == "__main__":
    asyncio.run(main())
```

### ë°ì´í„° ì¸í„°í”„ë¦¬í„° ì‚¬ìš©

```python
# data_interpreter_example.py
import asyncio
import pandas as pd
import numpy as np
from metagpt.roles.di.data_interpreter import DataInterpreter

async def analyze_iris_dataset():
    """Iris ë°ì´í„°ì…‹ ë¶„ì„ ì˜ˆì œ"""
    
    di = DataInterpreter()
    
    # ê¸°ë³¸ ë¶„ì„ ìš”ì²­
    result = await di.run("Run data analysis on sklearn Iris dataset, include a plot")
    
    print("ğŸ“Š ë¶„ì„ ì™„ë£Œ!")
    return result

async def analyze_custom_data():
    """ì»¤ìŠ¤í…€ ë°ì´í„° ë¶„ì„ ì˜ˆì œ"""
    
    # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    np.random.seed(42)
    data = {
        'date': pd.date_range('2024-01-01', periods=100),
        'sales': np.random.normal(1000, 200, 100),
        'marketing_spend': np.random.normal(500, 100, 100),
        'region': np.random.choice(['North', 'South', 'East', 'West'], 100)
    }
    
    df = pd.DataFrame(data)
    df.to_csv('./sample_sales_data.csv', index=False)
    
    di = DataInterpreter()
    
    analysis_request = """
    Analyze the sales data in ./sample_sales_data.csv and provide:
    1. Summary statistics
    2. Correlation analysis between sales and marketing spend
    3. Regional performance comparison
    4. Time series trend analysis
    5. Visualizations for each analysis
    6. Recommendations based on findings
    """
    
    result = await di.run(analysis_request)
    
    print("ğŸ“ˆ ì»¤ìŠ¤í…€ ë°ì´í„° ë¶„ì„ ì™„ë£Œ!")
    return result

async def financial_analysis():
    """ê¸ˆìœµ ë°ì´í„° ë¶„ì„ ì˜ˆì œ"""
    
    di = DataInterpreter()
    
    request = """
    Create a financial analysis dashboard that:
    1. Downloads stock data for Apple, Google, Microsoft (last 2 years)
    2. Calculates key financial metrics (volatility, Sharpe ratio, etc.)
    3. Performs portfolio optimization
    4. Creates interactive charts showing:
       - Price movements
       - Returns distribution
       - Correlation heatmap
       - Risk-return scatter plot
    5. Provides investment recommendations
    """
    
    result = await di.run(request)
    
    print("ğŸ’° ê¸ˆìœµ ë¶„ì„ ì™„ë£Œ!")
    return result

# ì‹¤í–‰ ì˜ˆì œ
async def main():
    print("ğŸ” ë°ì´í„° ë¶„ì„ ì‹œì‘...")
    
    # 1. ê¸°ë³¸ Iris ë¶„ì„
    await analyze_iris_dataset()
    
    # 2. ì»¤ìŠ¤í…€ ë°ì´í„° ë¶„ì„
    await analyze_custom_data()
    
    # 3. ê¸ˆìœµ ë¶„ì„ (ì‹œê°„ì´ ë” ê±¸ë¦¼)
    # await financial_analysis()

if __name__ == "__main__":
    asyncio.run(main())
```

## ê³ ê¸‰ í™œìš© ì‚¬ë¡€

### 1. ë””ë² ì´íŠ¸ ì‹œìŠ¤í…œ

```python
# debate_system.py
import asyncio
from metagpt.roles import Role
from metagpt.schema import Message
from metagpt.actions import Action
from metagpt.environment import Environment

class DebateAction(Action):
    """ë””ë² ì´íŠ¸ ì•¡ì…˜ í´ë˜ìŠ¤"""
    
    def __init__(self, stance: str):
        super().__init__()
        self.stance = stance  # "for" ë˜ëŠ” "against"
    
    async def run(self, topic: str, previous_arguments: list = None):
        """ë””ë² ì´íŠ¸ ë…¼ì¦ ìƒì„±"""
        
        context = f"Topic: {topic}\nStance: {self.stance}"
        
        if previous_arguments:
            context += f"\nPrevious arguments:\n" + "\n".join(previous_arguments)
        
        prompt = f"""
        {context}
        
        Please provide a well-reasoned argument for your stance.
        Include:
        1. Main thesis
        2. Supporting evidence
        3. Counter-arguments to opposing views
        4. Logical conclusion
        
        Keep it concise but persuasive (200-300 words).
        """
        
        response = await self._aask(prompt)
        return response

class Debater(Role):
    """ë””ë² ì´í„° ì—­í•  í´ë˜ìŠ¤"""
    
    def __init__(self, name: str, stance: str):
        super().__init__(name=name)
        self.stance = stance
        self.debate_action = DebateAction(stance)
        self.arguments_made = []
    
    async def _act(self) -> Message:
        """ë””ë² ì´íŠ¸ ìˆ˜í–‰"""
        
        # ìµœì‹  ë©”ì‹œì§€ì—ì„œ ì£¼ì œì™€ ì´ì „ ë…¼ì¦ë“¤ ì¶”ì¶œ
        topic = self.rc.env.get_topic()
        previous_args = self.rc.env.get_previous_arguments()
        
        # ë…¼ì¦ ìƒì„±
        argument = await self.debate_action.run(topic, previous_args)
        self.arguments_made.append(argument)
        
        # ë©”ì‹œì§€ ìƒì„±
        message = Message(
            content=argument,
            role=self.profile,
            cause_by=type(self.debate_action)
        )
        
        return message

class DebateEnvironment(Environment):
    """ë””ë² ì´íŠ¸ í™˜ê²½ í´ë˜ìŠ¤"""
    
    def __init__(self, topic: str, rounds: int = 3):
        super().__init__()
        self.topic = topic
        self.rounds = rounds
        self.current_round = 0
        self.arguments = []
    
    def get_topic(self):
        return self.topic
    
    def get_previous_arguments(self):
        return self.arguments[-4:]  # ìµœê·¼ 4ê°œ ë…¼ì¦ë§Œ ë°˜í™˜
    
    def add_argument(self, argument: str, debater: str):
        self.arguments.append(f"{debater}: {argument}")

async def run_debate():
    """ë””ë² ì´íŠ¸ ì‹¤í–‰"""
    
    topic = "Should artificial intelligence replace human jobs?"
    
    # í™˜ê²½ ì„¤ì •
    env = DebateEnvironment(topic, rounds=3)
    
    # ë””ë² ì´í„°ë“¤ ìƒì„±
    pro_debater = Debater("Pro-AI Advocate", "for")
    con_debater = Debater("Human-First Advocate", "against")
    
    # í™˜ê²½ì— ë””ë² ì´í„°ë“¤ ì¶”ê°€
    env.add_role(pro_debater)
    env.add_role(con_debater)
    
    print(f"ğŸ­ ë””ë² ì´íŠ¸ ì‹œì‘: {topic}")
    print("=" * 80)
    
    # ë””ë² ì´íŠ¸ ì§„í–‰
    for round_num in range(env.rounds):
        print(f"\nğŸ“ ë¼ìš´ë“œ {round_num + 1}")
        print("-" * 40)
        
        # Pro ì¸¡ ë…¼ì¦
        pro_message = await pro_debater._act()
        env.add_argument(pro_message.content, "Pro")
        print(f"\nğŸŸ¢ Pro-AI Advocate:")
        print(pro_message.content)
        
        # Con ì¸¡ ë…¼ì¦
        con_message = await con_debater._act()
        env.add_argument(con_message.content, "Con")
        print(f"\nğŸ”´ Human-First Advocate:")
        print(con_message.content)
        
        print("\n" + "="*80)
    
    # ë””ë² ì´íŠ¸ ìš”ì•½
    print(f"\nğŸ“Š ë””ë² ì´íŠ¸ ì™„ë£Œ!")
    print(f"ì´ {len(env.arguments)}ê°œì˜ ë…¼ì¦ì´ êµí™˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return env.arguments

# ì‹¤í–‰
if __name__ == "__main__":
    asyncio.run(run_debate())
```

### 2. ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸

```python
# research_assistant.py
import asyncio
import json
from datetime import datetime
from pathlib import Path
from metagpt.roles import Role
from metagpt.actions import Action
from metagpt.schema import Message

class LiteratureReviewAction(Action):
    """ë¬¸í—Œ ê²€í†  ì•¡ì…˜"""
    
    async def run(self, topic: str, search_terms: list):
        """ë¬¸í—Œ ê²€í†  ìˆ˜í–‰"""
        
        prompt = f"""
        Conduct a comprehensive literature review on: {topic}
        
        Search terms: {', '.join(search_terms)}
        
        Please provide:
        1. Key research themes and trends
        2. Major findings and conclusions
        3. Research gaps and future directions
        4. Methodology comparison
        5. Citation analysis
        6. Recommended reading list (10-15 papers)
        
        Format as a structured academic review.
        """
        
        review = await self._aask(prompt)
        return review

class ExperimentDesignAction(Action):
    """ì‹¤í—˜ ì„¤ê³„ ì•¡ì…˜"""
    
    async def run(self, research_question: str, constraints: dict):
        """ì‹¤í—˜ ì„¤ê³„ ìƒì„±"""
        
        prompt = f"""
        Design an experiment to answer: {research_question}
        
        Constraints:
        - Budget: {constraints.get('budget', 'Not specified')}
        - Timeline: {constraints.get('timeline', 'Not specified')}
        - Resources: {constraints.get('resources', 'Not specified')}
        
        Please provide:
        1. Hypothesis formulation
        2. Experimental design (methodology)
        3. Variables identification (dependent, independent, control)
        4. Sample size calculation
        5. Data collection procedures
        6. Statistical analysis plan
        7. Ethical considerations
        8. Timeline and milestones
        """
        
        design = await self._aask(prompt)
        return design

class DataAnalysisPlanAction(Action):
    """ë°ì´í„° ë¶„ì„ ê³„íš ì•¡ì…˜"""
    
    async def run(self, data_description: str, research_objectives: list):
        """ë°ì´í„° ë¶„ì„ ê³„íš ìƒì„±"""
        
        prompt = f"""
        Create a data analysis plan for:
        
        Data: {data_description}
        
        Research Objectives:
        {chr(10).join(f"{i+1}. {obj}" for i, obj in enumerate(research_objectives))}
        
        Please provide:
        1. Data preprocessing steps
        2. Descriptive analysis plan
        3. Statistical tests selection
        4. Visualization strategy
        5. Model selection rationale
        6. Validation procedures
        7. Interpretation guidelines
        8. Reporting structure
        """
        
        plan = await self._aask(prompt)
        return plan

class ResearchAssistant(Role):
    """ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ ì—­í• """
    
    def __init__(self, specialization: str = "General"):
        super().__init__(name=f"Research Assistant ({specialization})")
        self.specialization = specialization
        self.lit_review_action = LiteratureReviewAction()
        self.exp_design_action = ExperimentDesignAction()
        self.data_analysis_action = DataAnalysisPlanAction()
    
    async def conduct_literature_review(self, topic: str, search_terms: list):
        """ë¬¸í—Œ ê²€í†  ìˆ˜í–‰"""
        return await self.lit_review_action.run(topic, search_terms)
    
    async def design_experiment(self, research_question: str, constraints: dict):
        """ì‹¤í—˜ ì„¤ê³„"""
        return await self.exp_design_action.run(research_question, constraints)
    
    async def create_analysis_plan(self, data_description: str, objectives: list):
        """ë¶„ì„ ê³„íš ìƒì„±"""
        return await self.data_analysis_action.run(data_description, objectives)

class ResearchProject:
    """ì—°êµ¬ í”„ë¡œì íŠ¸ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, project_name: str, output_dir: str = "./research_output"):
        self.project_name = project_name
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        self.assistant = ResearchAssistant()
        self.project_data = {
            "project_name": project_name,
            "created_at": datetime.now().isoformat(),
            "components": {}
        }
    
    async def run_comprehensive_research(self, research_config: dict):
        """ì¢…í•©ì ì¸ ì—°êµ¬ ìˆ˜í–‰"""
        
        print(f"ğŸ”¬ ì—°êµ¬ í”„ë¡œì íŠ¸ ì‹œì‘: {self.project_name}")
        print("=" * 60)
        
        # 1. ë¬¸í—Œ ê²€í† 
        if "literature_review" in research_config:
            print("\nğŸ“š ë¬¸í—Œ ê²€í†  ìˆ˜í–‰ ì¤‘...")
            lit_config = research_config["literature_review"]
            
            literature_review = await self.assistant.conduct_literature_review(
                lit_config["topic"],
                lit_config["search_terms"]
            )
            
            self.project_data["components"]["literature_review"] = literature_review
            self._save_component("literature_review", literature_review)
            print("âœ… ë¬¸í—Œ ê²€í†  ì™„ë£Œ")
        
        # 2. ì‹¤í—˜ ì„¤ê³„
        if "experiment_design" in research_config:
            print("\nğŸ§ª ì‹¤í—˜ ì„¤ê³„ ìˆ˜í–‰ ì¤‘...")
            exp_config = research_config["experiment_design"]
            
            experiment_design = await self.assistant.design_experiment(
                exp_config["research_question"],
                exp_config["constraints"]
            )
            
            self.project_data["components"]["experiment_design"] = experiment_design
            self._save_component("experiment_design", experiment_design)
            print("âœ… ì‹¤í—˜ ì„¤ê³„ ì™„ë£Œ")
        
        # 3. ë°ì´í„° ë¶„ì„ ê³„íš
        if "data_analysis" in research_config:
            print("\nğŸ“Š ë°ì´í„° ë¶„ì„ ê³„íš ìˆ˜í–‰ ì¤‘...")
            data_config = research_config["data_analysis"]
            
            analysis_plan = await self.assistant.create_analysis_plan(
                data_config["data_description"],
                data_config["objectives"]
            )
            
            self.project_data["components"]["data_analysis_plan"] = analysis_plan
            self._save_component("data_analysis_plan", analysis_plan)
            print("âœ… ë°ì´í„° ë¶„ì„ ê³„íš ì™„ë£Œ")
        
        # í”„ë¡œì íŠ¸ ë©”íƒ€ë°ì´í„° ì €ì¥
        self._save_project_metadata()
        
        print(f"\nğŸ‰ ì—°êµ¬ í”„ë¡œì íŠ¸ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ ìœ„ì¹˜: {self.output_dir}")
        
        return self.project_data
    
    def _save_component(self, component_name: str, content: str):
        """ì»´í¬ë„ŒíŠ¸ ê²°ê³¼ ì €ì¥"""
        file_path = self.output_dir / f"{component_name}.md"
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(f"# {component_name.replace('_', ' ').title()}\n\n")
            f.write(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(content)
        
        print(f"   ğŸ’¾ ì €ì¥ë¨: {file_path}")
    
    def _save_project_metadata(self):
        """í”„ë¡œì íŠ¸ ë©”íƒ€ë°ì´í„° ì €ì¥"""
        metadata_path = self.output_dir / "project_metadata.json"
        
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(self.project_data, f, indent=2, ensure_ascii=False)

# ì—°êµ¬ í”„ë¡œì íŠ¸ ì‹¤í–‰ ì˜ˆì œ
async def run_ai_ethics_research():
    """AI ìœ¤ë¦¬ ì—°êµ¬ í”„ë¡œì íŠ¸ ì˜ˆì œ"""
    
    research_config = {
        "literature_review": {
            "topic": "AI Ethics in Healthcare Applications",
            "search_terms": [
                "artificial intelligence ethics",
                "healthcare AI",
                "medical AI bias",
                "algorithmic fairness",
                "AI governance healthcare"
            ]
        },
        "experiment_design": {
            "research_question": "How can we measure and mitigate bias in AI diagnostic systems?",
            "constraints": {
                "budget": "$50,000",
                "timeline": "6 months",
                "resources": "Hospital partnership, anonymized patient data"
            }
        },
        "data_analysis": {
            "data_description": "Anonymized patient diagnostic data with demographic information and AI system predictions",
            "objectives": [
                "Identify potential bias in AI diagnostic accuracy across demographic groups",
                "Quantify disparities in false positive/negative rates",
                "Evaluate fairness metrics for the AI system",
                "Propose bias mitigation strategies"
            ]
        }
    }
    
    project = ResearchProject("AI_Ethics_Healthcare_Study")
    result = await project.run_comprehensive_research(research_config)
    
    return result

# ì‹¤í–‰
if __name__ == "__main__":
    asyncio.run(run_ai_ethics_research())
```

### 3. ì˜ìˆ˜ì¦ ì²˜ë¦¬ ì–´ì‹œìŠ¤í„´íŠ¸

```python
# receipt_assistant.py
import asyncio
import json
import base64
from pathlib import Path
from datetime import datetime
from metagpt.roles import Role
from metagpt.actions import Action

class ReceiptProcessingAction(Action):
    """ì˜ìˆ˜ì¦ ì²˜ë¦¬ ì•¡ì…˜"""
    
    async def run(self, receipt_data: str, processing_type: str = "extract"):
        """ì˜ìˆ˜ì¦ ë°ì´í„° ì²˜ë¦¬"""
        
        if processing_type == "extract":
            prompt = f"""
            Extract structured information from this receipt:
            
            {receipt_data}
            
            Please provide a JSON response with:
            {% raw %}{{
                "merchant_name": "Store name",
                "date": "YYYY-MM-DD",
                "time": "HH:MM",
                "total_amount": 0.00,
                "tax_amount": 0.00,
                "items": [
                    {{
                        "name": "Item name",
                        "quantity": 1,
                        "unit_price": 0.00,
                        "total_price": 0.00,
                        "category": "Category"
                    }}
                ],
                "payment_method": "Cash/Card/etc",
                "receipt_number": "Number if available",
                "location": "Store address if available"
            }}{% endraw %}
            """
        
        elif processing_type == "categorize":
            prompt = f"""
            Categorize the expenses in this receipt for accounting purposes:
            
            {receipt_data}
            
            Provide categorization based on standard business expense categories:
            - Office Supplies
            - Meals & Entertainment
            - Travel
            - Equipment
            - Marketing
            - Utilities
            - Professional Services
            - Other
            
            Format as JSON with explanations.
            """
        
        elif processing_type == "validate":
            prompt = f"""
            Validate the mathematical accuracy of this receipt:
            
            {receipt_data}
            
            Check:
            1. Item totals (quantity Ã— unit price)
            2. Subtotal calculations
            3. Tax calculations
            4. Final total
            
            Report any discrepancies found.
            """
        
        response = await self._aask(prompt)
        return response

class ExpenseCategorizationAction(Action):
    """ë¹„ìš© ë¶„ë¥˜ ì•¡ì…˜"""
    
    async def run(self, receipts_data: list, business_rules: dict):
        """ë¹„ìš© ë¶„ë¥˜ ìˆ˜í–‰"""
        
        prompt = f"""
        Categorize these expenses according to business rules:
        
        Business Rules:
        {json.dumps(business_rules, indent=2)}
        
        Receipts:
        {json.dumps(receipts_data, indent=2)}
        
        Provide:
        1. Categorized expenses by type
        2. Monthly/quarterly summaries
        3. Tax-deductible vs non-deductible items
        4. Flagged items requiring review
        5. Compliance notes
        """
        
        categorization = await self._aask(prompt)
        return categorization

class ReceiptAssistant(Role):
    """ì˜ìˆ˜ì¦ ì²˜ë¦¬ ì–´ì‹œìŠ¤í„´íŠ¸"""
    
    def __init__(self):
        super().__init__(name="Receipt Processing Assistant")
        self.processing_action = ReceiptProcessingAction()
        self.categorization_action = ExpenseCategorizationAction()
        self.processed_receipts = []
    
    async def process_receipt(self, receipt_content: str):
        """ë‹¨ì¼ ì˜ìˆ˜ì¦ ì²˜ë¦¬"""
        
        # 1. ë°ì´í„° ì¶”ì¶œ
        extracted = await self.processing_action.run(receipt_content, "extract")
        
        # 2. ìœ íš¨ì„± ê²€ì¦
        validation = await self.processing_action.run(receipt_content, "validate")
        
        # 3. ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
        categorization = await self.processing_action.run(receipt_content, "categorize")
        
        processed_data = {
            "extracted_data": extracted,
            "validation_result": validation,
            "categorization": categorization,
            "processed_at": datetime.now().isoformat()
        }
        
        self.processed_receipts.append(processed_data)
        return processed_data
    
    async def batch_process_receipts(self, receipt_files: list):
        """ë°°ì¹˜ ì˜ìˆ˜ì¦ ì²˜ë¦¬"""
        
        results = []
        
        for i, receipt_file in enumerate(receipt_files):
            print(f"ğŸ“„ ì²˜ë¦¬ ì¤‘: {receipt_file} ({i+1}/{len(receipt_files)})")
            
            # íŒŒì¼ ì½ê¸°
            with open(receipt_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ì²˜ë¦¬
            result = await self.process_receipt(content)
            result["source_file"] = str(receipt_file)
            results.append(result)
        
        return results
    
    async def generate_expense_report(self, period: str = "monthly"):
        """ë¹„ìš© ë³´ê³ ì„œ ìƒì„±"""
        
        if not self.processed_receipts:
            return "ì²˜ë¦¬ëœ ì˜ìˆ˜ì¦ì´ ì—†ìŠµë‹ˆë‹¤."
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ì •ì˜
        business_rules = {
            "tax_deductible_categories": [
                "Office Supplies",
                "Business Meals",
                "Travel",
                "Professional Services"
            ],
            "approval_required_threshold": 500.00,
            "mileage_rate": 0.65,  # per mile
            "meal_deduction_percentage": 50
        }
        
        # ë¹„ìš© ë¶„ë¥˜ ë° ë³´ê³ ì„œ ìƒì„±
        report = await self.categorization_action.run(
            self.processed_receipts,
            business_rules
        )
        
        return report

class ReceiptManager:
    """ì˜ìˆ˜ì¦ ê´€ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, data_dir: str = "./receipt_data"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)
        
        self.assistant = ReceiptAssistant()
        
        # ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
        (self.data_dir / "raw").mkdir(exist_ok=True)
        (self.data_dir / "processed").mkdir(exist_ok=True)
        (self.data_dir / "reports").mkdir(exist_ok=True)
    
    async def process_receipt_folder(self, folder_path: str):
        """í´ë” ë‚´ ëª¨ë“  ì˜ìˆ˜ì¦ ì²˜ë¦¬"""
        
        folder = Path(folder_path)
        receipt_files = list(folder.glob("*.txt")) + list(folder.glob("*.md"))
        
        if not receipt_files:
            print("ì²˜ë¦¬í•  ì˜ìˆ˜ì¦ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ğŸš€ ì˜ìˆ˜ì¦ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {len(receipt_files)}ê°œ íŒŒì¼")
        
        # ë°°ì¹˜ ì²˜ë¦¬
        results = await self.assistant.batch_process_receipts(receipt_files)
        
        # ê²°ê³¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = self.data_dir / "processed" / f"batch_processed_{timestamp}.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {output_file}")
        
        # ë³´ê³ ì„œ ìƒì„±
        report = await self.assistant.generate_expense_report()
        
        report_file = self.data_dir / "reports" / f"expense_report_{timestamp}.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"ğŸ“Š ë³´ê³ ì„œ ìƒì„±: {report_file}")
        
        return results, report
    
    def create_sample_receipts(self):
        """ìƒ˜í”Œ ì˜ìˆ˜ì¦ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)"""
        
        sample_receipts = [
            {
                "filename": "coffee_shop_receipt.txt",
                "content": """
                Starbucks Coffee
                123 Main Street, Anytown, USA
                
                Date: 2025-01-27
                Time: 14:30
                
                1x Venti Latte        $5.95
                1x Blueberry Muffin   $3.25
                
                Subtotal:             $9.20
                Tax (8.5%):           $0.78
                Total:                $9.98
                
                Payment: Credit Card
                Receipt #: 1234567890
                """
            },
            {
                "filename": "office_supplies_receipt.txt", 
                "content": """
                Office Depot
                456 Business Blvd, Corporate City
                
                Date: 2025-01-26
                Time: 10:15
                
                2x Notebook Pack     $12.99 each   $25.98
                1x Pen Set           $8.50         $8.50
                1x Printer Paper     $15.99        $15.99
                
                Subtotal:                         $50.47
                Tax (7.25%):                      $3.66
                Total:                            $54.13
                
                Payment: Debit Card
                Receipt #: OD2025012601
                """
            }
        ]
        
        raw_dir = self.data_dir / "raw"
        
        for receipt in sample_receipts:
            file_path = raw_dir / receipt["filename"]
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(receipt["content"])
        
        print(f"ğŸ“„ ìƒ˜í”Œ ì˜ìˆ˜ì¦ ìƒì„±: {raw_dir}")
        return raw_dir

# ì‚¬ìš© ì˜ˆì œ
async def main():
    manager = ReceiptManager()
    
    # ìƒ˜í”Œ ì˜ìˆ˜ì¦ ìƒì„±
    sample_dir = manager.create_sample_receipts()
    
    # ì˜ìˆ˜ì¦ ì²˜ë¦¬
    results, report = await manager.process_receipt_folder(sample_dir)
    
    print("\nğŸ“Š ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½:")
    print(f"ì²˜ë¦¬ëœ ì˜ìˆ˜ì¦: {len(results)}ê°œ")
    
    # ê°„ë‹¨í•œ í†µê³„
    total_amount = 0
    for result in results:
        try:
            extracted = json.loads(result["extracted_data"])
            total_amount += float(extracted.get("total_amount", 0))
        except:
            pass
    
    print(f"ì´ ë¹„ìš©: ${total_amount:.2f}")

if __name__ == "__main__":
    asyncio.run(main())
```

## ì»¤ìŠ¤í…€ ì—ì´ì „íŠ¸ ê°œë°œ

### ê¸°ë³¸ ì—ì´ì „íŠ¸ êµ¬ì¡°

```python
# custom_agent.py
import asyncio
from typing import List, Dict, Any
from metagpt.roles import Role
from metagpt.actions import Action
from metagpt.schema import Message
from metagpt.memory import LongTermMemory

class CustomAction(Action):
    """ì»¤ìŠ¤í…€ ì•¡ì…˜ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    def __init__(self, name: str = "CustomAction", context: Dict[str, Any] = None):
        super().__init__(name=name)
        self.context = context or {}
    
    async def run(self, input_data: Any) -> Any:
        """ì•¡ì…˜ ì‹¤í–‰ ë¡œì§"""
        
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        prompt = f"""
        Context: {self.context}
        Input: {input_data}
        
        Please process the input according to the context and provide appropriate output.
        """
        
        response = await self._aask(prompt)
        return response

class CodeReviewAction(Action):
    """ì½”ë“œ ë¦¬ë·° ì „ë¬¸ ì•¡ì…˜"""
    
    def __init__(self):
        super().__init__(name="CodeReviewAction")
        self.review_criteria = {
            "functionality": "Does the code work as intended?",
            "readability": "Is the code easy to read and understand?",
            "performance": "Are there any performance issues?",
            "security": "Are there any security vulnerabilities?",
            "best_practices": "Does it follow coding best practices?",
            "testing": "Is the code properly tested?"
        }
    
    async def run(self, code: str, language: str = "python") -> Dict[str, Any]:
        """ì½”ë“œ ë¦¬ë·° ìˆ˜í–‰"""
        
        prompt = f"""
        Perform a comprehensive code review for the following {language} code:
        
        ```{language}
        {code}
        ```
        
        Review Criteria:
        {chr(10).join(f"- {k}: {v}" for k, v in self.review_criteria.items())}
        
        Please provide:
        1. Overall assessment (score 1-10)
        2. Detailed feedback for each criterion
        3. Specific issues found with line numbers
        4. Suggestions for improvement
        5. Refactored code examples if needed
        
        Format as structured JSON.
        """
        
        review = await self._aask(prompt)
        return review

class DocumentationAction(Action):
    """ë¬¸ì„œí™” ì „ë¬¸ ì•¡ì…˜"""
    
    async def run(self, code: str, doc_type: str = "api") -> str:
        """ë¬¸ì„œ ìƒì„±"""
        
        if doc_type == "api":
            prompt = f"""
            Generate comprehensive API documentation for this code:
            
            {code}
            
            Include:
            1. Function/class descriptions
            2. Parameters with types and descriptions
            3. Return values
            4. Usage examples
            5. Error handling
            6. Performance notes
            
            Use clear, professional documentation format.
            """
        
        elif doc_type == "readme":
            prompt = f"""
            Generate a README.md file for this project/code:
            
            {code}
            
            Include:
            1. Project description
            2. Installation instructions
            3. Usage examples
            4. API reference
            5. Contributing guidelines
            6. License information
            
            Use standard README format with proper markdown.
            """
        
        documentation = await self._aask(prompt)
        return documentation

class SeniorDeveloper(Role):
    """ì‹œë‹ˆì–´ ê°œë°œì ì—­í• """
    
    def __init__(self, specialization: str = "Full Stack"):
        super().__init__(name=f"Senior Developer ({specialization})")
        self.specialization = specialization
        
        # ì•¡ì…˜ë“¤ ì´ˆê¸°í™”
        self.code_review_action = CodeReviewAction()
        self.documentation_action = DocumentationAction()
        
        # ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ
        self.memory = LongTermMemory()
        
        # ì „ë¬¸ ì§€ì‹
        self.expertise = {
            "languages": ["Python", "JavaScript", "TypeScript", "Go", "Rust"],
            "frameworks": ["React", "Django", "FastAPI", "Express", "Next.js"],
            "databases": ["PostgreSQL", "MongoDB", "Redis", "Elasticsearch"],
            "cloud": ["AWS", "GCP", "Azure", "Docker", "Kubernetes"],
            "best_practices": [
                "SOLID principles",
                "Clean Code",
                "Test-Driven Development",
                "CI/CD",
                "Security best practices"
            ]
        }
    
    async def review_code(self, code: str, language: str = "python"):
        """ì½”ë“œ ë¦¬ë·° ìˆ˜í–‰"""
        
        print(f"ğŸ” ì½”ë“œ ë¦¬ë·° ì‹œì‘ ({language})")
        review = await self.code_review_action.run(code, language)
        
        # ë¦¬ë·° ê²°ê³¼ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥
        await self.memory.add(f"code_review_{hash(code)}", {
            "code": code,
            "language": language,
            "review": review,
            "timestamp": asyncio.get_event_loop().time()
        })
        
        return review
    
    async def generate_documentation(self, code: str, doc_type: str = "api"):
        """ë¬¸ì„œ ìƒì„±"""
        
        print(f"ğŸ“ ë¬¸ì„œ ìƒì„± ì‹œì‘ ({doc_type})")
        docs = await self.documentation_action.run(code, doc_type)
        return docs
    
    async def provide_mentorship(self, question: str, context: str = ""):
        """ë©˜í† ë§ ì œê³µ"""
        
        prompt = f"""
        As a Senior {self.specialization} Developer with expertise in:
        {', '.join(self.expertise['languages'])} and {', '.join(self.expertise['frameworks'])}
        
        Context: {context}
        Question: {question}
        
        Provide mentorship advice including:
        1. Direct answer to the question
        2. Best practices recommendations
        3. Common pitfalls to avoid
        4. Learning resources
        5. Next steps for skill development
        
        Be encouraging and practical in your advice.
        """
        
        advice = await self._aask(prompt)
        return advice
    
    async def architecture_review(self, system_design: str):
        """ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ë¦¬ë·°"""
        
        prompt = f"""
        Review this system architecture design:
        
        {system_design}
        
        As a Senior Developer, evaluate:
        1. Scalability considerations
        2. Security implications
        3. Performance bottlenecks
        4. Maintainability factors
        5. Technology stack appropriateness
        6. Cost implications
        7. Risk assessment
        
        Provide specific recommendations for improvement.
        """
        
        review = await self._aask(prompt)
        return review

class TeamLead(Role):
    """íŒ€ ë¦¬ë“œ ì—­í• """
    
    def __init__(self):
        super().__init__(name="Team Lead")
        self.team_members = []
        self.projects = []
    
    def add_team_member(self, member: Role):
        """íŒ€ ë©¤ë²„ ì¶”ê°€"""
        self.team_members.append(member)
        print(f"ğŸ‘¥ íŒ€ ë©¤ë²„ ì¶”ê°€: {member.name}")
    
    async def assign_task(self, task: str, assignee: str = None):
        """ì‘ì—… í• ë‹¹"""
        
        if assignee:
            # íŠ¹ì • ë©¤ë²„ì—ê²Œ í• ë‹¹
            member = next((m for m in self.team_members if m.name == assignee), None)
            if member:
                print(f"ğŸ“‹ ì‘ì—… í• ë‹¹: {task} â†’ {assignee}")
                return await self._delegate_task(member, task)
        else:
            # ìµœì ì˜ ë©¤ë²„ì—ê²Œ ìë™ í• ë‹¹
            best_member = await self._find_best_assignee(task)
            if best_member:
                print(f"ğŸ“‹ ìë™ í• ë‹¹: {task} â†’ {best_member.name}")
                return await self._delegate_task(best_member, task)
        
        return "í• ë‹¹í•  ìˆ˜ ìˆëŠ” íŒ€ ë©¤ë²„ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    async def _find_best_assignee(self, task: str):
        """ì‘ì—…ì— ê°€ì¥ ì í•©í•œ íŒ€ ë©¤ë²„ ì°¾ê¸°"""
        
        prompt = f"""
        Given this task: {task}
        
        And these team members:
        {chr(10).join(f"- {m.name}: {getattr(m, 'specialization', 'General')}" for m in self.team_members)}
        
        Who would be the best assignee? Return just the name.
        """
        
        best_assignee_name = await self._aask(prompt)
        return next((m for m in self.team_members if m.name in best_assignee_name), None)
    
    async def _delegate_task(self, member: Role, task: str):
        """ë©¤ë²„ì—ê²Œ ì‘ì—… ìœ„ì„"""
        
        if hasattr(member, '_act'):
            # ë©”ì‹œì§€ ìƒì„±í•˜ì—¬ ë©¤ë²„ì˜ _act ë©”ì„œë“œ í˜¸ì¶œ
            message = Message(content=task, role="team_lead")
            response = await member._act()
            return response
        else:
            return f"{member.name}ì—ê²Œ ì‘ì—…ì´ í• ë‹¹ë˜ì—ˆìŠµë‹ˆë‹¤: {task}"
    
    async def conduct_team_meeting(self, agenda: str):
        """íŒ€ ë¯¸íŒ… ì§„í–‰"""
        
        print(f"ğŸ“… íŒ€ ë¯¸íŒ… ì‹œì‘: {agenda}")
        
        meeting_notes = []
        
        for member in self.team_members:
            prompt = f"""
            Team meeting agenda: {agenda}
            
            As {member.name}, provide your input on:
            1. Current progress updates
            2. Challenges faced
            3. Ideas and suggestions
            4. Questions for the team
            
            Keep it concise and relevant.
            """
            
            input_msg = await self._aask_with_context(prompt, member.name)
            meeting_notes.append(f"{member.name}: {input_msg}")
        
        # ë¯¸íŒ… ìš”ì•½ ìƒì„±
        summary_prompt = f"""
        Summarize this team meeting:
        
        Agenda: {agenda}
        
        Team Input:
        {chr(10).join(meeting_notes)}
        
        Provide:
        1. Key decisions made
        2. Action items with owners
        3. Outstanding issues
        4. Next meeting agenda items
        """
        
        summary = await self._aask(summary_prompt)
        
        print("ğŸ“ ë¯¸íŒ… ìš”ì•½:")
        print(summary)
        
        return summary
    
    async def _aask_with_context(self, prompt: str, context: str):
        """ì»¨í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ì§ˆë¬¸"""
        full_prompt = f"Context: {context}\n\n{prompt}"
        return await self._aask(full_prompt)

# ì»¤ìŠ¤í…€ ì—ì´ì „íŠ¸ ì‚¬ìš© ì˜ˆì œ
async def demo_custom_agents():
    """ì»¤ìŠ¤í…€ ì—ì´ì „íŠ¸ ë°ëª¨"""
    
    # íŒ€ êµ¬ì„±
    team_lead = TeamLead()
    senior_dev_backend = SeniorDeveloper("Backend")
    senior_dev_frontend = SeniorDeveloper("Frontend")
    
    # íŒ€ êµ¬ì„±
    team_lead.add_team_member(senior_dev_backend)
    team_lead.add_team_member(senior_dev_frontend)
    
    # ì˜ˆì œ ì½”ë“œ
    sample_code = """
def calculate_fibonacci(n):
    if n <= 1:
        return n
    return calculate_fibonacci(n-1) + calculate_fibonacci(n-2)

def get_user_data(user_id):
    # TODO: Add input validation
    query = f"SELECT * FROM users WHERE id = {user_id}"
    return database.execute(query)
    """
    
    # 1. ì½”ë“œ ë¦¬ë·°
    print("=" * 60)
    review = await senior_dev_backend.review_code(sample_code, "python")
    print("ì½”ë“œ ë¦¬ë·° ê²°ê³¼:")
    print(review)
    
    # 2. ë¬¸ì„œ ìƒì„±
    print("\n" + "=" * 60)
    docs = await senior_dev_backend.generate_documentation(sample_code, "api")
    print("ìƒì„±ëœ ë¬¸ì„œ:")
    print(docs)
    
    # 3. ë©˜í† ë§
    print("\n" + "=" * 60)
    mentorship = await senior_dev_backend.provide_mentorship(
        "How can I improve the performance of recursive functions?",
        "I'm working on algorithm optimization"
    )
    print("ë©˜í† ë§ ì¡°ì–¸:")
    print(mentorship)
    
    # 4. íŒ€ ë¯¸íŒ…
    print("\n" + "=" * 60)
    meeting_summary = await team_lead.conduct_team_meeting(
        "Sprint Planning and Code Quality Improvements"
    )
    
    # 5. ì‘ì—… í• ë‹¹
    print("\n" + "=" * 60)
    assignment_result = await team_lead.assign_task(
        "Implement user authentication system with JWT tokens"
    )
    print(assignment_result)

if __name__ == "__main__":
    asyncio.run(demo_custom_agents())
```

## ì„±ëŠ¥ ìµœì í™” ë° í”„ë¡œë•ì…˜ ë°°í¬

### ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ ë° ëª¨ë‹ˆí„°ë§

```python
# production_optimization.py
import asyncio
import psutil
import time
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any
from contextlib import asynccontextmanager

class ResourceMonitor:
    """ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self, log_dir: str = "./monitoring_logs"):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        self.metrics_history = []
        self.setup_logging()
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.log_dir / 'resource_monitor.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def get_system_metrics(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        metrics = {
            "timestamp": datetime.now().isoformat(),
            "cpu": {
                "percent": cpu_percent,
                "count": psutil.cpu_count(),
                "freq": psutil.cpu_freq()._asdict() if psutil.cpu_freq() else None
            },
            "memory": {
                "total_gb": memory.total / (1024**3),
                "available_gb": memory.available / (1024**3),
                "used_gb": memory.used / (1024**3),
                "percent": memory.percent
            },
            "disk": {
                "total_gb": disk.total / (1024**3),
                "used_gb": disk.used / (1024**3),
                "free_gb": disk.free / (1024**3),
                "percent": (disk.used / disk.total) * 100
            }
        }
        
        # GPU ë©”íŠ¸ë¦­ (nvidia-ml-pyê°€ ì„¤ì¹˜ëœ ê²½ìš°)
        try:
            import pynvml
            pynvml.nvmlInit()
            gpu_count = pynvml.nvmlDeviceGetCount()
            
            gpu_metrics = []
            for i in range(gpu_count):
                handle = pynvml.nvmlDeviceGetHandleByIndex(i)
                
                memory_info = pynvml.nvmlDeviceGetMemoryInfo(handle)
                utilization = pynvml.nvmlDeviceGetUtilizationRates(handle)
                temperature = pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)
                
                gpu_metrics.append({
                    "index": i,
                    "memory_total_gb": memory_info.total / (1024**3),
                    "memory_used_gb": memory_info.used / (1024**3),
                    "memory_free_gb": memory_info.free / (1024**3),
                    "memory_percent": (memory_info.used / memory_info.total) * 100,
                    "utilization_percent": utilization.gpu,
                    "temperature_c": temperature
                })
            
            metrics["gpu"] = gpu_metrics
            
        except ImportError:
            metrics["gpu"] = "Not available (pynvml not installed)"
        except Exception as e:
            metrics["gpu"] = f"Error: {str(e)}"
        
        return metrics
    
    @asynccontextmanager
    async def monitor_execution(self, operation_name: str):
        """ì‹¤í–‰ ì¤‘ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§"""
        
        start_time = time.time()
        start_metrics = self.get_system_metrics()
        
        self.logger.info(f"ğŸ”„ ì‹œì‘: {operation_name}")
        self.logger.info(f"ì´ˆê¸° CPU: {start_metrics['cpu']['percent']:.1f}%")
        self.logger.info(f"ì´ˆê¸° ë©”ëª¨ë¦¬: {start_metrics['memory']['percent']:.1f}%")
        
        try:
            yield self
            
        finally:
            end_time = time.time()
            end_metrics = self.get_system_metrics()
            duration = end_time - start_time
            
            # ì„±ëŠ¥ ë¶„ì„
            cpu_delta = end_metrics['cpu']['percent'] - start_metrics['cpu']['percent']
            memory_delta = end_metrics['memory']['percent'] - start_metrics['memory']['percent']
            
            execution_log = {
                "operation": operation_name,
                "duration_seconds": duration,
                "start_metrics": start_metrics,
                "end_metrics": end_metrics,
                "resource_deltas": {
                    "cpu_percent": cpu_delta,
                    "memory_percent": memory_delta
                }
            }
            
            self.metrics_history.append(execution_log)
            
            self.logger.info(f"âœ… ì™„ë£Œ: {operation_name}")
            self.logger.info(f"ì‹¤í–‰ ì‹œê°„: {duration:.2f}ì´ˆ")
            self.logger.info(f"CPU ë³€í™”: {cpu_delta:+.1f}%")
            self.logger.info(f"ë©”ëª¨ë¦¬ ë³€í™”: {memory_delta:+.1f}%")
    
    def save_metrics_report(self):
        """ë©”íŠ¸ë¦­ ë³´ê³ ì„œ ì €ì¥"""
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = self.log_dir / f"metrics_report_{timestamp}.json"
        
        with open(report_file, 'w') as f:
            json.dump(self.metrics_history, f, indent=2)
        
        self.logger.info(f"ğŸ“Š ë©”íŠ¸ë¦­ ë³´ê³ ì„œ ì €ì¥: {report_file}")
        return report_file

class OptimizedMetaGPT:
    """ìµœì í™”ëœ MetaGPT ì‹¤í–‰ í´ë˜ìŠ¤"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or self._get_default_config()
        self.monitor = ResourceMonitor()
        
        # ì„±ëŠ¥ í†µê³„
        self.performance_stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "average_response_time": 0,
            "total_tokens_used": 0
        }
    
    def _get_default_config(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ì„¤ì • ë°˜í™˜"""
        return {
            "llm": {
                "model": "gpt-4-turbo",
                "max_tokens": 4096,
                "temperature": 0.7,
                "timeout": 120
            },
            "optimization": {
                "max_concurrent_requests": 3,
                "request_rate_limit": 10,  # per minute
                "memory_threshold_percent": 85,
                "cpu_threshold_percent": 90
            },
            "caching": {
                "enabled": True,
                "cache_dir": "./cache",
                "max_cache_size_gb": 5
            }
        }
    
    async def generate_project_optimized(self, requirement: str):
        """ìµœì í™”ëœ í”„ë¡œì íŠ¸ ìƒì„±"""
        
        async with self.monitor.monitor_execution(f"Project Generation: {requirement[:50]}..."):
            
            # ë¦¬ì†ŒìŠ¤ ì²´í¬
            if not self._check_resource_availability():
                raise RuntimeError("ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤")
            
            # ìºì‹œ í™•ì¸
            cached_result = await self._check_cache(requirement)
            if cached_result:
                self.monitor.logger.info("ğŸ’¾ ìºì‹œì—ì„œ ê²°ê³¼ ë°˜í™˜")
                return cached_result
            
            # í”„ë¡œì íŠ¸ ìƒì„±
            try:
                from metagpt.software_company import generate_repo
                
                start_time = time.time()
                repo = await generate_repo(requirement)
                end_time = time.time()
                
                # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
                self.performance_stats["total_requests"] += 1
                self.performance_stats["successful_requests"] += 1
                
                response_time = end_time - start_time
                self._update_average_response_time(response_time)
                
                # ìºì‹œ ì €ì¥
                await self._save_to_cache(requirement, repo)
                
                return repo
                
            except Exception as e:
                self.performance_stats["total_requests"] += 1
                self.performance_stats["failed_requests"] += 1
                
                self.monitor.logger.error(f"âŒ í”„ë¡œì íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
                raise
    
    def _check_resource_availability(self) -> bool:
        """ë¦¬ì†ŒìŠ¤ ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸"""
        
        metrics = self.monitor.get_system_metrics()
        
        cpu_ok = metrics["cpu"]["percent"] < self.config["optimization"]["cpu_threshold_percent"]
        memory_ok = metrics["memory"]["percent"] < self.config["optimization"]["memory_threshold_percent"]
        
        if not cpu_ok:
            self.monitor.logger.warning(f"âš ï¸ CPU ì‚¬ìš©ë¥  ë†’ìŒ: {metrics['cpu']['percent']:.1f}%")
        
        if not memory_ok:
            self.monitor.logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ: {metrics['memory']['percent']:.1f}%")
        
        return cpu_ok and memory_ok
    
    async def _check_cache(self, requirement: str):
        """ìºì‹œ í™•ì¸"""
        
        if not self.config["caching"]["enabled"]:
            return None
        
        cache_dir = Path(self.config["caching"]["cache_dir"])
        cache_dir.mkdir(exist_ok=True)
        
        # ìš”êµ¬ì‚¬í•­ í•´ì‹œë¡œ ìºì‹œ í‚¤ ìƒì„±
        import hashlib
        cache_key = hashlib.md5(requirement.encode()).hexdigest()
        cache_file = cache_dir / f"{cache_key}.json"
        
        if cache_file.exists():
            try:
                with open(cache_file, 'r') as f:
                    cached_data = json.load(f)
                
                # ìºì‹œ ìœ íš¨ì„± í™•ì¸ (ì˜ˆ: 24ì‹œê°„)
                cache_time = datetime.fromisoformat(cached_data["timestamp"])
                if (datetime.now() - cache_time).total_seconds() < 86400:  # 24ì‹œê°„
                    return cached_data["result"]
                    
            except Exception as e:
                self.monitor.logger.warning(f"ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return None
    
    async def _save_to_cache(self, requirement: str, result):
        """ìºì‹œ ì €ì¥"""
        
        if not self.config["caching"]["enabled"]:
            return
        
        cache_dir = Path(self.config["caching"]["cache_dir"])
        
        import hashlib
        cache_key = hashlib.md5(requirement.encode()).hexdigest()
        cache_file = cache_dir / f"{cache_key}.json"
        
        try:
            cache_data = {
                "timestamp": datetime.now().isoformat(),
                "requirement": requirement,
                "result": str(result)  # ProjectRepoë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            }
            
            with open(cache_file, 'w') as f:
                json.dump(cache_data, f, indent=2)
                
        except Exception as e:
            self.monitor.logger.warning(f"ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _update_average_response_time(self, response_time: float):
        """í‰ê·  ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸"""
        
        current_avg = self.performance_stats["average_response_time"]
        total_requests = self.performance_stats["successful_requests"]
        
        if total_requests == 1:
            new_avg = response_time
        else:
            new_avg = ((current_avg * (total_requests - 1)) + response_time) / total_requests
        
        self.performance_stats["average_response_time"] = new_avg
    
    def get_performance_report(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„±"""
        
        success_rate = 0
        if self.performance_stats["total_requests"] > 0:
            success_rate = (self.performance_stats["successful_requests"] / 
                          self.performance_stats["total_requests"]) * 100
        
        return {
            "performance_stats": self.performance_stats,
            "success_rate_percent": success_rate,
            "system_metrics": self.monitor.get_system_metrics(),
            "configuration": self.config
        }

# ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
class BatchProcessor:
    """ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™” í´ë˜ìŠ¤"""
    
    def __init__(self, max_concurrent: int = 3):
        self.max_concurrent = max_concurrent
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.optimized_metagpt = OptimizedMetaGPT()
    
    async def process_batch(self, requirements: List[str]):
        """ë°°ì¹˜ ìš”êµ¬ì‚¬í•­ ì²˜ë¦¬"""
        
        print(f"ğŸš€ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {len(requirements)}ê°œ ìš”êµ¬ì‚¬í•­")
        
        async def process_single(req: str):
            async with self.semaphore:
                try:
                    result = await self.optimized_metagpt.generate_project_optimized(req)
                    return {"requirement": req, "result": result, "status": "success"}
                except Exception as e:
                    return {"requirement": req, "error": str(e), "status": "failed"}
        
        # ë³‘ë ¬ ì²˜ë¦¬
        tasks = [process_single(req) for req in requirements]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ê²°ê³¼ ë¶„ì„
        successful = sum(1 for r in results if isinstance(r, dict) and r.get("status") == "success")
        failed = len(results) - successful
        
        print(f"âœ… ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ:")
        print(f"   ì„±ê³µ: {successful}")
        print(f"   ì‹¤íŒ¨: {failed}")
        print(f"   ì„±ê³µë¥ : {(successful/len(results)*100):.1f}%")
        
        return results

# í”„ë¡œë•ì…˜ ì‚¬ìš© ì˜ˆì œ
async def production_demo():
    """í”„ë¡œë•ì…˜ í™˜ê²½ ë°ëª¨"""
    
    # ìµœì í™”ëœ MetaGPT ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    optimized = OptimizedMetaGPT({
        "llm": {
            "model": "gpt-3.5-turbo",  # ë¹ ë¥¸ ëª¨ë¸ ì‚¬ìš©
            "max_tokens": 2048,
            "temperature": 0.5
        },
        "optimization": {
            "max_concurrent_requests": 2,
            "memory_threshold_percent": 80,
            "cpu_threshold_percent": 85
        },
        "caching": {
            "enabled": True,
            "cache_dir": "./production_cache"
        }
    })
    
    # í…ŒìŠ¤íŠ¸ ìš”êµ¬ì‚¬í•­ë“¤
    requirements = [
        "Create a simple todo list app",
        "Create a weather dashboard",
        "Create a password generator"
    ]
    
    # ë°°ì¹˜ ì²˜ë¦¬
    batch_processor = BatchProcessor(max_concurrent=2)
    results = await batch_processor.process_batch(requirements)
    
    # ì„±ëŠ¥ ë³´ê³ ì„œ
    report = optimized.get_performance_report()
    print("\nğŸ“Š ì„±ëŠ¥ ë³´ê³ ì„œ:")
    print(json.dumps(report, indent=2))
    
    # ë©”íŠ¸ë¦­ ë³´ê³ ì„œ ì €ì¥
    optimized.monitor.save_metrics_report()

if __name__ == "__main__":
    asyncio.run(production_demo())
```

## ì‹¤ì œ í”„ë¡œì íŠ¸ ìƒì„± ë° í…ŒìŠ¤íŠ¸

<function_calls>
<invoke name="run_terminal_cmd">
<parameter name="command">mkdir -p tutorials/metagpt-test
