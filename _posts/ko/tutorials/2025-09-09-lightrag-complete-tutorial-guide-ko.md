---
title: "LightRAG ì™„ì „ ì •ë³µ ê°€ì´ë“œ: ë¹ ë¥´ê³  ê°„ë‹¨í•œ RAG ì‹œìŠ¤í…œ êµ¬ì¶•í•˜ê¸°"
excerpt: "GraphRAGë¥¼ ë›°ì–´ë„˜ëŠ” ì„±ëŠ¥ì˜ LightRAG êµ¬í˜„ ë°©ë²•ì„ ì™„ì „ ì •ë³µí•´ë³´ì„¸ìš”. ì„¤ì¹˜ë¶€í„° ì‹¤ì „ í™œìš©ê¹Œì§€ ëª¨ë“  ê²ƒì„ ë‹¤ë£¹ë‹ˆë‹¤."
seo_title: "LightRAG ì™„ì „ ê°€ì´ë“œ: ê³ ì„±ëŠ¥ RAG ì‹œìŠ¤í…œ êµ¬ì¶• - Thaki Cloud"
seo_description: "LightRAG ì„¤ì¹˜, ì‚¬ìš©ë²•, ì‹¤ì „ ì˜ˆì œê¹Œì§€ ì™„ë²½ ê°€ì´ë“œ. ì§€ì‹ ê·¸ë˜í”„ ê¸°ë°˜ RAG ì‹œìŠ¤í…œìœ¼ë¡œ AI ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ì„¸ìš”."
date: 2025-09-09
categories:
  - tutorials
tags:
  - LightRAG
  - RAG
  - ì§€ì‹ê·¸ë˜í”„
  - AI
  - Python
  - GraphRAG
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
lang: ko
permalink: /ko/tutorials/lightrag-complete-tutorial-guide/
canonical_url: "https://thakicloud.github.io/ko/tutorials/lightrag-complete-tutorial-guide/"
---

â±ï¸ **ì˜ˆìƒ ì½ê¸° ì‹œê°„**: 15ë¶„

## ğŸš€ LightRAG ì†Œê°œ

**LightRAG** (Light Retrieval-Augmented Generation)ëŠ” ë¹ ë¥´ê³  ê°„ë‹¨í•œ ê²€ìƒ‰ ì¦ê°• ìƒì„± ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” í˜ì‹ ì ì¸ ì˜¤í”ˆì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ê¸°ì¡´ RAG ì‹œìŠ¤í…œê³¼ ë‹¬ë¦¬ ì´ì¤‘ ë ˆë²¨ ì§€ì‹ ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ í™œìš©í•˜ì—¬ ë‹¨ìˆœí•¨ì„ ìœ ì§€í•˜ë©´ì„œë„ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.

### ğŸ¯ LightRAGë¥¼ ì„ íƒí•´ì•¼ í•˜ëŠ” ì´ìœ 

LightRAGëŠ” ê¸°ì¡´ RAG ì†”ë£¨ì…˜ë“¤ê³¼ ë¹„êµí•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ í•µì‹¬ ì¥ì ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤:

- **ë›°ì–´ë‚œ ì„±ëŠ¥**: ì¢…í•© í‰ê°€ì—ì„œ GraphRAG, RQ-RAG, HyDEë¥¼ ëŠ¥ê°€í•˜ëŠ” ì„±ê³¼
- **ê°„ë‹¨í•œ êµ¬í˜„**: ë³µì¡í•œ ëŒ€ì•ˆë“¤ ëŒ€ë¹„ ìµœì†Œí•œì˜ ì„¤ì •ìœ¼ë¡œ ì‹œì‘ ê°€ëŠ¥
- **ë¹ ë¥¸ ì‹¤í–‰ ì†ë„**: ì •í™•ë„ë¥¼ í¬ìƒí•˜ì§€ ì•Šìœ¼ë©´ì„œë„ ì†ë„ì— ìµœì í™”
- **ì§€ì‹ ê·¸ë˜í”„ í†µí•©**: í–¥ìƒëœ ì»¨í…ìŠ¤íŠ¸ ì´í•´ë¥¼ ìœ„í•œ ì´ì¤‘ ë ˆë²¨ ê·¸ë˜í”„ êµ¬ì¡°
- **ìœ ì—°í•œ ì•„í‚¤í…ì²˜**: ë‹¤ì–‘í•œ LLM ëª¨ë¸ê³¼ ì„ë² ë”© ì‹œìŠ¤í…œ ì§€ì›

### ğŸ“Š ì„±ëŠ¥ ë¹„êµ ë¶„ì„

ìµœê·¼ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ëŠ” ë‹¤ì–‘í•œ ì§€í‘œì—ì„œ LightRAGì˜ ìš°ìˆ˜ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤:

| í‰ê°€ ì§€í‘œ | LightRAG vs GraphRAG | LightRAG vs RQ-RAG | LightRAG vs HyDE |
|-----------|---------------------|--------------------|--------------------|
| **í¬ê´„ì„±** | 54.4% vs 45.6% | 68.4% vs 31.6% | 74.0% vs 26.0% |
| **ë‹¤ì–‘ì„±** | 77.2% vs 22.8% | 70.8% vs 29.2% | 76.0% vs 24.0% |
| **ì „ì²´ ì„±ëŠ¥** | 54.8% vs 45.2% | 67.6% vs 32.4% | 75.2% vs 24.8% |

## ğŸ› ï¸ ì„¤ì¹˜ ë° í™˜ê²½ ì„¤ì •

### ì‚¬ì „ ìš”êµ¬ì‚¬í•­

ì‹œì‘í•˜ê¸° ì „ì— ë‹¤ìŒ ì‚¬í•­ë“¤ì„ ì¤€ë¹„í•´ì£¼ì„¸ìš”:
- Python 3.8 ì´ìƒ
- pip íŒ¨í‚¤ì§€ ê´€ë¦¬ì
- Git (ë¦¬í¬ì§€í† ë¦¬ í´ë¡ ìš©)
- ì›í•˜ëŠ” LLM ì œê³µì—…ì²´ì˜ API í‚¤ (OpenAI, Anthropic ë“±)

### 1ë‹¨ê³„: ë¦¬í¬ì§€í† ë¦¬ í´ë¡ 

```bash
git clone https://github.com/HKUDS/LightRAG.git
cd LightRAG
```

### 2ë‹¨ê³„: ì˜ì¡´ì„± ì„¤ì¹˜

```bash
# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt

# ê°œë°œìš© ì„¤ì •
pip install -e .
```

### 3ë‹¨ê³„: í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— `.env` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```bash
# OpenAI ì„¤ì •
OPENAI_API_KEY=your_openai_api_key_here

# ëŒ€ì•ˆ LLM ì œê³µì—…ì²´ë“¤
ANTHROPIC_API_KEY=your_anthropic_key_here
AZURE_OPENAI_API_KEY=your_azure_key_here
AZURE_OPENAI_ENDPOINT=your_azure_endpoint_here
```

## ğŸ”§ ê¸°ë³¸ ì‚¬ìš©ë²•

### ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì‚½ì… ë° ì§ˆì˜

ë¬¸ì„œë¥¼ ì‚½ì…í•˜ê³  LightRAGì— ì§ˆì˜í•˜ëŠ” ê¸°ë³¸ ì˜ˆì œë¶€í„° ì‹œì‘í•´ë³´ê² ìŠµë‹ˆë‹¤:

```python
import os
from lightrag import LightRAG, QueryParam
from lightrag.llm import gpt_4o_mini_complete, gpt_4o_complete

# LightRAG ì´ˆê¸°í™”
working_dir = "./dickens"
rag = LightRAG(
    working_dir=working_dir,
    llm_model_func=gpt_4o_mini_complete  # ë” ë‚˜ì€ ì„±ëŠ¥ì„ ìœ„í•´ì„œëŠ” gpt_4o_complete ì‚¬ìš©
)

# í…ìŠ¤íŠ¸ ë¬¸ì„œ ì‚½ì…
with open("./book.txt", "r", encoding="utf-8") as f:
    rag.insert(f.read())

# ì‹œìŠ¤í…œì— ì§ˆì˜í•˜ê¸°
# ë‹¨ìˆœ ê²€ìƒ‰
print(rag.query("ì´ ì´ì•¼ê¸°ì˜ ì£¼ìš” í…Œë§ˆëŠ” ë¬´ì—‡ì¸ê°€ìš”?", param=QueryParam(mode="naive")))

# ì§€ì—­ ê²€ìƒ‰ (ë” ìƒì„¸í•¨)
print(rag.query("ì´ ì´ì•¼ê¸°ì˜ ì£¼ìš” í…Œë§ˆëŠ” ë¬´ì—‡ì¸ê°€ìš”?", param=QueryParam(mode="local")))

# ì „ì—­ ê²€ìƒ‰ (í¬ê´„ì )
print(rag.query("ì´ ì´ì•¼ê¸°ì˜ ì£¼ìš” í…Œë§ˆëŠ” ë¬´ì—‡ì¸ê°€ìš”?", param=QueryParam(mode="global")))

# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë‘ ë°©ì‹ì˜ ì¥ì  ê²°í•©)
print(rag.query("ì´ ì´ì•¼ê¸°ì˜ ì£¼ìš” í…Œë§ˆëŠ” ë¬´ì—‡ì¸ê°€ìš”?", param=QueryParam(mode="hybrid")))
```

### ì§ˆì˜ ëª¨ë“œ ì´í•´í•˜ê¸°

LightRAGëŠ” ë„¤ ê°€ì§€ ë…íŠ¹í•œ ì§ˆì˜ ëª¨ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤:

1. **ë‹¨ìˆœ ëª¨ë“œ(Naive)**: í‚¤ì›Œë“œ ê¸°ë°˜ ë‹¨ìˆœ ê²€ìƒ‰
2. **ì§€ì—­ ëª¨ë“œ(Local)**: íŠ¹ì • ì—”í‹°í‹°ì™€ ê·¸ë“¤ì˜ ì§ì ‘ì ì¸ ê´€ê³„ì— ì§‘ì¤‘
3. **ì „ì—­ ëª¨ë“œ(Global)**: ì „ì²´ ì§€ì‹ ê·¸ë˜í”„ì—ì„œ ê´‘ë²”ìœ„í•œ íŒ¨í„´ê³¼ í…Œë§ˆ ë¶„ì„
4. **í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ(Hybrid)**: ì§€ì—­ê³¼ ì „ì—­ ì ‘ê·¼ ë°©ì‹ì„ ê²°í•©í•˜ì—¬ í¬ê´„ì  ê²°ê³¼ ì œê³µ

## ğŸŒ ê³ ê¸‰ ê¸°ëŠ¥

### ì§€ì‹ ê·¸ë˜í”„ ì‹œê°í™”

LightRAGëŠ” ë¬¸ì„œë¡œë¶€í„° ìë™ìœ¼ë¡œ ì§€ì‹ ê·¸ë˜í”„ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤. ì´ ê·¸ë˜í”„ë“¤ì„ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
# ì§€ì‹ ê·¸ë˜í”„ ì¶”ì¶œ ë° ì‹œê°í™”
from lightrag.utils import xml_to_json
import json

# ì§€ì‹ ê·¸ë˜í”„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
kg_data = rag.chunk_entity_relation_graph

# ì‹œê°í™” í¬ë§·ìœ¼ë¡œ ë³€í™˜
graph_json = xml_to_json(kg_data)
print(json.dumps(graph_json, indent=2, ensure_ascii=False))
```

### ë°°ì¹˜ ì²˜ë¦¬

ëŒ€ê·œëª¨ ë¬¸ì„œ ì»¬ë ‰ì…˜ì˜ ê²½ìš° ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤:

```python
import glob
import asyncio

async def batch_insert_documents():
    # ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  í…ìŠ¤íŠ¸ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
    file_paths = glob.glob("./documents/*.txt")
    
    for file_path in file_paths:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()
        
        try:
            rag.insert(content)
            print(f"ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë¨: {file_path}")
        except Exception as e:
            print(f"{file_path} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

# ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰
asyncio.run(batch_insert_documents())
```

### ì»¤ìŠ¤í…€ LLM ì„¤ì •

LightRAGëŠ” ë‹¤ì–‘í•œ LLM ì œê³µì—…ì²´ë¥¼ ì§€ì›í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ëª¨ë¸ ì„¤ì • ë°©ë²•ì…ë‹ˆë‹¤:

```python
from lightrag.llm import openai_complete, azure_openai_complete

# OpenAI ì„¤ì •
def custom_openai_complete(prompt, **kwargs):
    return openai_complete(
        prompt=prompt,
        model="gpt-4",
        temperature=0.1,
        max_tokens=1000,
        **kwargs
    )

# Azure OpenAI ì„¤ì •
def custom_azure_complete(prompt, **kwargs):
    return azure_openai_complete(
        prompt=prompt,
        model="gpt-4",
        temperature=0.1,
        **kwargs
    )

# ì»¤ìŠ¤í…€ LLMìœ¼ë¡œ ì´ˆê¸°í™”
rag = LightRAG(
    working_dir="./custom_rag",
    llm_model_func=custom_openai_complete
)
```

## ğŸ–¥ï¸ ì›¹ UI ì¸í„°í˜ì´ìŠ¤

LightRAGëŠ” ë” ì‰¬ìš´ ìƒí˜¸ì‘ìš©ì„ ìœ„í•œ ì•„ë¦„ë‹¤ìš´ ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ í¬í•¨í•©ë‹ˆë‹¤:

### ì›¹ UI ì‹œì‘í•˜ê¸°

```bash
# ì›¹ UI ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd lightrag_webui

# ì›¹ UI ì˜ì¡´ì„± ì„¤ì¹˜
npm install

# ê°œë°œ ì„œë²„ ì‹œì‘
npm run dev
```

ì›¹ UIëŠ” ë‹¤ìŒ ê¸°ëŠ¥ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤:
- ë¬¸ì„œ ì—…ë¡œë“œ ì¸í„°í˜ì´ìŠ¤
- ëŒ€í™”í˜• ì§ˆì˜ í…ŒìŠ¤íŠ¸
- ì§€ì‹ ê·¸ë˜í”„ ì‹œê°í™”
- ì„±ëŠ¥ ì§€í‘œ ëŒ€ì‹œë³´ë“œ
- ì‹¤ì‹œê°„ ì²˜ë¦¬ ìƒíƒœ

### ì›¹ UI ì£¼ìš” ê¸°ëŠ¥

1. **ë¬¸ì„œ ê´€ë¦¬**: ë¬¸ì„œ ì»¬ë ‰ì…˜ ì—…ë¡œë“œ ë° ê´€ë¦¬
2. **ëŒ€í™”í˜• ì§ˆì˜**: ì‹¤ì‹œê°„ ê²°ê³¼ì™€ í•¨ê»˜ ë‹¤ì–‘í•œ ì§ˆì˜ ëª¨ë“œ í…ŒìŠ¤íŠ¸
3. **ê·¸ë˜í”„ ì‹œê°í™”**: ìƒì„±ëœ ì§€ì‹ ê·¸ë˜í”„ íƒìƒ‰
4. **ë¶„ì„ ëŒ€ì‹œë³´ë“œ**: ì„±ëŠ¥ ë° ì‚¬ìš© í†µê³„ ëª¨ë‹ˆí„°ë§

## ğŸ” ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€

### ì‚¬ìš© ì‚¬ë¡€ 1: ì—°êµ¬ ë…¼ë¬¸ ë¶„ì„

```python
# ì—°êµ¬ ë…¼ë¬¸ ì»¬ë ‰ì…˜ ë¶„ì„
research_rag = LightRAG(
    working_dir="./research_papers",
    llm_model_func=gpt_4o_complete
)

# ì—¬ëŸ¬ ë…¼ë¬¸ ì‚½ì…
papers = ["paper1.txt", "paper2.txt", "paper3.txt"]
for paper in papers:
    with open(paper, "r", encoding="utf-8") as f:
        research_rag.insert(f.read())

# ì—°êµ¬ ì¸ì‚¬ì´íŠ¸ ì§ˆì˜
queries = [
    "ì´ ë…¼ë¬¸ë“¤ì—ì„œ ë…¼ì˜ëœ ì£¼ìš” ë°©ë²•ë¡ ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "ì´ ë…¼ë¬¸ë“¤ì˜ ì—°êµ¬ ê²°ê³¼ë“¤ì€ ì„œë¡œ ì–´ë–¤ ê´€ë ¨ì´ ìˆë‚˜ìš”?",
    "ì œì•ˆëœ ë¯¸ë˜ ì—°êµ¬ ë°©í–¥ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "ìœ ì‚¬í•œ ê´€ë ¨ ì—°êµ¬ë¥¼ ì¸ìš©í•œ ë…¼ë¬¸ë“¤ì€ ì–´ë–¤ ê²ƒë“¤ì¸ê°€ìš”?"
]

for query in queries:
    result = research_rag.query(query, param=QueryParam(mode="hybrid"))
    print(f"ì§ˆë¬¸: {query}")
    print(f"ë‹µë³€: {result}\n")
```

### ì‚¬ìš© ì‚¬ë¡€ 2: ê¸°ì—… ì§€ì‹ ë² ì´ìŠ¤

```python
# íšŒì‚¬ ì§€ì‹ ë² ì´ìŠ¤ êµ¬ì¶•
company_rag = LightRAG(
    working_dir="./company_kb",
    llm_model_func=gpt_4o_mini_complete
)

# ë‹¤ì–‘í•œ íšŒì‚¬ ë¬¸ì„œ ì‚½ì…
documents = [
    "employee_handbook.txt",
    "project_documentation.txt",
    "meeting_minutes.txt",
    "policy_documents.txt"
]

for doc in documents:
    with open(doc, "r", encoding="utf-8") as f:
        company_rag.insert(f.read())

# íšŒì‚¬ ì •ë³´ ì§ˆì˜
hr_queries = [
    "ì¬íƒê·¼ë¬´ì— ëŒ€í•œ íšŒì‚¬ ì •ì±…ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "íœ´ê°€ ì‹ ì²­ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?",
    "ì„±ê³¼ í‰ê°€ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
    "í”„ë¡œì íŠ¸ Xì˜ í•µì‹¬ ì´í•´ê´€ê³„ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”?"
]

for query in hr_queries:
    result = company_rag.query(query, param=QueryParam(mode="local"))
    print(f"HR ì§ˆë¬¸: {query}")
    print(f"ë‹µë³€: {result}\n")
```

## ğŸš€ ì„±ëŠ¥ ìµœì í™”

### ë©”ëª¨ë¦¬ ê´€ë¦¬

ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ì˜ ê²½ìš° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìµœì í™”í•©ë‹ˆë‹¤:

```python
# ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì„¤ì • êµ¬ì„±
rag = LightRAG(
    working_dir="./large_dataset",
    llm_model_func=gpt_4o_mini_complete,
    chunk_size=1200,  # ì²­í¬ í¬ê¸° ì¡°ì •
    chunk_overlap=200,  # ì˜¤ë²„ë© ê°ì†Œ
    max_tokens=500  # ì‘ë‹µ ê¸¸ì´ ì œí•œ
)
```

### ë³‘ë ¬ ì²˜ë¦¬

ë³‘ë ¬ ì‚½ì…ìœ¼ë¡œ ë¬¸ì„œ ì²˜ë¦¬ ì†ë„ í–¥ìƒ:

```python
import concurrent.futures
import threading

def process_document(file_path):
    with open(file_path, "r", encoding="utf-8") as f:
        content = f.read()
    
    # ìŠ¤ë ˆë“œ ì•ˆì „ ì‚½ì…
    with threading.Lock():
        rag.insert(content)
    
    return f"ì²˜ë¦¬ ì™„ë£Œ: {file_path}"

# ë³‘ë ¬ ì²˜ë¦¬
with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
    futures = [executor.submit(process_document, file) for file in file_list]
    
    for future in concurrent.futures.as_completed(futures):
        result = future.result()
        print(result)
```

### ìºì‹± ì „ëµ

ìì£¼ ì ‘ê·¼í•˜ëŠ” ì§ˆì˜ì— ëŒ€í•œ ìºì‹± êµ¬í˜„:

```python
from functools import lru_cache

class CachedLightRAG:
    def __init__(self, working_dir, llm_model_func):
        self.rag = LightRAG(working_dir=working_dir, llm_model_func=llm_model_func)
    
    @lru_cache(maxsize=100)
    def cached_query(self, query_text, mode="hybrid"):
        return self.rag.query(query_text, param=QueryParam(mode=mode))

# ìºì‹œëœ RAG ì‚¬ìš©
cached_rag = CachedLightRAG("./cached_rag", gpt_4o_mini_complete)
```

## ğŸ› ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œì™€ í•´ê²°ì±…

#### ë¬¸ì œ 1: API ì†ë„ ì œí•œ

```python
import time
import random

def rate_limited_query(rag, query, max_retries=3):
    for attempt in range(max_retries):
        try:
            return rag.query(query, param=QueryParam(mode="hybrid"))
        except Exception as e:
            if "rate_limit" in str(e).lower():
                wait_time = (2 ** attempt) + random.uniform(0, 1)
                print(f"ì†ë„ ì œí•œì— ê±¸ë¦¼. {wait_time:.2f}ì´ˆ ëŒ€ê¸° ì¤‘...")
                time.sleep(wait_time)
            else:
                raise e
    
    raise Exception("ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
```

#### ë¬¸ì œ 2: ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ë©”ëª¨ë¦¬ ì´ìŠˆ

```python
def chunked_insertion(rag, large_text, chunk_size=5000):
    """ëŒ€ìš©ëŸ‰ í…ìŠ¤íŠ¸ë¥¼ ì‘ì€ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì‚½ì…"""
    text_chunks = [large_text[i:i+chunk_size] for i in range(0, len(large_text), chunk_size)]
    
    for i, chunk in enumerate(text_chunks):
        try:
            rag.insert(chunk)
            print(f"ì²­í¬ {i+1}/{len(text_chunks)} ì‚½ì… ì™„ë£Œ")
        except Exception as e:
            print(f"ì²­í¬ {i+1} ì‚½ì… ì¤‘ ì˜¤ë¥˜: {e}")
```

#### ë¬¸ì œ 3: ì¼ê´€ì„± ì—†ëŠ” ê²°ê³¼

```python
# ì¼ê´€ëœ ì˜¨ë„ ì„¤ì • ì‚¬ìš©
def stable_query(rag, query, runs=3):
    """ì§ˆì˜ë¥¼ ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰í•˜ê³  ê°€ì¥ ì¼ë°˜ì ì¸ ê²°ê³¼ ë°˜í™˜"""
    results = []
    
    for _ in range(runs):
        result = rag.query(query, param=QueryParam(mode="hybrid"))
        results.append(result)
    
    # ê°€ì¥ ë¹ˆë²ˆí•œ ê²°ê³¼ ë°˜í™˜ (ë‹¨ìˆœí™”ëœ ì ‘ê·¼ë²•)
    return max(set(results), key=results.count)
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ë¶„ì„

### ì„±ëŠ¥ ì§€í‘œ

LightRAG ì„±ëŠ¥ì„ ì¶”ì í•©ë‹ˆë‹¤:

```python
import time
import psutil
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RAGMonitor:
    def __init__(self, rag):
        self.rag = rag
        self.query_times = []
        self.memory_usage = []
    
    def monitored_query(self, query, mode="hybrid"):
        start_time = time.time()
        start_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        
        try:
            result = self.rag.query(query, param=QueryParam(mode=mode))
            
            end_time = time.time()
            end_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
            
            query_time = end_time - start_time
            memory_delta = end_memory - start_memory
            
            self.query_times.append(query_time)
            self.memory_usage.append(memory_delta)
            
            logger.info(f"ì§ˆì˜ ì™„ë£Œ: {query_time:.2f}ì´ˆ, ë©”ëª¨ë¦¬ ë³€í™”: {memory_delta:.2f}MB")
            
            return result
            
        except Exception as e:
            logger.error(f"ì§ˆì˜ ì‹¤íŒ¨: {e}")
            raise
    
    def get_stats(self):
        if not self.query_times:
            return "ì•„ì§ ê¸°ë¡ëœ ì§ˆì˜ê°€ ì—†ìŠµë‹ˆë‹¤"
        
        avg_time = sum(self.query_times) / len(self.query_times)
        avg_memory = sum(self.memory_usage) / len(self.memory_usage)
        
        return {
            "í‰ê· _ì§ˆì˜_ì‹œê°„": f"{avg_time:.2f}ì´ˆ",
            "í‰ê· _ë©”ëª¨ë¦¬_ë³€í™”": f"{avg_memory:.2f}MB",
            "ì´_ì§ˆì˜_ìˆ˜": len(self.query_times)
        }

# ì‚¬ìš©ë²•
monitor = RAGMonitor(rag)
result = monitor.monitored_query("ì£¼ìš” í…Œë§ˆëŠ” ë¬´ì—‡ì¸ê°€ìš”?")
print(monitor.get_stats())
```

## ğŸ¯ ëª¨ë²” ì‚¬ë¡€

### 1. ë¬¸ì„œ ì „ì²˜ë¦¬

```python
import re

def preprocess_document(text):
    """ë” ë‚˜ì€ RAG ì„±ëŠ¥ì„ ìœ„í•œ ë¬¸ì„œ ì •ë¦¬ ë° ì¤€ë¹„"""
    # ê³¼ë„í•œ ê³µë°± ì œê±°
    text = re.sub(r'\s+', ' ', text)
    
    # ë°©í•´ê°€ ë  ìˆ˜ ìˆëŠ” íŠ¹ìˆ˜ ë¬¸ì ì œê±°
    text = re.sub(r'[^\w\s\.\,\!\?\;\:\-\(\)\uAC00-\uD7AF]', '', text)
    
    # ì ì ˆí•œ ë¬¸ì¥ ë ë³´ì¥
    text = re.sub(r'(?<=[ê°€-í£])(?=[ê°€-í£])', '. ', text)
    
    return text.strip()

# ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ ì‚¬ìš©
with open("document.txt", "r", encoding="utf-8") as f:
    raw_text = f.read()

clean_text = preprocess_document(raw_text)
rag.insert(clean_text)
```

### 2. ì§ˆì˜ ìµœì í™”

```python
def optimize_query(query):
    """ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ìœ„í•œ ì§ˆì˜ ìµœì í™”"""
    # ì»¨í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ ì¶”ê°€
    optimized_queries = {
        "ìš”ì•½": f"ë‹¤ìŒ ë‚´ìš©ì„ ì¢…í•©ì ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”: {query}",
        "ë¹„êµ": f"ë‹¤ìŒ ì¸¡ë©´ë“¤ì„ ë¹„êµ ë¶„ì„í•´ì£¼ì„¸ìš”: {query}",
        "ë¶„ì„": f"ë‹¤ìŒì— ëŒ€í•œ ìƒì„¸í•œ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”: {query}",
        "ì„¤ëª…": f"ë‹¤ìŒì„ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”: {query}"
    }
    
    # ì§ˆì˜ ìœ í˜• ê°ì§€ ë° ìµœì í™”
    for key, template in optimized_queries.items():
        if key in query:
            return template
    
    return query

# ì‚¬ìš©ë²•
original_query = "ì£¼ìš” í¬ì¸íŠ¸ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”"
optimized = optimize_query(original_query)
result = rag.query(optimized, param=QueryParam(mode="hybrid"))
```

### 3. ì •ê¸° ìœ ì§€ë³´ìˆ˜

```python
def maintain_rag_system(rag, working_dir):
    """ìµœì  ì„±ëŠ¥ì„ ìœ„í•œ ì •ê¸° ìœ ì§€ë³´ìˆ˜ ì‘ì—…"""
    import os
    import shutil
    
    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
    temp_dir = os.path.join(working_dir, "temp")
    if os.path.exists(temp_dir):
        shutil.rmtree(temp_dir)
        os.makedirs(temp_dir)
    
    # ìœ ì§€ë³´ìˆ˜ ë¡œê·¸
    print(f"{working_dir}ì— ëŒ€í•œ ìœ ì§€ë³´ìˆ˜ ì™„ë£Œ")

# ì •ê¸° ìœ ì§€ë³´ìˆ˜ ìŠ¤ì¼€ì¤„ë§
import schedule

schedule.every().day.at("02:00").do(maintain_rag_system, rag, working_dir)
```

## ğŸ”® í–¥í›„ ê°œì„ ì‚¬í•­

LightRAGëŠ” í¥ë¯¸ë¡œìš´ í–¥í›„ ê¸°ëŠ¥ë“¤ê³¼ í•¨ê»˜ ê³„ì† ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤:

### ê³„íšëœ ê¸°ëŠ¥ë“¤
- **ë©€í‹°ëª¨ë‹¬ ì§€ì›**: ì´ë¯¸ì§€ ë° ë¹„ë””ì˜¤ ì²˜ë¦¬ì™€ì˜ í†µí•©
- **í–¥ìƒëœ ê·¸ë˜í”„ ì•Œê³ ë¦¬ì¦˜**: ë” ì •êµí•œ ê´€ê³„ ì¶”ì¶œ
- **ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸**: ì „ì²´ ì¬ì¸ë±ì‹± ì—†ì´ ì‹¤ì‹œê°„ ë¬¸ì„œ ì—…ë°ì´íŠ¸
- **ê³ ê¸‰ ìºì‹±**: ì§€ëŠ¥ì ì¸ ì§ˆì˜ ê²°ê³¼ ìºì‹±
- **ì»¤ìŠ¤í…€ ì„ë² ë”© ëª¨ë¸**: ë„ë©”ì¸ë³„ ì„ë² ë”© ì§€ì›

### ì»¤ë®¤ë‹ˆí‹° ê¸°ì—¬
- í™œë°œí•œ ê°œë°œ ì»¤ë®¤ë‹ˆí‹°
- ì •ê¸°ì ì¸ ì„±ëŠ¥ ê°œì„ 
- í™•ì¥ ìƒíƒœê³„
- ì¸ê¸° ML í”„ë ˆì„ì›Œí¬ì™€ì˜ í†µí•©

## ğŸ“š ìë£Œ ë° ì¶”ê°€ ì½ì„ê±°ë¦¬

### ê³µì‹ ë¬¸ì„œ
- [LightRAG GitHub ë¦¬í¬ì§€í† ë¦¬](https://github.com/HKUDS/LightRAG)
- [ì—°êµ¬ ë…¼ë¬¸](https://arxiv.org/abs/2410.05779)
- [API ë¬¸ì„œ](https://github.com/HKUDS/LightRAG/tree/main/docs)

### ê´€ë ¨ í”„ë¡œì íŠ¸
- [RAG-Anything](https://github.com/HKUDS/RAG-Anything): ë©€í‹°ëª¨ë‹¬ RAG
- [VideoRAG](https://github.com/HKUDS/VideoRAG): ë¹„ë””ì˜¤ ì „ìš© RAG
- [MiniRAG](https://github.com/HKUDS/MiniRAG): ê²½ëŸ‰ RAG

### ì»¤ë®¤ë‹ˆí‹°
- GitHub í† ë¡ 
- ì´ìŠˆ ë° ë²„ê·¸ ë¦¬í¬íŠ¸
- ê¸°ëŠ¥ ìš”ì²­

## ğŸŠ ê²°ë¡ 

LightRAGëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„± ê¸°ìˆ  ë¶„ì•¼ì—ì„œ ì¤‘ëŒ€í•œ ì§„ì „ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ë‹¨ìˆœí•¨, ì†ë„, ë›°ì–´ë‚œ ì„±ëŠ¥ì˜ ì¡°í•©ì€ ì´ˆë³´ìì™€ ìˆ™ë ¨ëœ ì‹¤ë¬´ì ëª¨ë‘ì—ê²Œ íƒì›”í•œ ì„ íƒì´ ë©ë‹ˆë‹¤.

í•µì‹¬ ìš”ì ë“¤:
- **ì‰¬ìš´ ì„¤ì •**: ìµœì†Œí•œì˜ êµ¬ì„±ìœ¼ë¡œ ì‹œì‘ ê°€ëŠ¥
- **ë›°ì–´ë‚œ ì„±ëŠ¥**: ê¸°ì¡´ RAG ì†”ë£¨ì…˜ë“¤ì„ ëŠ¥ê°€
- **ìœ ì—°í•œ ì•„í‚¤í…ì²˜**: ë‹¤ì–‘í•œ ì‚¬ìš© ì‚¬ë¡€ì™€ êµ¬ì„± ì§€ì›
- **í™œë°œí•œ ê°œë°œ**: ì •ê¸°ì ì¸ ì—…ë°ì´íŠ¸ì™€ ì»¤ë®¤ë‹ˆí‹° ì§€ì›

ê¸°ì—… ì§€ì‹ ë² ì´ìŠ¤ êµ¬ì¶•, ì—°êµ¬ ë…¼ë¬¸ ë¶„ì„, AI ê¸°ë°˜ ì–´ì‹œìŠ¤í„´íŠ¸ ìƒì„± ë“± ì–´ë–¤ ì‘ì—…ì„ í•˜ë“ , LightRAGëŠ” ì„±ê³µì— í•„ìš”í•œ ë„êµ¬ì™€ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

ì˜¤ëŠ˜ LightRAG ì—¬ì •ì„ ì‹œì‘í•˜ì—¬ ê²€ìƒ‰ ì¦ê°• ìƒì„±ì˜ ë¯¸ë˜ë¥¼ ê²½í—˜í•´ë³´ì„¸ìš”!

---

*ì´ íŠœí† ë¦¬ì–¼ì´ ë„ì›€ì´ ë˜ì…¨ë‚˜ìš”? íŒ€ê³¼ ê³µìœ í•˜ê³  GitHubì—ì„œ LightRAG ì»¤ë®¤ë‹ˆí‹°ì— ê¸°ì—¬í•´ë³´ì„¸ìš”!*
