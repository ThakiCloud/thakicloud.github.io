---
title: "Maestro: AI ê¸°ë°˜ ì—°êµ¬ ìë™í™” í”Œë«í¼ ì™„ì „ ê°€ì´ë“œ - ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œìœ¼ë¡œ ì—°êµ¬ í˜ì‹ í•˜ê¸°"
excerpt: "ë³µì¡í•œ ì—°êµ¬ ì‘ì—…ì„ ìë™í™”í•˜ëŠ” Maestroì˜ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ë§ˆìŠ¤í„°í•˜ì„¸ìš”. Docker ê¸°ë°˜ ì„¤ì¹˜ë¶€í„° RAG íŒŒì´í”„ë¼ì¸, ì‹¤ì‹œê°„ ì—°êµ¬ ì¶”ì ê¹Œì§€ ì™„ì „ ìì²´ í˜¸ìŠ¤íŒ… ì†”ë£¨ì…˜ì„ êµ¬ì¶•í•©ë‹ˆë‹¤."
seo_title: "Maestro AI ì—°êµ¬ ìë™í™” í”Œë«í¼ ì™„ì „ ê°€ì´ë“œ - ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ - Thaki Cloud"
seo_description: "Maestro AI ì—°êµ¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶• ë°©ë²•ë¶€í„° RAG íŒŒì´í”„ë¼ì¸, ì‹¤ì‹œê°„ ì¶”ì , ìì²´ í˜¸ìŠ¤íŒ…ê¹Œì§€ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ì—°êµ¬ ìë™í™” ì†”ë£¨ì…˜ì„ ì™„ë²½ ë§ˆìŠ¤í„°í•˜ì„¸ìš”."
date: 2025-08-03
last_modified_at: 2025-08-03
categories:
  - tutorials
  - dev
  - llmops
tags:
  - Maestro
  - AI-Research
  - Multi-Agent-System
  - RAG-Pipeline
  - Docker
  - FastAPI
  - React
  - WebSocket
  - Research-Automation
  - Self-Hosted
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
toc_icon: "cog"
toc_sticky: true
canonical_url: "https://thakicloud.github.io/tutorials/maestro-ai-powered-research-automation-complete-guide/"
reading_time: true
---

â±ï¸ **ì˜ˆìƒ ì½ê¸° ì‹œê°„**: 22ë¶„

## ì„œë¡ 

í˜„ëŒ€ ì—°êµ¬ í™˜ê²½ì—ì„œ ì •ë³´ì˜ ì–‘ì€ ê¸°í•˜ê¸‰ìˆ˜ì ìœ¼ë¡œ ì¦ê°€í•˜ê³  ìˆì§€ë§Œ, ì—°êµ¬ìë“¤ì´ ì´ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  ì¢…í•©í•  ì‹œê°„ì€ í•œì •ì ì…ë‹ˆë‹¤. [Maestro](https://github.com/murtaza-nasir/maestro)ëŠ” ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê°œë°œëœ AI ê¸°ë°˜ ì—°êµ¬ ìë™í™” í”Œë«í¼ìœ¼ë¡œ, ë³µì¡í•œ ì—°êµ¬ ì‘ì—…ì„ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ í†µí•´ ìë™í™”í•©ë‹ˆë‹¤.

ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” Maestroì˜ í•µì‹¬ ì•„í‚¤í…ì²˜ë¶€í„° ì‹¤ì œ ë°°í¬ê¹Œì§€, ì—°êµ¬ ì›Œí¬í”Œë¡œìš°ë¥¼ í˜ì‹ í•  ìˆ˜ ìˆëŠ” ì™„ì „í•œ ì†”ë£¨ì…˜ì„ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.

## Maestro í”Œë«í¼ ê°œìš”

### í•µì‹¬ ê¸°ëŠ¥ê³¼ íŠ¹ì§•

**ğŸ¤– ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ**
- **Planning Agent**: ì—°êµ¬ ê³„íš ë° êµ¬ì¡°í™”
- **Research Agent**: ì •ë³´ ìˆ˜ì§‘ ë° RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
- **Reflection Agent**: ë¹„íŒì  ê²€í†  ë° í’ˆì§ˆ ê´€ë¦¬
- **Writing Agent**: ë³´ê³ ì„œ ì‘ì„± ë° ì¢…í•©
- **Agent Controller**: ì „ì²´ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬

**ğŸ” ê³ ê¸‰ ì—°êµ¬ ê¸°ëŠ¥**
- ë¡œì»¬ RAG íŒŒì´í”„ë¼ì¸ ì§€ì›
- ì›¹ ê²€ìƒ‰ í†µí•© (SearXNG)
- ì‹¤ì‹œê°„ ì—°êµ¬ ì§„í–‰ ì¶”ì 
- íˆ¬ëª…í•œ AI ì¶”ë¡  ê³¼ì •
- ì™„ì „ ìì²´ í˜¸ìŠ¤íŒ… ê°€ëŠ¥

**ğŸ’» í˜„ëŒ€ì  ì•„í‚¤í…ì²˜**
- FastAPI ë°±ì—”ë“œ
- React + TypeScript í”„ë¡ íŠ¸ì—”ë“œ
- WebSocket ì‹¤ì‹œê°„ í†µì‹ 
- SQLAlchemy + SQLite ë°ì´í„°ë² ì´ìŠ¤
- Docker ì»¨í…Œì´ë„ˆí™”

## ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

### í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­

```bash
# ìµœì†Œ ì‚¬ì–‘
CPU: 4 cores (Intel i5 ë˜ëŠ” AMD Ryzen 5 ì´ìƒ)
RAM: 8GB (16GB ê¶Œì¥)
Storage: 10GB ì—¬ìœ  ê³µê°„

# ê¶Œì¥ ì‚¬ì–‘ (AI ëª¨ë¸ í¬í•¨)
CPU: 8 cores (Intel i7 ë˜ëŠ” AMD Ryzen 7 ì´ìƒ)
RAM: 16GB (32GB ê¶Œì¥)
GPU: NVIDIA GPU (CUDA ì§€ì›, 8GB VRAM ì´ìƒ)
Storage: 20GB ì—¬ìœ  ê³µê°„ (SSD ê¶Œì¥)
```

### ì†Œí”„íŠ¸ì›¨ì–´ ìš”êµ¬ì‚¬í•­

```bash
# í•„ìˆ˜ ì†Œí”„íŠ¸ì›¨ì–´
Docker: 24.0 ì´ìƒ
Docker Compose: 2.0 ì´ìƒ
Git: 2.30 ì´ìƒ

# ì„ íƒì‚¬í•­ (ê°œë°œ í™˜ê²½)
Node.js: 18.0 ì´ìƒ
Python: 3.9 ì´ìƒ
```

## ì„¤ì¹˜ ë° í™˜ê²½ ì„¤ì •

### 1. ì €ì¥ì†Œ í´ë¡  ë° ê¸°ë³¸ ì„¤ì •

```bash
# Maestro ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/murtaza-nasir/maestro.git
cd maestro

# ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ì¸
ls -la
```

```
maestro/
â”œâ”€â”€ maestro_backend/          # FastAPI ë°±ì—”ë“œ
â”œâ”€â”€ maestro_frontend/         # React í”„ë¡ íŠ¸ì—”ë“œ
â”œâ”€â”€ evaluation/              # ì„±ëŠ¥ í‰ê°€ ë„êµ¬
â”œâ”€â”€ example reports/         # ì˜ˆì œ ë³´ê³ ì„œ
â”œâ”€â”€ scripts/                # ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ docker-compose.yml      # Docker êµ¬ì„±
â”œâ”€â”€ setup-env.sh           # í™˜ê²½ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ README.md
```

### 2. ëŒ€í™”í˜• í™˜ê²½ ì„¤ì •

```bash
# ëŒ€í™”í˜• ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
chmod +x setup-env.sh
./setup-env.sh
```

ì„¤ì • ê³¼ì •ì—ì„œ ë‹¤ìŒ í•­ëª©ë“¤ì„ êµ¬ì„±í•©ë‹ˆë‹¤:

```bash
# ë„¤íŠ¸ì›Œí¬ ì„¤ì •
í¬íŠ¸ ì„¤ì •: 3030 (ê¸°ë³¸ê°’)
í˜¸ìŠ¤íŠ¸ ì£¼ì†Œ: localhost (ê¸°ë³¸ê°’)

# API í‚¤ ì„¤ì •
OpenAI API Key: [ì„ íƒì‚¬í•­ - ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©ì‹œ ë¶ˆí•„ìš”]
SearXNG URL: [ì›¹ ê²€ìƒ‰ìš©, ê¸°ë³¸ê°’ ì‚¬ìš© ê°€ëŠ¥]

# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
SQLite ê²½ë¡œ: ./data/maestro.db (ê¸°ë³¸ê°’)

# ë³´ì•ˆ ì„¤ì •
JWT Secret Key: [ìë™ ìƒì„±]
Admin Password: [ì„¤ì • í•„ìš”]
```

### 3. í™˜ê²½ ë³€ìˆ˜ í™•ì¸

ìƒì„±ëœ `.env` íŒŒì¼ì„ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ìˆ˜ì •í•©ë‹ˆë‹¤:

```bash
# .env íŒŒì¼ ë‚´ìš© í™•ì¸
cat .env
```

```ini
# ê¸°ë³¸ ì„¤ì • ì˜ˆì‹œ
FRONTEND_PORT=3030
BACKEND_PORT=8000
DATABASE_URL=sqlite:///./data/maestro.db

# API ì„¤ì •
OPENAI_API_KEY=your_openai_key_here
SEARXNG_URL=https://search.example.com

# ë³´ì•ˆ ì„¤ì •
JWT_SECRET_KEY=your_generated_secret_key
ADMIN_USERNAME=admin
ADMIN_PASSWORD=your_secure_password

# AI ëª¨ë¸ ì„¤ì •
LOCAL_MODEL_URL=http://localhost:11434  # Ollama ê¸°ë³¸ê°’
MODEL_NAME=llama2  # ì‚¬ìš©í•  ëª¨ë¸ëª…
```

## Docker ê¸°ë°˜ ë°°í¬

### 1. ì»¨í…Œì´ë„ˆ ë¹Œë“œ ë° ì‹¤í–‰

```bash
# ì»¨í…Œì´ë„ˆ ë¹Œë“œ ë° ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
docker compose up --build -d

# ì‹¤í–‰ ìƒíƒœ í™•ì¸
docker compose ps
```

```
NAME                    COMMAND                  SERVICE             STATUS              PORTS
maestro-frontend-1      "docker-entrypoint.sâ€¦"   frontend           running             0.0.0.0:3030->3000/tcp
maestro-backend-1       "uvicorn main:app --â€¦"   backend            running             0.0.0.0:8000->8000/tcp
maestro-db-1           "docker-entrypoint.sâ€¦"   database           running             5432/tcp
```

### 2. ë¡œê·¸ ëª¨ë‹ˆí„°ë§

```bash
# ì „ì²´ ì„œë¹„ìŠ¤ ë¡œê·¸ í™•ì¸
docker compose logs -f

# íŠ¹ì • ì„œë¹„ìŠ¤ ë¡œê·¸ í™•ì¸
docker compose logs -f backend
docker compose logs -f frontend
```

### 3. í—¬ìŠ¤ì²´í¬ ë° ì ‘ì† í™•ì¸

```bash
# ë°±ì—”ë“œ í—¬ìŠ¤ì²´í¬
curl http://localhost:8000/health

# í”„ë¡ íŠ¸ì—”ë“œ ì ‘ì† í™•ì¸
curl http://localhost:3030
```

## í•µì‹¬ ê¸°ëŠ¥ í™œìš© ê°€ì´ë“œ

### 1. ì²« ì—°êµ¬ ë¯¸ì…˜ ìƒì„±

ì›¹ ì¸í„°í˜ì´ìŠ¤(http://localhost:3030)ì— ì ‘ì† í›„:

```javascript
// ì—°êµ¬ ë¯¸ì…˜ ì˜ˆì‹œ
{
  "title": "AI ìœ¤ë¦¬ ê°€ì´ë“œë¼ì¸ ë¶„ì„",
  "description": "ìµœì‹  AI ìœ¤ë¦¬ ê°€ì´ë“œë¼ì¸ë“¤ì„ ë¹„êµ ë¶„ì„í•˜ê³  í•µì‹¬ ì›ì¹™ë“¤ì„ ë„ì¶œ",
  "research_questions": [
    "ì£¼ìš” AI ìœ¤ë¦¬ ê°€ì´ë“œë¼ì¸ë“¤ì˜ ê³µí†µ ì›ì¹™ì€ ë¬´ì—‡ì¸ê°€?",
    "ê° ê°€ì´ë“œë¼ì¸ë³„ ì°¨ì´ì ê³¼ íŠ¹ì§•ì€?",
    "ì‹¤ë¬´ ì ìš©ì„ ìœ„í•œ êµ¬ì²´ì  ë°©ì•ˆì€?"
  ],
  "sources": [
    "local_documents",
    "web_search"
  ]
}
```

### 2. ë©€í‹° ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° ì´í•´

**Phase 1: Planning**
```python
# Planning Agent ì‘ì—… íë¦„
def create_research_plan(mission):
    """
    1. ì—°êµ¬ ì§ˆë¬¸ ë¶„ì„
    2. ê³„ì¸µì  ì—°êµ¬ ê³„íš ìˆ˜ë¦½
    3. ë³´ê³ ì„œ ê°œìš” ì‘ì„±
    4. ì‘ì—… ìš°ì„ ìˆœìœ„ ì„¤ì •
    """
    return structured_plan
```

**Phase 2: Research & Reflection**
```python
# Research-Reflection Loop
def research_cycle(plan):
    """
    1. Research Agent: ì •ë³´ ìˆ˜ì§‘
    2. Reflection Agent: í’ˆì§ˆ ê²€í† 
    3. í•„ìš”ì‹œ ê³„íš ìˆ˜ì •
    4. ì¶”ê°€ ì—°êµ¬ ìˆ˜í–‰
    """
    while not research_complete:
        findings = research_agent.gather_info()
        feedback = reflection_agent.critique(findings)
        if feedback.requires_more_research:
            plan = update_plan(feedback)
        else:
            break
    return comprehensive_findings
```

**Phase 3: Writing & Finalization**
```python
# Writing-Reflection Loop
def writing_cycle(findings):
    """
    1. Writing Agent: ë³´ê³ ì„œ ì´ˆì•ˆ ì‘ì„±
    2. Reflection Agent: ê¸€ ê²€í† 
    3. í•„ìš”ì‹œ ìˆ˜ì • ë° ê°œì„ 
    4. ìµœì¢… ë³´ê³ ì„œ ì™„ì„±
    """
    draft = writing_agent.create_draft(findings)
    while not writing_approved:
        feedback = reflection_agent.review_writing(draft)
        draft = writing_agent.revise(draft, feedback)
    return final_report
```

### 3. RAG íŒŒì´í”„ë¼ì¸ í™œìš©

**ë¬¸ì„œ ì—…ë¡œë“œ ë° ì¸ë±ì‹±**
```bash
# CLIë¥¼ í†µí•œ ë¬¸ì„œ ì¼ê´„ ì—…ë¡œë“œ
docker exec -it maestro-backend-1 python scripts/ingest_documents.py \
  --directory /path/to/documents \
  --format pdf,docx,txt \
  --chunk_size 1000 \
  --overlap 200
```

**ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸**
```python
# ì¸ë±ì‹±ëœ ë¬¸ì„œ í™•ì¸
from maestro_backend.vector_store import VectorStore

store = VectorStore()
documents = store.list_documents()
print(f"ì´ {len(documents)}ê°œ ë¬¸ì„œê°€ ì¸ë±ì‹±ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
results = store.similarity_search("AI ethics principles", k=5)
for doc in results:
    print(f"ë¬¸ì„œ: {doc.source}, ìœ ì‚¬ë„: {doc.score:.3f}")
```

### 4. ì›¹ ê²€ìƒ‰ í†µí•© (SearXNG)

**SearXNG ì„¤ì •**
```yaml
# docker-compose.ymlì— SearXNG ì¶”ê°€
services:
  searxng:
    image: searxng/searxng:latest
    ports:
      - "8080:8080"
    environment:
      - SEARXNG_SECRET=your_secret_key
    volumes:
      - ./searxng:/etc/searxng
```

**ê²€ìƒ‰ ì„¤ì • ìµœì í™”**
```yaml
# searxng/settings.yml
search:
  default_lang: "ko"
  autocomplete: "google"
  safe_search: 1

engines:
  - name: google
    weight: 1.0
    disabled: false
  - name: scholar
    weight: 1.5
    disabled: false
  - name: arxiv
    weight: 2.0
    disabled: false
```

## ê³ ê¸‰ ì„¤ì • ë° ìµœì í™”

### 1. ë¡œì»¬ LLM ëª¨ë¸ ì„¤ì •

**Ollama ì„¤ì •**
```bash
# Ollama ì„¤ì¹˜ (macOS/Linux)
curl -fsSL https://ollama.ai/install.sh | sh

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ollama pull llama2
ollama pull mistral
ollama pull codellama

# ì„œë¹„ìŠ¤ ì‹œì‘
ollama serve
```

**Maestroì™€ Ollama ì—°ë™**
```python
# maestro_backend/config.py
LOCAL_MODEL_CONFIG = {
    "base_url": "http://localhost:11434",
    "model": "llama2",
    "temperature": 0.7,
    "max_tokens": 2048,
    "context_window": 4096
}
```

### 2. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”

**ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§**
```bash
# Docker ì»¨í…Œì´ë„ˆ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
docker stats

# GPU ì‚¬ìš©ëŸ‰ (NVIDIA)
nvidia-smi

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìƒì„¸
docker exec maestro-backend-1 python -c "
import psutil
print(f'CPU: {psutil.cpu_percent()}%')
print(f'Memory: {psutil.virtual_memory().percent}%')
"
```

**ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”**
```sql
-- SQLite ì„±ëŠ¥ ìµœì í™” ì„¤ì •
PRAGMA journal_mode = WAL;
PRAGMA synchronous = NORMAL;
PRAGMA cache_size = 10000;
PRAGMA foreign_keys = ON;

-- ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX idx_research_created_at ON research_missions(created_at);
CREATE INDEX idx_agent_logs_mission_id ON agent_logs(mission_id);
```

### 3. ê³ ê¸‰ ì—ì´ì „íŠ¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•

**ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸ ìµœì í™”**
```python
# maestro_backend/agents/research_agent.py
RESEARCH_PROMPT_TEMPLATE = """
ë‹¹ì‹ ì€ ì „ë¬¸ ì—°êµ¬ì›ì…ë‹ˆë‹¤. ë‹¤ìŒ ì—°êµ¬ ê³„íšì— ë”°ë¼ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”:

ì—°êµ¬ ëª©í‘œ: {research_goal}
í˜„ì¬ ë‹¨ê³„: {current_phase}
ìˆ˜ì§‘í•´ì•¼ í•  ì •ë³´: {target_information}

ê²€ìƒ‰ ì „ëµ:
1. í•µì‹¬ í‚¤ì›Œë“œ ì‹ë³„
2. ë‹¤ì–‘í•œ ì •ë³´ì› í™œìš©
3. ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ ìš°ì„ 
4. ìµœì‹ ì„±ê³¼ ê´€ë ¨ì„± ê³ ë ¤

ìˆ˜ì§‘ëœ ì •ë³´ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”:
- ì¶œì²˜: [URL ë˜ëŠ” ë¬¸ì„œëª…]
- ì‹ ë¢°ë„: [1-10 ì ìˆ˜]
- í•µì‹¬ ë‚´ìš©: [3-5ë¬¸ì¥ ìš”ì•½]
- ì—°ê´€ì„±: [ì—°êµ¬ ëª©í‘œì™€ì˜ ê´€ë ¨ì„±]
"""
```

**ì—ì´ì „íŠ¸ ê°„ í˜‘ì—… ë¡œì§**
```python
# maestro_backend/agents/agent_controller.py
class AgentController:
    def coordinate_research_cycle(self, mission):
        """ì—ì´ì „íŠ¸ ê°„ í˜‘ì—… ê´€ë¦¬"""
        plan = self.planning_agent.create_plan(mission)
        
        iteration = 0
        max_iterations = 5
        
        while iteration < max_iterations:
            # ì—°êµ¬ ìˆ˜í–‰
            findings = self.research_agent.execute(plan)
            
            # í’ˆì§ˆ ê²€í† 
            feedback = self.reflection_agent.evaluate(
                findings, plan, mission.requirements
            )
            
            if feedback.quality_score >= 0.8:
                break
                
            # ê³„íš ìˆ˜ì •
            plan = self.planning_agent.refine_plan(
                plan, feedback.suggestions
            )
            iteration += 1
        
        return self.writing_agent.synthesize(findings, plan)
```

## ì‹¤ì „ í™œìš© ì‹œë‚˜ë¦¬ì˜¤

### 1. í•™ìˆ  ì—°êµ¬ ì§€ì›

**ë…¼ë¬¸ ë¦¬ë·° ìë™í™”**
```python
# ë…¼ë¬¸ ë¦¬ë·° ë¯¸ì…˜ ì„¤ì •
paper_review_mission = {
    "title": "ìì—°ì–´ ì²˜ë¦¬ ìµœì‹  ë…¼ë¬¸ ë¦¬ë·°",
    "scope": "2024ë…„ EMNLP, ACL ì£¼ìš” ë…¼ë¬¸",
    "focus_areas": [
        "Large Language Models",
        "Few-shot Learning", 
        "Multimodal AI"
    ],
    "output_format": "systematic_review"
}
```

**ì—°êµ¬ ë™í–¥ ë¶„ì„**
```bash
# ì •ê¸°ì  ì—°êµ¬ ë™í–¥ ëª¨ë‹ˆí„°ë§ ì„¤ì •
docker exec maestro-backend-1 python scripts/schedule_research.py \
  --topic "AI Safety Research" \
  --frequency weekly \
  --sources "arxiv,scholar,conferences" \
  --alert_threshold 10
```

### 2. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤

**ì‹œì¥ ì¡°ì‚¬ ìë™í™”**
```python
market_research_config = {
    "industry": "AI SaaS",
    "regions": ["North America", "Europe", "Asia"],
    "timeframe": "2024-2025",
    "competitors": ["identified_automatically"],
    "metrics": [
        "market_size",
        "growth_rate",
        "key_players",
        "emerging_trends"
    ]
}
```

**ê¸°ìˆ  íŠ¸ë Œë“œ ë¶„ì„**
```bash
# ê¸°ìˆ  íŠ¸ë Œë“œ ì •ê¸° ë¶„ì„
curl -X POST http://localhost:8000/api/missions \
  -H "Content-Type: application/json" \
  -d '{
    "title": "AI Infrastructure Trends Q1 2025",
    "research_questions": [
      "What are the emerging AI infrastructure technologies?",
      "Which companies are leading in AI hardware?",
      "What are the cost optimization trends?"
    ],
    "automated": true,
    "schedule": "monthly"
  }'
```

### 3. ì •ì±… ì—°êµ¬ ë° ë¶„ì„

**ê·œì œ ë¶„ì„**
```python
regulatory_analysis = {
    "scope": "AI Regulation Global Overview",
    "jurisdictions": ["EU", "US", "China", "UK"],
    "focus": [
        "AI Act compliance",
        "Data privacy requirements",
        "Algorithm transparency",
        "Liability frameworks"
    ],
    "update_frequency": "quarterly"
}
```

## ë¬¸ì œ í•´ê²° ë° ë””ë²„ê¹…

### 1. ì¼ë°˜ì ì¸ ë¬¸ì œì ë“¤

**ë©”ëª¨ë¦¬ ë¶€ì¡± ë¬¸ì œ**
```bash
# Docker ë©”ëª¨ë¦¬ í•œê³„ ì¦ê°€
echo '{
  "default-runtime": "runc",
  "runtimes": {
    "runc": {
      "path": "runc"
    }
  },
  "default-ulimits": {
    "memlock": {
      "Name": "memlock",
      "Hard": -1,
      "Soft": -1
    }
  }
}' | sudo tee /etc/docker/daemon.json

sudo systemctl restart docker
```

**ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨**
```python
# ëª¨ë¸ ìƒíƒœ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸
def check_model_status():
    try:
        response = requests.get("http://localhost:11434/api/tags")
        models = response.json()
        print("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤:")
        for model in models.get('models', []):
            print(f"- {model['name']}")
    except Exception as e:
        print(f"ëª¨ë¸ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")

check_model_status()
```

**WebSocket ì—°ê²° ë¬¸ì œ**
```javascript
// í”„ë¡ íŠ¸ì—”ë“œ WebSocket ì¬ì—°ê²° ë¡œì§
class WebSocketManager {
    constructor(url) {
        this.url = url;
        this.reconnectAttempts = 0;
        this.maxReconnectAttempts = 5;
        this.connect();
    }
    
    connect() {
        this.ws = new WebSocket(this.url);
        
        this.ws.onopen = () => {
            console.log('WebSocket ì—°ê²°ë¨');
            this.reconnectAttempts = 0;
        };
        
        this.ws.onclose = () => {
            if (this.reconnectAttempts < this.maxReconnectAttempts) {
                setTimeout(() => {
                    this.reconnectAttempts++;
                    this.connect();
                }, 5000);
            }
        };
    }
}
```

### 2. ë¡œê·¸ ë¶„ì„ ë° ëª¨ë‹ˆí„°ë§

**êµ¬ì¡°í™”ëœ ë¡œê¹… ì„¤ì •**
```python
# maestro_backend/utils/logging_config.py
import logging
import json
from datetime import datetime

class JSONFormatter(logging.Formatter):
    def format(self, record):
        log_obj = {
            'timestamp': datetime.utcnow().isoformat(),
            'level': record.levelname,
            'logger': record.name,
            'message': record.getMessage(),
            'module': record.module,
            'function': record.funcName,
            'line': record.lineno
        }
        
        if hasattr(record, 'mission_id'):
            log_obj['mission_id'] = record.mission_id
        if hasattr(record, 'agent_type'):
            log_obj['agent_type'] = record.agent_type
            
        return json.dumps(log_obj)
```

**ì‹¤ì‹œê°„ ë¡œê·¸ ëŒ€ì‹œë³´ë“œ**
```bash
# ELK ìŠ¤íƒì„ ì´ìš©í•œ ë¡œê·¸ ì‹œê°í™”
docker run -d \
  --name elasticsearch \
  -p 9200:9200 \
  -e "discovery.type=single-node" \
  docker.elastic.co/elasticsearch/elasticsearch:8.11.0

docker run -d \
  --name kibana \
  -p 5601:5601 \
  --link elasticsearch:elasticsearch \
  docker.elastic.co/kibana/kibana:8.11.0
```

## í™•ì¥ ë° ì»¤ìŠ¤í„°ë§ˆì´ì§•

### 1. ì»¤ìŠ¤í…€ ì—ì´ì „íŠ¸ ê°œë°œ

**ìƒˆë¡œìš´ ì—ì´ì „íŠ¸ í´ë˜ìŠ¤ ìƒì„±**
```python
# maestro_backend/agents/custom_agent.py
from .base_agent import BaseAgent

class DataAnalysisAgent(BaseAgent):
    """ë°ì´í„° ë¶„ì„ ì „ë¬¸ ì—ì´ì „íŠ¸"""
    
    def __init__(self, model_config):
        super().__init__(model_config)
        self.agent_type = "data_analysis"
        
    def analyze_dataset(self, data_path, analysis_type):
        """ë°ì´í„°ì…‹ ë¶„ì„ ìˆ˜í–‰"""
        prompt = f"""
        ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì„¸ìš”:
        
        ë°ì´í„° ê²½ë¡œ: {data_path}
        ë¶„ì„ ìœ í˜•: {analysis_type}
        
        ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”:
        1. ë°ì´í„° êµ¬ì¡° íŒŒì•…
        2. ê¸°ì´ˆ í†µê³„ ë¶„ì„
        3. íŒ¨í„´ ë° ì´ìƒì¹˜ íƒì§€
        4. ì‹œê°í™” ì œì•ˆ
        5. ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
        """
        
        return self.execute_task(prompt)
    
    def generate_report(self, analysis_results):
        """ë¶„ì„ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±"""
        # ë³´ê³ ì„œ ìƒì„± ë¡œì§ êµ¬í˜„
        pass
```

### 2. í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œ êµ¬ì¶•

**í”ŒëŸ¬ê·¸ì¸ ì¸í„°í˜ì´ìŠ¤**
```python
# maestro_backend/plugins/base_plugin.py
from abc import ABC, abstractmethod

class MaestroPlugin(ABC):
    """Maestro í”ŒëŸ¬ê·¸ì¸ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    @abstractmethod
    def initialize(self, config):
        """í”ŒëŸ¬ê·¸ì¸ ì´ˆê¸°í™”"""
        pass
    
    @abstractmethod
    def execute(self, request):
        """í”ŒëŸ¬ê·¸ì¸ ì‹¤í–‰"""
        pass
    
    @abstractmethod
    def cleanup(self):
        """í”ŒëŸ¬ê·¸ì¸ ì •ë¦¬"""
        pass

# ë°ì´í„° ì†ŒìŠ¤ í”ŒëŸ¬ê·¸ì¸ ì˜ˆì‹œ
class DatabasePlugin(MaestroPlugin):
    def initialize(self, config):
        self.connection = create_connection(config.db_url)
    
    def execute(self, query):
        return self.connection.execute(query)
    
    def cleanup(self):
        self.connection.close()
```

### 3. API í™•ì¥

**ì»¤ìŠ¤í…€ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€**
```python
# maestro_backend/api/custom_endpoints.py
from fastapi import APIRouter, Depends
from .auth import get_current_user

router = APIRouter(prefix="/api/v1/custom")

@router.post("/analyze-data")
async def analyze_data(
    data_request: DataAnalysisRequest,
    user: User = Depends(get_current_user)
):
    """ë°ì´í„° ë¶„ì„ API"""
    agent = DataAnalysisAgent(app.config.model_config)
    result = await agent.analyze_dataset(
        data_request.data_path,
        data_request.analysis_type
    )
    return {"analysis": result, "status": "completed"}

@router.get("/research-stats")
async def get_research_statistics():
    """ì—°êµ¬ í†µê³„ API"""
    stats = {
        "total_missions": Mission.count(),
        "active_missions": Mission.count_active(),
        "completed_missions": Mission.count_completed(),
        "avg_completion_time": Mission.avg_completion_time()
    }
    return stats
```

## ë³´ì•ˆ ë° í”„ë¼ì´ë²„ì‹œ

### 1. ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬

**JWT ê¸°ë°˜ ì¸ì¦ ê°•í™”**
```python
# maestro_backend/auth/jwt_manager.py
import jwt
from datetime import datetime, timedelta
from passlib.context import CryptContext

class JWTManager:
    def __init__(self, secret_key, algorithm="HS256"):
        self.secret_key = secret_key
        self.algorithm = algorithm
        self.pwd_context = CryptContext(schemes=["bcrypt"])
    
    def create_access_token(self, user_id: str, permissions: list):
        payload = {
            "user_id": user_id,
            "permissions": permissions,
            "exp": datetime.utcnow() + timedelta(hours=24),
            "iat": datetime.utcnow()
        }
        return jwt.encode(payload, self.secret_key, self.algorithm)
    
    def verify_token(self, token: str):
        try:
            payload = jwt.decode(token, self.secret_key, [self.algorithm])
            return payload
        except jwt.ExpiredSignatureError:
            raise HTTPException(401, "Token expired")
        except jwt.InvalidTokenError:
            raise HTTPException(401, "Invalid token")
```

**ì—­í•  ê¸°ë°˜ ì ‘ê·¼ ì œì–´**
```python
# ì‚¬ìš©ì ì—­í•  ì •ì˜
class UserRole(Enum):
    ADMIN = "admin"
    RESEARCHER = "researcher"
    VIEWER = "viewer"

# ê¶Œí•œ ë°ì½”ë ˆì´í„°
def require_role(required_role: UserRole):
    def decorator(func):
        async def wrapper(*args, **kwargs):
            user = kwargs.get('current_user')
            if user.role != required_role.value:
                raise HTTPException(403, "Insufficient permissions")
            return await func(*args, **kwargs)
        return wrapper
    return decorator
```

### 2. ë°ì´í„° ë³´í˜¸

**ë¯¼ê° ì •ë³´ ë§ˆìŠ¤í‚¹**
```python
# maestro_backend/utils/data_protection.py
import re
from typing import str

class DataMasker:
    """ë¯¼ê° ì •ë³´ ë§ˆìŠ¤í‚¹ í´ë˜ìŠ¤"""
    
    @staticmethod
    def mask_email(text: str) -> str:
        """ì´ë©”ì¼ ì£¼ì†Œ ë§ˆìŠ¤í‚¹"""
        pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        return re.sub(pattern, '[EMAIL_MASKED]', text)
    
    @staticmethod
    def mask_phone(text: str) -> str:
        """ì „í™”ë²ˆí˜¸ ë§ˆìŠ¤í‚¹"""
        pattern = r'\b\d{3}-?\d{3,4}-?\d{4}\b'
        return re.sub(pattern, '[PHONE_MASKED]', text)
    
    @staticmethod
    def mask_personal_data(text: str) -> str:
        """ê°œì¸ì •ë³´ ì¢…í•© ë§ˆìŠ¤í‚¹"""
        text = DataMasker.mask_email(text)
        text = DataMasker.mask_phone(text)
        return text
```

**ë°ì´í„° ì•”í˜¸í™”**
```python
# ë°ì´í„°ë² ì´ìŠ¤ í•„ë“œ ì•”í˜¸í™”
from cryptography.fernet import Fernet

class EncryptedField:
    def __init__(self, key: bytes):
        self.cipher = Fernet(key)
    
    def encrypt(self, data: str) -> str:
        return self.cipher.encrypt(data.encode()).decode()
    
    def decrypt(self, encrypted_data: str) -> str:
        return self.cipher.decrypt(encrypted_data.encode()).decode()
```

## ìš´ì˜ ë° ìœ ì§€ë³´ìˆ˜

### 1. ë°±ì—… ë° ë³µêµ¬

**ìë™ ë°±ì—… ìŠ¤í¬ë¦½íŠ¸**
```bash
#!/bin/bash
# scripts/backup.sh

BACKUP_DIR="/backup/maestro/$(date +%Y%m%d_%H%M%S)"
mkdir -p "$BACKUP_DIR"

# ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
docker exec maestro-backend-1 sqlite3 /app/data/maestro.db ".backup /tmp/backup.db"
docker cp maestro-backend-1:/tmp/backup.db "$BACKUP_DIR/database.db"

# ì„¤ì • íŒŒì¼ ë°±ì—…
cp .env "$BACKUP_DIR/"
cp docker-compose.yml "$BACKUP_DIR/"

# ì—…ë¡œë“œëœ ë¬¸ì„œ ë°±ì—…
docker exec maestro-backend-1 tar -czf /tmp/documents.tar.gz /app/data/documents/
docker cp maestro-backend-1:/tmp/documents.tar.gz "$BACKUP_DIR/"

# ë°±ì—… ì™„ë£Œ ì•Œë¦¼
echo "ë°±ì—… ì™„ë£Œ: $BACKUP_DIR"
```

**ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸**
```bash
#!/bin/bash
# scripts/restore.sh

BACKUP_PATH=$1
if [ -z "$BACKUP_PATH" ]; then
    echo "ì‚¬ìš©ë²•: $0 <backup_directory>"
    exit 1
fi

# ì„œë¹„ìŠ¤ ì¤‘ë‹¨
docker compose down

# ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬
docker cp "$BACKUP_PATH/database.db" maestro-backend-1:/app/data/maestro.db

# ë¬¸ì„œ ë³µêµ¬
docker cp "$BACKUP_PATH/documents.tar.gz" maestro-backend-1:/tmp/
docker exec maestro-backend-1 tar -xzf /tmp/documents.tar.gz -C /app/data/

# ì„œë¹„ìŠ¤ ì¬ì‹œì‘
docker compose up -d

echo "ë³µêµ¬ ì™„ë£Œ"
```

### 2. ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼

**Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘**
```python
# maestro_backend/monitoring/metrics.py
from prometheus_client import Counter, Histogram, Gauge

# ë©”íŠ¸ë¦­ ì •ì˜
research_missions_total = Counter(
    'maestro_research_missions_total',
    'Total number of research missions',
    ['status']
)

agent_execution_duration = Histogram(
    'maestro_agent_execution_duration_seconds',
    'Agent execution duration',
    ['agent_type']
)

active_missions_gauge = Gauge(
    'maestro_active_missions',
    'Number of currently active missions'
)

# ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ í•¨ìˆ˜
def record_mission_completion(status: str, duration: float):
    research_missions_total.labels(status=status).inc()
    
def record_agent_execution(agent_type: str, duration: float):
    agent_execution_duration.labels(agent_type=agent_type).observe(duration)
```

**Grafana ëŒ€ì‹œë³´ë“œ ì„¤ì •**
```yaml
# monitoring/grafana-dashboard.json
{
  "dashboard": {
    "title": "Maestro AI Research Platform",
    "panels": [
      {
        "title": "Research Missions Status",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(maestro_research_missions_total) by (status)"
          }
        ]
      },
      {
        "title": "Agent Performance",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, maestro_agent_execution_duration_seconds_bucket)"
          }
        ]
      }
    ]
  }
}
```

## ê²°ë¡ 

MaestroëŠ” AI ê¸°ë°˜ ì—°êµ¬ ìë™í™”ì˜ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì„ ì œì‹œí•˜ëŠ” ê°•ë ¥í•œ í”Œë«í¼ì…ë‹ˆë‹¤. ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ í†µí•´ ë³µì¡í•œ ì—°êµ¬ ì‘ì—…ì„ ì²´ê³„ì ìœ¼ë¡œ ìë™í™”í•˜ê³ , ì™„ì „í•œ ìì²´ í˜¸ìŠ¤íŒ…ì„ í†µí•´ ë°ì´í„° í”„ë¼ì´ë²„ì‹œë¥¼ ë³´ì¥í•©ë‹ˆë‹¤.

### í•µì‹¬ ì¥ì  ìš”ì•½

1. **ì§€ëŠ¥ì  ìë™í™”**: 5ê°œì˜ ì „ë¬¸ ì—ì´ì „íŠ¸ê°€ í˜‘ë ¥í•˜ì—¬ ì¸ê°„ ìˆ˜ì¤€ì˜ ì—°êµ¬ í’ˆì§ˆ ë‹¬ì„±
2. **ì™„ì „í•œ íˆ¬ëª…ì„±**: ëª¨ë“  ì¶”ë¡  ê³¼ì •ê³¼ ì˜ì‚¬ê²°ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶”ì  ê°€ëŠ¥
3. **í™•ì¥ ê°€ëŠ¥ì„±**: í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œê³¼ APIë¥¼ í†µí•œ ë¬´ì œí•œ í™•ì¥
4. **í”„ë¼ì´ë²„ì‹œ ë³´ì¥**: ì™„ì „ ìì²´ í˜¸ìŠ¤íŒ…ìœ¼ë¡œ ë¯¼ê°í•œ ì—°êµ¬ ë°ì´í„° ë³´í˜¸
5. **ë¹„ìš© íš¨ìœ¨ì„±**: ë¡œì»¬ ëª¨ë¸ ì§€ì›ìœ¼ë¡œ API ë¹„ìš© ì—†ì´ ìš´ì˜ ê°€ëŠ¥

### ë‹¤ìŒ ë‹¨ê³„

1. **ê³ ê¸‰ ê¸°ëŠ¥ íƒìƒ‰**: ì»¤ìŠ¤í…€ ì—ì´ì „íŠ¸ ê°œë°œ ë° í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œ í™œìš©
2. **ì„±ëŠ¥ ìµœì í™”**: GPU í´ëŸ¬ìŠ¤í„°ë§ ë° ë¶„ì‚° ì²˜ë¦¬ êµ¬í˜„
3. **ë„ë©”ì¸ íŠ¹í™”**: íŠ¹ì • ì—°êµ¬ ë¶„ì•¼ì— ë§ëŠ” ì „ë¬¸ ì—ì´ì „íŠ¸ ê°œë°œ
4. **í˜‘ì—… ê¸°ëŠ¥**: ë©€í‹° ìœ ì € í™˜ê²½ ë° íŒ€ í˜‘ì—… ê¸°ëŠ¥ êµ¬ì¶•

Maestroë¥¼ í†µí•´ ì—°êµ¬ì˜ ë¯¸ë˜ë¥¼ ê²½í—˜í•˜ê³ , AIì™€ í•¨ê»˜í•˜ëŠ” ìƒˆë¡œìš´ ì§€ì‹ ì°½ì¡°ì˜ ì—¬ì •ì„ ì‹œì‘í•˜ì„¸ìš”.

### ì¶”ê°€ ë¦¬ì†ŒìŠ¤

- **ê³µì‹ ë¬¸ì„œ**: [Maestro GitHub](https://github.com/murtaza-nasir/maestro)
- **ì»¤ë®¤ë‹ˆí‹°**: GitHub Issues ë° Discussions
- **ê¸°ìˆ  ì§€ì›**: Docker ì„¤ì • ë° í™˜ê²½ ë¬¸ì œí•´ê²° ê°€ì´ë“œ
- **í™•ì¥ ê°€ì´ë“œ**: ì»¤ìŠ¤í…€ ì—ì´ì „íŠ¸ ë° í”ŒëŸ¬ê·¸ì¸ ê°œë°œ ë¬¸ì„œ