---
title: "LangGraph Studio ì™„ì „ ê°€ì´ë“œ - AI ì—ì´ì „íŠ¸ ê°œë°œ ë° ë””ë²„ê¹… IDE"
excerpt: "LangGraph Studio CLIë¥¼ í™œìš©í•œ AI ì—ì´ì „íŠ¸ ì‹œê°í™”, ë””ë²„ê¹…, ìƒí˜¸ì‘ìš© ì™„ë²½ ë§ˆìŠ¤í„° ê°€ì´ë“œ"
seo_title: "LangGraph Studio ì™„ì „ ê°€ì´ë“œ - AI ì—ì´ì „íŠ¸ IDE macOS ì„¤ì¹˜ë¶€í„° ì‹¤ìŠµê¹Œì§€ - Thaki Cloud"
seo_description: "LangGraph Studio CLI ì„¤ì¹˜, AI ì—ì´ì „íŠ¸ ê°œë°œ, ê·¸ë˜í”„ ì‹œê°í™”, ë””ë²„ê¹… ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ì•Œì•„ë³´ì„¸ìš”. macOS ì‹¤í–‰ í…ŒìŠ¤íŠ¸ í¬í•¨"
date: 2025-08-21
last_modified_at: 2025-08-21
categories:
  - tutorials
tags:
  - LangGraph
  - AIì—ì´ì „íŠ¸
  - ë””ë²„ê¹…
  - ì‹œê°í™”
  - CLI
  - macOS
  - ê°œë°œë„êµ¬
  - IDE
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
toc_icon: "cog"
toc_sticky: true
canonical_url: "https://thakicloud.github.io/tutorials/langgraph-studio-complete-guide/"
reading_time: true
---

â±ï¸ **ì˜ˆìƒ ì½ê¸° ì‹œê°„**: 15ë¶„

## ì„œë¡ 

LangGraph StudioëŠ” AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ê°œë°œ, ì‹œê°í™”, ë””ë²„ê¹…ì„ ìœ„í•œ ì „ë¬¸ IDEì…ë‹ˆë‹¤. ë³µì¡í•œ ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ë¥¼ ê·¸ë˜í”„ í˜•íƒœë¡œ ì‹œê°í™”í•˜ê³ , ì‹¤ì‹œê°„ìœ¼ë¡œ ìƒíƒœë¥¼ ì¶”ì í•˜ë©°, ì‹œê°„ ì—¬í–‰ ë””ë²„ê¹…ê¹Œì§€ ì§€ì›í•˜ëŠ” ê°•ë ¥í•œ ë„êµ¬ì…ë‹ˆë‹¤.

### ì£¼ìš” íŠ¹ì§•

- **ê·¸ë˜í”„ ì•„í‚¤í…ì²˜ ì‹œê°í™”**: ì—ì´ì „íŠ¸ì˜ ë…¸ë“œì™€ ì—£ì§€ë¥¼ ì§ê´€ì ìœ¼ë¡œ í‘œí˜„
- **ì‹¤ì‹œê°„ ìƒí˜¸ì‘ìš©**: ì—ì´ì „íŠ¸ì™€ ì§ì ‘ ì±„íŒ…í•˜ë©° ë™ì‘ í™•ì¸
- **ì‹œê°„ ì—¬í–‰ ë””ë²„ê¹…**: ê³¼ê±° ìƒíƒœë¡œ ëŒì•„ê°€ì„œ ë””ë²„ê¹… ê°€ëŠ¥
- **LangSmith í†µí•©**: ì¶”ì , í‰ê°€, í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ì§€ì›
- **ë©€í‹° í”Œë«í¼**: macOS, Windows, Linux ì§€ì›

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

- Python 3.8+
- Node.js 16+ (ì„ íƒì‚¬í•­)
- Docker & Docker Compose
- macOS, Windows, ë˜ëŠ” Linux

## LangGraph CLI ì„¤ì¹˜ ë° ì„¤ì •

### Python í™˜ê²½ ì„¤ì •

ë¨¼ì € Python ê°€ìƒí™˜ê²½ì„ ìƒì„±í•˜ê³  LangGraph CLIë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤:

```bash
# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python -m venv venv
source venv/bin/activate  # macOS/Linux
# venv\Scripts\activate  # Windows

# LangGraph CLI ì„¤ì¹˜
pip install -U langgraph-cli
```

### ì„¤ì¹˜ í™•ì¸

```bash
# CLI ë²„ì „ í™•ì¸
langgraph --version

# ë„ì›€ë§ í™•ì¸
langgraph --help
```

### Docker í™˜ê²½ í™•ì¸

LangGraph StudioëŠ” Dockerë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ Dockerê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤:

```bash
# Docker ìƒíƒœ í™•ì¸
docker --version
docker-compose --version

# Docker ë°ëª¬ ì‹¤í–‰ í™•ì¸
docker ps
```

## ì²« ë²ˆì§¸ LangGraph í”„ë¡œì íŠ¸ ìƒì„±

### í”„ë¡œì íŠ¸ ì´ˆê¸°í™”

```bash
# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir my-langgraph-agent
cd my-langgraph-agent

# LangGraph í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
langgraph new
```

### ê¸°ë³¸ ì—ì´ì „íŠ¸ ì½”ë“œ ì‘ì„±

{% raw %}
```python
# main.py
from typing import TypedDict, Literal
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

class GraphState(TypedDict):
    messages: list
    current_step: str

def start_node(state: GraphState) -> GraphState:
    """ì‹œì‘ ë…¸ë“œ"""
    return {
        "messages": state["messages"] + ["Starting agent..."],
        "current_step": "processing"
    }

def process_node(state: GraphState) -> GraphState:
    """ì²˜ë¦¬ ë…¸ë“œ"""
    return {
        "messages": state["messages"] + ["Processing user request..."],
        "current_step": "responding"
    }

def response_node(state: GraphState) -> GraphState:
    """ì‘ë‹µ ë…¸ë“œ"""
    return {
        "messages": state["messages"] + ["Generating response..."],
        "current_step": "complete"
    }

def should_continue(state: GraphState) -> Literal["process", "end"]:
    """ì¡°ê±´ë¶€ ë¼ìš°íŒ…"""
    if state["current_step"] == "processing":
        return "process"
    return "end"

# ê·¸ë˜í”„ ìƒì„±
def create_graph():
    workflow = StateGraph(GraphState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("start", start_node)
    workflow.add_node("process", process_node)
    workflow.add_node("response", response_node)
    
    # ì—£ì§€ ì¶”ê°€
    workflow.set_entry_point("start")
    workflow.add_conditional_edges(
        "start",
        should_continue,
        {
            "process": "process",
            "end": END
        }
    )
    workflow.add_edge("process", "response")
    workflow.add_edge("response", END)
    
    # ë©”ëª¨ë¦¬ ì €ì¥ì†Œ ì„¤ì •
    memory = MemorySaver()
    return workflow.compile(checkpointer=memory)

# ê·¸ë˜í”„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
app = create_graph()
```
{% endraw %}

### LangGraph ì„¤ì • íŒŒì¼ ìƒì„±

```json
{
  "dependencies": ["langgraph", "langchain", "python-dotenv"],
  "graphs": {
    "agent": "./main.py:app"
  },
  "env": ".env"
}
```

## LangGraph Studio ì‹¤í–‰

### ê°œë°œ ëª¨ë“œ ì‹¤í–‰

```bash
# ê°œë°œ ì„œë²„ ì‹œì‘
langgraph dev

# ë˜ëŠ” íŠ¹ì • ê·¸ë˜í”„ ì§€ì •
langgraph dev --graph agent
```

### í”„ë¡œë•ì…˜ ëª¨ë“œ ì‹¤í–‰

```bash
# í”„ë¡œë•ì…˜ ì„œë²„ ì‹œì‘
langgraph up

# ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
langgraph up -d
```

### Studio ì ‘ì†

ë¸Œë¼ìš°ì €ì—ì„œ ë‹¤ìŒ URLë¡œ ì ‘ì†:
- ê°œë°œ ëª¨ë“œ: `http://localhost:8123`
- Studio ì›¹ ì¸í„°í˜ì´ìŠ¤: `https://smith.langchain.com/studio`

## Graph ëª¨ë“œ ì‚¬ìš©ë²•

### ê·¸ë˜í”„ ì‹œê°í™”

1. **ë…¸ë“œ ë·°**: ê° ë…¸ë“œì˜ ì‹¤í–‰ ìƒíƒœì™€ ë°ì´í„° í™•ì¸
2. **ì—£ì§€ ë·°**: ë…¸ë“œ ê°„ ì—°ê²° ê´€ê³„ì™€ ì¡°ê±´ë¶€ ë¼ìš°íŒ… í‘œì‹œ
3. **ìƒíƒœ ë·°**: í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœì™€ ë³€ìˆ˜ ê°’ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

### ë””ë²„ê¹… ê¸°ëŠ¥

#### ì‹œê°„ ì—¬í–‰ ë””ë²„ê¹…

```python
# íŠ¹ì • ì‹œì ìœ¼ë¡œ ë˜ëŒë¦¬ê¸°
from langgraph.checkpoint import Checkpoint

def debug_at_step(thread_id: str, step: int):
    """íŠ¹ì • ìŠ¤í…ì—ì„œ ìƒíƒœ í™•ì¸"""
    checkpoints = app.get_state_history(
        {"configurable": {"thread_id": thread_id}}
    )
    
    for i, checkpoint in enumerate(checkpoints):
        if i == step:
            return checkpoint.values
```

#### ë¸Œë ˆì´í¬í¬ì¸íŠ¸ ì„¤ì •

```python
def breakpoint_node(state: GraphState) -> GraphState:
    """ë””ë²„ê¹…ìš© ë¸Œë ˆì´í¬í¬ì¸íŠ¸"""
    import pdb; pdb.set_trace()  # ë””ë²„ê±° í™œì„±í™”
    return state
```

### ìƒíƒœ ê´€ë¦¬

#### ìƒíƒœ ì¶”ì 

```python
# ìƒíƒœ ë³€í™” ë¡œê¹…
def log_state_change(state: GraphState, node_name: str):
    print(f"Node: {node_name}")
    print(f"Current State: {state}")
    print(f"Messages: {len(state.get('messages', []))}")
    print("-" * 40)
```

#### ë©”ëª¨ë¦¬ ê´€ë¦¬

```python
from langgraph.checkpoint.sqlite import SqliteSaver

# SQLite ê¸°ë°˜ ì˜êµ¬ ì €ì¥
def create_persistent_graph():
    memory = SqliteSaver.from_conn_string("checkpoints.sqlite")
    return workflow.compile(checkpointer=memory)
```

## Chat ëª¨ë“œ ì‚¬ìš©ë²•

### ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ì„¤ì •

Chat ëª¨ë“œëŠ” `MessagesState`ë¥¼ í™•ì¥í•˜ëŠ” ìƒíƒœì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤:

```python
from langchain_core.messages import BaseMessage
from langgraph.graph.message import add_messages

class ChatState(TypedDict):
    messages: list[BaseMessage]
    
def create_chat_graph():
    workflow = StateGraph(ChatState)
    
    def chat_node(state: ChatState) -> ChatState:
        # ì±„íŒ… ë¡œì§ êµ¬í˜„
        return {"messages": add_messages(state["messages"], response)}
    
    workflow.add_node("chat", chat_node)
    workflow.set_entry_point("chat")
    workflow.add_edge("chat", END)
    
    return workflow.compile()
```

### ëŒ€í™” ê´€ë¦¬

#### ìŠ¤ë ˆë“œ ê´€ë¦¬

```python
# ìƒˆ ëŒ€í™” ìŠ¤ë ˆë“œ ìƒì„±
thread_config = {"configurable": {"thread_id": "user-123"}}

# ë©”ì‹œì§€ ì „ì†¡
response = app.invoke(
    {"messages": [("user", "Hello, how are you?")]},
    config=thread_config
)
```

#### ëŒ€í™” íˆìŠ¤í† ë¦¬

```python
# ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ
def get_conversation_history(thread_id: str):
    state = app.get_state({"configurable": {"thread_id": thread_id}})
    return state.values.get("messages", [])
```

## ê³ ê¸‰ ê¸°ëŠ¥ í™œìš©

### LangSmith í†µí•©

#### ì¶”ì  ì„¤ì •

```python
import os
from langsmith import Client

# LangSmith ì„¤ì •
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = "my-langgraph-project"
os.environ["LANGCHAIN_API_KEY"] = "your-api-key"

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = Client()
```

#### ì‹¤í—˜ ì‹¤í–‰

```python
# ë°ì´í„°ì…‹ ìƒì„±
dataset = client.create_dataset(
    dataset_name="test-conversations",
    description="Test dataset for agent evaluation"
)

# í‰ê°€ ì‹¤í–‰
def run_evaluation():
    results = []
    for example in dataset.examples:
        response = app.invoke(
            {"messages": [("user", example.inputs["message"])]},
            config={"configurable": {"thread_id": f"eval-{example.id}"}}
        )
        results.append({
            "input": example.inputs,
            "output": response,
            "expected": example.outputs
        })
    return results
```

### ì»¤ìŠ¤í…€ ë„êµ¬ í†µí•©

```python
from langchain_core.tools import tool

@tool
def calculator(expression: str) -> str:
    """ê°„ë‹¨í•œ ê³„ì‚°ê¸° ë„êµ¬"""
    try:
        result = eval(expression)  # ì‹¤ì œ ì‚¬ìš©ì‹œ ë³´ì•ˆ ì£¼ì˜
        return str(result)
    except Exception as e:
        return f"Error: {str(e)}"

# ë„êµ¬ë¥¼ ê·¸ë˜í”„ì— ì¶”ê°€
def tool_node(state: GraphState) -> GraphState:
    # ë„êµ¬ í˜¸ì¶œ ë¡œì§
    return state
```

## ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### Safari ì—°ê²° ë¬¸ì œ

Safariì—ì„œ localhost HTTP íŠ¸ë˜í”½ì´ ì°¨ë‹¨ë˜ëŠ” ê²½ìš°:

#### í•´ê²°ë°©ë²• 1: Cloudflare Tunnel ì‚¬ìš©

```bash
# Cloudflare í„°ë„ë¡œ ì‹¤í–‰
langgraph dev --tunnel
```

#### í•´ê²°ë°©ë²• 2: Chrome/Edge ì‚¬ìš©

```bash
# ì¼ë°˜ ê°œë°œ ëª¨ë“œë¡œ ì‹¤í–‰ í›„ Chromeì—ì„œ ì ‘ì†
langgraph dev
```

### Docker ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ

ë¡œì»¬ ì„œë¹„ìŠ¤(Ollama, Chroma ë“±) ì ‘ê·¼ ì‹œ:

```python
# localhost ëŒ€ì‹  host.docker.internal ì‚¬ìš©
OLLAMA_URL = "http://host.docker.internal:11434"
CHROMA_URL = "http://host.docker.internal:8000"
```

### ë¹Œë“œ ì˜ì¡´ì„± ë¬¸ì œ

ë„¤ì´í‹°ë¸Œ ì˜ì¡´ì„±ì´ í•„ìš”í•œ ê²½ìš° `langgraph.json`ì— ì¶”ê°€:

```json
{
  "dockerfile_lines": [
    "RUN apt-get update && apt-get install -y gcc build-essential"
  ]
}
```

### ê·¸ë˜í”„ ì—£ì§€ ë¬¸ì œ

ì¡°ê±´ë¶€ ì—£ì§€ê°€ ì˜¬ë°”ë¥´ê²Œ í‘œì‹œë˜ì§€ ì•ŠëŠ” ê²½ìš°:

```python
# ëª…ì‹œì  ê²½ë¡œ ë§¤í•‘ ì‚¬ìš©
graph.add_conditional_edges(
    "router_node",
    routing_function,
    {
        True: "target_node_a",
        False: "target_node_b"
    }
)

# ë˜ëŠ” íƒ€ì… íŒíŠ¸ ì‚¬ìš©
def routing_function(state: GraphState) -> Literal["node_a", "node_b"]:
    if state['condition']:
        return "node_a"
    else:
        return "node_b"
```

## ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€

### 1. ê³ ê° ì„œë¹„ìŠ¤ ë´‡

```python
class CustomerServiceState(TypedDict):
    messages: list[BaseMessage]
    customer_id: str
    issue_type: str
    resolved: bool

def create_customer_service_bot():
    workflow = StateGraph(CustomerServiceState)
    
    def classify_issue(state):
        # ì´ìŠˆ ë¶„ë¥˜ ë¡œì§
        return state
    
    def route_to_agent(state):
        # ì ì ˆí•œ ì—ì´ì „íŠ¸ë¡œ ë¼ìš°íŒ…
        return state
    
    def resolve_issue(state):
        # ì´ìŠˆ í•´ê²° ë¡œì§
        return state
    
    # ì›Œí¬í”Œë¡œìš° êµ¬ì„±...
    return workflow.compile()
```

### 2. ë¬¸ì„œ ë¶„ì„ íŒŒì´í”„ë¼ì¸

```python
class DocumentAnalysisState(TypedDict):
    document: str
    summary: str
    key_points: list
    questions: list

def create_document_analyzer():
    workflow = StateGraph(DocumentAnalysisState)
    
    def extract_text(state):
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
        return state
    
    def summarize(state):
        # ìš”ì•½ ìƒì„±
        return state
    
    def extract_key_points(state):
        # í•µì‹¬ í¬ì¸íŠ¸ ì¶”ì¶œ
        return state
    
    def generate_questions(state):
        # ì§ˆë¬¸ ìƒì„±
        return state
    
    # ì›Œí¬í”Œë¡œìš° êµ¬ì„±...
    return workflow.compile()
```

## ì„±ëŠ¥ ìµœì í™”

### ë©”ëª¨ë¦¬ ìµœì í™”

```python
# ì²´í¬í¬ì¸íŠ¸ ì •ë¦¬
def cleanup_old_checkpoints(days_old: int = 7):
    cutoff_date = datetime.now() - timedelta(days=days_old)
    # ì˜¤ë˜ëœ ì²´í¬í¬ì¸íŠ¸ ì‚­ì œ ë¡œì§
    pass

# ë°°ì¹˜ ì²˜ë¦¬
def process_batch(messages: list, batch_size: int = 10):
    for i in range(0, len(messages), batch_size):
        batch = messages[i:i + batch_size]
        # ë°°ì¹˜ ì²˜ë¦¬ ë¡œì§
        yield batch
```

### ìºì‹± ì „ëµ

```python
from functools import lru_cache

@lru_cache(maxsize=128)
def expensive_computation(input_data: str) -> str:
    # ë¹„ìš©ì´ í° ì—°ì‚°ì„ ìºì‹±
    return result
```

## í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ë° ìë™í™”

### í™˜ê²½ ì„¤ì • ìë™í™” ìŠ¤í¬ë¦½íŠ¸

ì™„ì „í•œ LangGraph Studio í™˜ê²½ì„ ìë™ìœ¼ë¡œ ì„¤ì •í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤:

```bash
#!/bin/bash
# íŒŒì¼: setup-langgraph-studio-aliases.sh

# LangGraph Studio ì™„ì „ ì„¤ì¹˜ ë° ì„¤ì •
curl -sSL https://raw.githubusercontent.com/your-repo/setup-langgraph-studio.sh | bash
```

### macOS ì‹¤í–‰ í…ŒìŠ¤íŠ¸ ê²°ê³¼

ì‹¤ì œ macOS í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸í•œ ê²°ê³¼:

```bash
# ì‹œìŠ¤í…œ ì •ë³´
$ uname -a
Darwin MacBook-Pro.local 21.6.0 Darwin Kernel Version 21.6.0 arm64

# Python í™˜ê²½
$ python3 --version
Python 3.12.8

# LangGraph CLI ì„¤ì¹˜ ë° ë²„ì „ í™•ì¸
$ pip install -U "langgraph-cli[inmem]"
Successfully installed langgraph-cli-0.3.7 langgraph-api-0.2.137

$ langgraph --version
LangGraph CLI, version 0.3.7

# ìƒ˜í”Œ í”„ë¡œì íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
$ printf ".\n1\n1\n" | langgraph new
âœ… New project created at /path/to/demo-agent

# ê°œë°œ ì„œë²„ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
$ langgraph dev --no-browser --port 8123
INFO: Starting LangGraph API server
ğŸš€ API: http://127.0.0.1:8123
ğŸ¨ Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:8123
ğŸ“š API Docs: http://127.0.0.1:8123/docs
```

### zshrc Aliases ê°€ì´ë“œ

ë‹¤ìŒ aliasesë¥¼ `~/.zshrc`ì— ì¶”ê°€í•˜ë©´ LangGraph Studio ì‘ì—…ì´ í›¨ì”¬ í¸í•´ì§‘ë‹ˆë‹¤:

```bash
# LangGraph Studio Aliases
export LANGGRAPH_PROJECT_DIR="$HOME/langgraph-projects"

# í™˜ê²½ ê´€ë¦¬
alias lg-env="cd $LANGGRAPH_PROJECT_DIR && source venv/bin/activate"
alias lg-install="pip install -U \"langgraph-cli[inmem]\""
alias lg-version="langgraph --version"

# í”„ë¡œì íŠ¸ ê´€ë¦¬
alias lg-new="langgraph new"
alias lg-init="mkdir -p langgraph-project && cd langgraph-project && python3 -m venv venv && source venv/bin/activate && pip install -U \"langgraph-cli[inmem]\""

# ê°œë°œ ì„œë²„
alias lg-dev="langgraph dev --no-browser"
alias lg-dev-tunnel="langgraph dev --tunnel"
alias lg-up="langgraph up"

# Studio ì ‘ì†
alias lg-studio="open https://smith.langchain.com/studio/"
alias lg-docs="open http://localhost:8123/docs"

# ìœ í‹¸ë¦¬í‹°
alias lg-check="docker ps && python3 --version && langgraph --version"
alias lg-help="echo \"LangGraph Studio ëª…ë ¹ì–´ ëª©ë¡ ì¶œë ¥\""
```

### ì„¤ì • ì ìš©

```bash
# zshrc ì¬ë¡œë“œ
source ~/.zshrc

# í™˜ê²½ í™•ì¸
lg-check

# ìƒˆ í”„ë¡œì íŠ¸ ìƒì„±
lg-init

# ê°œë°œ ì„œë²„ ì‹œì‘
lg-dev

# Studio ì›¹ ì¸í„°í˜ì´ìŠ¤ ì—´ê¸°
lg-studio
```

### ê°œë°œ í™˜ê²½ ë²„ì „ ì •ë³´

í…ŒìŠ¤íŠ¸ ì™„ë£Œëœ í™˜ê²½:
- **OS**: macOS 14.0+ (Apple Silicon)
- **Python**: 3.12.8
- **Node.js**: 22.16.0 (ì„ íƒì‚¬í•­)
- **Docker**: 24.0.0+
- **LangGraph CLI**: 0.3.7
- **LangGraph API**: 0.2.137

## ê²°ë¡ 

LangGraph StudioëŠ” AI ì—ì´ì „íŠ¸ ê°œë°œì˜ ë³µì¡ì„±ì„ í¬ê²Œ ì¤„ì—¬ì£¼ëŠ” ê°•ë ¥í•œ ë„êµ¬ì…ë‹ˆë‹¤. ê·¸ë˜í”„ ì‹œê°í™”ë¥¼ í†µí•´ ì—ì´ì „íŠ¸ì˜ ë™ì‘ì„ ì§ê´€ì ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆê³ , ì‹œê°„ ì—¬í–‰ ë””ë²„ê¹…ìœ¼ë¡œ ë³µì¡í•œ ìƒíƒœ ë³€í™”ë¥¼ ì¶”ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### í•µì‹¬ í¬ì¸íŠ¸

1. **ì‹œê°ì  ê°œë°œ**: ë³µì¡í•œ ì—ì´ì „íŠ¸ ë¡œì§ì„ ê·¸ë˜í”„ë¡œ í‘œí˜„
2. **ì‹¤ì‹œê°„ ë””ë²„ê¹…**: ìƒíƒœ ë³€í™”ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§
3. **í†µí•© í™˜ê²½**: LangSmithì™€ì˜ seamless í†µí•©ìœ¼ë¡œ ì „ì²´ ML íŒŒì´í”„ë¼ì¸ ê´€ë¦¬
4. **ë©€í‹° í”Œë«í¼**: ë‹¤ì–‘í•œ ê°œë°œ í™˜ê²½ì—ì„œ ì¼ê´€ëœ ê²½í—˜ ì œê³µ

### ë‹¤ìŒ ë‹¨ê³„

- ë³µì¡í•œ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶•
- í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œì˜ ëª¨ë‹ˆí„°ë§ ë° ê´€ë¦¬
- ì»¤ìŠ¤í…€ ë„êµ¬ ë° í†µí•© ê°œë°œ
- ì„±ëŠ¥ ìµœì í™” ë° ìŠ¤ì¼€ì¼ë§

LangGraph Studioë¥¼ í™œìš©í•˜ì—¬ ë”ìš± íš¨ìœ¨ì ì´ê³  ê°•ë ¥í•œ AI ì—ì´ì „íŠ¸ë¥¼ ê°œë°œí•´ë³´ì„¸ìš”!

## ì°¸ê³  ìë£Œ

- [LangGraph Studio ê³µì‹ ë¬¸ì„œ](https://github.com/langchain-ai/langgraph-studio)
- [LangGraph Platform ê°€ì´ë“œ](https://langchain-ai.github.io/langgraph/)
- [LangSmith ë¬¸ì„œ](https://docs.smith.langchain.com/)
- [Docker Compose ê°€ì´ë“œ](https://docs.docker.com/compose/)
