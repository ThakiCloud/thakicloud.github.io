---
title: "Amazon S3 Vectorsë¡œ RAG ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¶•í•˜ê¸°: ë²¡í„° ìŠ¤í† ë¦¬ì§€ë¶€í„° ê²€ìƒ‰ê¹Œì§€"
excerpt: "AWSì˜ ìƒˆë¡œìš´ S3 Vectorsë¥¼ í™œìš©í•˜ì—¬ ë¹„ìš© íš¨ìœ¨ì ì¸ RAG ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•˜ëŠ” ì™„ì „ ê°€ì´ë“œ. ì‹¤ì œ ì½”ë“œ ì˜ˆì œì™€ ìµœì í™” íŒ í¬í•¨"
seo_title: "Amazon S3 Vectors RAG ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¶• ì™„ì „ ê°€ì´ë“œ - Thaki Cloud"
seo_description: "AWS S3 Vectorsë¥¼ í™œìš©í•œ RAG ì‹œìŠ¤í…œ êµ¬ì¶•. ë²¡í„° ì„ë² ë”© ìƒì„±ë¶€í„° ì˜ë¯¸ì  ê²€ìƒ‰ê¹Œì§€ ì‹¤ë¬´ ì¤‘ì‹¬ íŠœí† ë¦¬ì–¼"
date: 2025-07-16
last_modified_at: 2025-07-16
categories:
  - tutorials
  - llmops
tags:
  - amazon-s3-vectors
  - aws
  - rag
  - vector-database
  - amazon-bedrock
  - embedding
  - semantic-search
  - python
  - boto3
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
toc_icon: "cog"
toc_sticky: true
canonical_url: "https://thakicloud.github.io/tutorials/amazon-s3-vectors-tutorial/"
reading_time: true
---

â±ï¸ **ì˜ˆìƒ ì½ê¸° ì‹œê°„**: 15ë¶„

## ì„œë¡ 

AWSê°€ 2025ë…„ 7ì›”ì— ë°œí‘œí•œ **Amazon S3 Vectors**ëŠ” í´ë¼ìš°ë“œì—ì„œ ìµœì´ˆë¡œ ë„¤ì´í‹°ë¸Œ ë²¡í„° ì§€ì›ì„ ì œê³µí•˜ëŠ” ìŠ¤í† ë¦¬ì§€ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. ê¸°ì¡´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ëŒ€ë¹„ ìµœëŒ€ 90%ì˜ ë¹„ìš© ì ˆê°ê³¼ ì„œë¸Œì´ˆ ì¿¼ë¦¬ ì„±ëŠ¥ì„ ì œê³µí•˜ë©°, RAG(Retrieval-Augmented Generation) ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¶•ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” S3 Vectorsë¥¼ í™œìš©í•˜ì—¬ ì‹¤ì œ RAG ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•˜ëŠ” ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ë‹¤ë¤„ë³´ê² ìŠµë‹ˆë‹¤.

### í•™ìŠµ ëª©í‘œ

- Amazon S3 Vectorsì˜ í•µì‹¬ ê°œë… ì´í•´
- ë²¡í„° ë²„í‚·ê³¼ ì¸ë±ìŠ¤ ìƒì„± ë° ê´€ë¦¬
- Amazon Bedrockê³¼ ì—°ë™í•œ ì„ë² ë”© ìƒì„±
- ì˜ë¯¸ì  ê²€ìƒ‰ êµ¬í˜„
- OpenSearchì™€ì˜ í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜ êµ¬ì„±
- ì„±ëŠ¥ ìµœì í™” ë° ë¹„ìš© ê´€ë¦¬

## 1. í™˜ê²½ ì„¤ì • ë° ì¤€ë¹„ì‚¬í•­

### 1.1 AWS ê³„ì • ë° ê¶Œí•œ ì„¤ì •

S3 VectorsëŠ” í˜„ì¬ í”„ë¦¬ë·° ë‹¨ê³„ë¡œ ë‹¤ìŒ ë¦¬ì „ì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤:

```bash
# ì§€ì› ë¦¬ì „
us-east-1      # US East (N. Virginia)
us-east-2      # US East (Ohio)
us-west-2      # US West (Oregon)
eu-central-1   # Europe (Frankfurt)
ap-southeast-2 # Asia Pacific (Sydney)
```

í•„ìš”í•œ IAM ê¶Œí•œ:

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "s3vectors:*",
                "bedrock:InvokeModel",
                "bedrock:CreateKnowledgeBase",
                "bedrock:GetKnowledgeBase"
            ],
            "Resource": "*"
        }
    ]
}
```

### 1.2 Python í™˜ê²½ ì„¤ì •

```bash
# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv s3vectors_env
source s3vectors_env/bin/activate  # macOS/Linux
# s3vectors_env\Scripts\activate    # Windows

# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install boto3 python-dotenv pandas numpy
```

requirements.txt:

```txt
boto3>=1.34.0
python-dotenv>=1.0.0
pandas>=2.0.0
numpy>=1.24.0
requests>=2.31.0
```

### 1.3 AWS ìê²© ì¦ëª… ì„¤ì •

`.env` íŒŒì¼ ìƒì„±:

```bash
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
AWS_DEFAULT_REGION=us-west-2
S3_VECTOR_BUCKET_NAME=my-rag-vector-bucket
S3_VECTOR_INDEX_NAME=document-embeddings
```

## 2. S3 Vectors ê¸°ë³¸ ì„¤ì •

### 2.1 ë²¡í„° ë²„í‚· ìƒì„±

```python
import boto3
import json
import os
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class S3VectorManager:
    def __init__(self, region_name='us-west-2'):
        self.region_name = region_name
        self.s3vectors = boto3.client('s3vectors', region_name=region_name)
        self.bedrock = boto3.client('bedrock-runtime', region_name=region_name)
        
    def create_vector_bucket(self, bucket_name):
        """ë²¡í„° ë²„í‚· ìƒì„±"""
        try:
            response = self.s3vectors.create_vector_bucket(
                vectorBucketName=bucket_name,
                encryption={
                    'type': 'SSE-S3'  # ë˜ëŠ” 'SSE-KMS'
                }
            )
            print(f"ë²¡í„° ë²„í‚· '{bucket_name}' ìƒì„± ì™„ë£Œ")
            return response
        except Exception as e:
            print(f"ë²¡í„° ë²„í‚· ìƒì„± ì˜¤ë¥˜: {e}")
            return None
    
    def create_vector_index(self, bucket_name, index_name, dimensions=1024, distance_metric='cosine'):
        """ë²¡í„° ì¸ë±ìŠ¤ ìƒì„±"""
        try:
            response = self.s3vectors.create_vector_index(
                vectorBucketName=bucket_name,
                indexName=index_name,
                dimensions=dimensions,
                distanceMetric=distance_metric  # 'cosine' ë˜ëŠ” 'euclidean'
            )
            print(f"ë²¡í„° ì¸ë±ìŠ¤ '{index_name}' ìƒì„± ì™„ë£Œ (ì°¨ì›: {dimensions})")
            return response
        except Exception as e:
            print(f"ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± ì˜¤ë¥˜: {e}")
            return None

# ì‚¬ìš© ì˜ˆì œ
vector_manager = S3VectorManager()

# ë²¡í„° ë²„í‚· ìƒì„±
bucket_name = os.getenv('S3_VECTOR_BUCKET_NAME')
vector_manager.create_vector_bucket(bucket_name)

# ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± (Amazon Titan Embedding V2ëŠ” 1024ì°¨ì›)
index_name = os.getenv('S3_VECTOR_INDEX_NAME')
vector_manager.create_vector_index(bucket_name, index_name, dimensions=1024)
```

### 2.2 ì½˜ì†”ì—ì„œ ë²¡í„° ë²„í‚· ìƒì„±

AWS ì½˜ì†”ì„ í†µí•œ ìƒì„±ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤:

1. **S3 ì½˜ì†”** â†’ **Vector buckets** â†’ **Create vector bucket**
2. ë²„í‚· ì´ë¦„ ì…ë ¥ ë° ì•”í˜¸í™” ë°©ì‹ ì„ íƒ
3. **Vector index** ìƒì„± ì‹œ ì°¨ì› ìˆ˜ì™€ ê±°ë¦¬ ë©”íŠ¸ë¦­ ì„¤ì •

## 3. ë¬¸ì„œ ì„ë² ë”© ìƒì„± ë° ì €ì¥

### 3.1 Amazon Bedrockì„ í™œìš©í•œ ì„ë² ë”© ìƒì„±

```python
class DocumentEmbedder:
    def __init__(self, vector_manager):
        self.vector_manager = vector_manager
        self.bedrock = vector_manager.bedrock
        
    def generate_embedding(self, text, model_id='amazon.titan-embed-text-v2:0'):
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„° ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        try:
            body = json.dumps({"inputText": text})
            response = self.bedrock.invoke_model(
                modelId=model_id,
                body=body
            )
            response_body = json.loads(response['body'].read())
            return response_body['embedding']
        except Exception as e:
            print(f"ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {e}")
            return None
    
    def process_documents(self, documents):
        """ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ì—¬ ì„ë² ë”© ìƒì„±"""
        embeddings = []
        for i, doc in enumerate(documents):
            embedding = self.generate_embedding(doc['content'])
            if embedding:
                embeddings.append({
                    'key': f'doc_{i}',
                    'content': doc['content'],
                    'metadata': doc.get('metadata', {}),
                    'embedding': embedding
                })
        return embeddings

# ìƒ˜í”Œ ë¬¸ì„œ ë°ì´í„°
sample_documents = [
    {
        'content': 'Amazon S3 VectorsëŠ” í´ë¼ìš°ë“œì—ì„œ ìµœì´ˆë¡œ ë„¤ì´í‹°ë¸Œ ë²¡í„° ì§€ì›ì„ ì œê³µí•˜ëŠ” ìŠ¤í† ë¦¬ì§€ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.',
        'metadata': {
            'title': 'S3 Vectors ì†Œê°œ',
            'category': 'aws-service',
            'created_date': '2025-07-15'
        }
    },
    {
        'content': 'RAGëŠ” Retrieval-Augmented Generationì˜ ì¤„ì„ë§ë¡œ, ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰í•˜ì—¬ ë” ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” AI ê¸°ë²•ì…ë‹ˆë‹¤.',
        'metadata': {
            'title': 'RAG ê°œë…',
            'category': 'ai-concept',
            'created_date': '2025-07-16'
        }
    },
    {
        'content': 'ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ëŠ” ê³ ì°¨ì› ë²¡í„° ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì €ì¥í•˜ê³  ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” íŠ¹ë³„í•œ ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.',
        'metadata': {
            'title': 'ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤',
            'category': 'database',
            'created_date': '2025-07-16'
        }
    }
]

# ì„ë² ë”© ìƒì„±
embedder = DocumentEmbedder(vector_manager)
document_embeddings = embedder.process_documents(sample_documents)
print(f"ì´ {len(document_embeddings)}ê°œ ë¬¸ì„œì˜ ì„ë² ë”© ìƒì„± ì™„ë£Œ")
```

### 3.2 ë²¡í„° ë°ì´í„° ì €ì¥

```python
class VectorStorage:
    def __init__(self, vector_manager):
        self.vector_manager = vector_manager
        self.s3vectors = vector_manager.s3vectors
    
    def store_vectors(self, bucket_name, index_name, embeddings, batch_size=100):
        """ë²¡í„° ë°ì´í„°ë¥¼ ë°°ì¹˜ë¡œ ì €ì¥"""
        total_stored = 0
        
        for i in range(0, len(embeddings), batch_size):
            batch = embeddings[i:i + batch_size]
            vectors = []
            
            for emb in batch:
                vector_data = {
                    'key': emb['key'],
                    'data': {'float32': emb['embedding']},
                    'metadata': {
                        'content': emb['content'][:500],  # ë©”íƒ€ë°ì´í„° í¬ê¸° ì œí•œ
                        **emb['metadata']
                    }
                }
                vectors.append(vector_data)
            
            try:
                response = self.s3vectors.put_vectors(
                    vectorBucketName=bucket_name,
                    indexName=index_name,
                    vectors=vectors
                )
                total_stored += len(vectors)
                print(f"ë°°ì¹˜ ì €ì¥ ì™„ë£Œ: {len(vectors)}ê°œ ë²¡í„°")
                
            except Exception as e:
                print(f"ë²¡í„° ì €ì¥ ì˜¤ë¥˜: {e}")
        
        print(f"ì´ {total_stored}ê°œ ë²¡í„° ì €ì¥ ì™„ë£Œ")
        return total_stored

# ë²¡í„° ì €ì¥
storage = VectorStorage(vector_manager)
bucket_name = os.getenv('S3_VECTOR_BUCKET_NAME')
index_name = os.getenv('S3_VECTOR_INDEX_NAME')

storage.store_vectors(bucket_name, index_name, document_embeddings)
```

## 4. ì˜ë¯¸ì  ê²€ìƒ‰ êµ¬í˜„

### 4.1 ê²€ìƒ‰ í´ë˜ìŠ¤ êµ¬í˜„

```python
class SemanticSearch:
    def __init__(self, vector_manager, embedder):
        self.vector_manager = vector_manager
        self.embedder = embedder
        self.s3vectors = vector_manager.s3vectors
    
    def search(self, query, bucket_name, index_name, top_k=5, filter_conditions=None):
        """ì˜ë¯¸ì  ê²€ìƒ‰ ìˆ˜í–‰"""
        # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_embedding = self.embedder.generate_embedding(query)
        if not query_embedding:
            return []
        
        # 2. ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰
        search_params = {
            'vectorBucketName': bucket_name,
            'indexName': index_name,
            'queryVector': {'float32': query_embedding},
            'topK': top_k,
            'returnDistance': True,
            'returnMetadata': True
        }
        
        # 3. í•„í„° ì¡°ê±´ ì¶”ê°€
        if filter_conditions:
            search_params['filter'] = filter_conditions
        
        try:
            response = self.s3vectors.query_vectors(**search_params)
            return self._format_results(response.get('vectors', []))
        except Exception as e:
            print(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def _format_results(self, raw_results):
        """ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…"""
        formatted_results = []
        for result in raw_results:
            formatted_result = {
                'key': result.get('key'),
                'distance': result.get('distance'),
                'similarity_score': 1 - result.get('distance', 1),  # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
                'content': result.get('metadata', {}).get('content', ''),
                'metadata': {k: v for k, v in result.get('metadata', {}).items() 
                           if k != 'content'}
            }
            formatted_results.append(formatted_result)
        
        return sorted(formatted_results, key=lambda x: x['similarity_score'], reverse=True)

# ê²€ìƒ‰ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
search_system = SemanticSearch(vector_manager, embedder)

# ê²€ìƒ‰ ì˜ˆì œ
search_queries = [
    "AWSì˜ ìƒˆë¡œìš´ ë²¡í„° ìŠ¤í† ë¦¬ì§€ ì„œë¹„ìŠ¤ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
    "ì¸ê³µì§€ëŠ¥ì—ì„œ ì™¸ë¶€ ì§€ì‹ì„ í™œìš©í•˜ëŠ” ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "ê³ ì°¨ì› ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì €ì¥í•˜ëŠ” ë°©ë²•"
]

for query in search_queries:
    print(f"\nğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
    results = search_system.search(
        query=query,
        bucket_name=bucket_name,
        index_name=index_name,
        top_k=3
    )
    
    for i, result in enumerate(results, 1):
        print(f"{i}. ìœ ì‚¬ë„: {result['similarity_score']:.3f}")
        print(f"   ë‚´ìš©: {result['content'][:100]}...")
        print(f"   ë©”íƒ€ë°ì´í„°: {result['metadata']}")
```

### 4.2 í•„í„°ë§ì„ í™œìš©í•œ ê³ ê¸‰ ê²€ìƒ‰

```python
class AdvancedSearch(SemanticSearch):
    def search_by_category(self, query, bucket_name, index_name, category, top_k=5):
        """ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰"""
        filter_conditions = {'category': category}
        return self.search(query, bucket_name, index_name, top_k, filter_conditions)
    
    def search_by_date_range(self, query, bucket_name, index_name, start_date, end_date, top_k=5):
        """ë‚ ì§œ ë²”ìœ„ë³„ ê²€ìƒ‰"""
        filter_conditions = {
            'created_date': {
                'gte': start_date,
                'lte': end_date
            }
        }
        return self.search(query, bucket_name, index_name, top_k, filter_conditions)
    
    def multi_modal_search(self, text_query, metadata_filters, bucket_name, index_name, top_k=5):
        """ë‹¤ì¤‘ ì¡°ê±´ ê²€ìƒ‰"""
        return self.search(text_query, bucket_name, index_name, top_k, metadata_filters)

# ê³ ê¸‰ ê²€ìƒ‰ ì‚¬ìš© ì˜ˆì œ
advanced_search = AdvancedSearch(vector_manager, embedder)

# ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰
aws_results = advanced_search.search_by_category(
    query="í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ ì„œë¹„ìŠ¤",
    bucket_name=bucket_name,
    index_name=index_name,
    category="aws-service"
)

print("ğŸ·ï¸ AWS ì„œë¹„ìŠ¤ ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ ê²°ê³¼:")
for result in aws_results:
    print(f"- {result['content'][:80]}... (ìœ ì‚¬ë„: {result['similarity_score']:.3f})")
```

## 5. RAG ì‹œìŠ¤í…œ êµ¬ì¶•

### 5.1 ì™„ì „í•œ RAG íŒŒì´í”„ë¼ì¸

```python
import openai  # ë˜ëŠ” ë‹¤ë¥¸ LLM í´ë¼ì´ì–¸íŠ¸

class RAGSystem:
    def __init__(self, vector_manager, embedder, llm_client=None):
        self.search_system = SemanticSearch(vector_manager, embedder)
        self.llm_client = llm_client
        self.bucket_name = os.getenv('S3_VECTOR_BUCKET_NAME')
        self.index_name = os.getenv('S3_VECTOR_INDEX_NAME')
    
    def retrieve_context(self, query, top_k=3, min_similarity=0.7):
        """ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰"""
        results = self.search_system.search(
            query=query,
            bucket_name=self.bucket_name,
            index_name=self.index_name,
            top_k=top_k
        )
        
        # ìœ ì‚¬ë„ê°€ ë‚®ì€ ê²°ê³¼ í•„í„°ë§
        filtered_results = [r for r in results if r['similarity_score'] >= min_similarity]
        
        return filtered_results
    
    def generate_answer(self, query, context_docs):
        """ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±"""
        if not context_docs:
            return "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ì»¨í…ìŠ¤íŠ¸ ë¬¸ì„œë“¤ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ ê²°í•©
        context_text = "\n\n".join([doc['content'] for doc in context_docs])
        
        # Amazon Bedrockì˜ Claude ë˜ëŠ” ë‹¤ë¥¸ ëª¨ë¸ ì‚¬ìš©
        prompt = f"""
ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:

ì»¨í…ìŠ¤íŠ¸:
{context_text}

ì§ˆë¬¸: {query}

ë‹µë³€:
"""
        
        try:
            # Amazon Bedrock Claude ëª¨ë¸ ì‚¬ìš© ì˜ˆì œ
            response = self.llm_client.invoke_model(
                modelId='anthropic.claude-3-sonnet-20240229-v1:0',
                body=json.dumps({
                    'anthropic_version': 'bedrock-2023-05-31',
                    'max_tokens': 1000,
                    'messages': [
                        {
                            'role': 'user',
                            'content': prompt
                        }
                    ]
                })
            )
            
            response_body = json.loads(response['body'].read())
            return response_body['content'][0]['text']
            
        except Exception as e:
            print(f"ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
            return "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def ask(self, question):
        """ì§ˆë¬¸-ë‹µë³€ ì „ì²´ íŒŒì´í”„ë¼ì¸"""
        print(f"â“ ì§ˆë¬¸: {question}")
        
        # 1. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        context_docs = self.retrieve_context(question)
        print(f"ğŸ“š ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(context_docs)}")
        
        # 2. ë‹µë³€ ìƒì„±
        if context_docs:
            answer = self.generate_answer(question, context_docs)
            
            # 3. ê²°ê³¼ ì¶œë ¥
            print(f"ğŸ’¡ ë‹µë³€: {answer}")
            print("\nğŸ“– ì°¸ì¡° ë¬¸ì„œ:")
            for i, doc in enumerate(context_docs, 1):
                print(f"{i}. {doc['content'][:100]}... (ìœ ì‚¬ë„: {doc['similarity_score']:.3f})")
        else:
            print("âŒ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return {
            'question': question,
            'context_docs': context_docs,
            'answer': answer if context_docs else None
        }

# RAG ì‹œìŠ¤í…œ ì‚¬ìš© ì˜ˆì œ
bedrock_client = boto3.client('bedrock-runtime', region_name='us-west-2')
rag_system = RAGSystem(vector_manager, embedder, bedrock_client)

# ì§ˆë¬¸-ë‹µë³€ í…ŒìŠ¤íŠ¸
test_questions = [
    "S3 Vectorsì˜ ì£¼ìš” ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "RAG ì‹œìŠ¤í…œì€ ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜ìš”?",
    "ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì˜ íŠ¹ì§•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”."
]

for question in test_questions:
    print("\n" + "="*50)
    rag_system.ask(question)
```

## 6. Amazon Bedrock Knowledge Bases ì—°ë™

### 6.1 Knowledge Base ìƒì„±

```python
class BedrockKnowledgeBase:
    def __init__(self, region_name='us-west-2'):
        self.bedrock_agent = boto3.client('bedrock-agent', region_name=region_name)
        self.region_name = region_name
    
    def create_knowledge_base(self, kb_name, s3_bucket_name, vector_index_name, role_arn):
        """Bedrock Knowledge Base ìƒì„±"""
        try:
            response = self.bedrock_agent.create_knowledge_base(
                name=kb_name,
                description=f"S3 Vectorsë¥¼ í™œìš©í•œ {kb_name} ì§€ì‹ ë² ì´ìŠ¤",
                roleArn=role_arn,
                knowledgeBaseConfiguration={
                    'type': 'VECTOR',
                    'vectorKnowledgeBaseConfiguration': {
                        'embeddingModelArn': f'arn:aws:bedrock:{self.region_name}::foundation-model/amazon.titan-embed-text-v2:0'
                    }
                },
                storageConfiguration={
                    'type': 'S3_VECTORS',
                    's3VectorsConfiguration': {
                        'bucketName': s3_bucket_name,
                        'indexName': vector_index_name
                    }
                }
            )
            
            kb_id = response['knowledgeBase']['knowledgeBaseId']
            print(f"Knowledge Base ìƒì„± ì™„ë£Œ: {kb_id}")
            return kb_id
            
        except Exception as e:
            print(f"Knowledge Base ìƒì„± ì˜¤ë¥˜: {e}")
            return None
    
    def create_data_source(self, kb_id, data_source_name, s3_data_uri):
        """ë°ì´í„° ì†ŒìŠ¤ ìƒì„±"""
        try:
            response = self.bedrock_agent.create_data_source(
                knowledgeBaseId=kb_id,
                name=data_source_name,
                dataSourceConfiguration={
                    'type': 'S3',
                    's3Configuration': {
                        'bucketArn': s3_data_uri,
                        'inclusionPrefixes': ['documents/']
                    }
                }
            )
            
            ds_id = response['dataSource']['dataSourceId']
            print(f"ë°ì´í„° ì†ŒìŠ¤ ìƒì„± ì™„ë£Œ: {ds_id}")
            return ds_id
            
        except Exception as e:
            print(f"ë°ì´í„° ì†ŒìŠ¤ ìƒì„± ì˜¤ë¥˜: {e}")
            return None

# Knowledge Base ìƒì„± ì˜ˆì œ
kb_manager = BedrockKnowledgeBase()

# í•„ìš”í•œ ì •ë³´ ì„¤ì •
kb_name = "S3Vectors-RAG-KB"
role_arn = "arn:aws:iam::123456789012:role/BedrockKnowledgeBaseRole"
s3_data_uri = "arn:aws:s3:::my-documents-bucket"

kb_id = kb_manager.create_knowledge_base(
    kb_name=kb_name,
    s3_bucket_name=bucket_name,
    vector_index_name=index_name,
    role_arn=role_arn
)
```

### 6.2 Knowledge Baseë¥¼ í™œìš©í•œ ê²€ìƒ‰

```python
class BedrockRAG:
    def __init__(self, knowledge_base_id, region_name='us-west-2'):
        self.bedrock_agent_runtime = boto3.client('bedrock-agent-runtime', region_name=region_name)
        self.knowledge_base_id = knowledge_base_id
    
    def retrieve_and_generate(self, query, model_arn=None):
        """Knowledge Baseë¥¼ í†µí•œ ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±"""
        if not model_arn:
            model_arn = "arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0"
        
        try:
            response = self.bedrock_agent_runtime.retrieve_and_generate(
                input={
                    'text': query
                },
                retrieveAndGenerateConfiguration={
                    'type': 'KNOWLEDGE_BASE',
                    'knowledgeBaseConfiguration': {
                        'knowledgeBaseId': self.knowledge_base_id,
                        'modelArn': model_arn,
                        'retrievalConfiguration': {
                            'vectorSearchConfiguration': {
                                'numberOfResults': 5
                            }
                        }
                    }
                }
            )
            
            return {
                'answer': response['output']['text'],
                'citations': response.get('citations', []),
                'session_id': response.get('sessionId')
            }
            
        except Exception as e:
            print(f"ê²€ìƒ‰ ë° ìƒì„± ì˜¤ë¥˜: {e}")
            return None

# Bedrock RAG ì‚¬ìš© ì˜ˆì œ
if kb_id:
    bedrock_rag = BedrockRAG(kb_id)
    
    result = bedrock_rag.retrieve_and_generate(
        "S3 Vectorsì˜ ë¹„ìš© íš¨ìœ¨ì„±ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”."
    )
    
    if result:
        print(f"ë‹µë³€: {result['answer']}")
        print(f"ì¸ìš©: {len(result['citations'])}ê°œ ë¬¸ì„œ ì°¸ì¡°")
```

## 7. OpenSearchì™€ì˜ í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜

### 7.1 í‹°ì–´ë“œ ìŠ¤í† ë¦¬ì§€ ì „ëµ

```python
class HybridVectorStorage:
    def __init__(self, s3_vector_manager, opensearch_client):
        self.s3_vectors = s3_vector_manager
        self.opensearch = opensearch_client
        
    def tier_data(self, bucket_name, index_name, hot_threshold_days=30):
        """ë°ì´í„° í‹°ì–´ë§: ìµœê·¼ ë°ì´í„°ëŠ” OpenSearch, ì˜¤ë˜ëœ ë°ì´í„°ëŠ” S3 Vectors"""
        
        # 1. S3 Vectorsì—ì„œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
        vectors = self.s3_vectors.list_vectors(
            vectorBucketName=bucket_name,
            indexName=index_name
        )
        
        hot_vectors = []
        cold_vectors = []
        current_date = datetime.now()
        
        for vector in vectors:
            created_date = datetime.fromisoformat(
                vector['metadata'].get('created_date', '2025-01-01')
            )
            days_old = (current_date - created_date).days
            
            if days_old <= hot_threshold_days:
                hot_vectors.append(vector)
            else:
                cold_vectors.append(vector)
        
        print(f"Hot ë°ì´í„°: {len(hot_vectors)}ê°œ, Cold ë°ì´í„°: {len(cold_vectors)}ê°œ")
        
        # 2. Hot ë°ì´í„°ë¥¼ OpenSearchë¡œ ì´ë™
        if hot_vectors:
            self._export_to_opensearch(hot_vectors)
        
        return len(hot_vectors), len(cold_vectors)
    
    def _export_to_opensearch(self, vectors):
        """S3 Vectorsì—ì„œ OpenSearchë¡œ ë°ì´í„° ë‚´ë³´ë‚´ê¸°"""
        # AWS ì½˜ì†”ì˜ "Export to OpenSearch" ê¸°ëŠ¥ ì‚¬ìš©í•˜ê±°ë‚˜
        # APIë¥¼ í†µí•œ í”„ë¡œê·¸ë˜ë° ë°©ì‹ êµ¬í˜„
        pass
    
    def hybrid_search(self, query, use_hot_data=True, use_cold_data=True):
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: OpenSearch + S3 Vectors"""
        results = []
        
        if use_hot_data:
            # OpenSearchì—ì„œ ì‹¤ì‹œê°„ ê²€ìƒ‰ (ë‚®ì€ ì§€ì—°ì‹œê°„)
            hot_results = self._search_opensearch(query)
            results.extend(hot_results)
        
        if use_cold_data:
            # S3 Vectorsì—ì„œ ê²€ìƒ‰ (ë¹„ìš© íš¨ìœ¨ì )
            cold_results = self._search_s3_vectors(query)
            results.extend(cold_results)
        
        # ê²°ê³¼ ë³‘í•© ë° ì •ë ¬
        return sorted(results, key=lambda x: x['score'], reverse=True)
```

### 7.2 S3 Vectors ë°ì´í„°ë¥¼ OpenSearchë¡œ ë‚´ë³´ë‚´ê¸°

```python
def export_to_opensearch_console():
    """AWS ì½˜ì†”ì„ í†µí•œ OpenSearch ë‚´ë³´ë‚´ê¸° ê°€ì´ë“œ"""
    steps = """
    1. S3 ì½˜ì†”ì—ì„œ Vector buckets ì„ íƒ
    2. í•´ë‹¹ ë²¡í„° ì¸ë±ìŠ¤ ì„ íƒ
    3. "Advanced search export" â†’ "Export to OpenSearch" í´ë¦­
    4. OpenSearch Service Integration ì½˜ì†”ì—ì„œ ì„¤ì •:
       - Source: S3 vector index
       - Target: OpenSearch Serverless collection
       - Service access role ì„¤ì •
    5. "Export" ë²„íŠ¼ í´ë¦­í•˜ì—¬ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘
    """
    return steps

# í”„ë¡œê·¸ë˜ë° ë°©ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸° ëª¨ë‹ˆí„°ë§
class OpenSearchExportMonitor:
    def __init__(self, region_name='us-west-2'):
        self.opensearch_serverless = boto3.client('opensearchserverless', region_name=region_name)
    
    def monitor_import_jobs(self, collection_id):
        """OpenSearch ê°€ì ¸ì˜¤ê¸° ì‘ì—… ëª¨ë‹ˆí„°ë§"""
        try:
            response = self.opensearch_serverless.list_vpc_endpoints()
            # ì‹¤ì œ import job ìƒíƒœ í™•ì¸ ë¡œì§
            print("Import job ëª¨ë‹ˆí„°ë§ ì¤‘...")
            return response
        except Exception as e:
            print(f"ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
            return None
```

## 8. ì„±ëŠ¥ ìµœì í™” ë° ëª¨ë‹ˆí„°ë§

### 8.1 ë²¡í„° ì¸ë±ìŠ¤ ìµœì í™”

```python
class VectorIndexOptimizer:
    def __init__(self, s3vectors_client):
        self.s3vectors = s3vectors_client
    
    def optimize_index(self, bucket_name, index_name):
        """ë²¡í„° ì¸ë±ìŠ¤ ìµœì í™”"""
        try:
            # S3 VectorsëŠ” ìë™ìœ¼ë¡œ ìµœì í™”í•˜ì§€ë§Œ, ìˆ˜ë™ ìµœì í™”ë„ ê°€ëŠ¥
            response = self.s3vectors.optimize_vector_index(
                vectorBucketName=bucket_name,
                indexName=index_name
            )
            print("ì¸ë±ìŠ¤ ìµœì í™” ì™„ë£Œ")
            return response
        except Exception as e:
            print(f"ìµœì í™” ì˜¤ë¥˜: {e}")
            return None
    
    def get_index_stats(self, bucket_name, index_name):
        """ì¸ë±ìŠ¤ í†µê³„ ì¡°íšŒ"""
        try:
            response = self.s3vectors.describe_vector_index(
                vectorBucketName=bucket_name,
                indexName=index_name
            )
            
            stats = {
                'vector_count': response.get('vectorCount', 0),
                'dimensions': response.get('dimensions', 0),
                'storage_size': response.get('storageSize', 0),
                'last_modified': response.get('lastModified'),
                'distance_metric': response.get('distanceMetric')
            }
            
            return stats
        except Exception as e:
            print(f"í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return None

# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤
class PerformanceMonitor:
    def __init__(self, vector_manager):
        self.vector_manager = vector_manager
        self.metrics = []
    
    def benchmark_search(self, queries, bucket_name, index_name, num_runs=5):
        """ê²€ìƒ‰ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
        import time
        
        search_system = SemanticSearch(self.vector_manager, embedder)
        
        for query in queries:
            total_time = 0
            for _ in range(num_runs):
                start_time = time.time()
                results = search_system.search(query, bucket_name, index_name)
                end_time = time.time()
                total_time += (end_time - start_time)
            
            avg_time = total_time / num_runs
            self.metrics.append({
                'query': query,
                'avg_response_time': avg_time,
                'results_count': len(results)
            })
            
            print(f"ì¿¼ë¦¬: '{query[:50]}...'")
            print(f"í‰ê·  ì‘ë‹µì‹œê°„: {avg_time:.3f}ì´ˆ")
            print(f"ê²°ê³¼ ìˆ˜: {len(results)}")
            print("-" * 50)
    
    def get_performance_report(self):
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        if not self.metrics:
            return "ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        avg_response_time = sum(m['avg_response_time'] for m in self.metrics) / len(self.metrics)
        total_queries = len(self.metrics)
        
        report = f"""
ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë¦¬í¬íŠ¸
===================
ì´ ì¿¼ë¦¬ ìˆ˜: {total_queries}
í‰ê·  ì‘ë‹µì‹œê°„: {avg_response_time:.3f}ì´ˆ
ìµœê³  ì‘ë‹µì‹œê°„: {max(m['avg_response_time'] for m in self.metrics):.3f}ì´ˆ
ìµœì € ì‘ë‹µì‹œê°„: {min(m['avg_response_time'] for m in self.metrics):.3f}ì´ˆ
"""
        return report

# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
performance_monitor = PerformanceMonitor(vector_manager)

test_queries = [
    "Amazon S3 Vectorsì˜ íŠ¹ì§•",
    "í´ë¼ìš°ë“œ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë¹„ìš©",
    "RAG ì‹œìŠ¤í…œ êµ¬ì¶• ë°©ë²•"
]

performance_monitor.benchmark_search(
    queries=test_queries,
    bucket_name=bucket_name,
    index_name=index_name
)

print(performance_monitor.get_performance_report())
```

### 8.2 ë¹„ìš© ìµœì í™” ì „ëµ

```python
class CostOptimizer:
    def __init__(self, s3vectors_client):
        self.s3vectors = s3vectors_client
    
    def analyze_storage_costs(self, bucket_name, index_name):
        """ìŠ¤í† ë¦¬ì§€ ë¹„ìš© ë¶„ì„"""
        stats = self.get_storage_stats(bucket_name, index_name)
        
        # S3 Vectors ê°€ê²© ì¶”ì • (ì‹¤ì œ ê°€ê²©ì€ AWS ê³µì‹ ë¬¸ì„œ ì°¸ì¡°)
        storage_gb = stats['storage_size'] / (1024**3)  # GB ë‹¨ìœ„
        estimated_monthly_cost = storage_gb * 0.023  # ì˜ˆì‹œ ê°€ê²©
        
        cost_analysis = {
            'storage_size_gb': storage_gb,
            'vector_count': stats['vector_count'],
            'estimated_monthly_cost_usd': estimated_monthly_cost,
            'cost_per_vector': estimated_monthly_cost / max(stats['vector_count'], 1)
        }
        
        return cost_analysis
    
    def suggest_optimizations(self, cost_analysis):
        """ë¹„ìš© ìµœì í™” ì œì•ˆ"""
        suggestions = []
        
        if cost_analysis['storage_size_gb'] > 100:
            suggestions.append("ëŒ€ìš©ëŸ‰ ë°ì´í„° â†’ OpenSearch í‹°ì–´ë§ ê³ ë ¤")
        
        if cost_analysis['cost_per_vector'] > 0.001:
            suggestions.append("ë²¡í„° ì°¨ì› ìˆ˜ ìµœì í™” ê²€í† ")
            
        if cost_analysis['vector_count'] < 10000:
            suggestions.append("ë°°ì¹˜ ì—…ë¡œë“œë¡œ ë¹„ìš© íš¨ìœ¨ì„± ê°œì„ ")
        
        return suggestions

# ë¹„ìš© ë¶„ì„ ì‹¤í–‰
cost_optimizer = CostOptimizer(vector_manager.s3vectors)
# cost_analysis = cost_optimizer.analyze_storage_costs(bucket_name, index_name)
# suggestions = cost_optimizer.suggest_optimizations(cost_analysis)
```

## 9. ì‹¤ì œ ìš´ì˜ ì‹œë‚˜ë¦¬ì˜¤

### 9.1 ëŒ€ê·œëª¨ ë¬¸ì„œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

```python
import asyncio
import concurrent.futures
from typing import List, Dict

class ProductionRAGPipeline:
    def __init__(self, vector_manager, max_workers=10):
        self.vector_manager = vector_manager
        self.embedder = DocumentEmbedder(vector_manager)
        self.max_workers = max_workers
        
    def process_document_batch(self, documents: List[Dict], batch_size: int = 100):
        """ëŒ€ê·œëª¨ ë¬¸ì„œ ë°°ì¹˜ ì²˜ë¦¬"""
        total_docs = len(documents)
        processed = 0
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = []
            
            for i in range(0, total_docs, batch_size):
                batch = documents[i:i + batch_size]
                future = executor.submit(self._process_batch, batch)
                futures.append(future)
            
            for future in concurrent.futures.as_completed(futures):
                try:
                    batch_result = future.result()
                    processed += len(batch_result)
                    print(f"ì§„í–‰ë¥ : {processed}/{total_docs} ({processed/total_docs*100:.1f}%)")
                except Exception as e:
                    print(f"ë°°ì¹˜ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        
        return processed
    
    def _process_batch(self, batch: List[Dict]) -> List[Dict]:
        """ë‹¨ì¼ ë°°ì¹˜ ì²˜ë¦¬"""
        # 1. ì„ë² ë”© ìƒì„±
        embeddings = self.embedder.process_documents(batch)
        
        # 2. ë²¡í„° ì €ì¥
        storage = VectorStorage(self.vector_manager)
        storage.store_vectors(
            bucket_name=os.getenv('S3_VECTOR_BUCKET_NAME'),
            index_name=os.getenv('S3_VECTOR_INDEX_NAME'),
            embeddings=embeddings
        )
        
        return embeddings

# ìš´ì˜ íŒŒì´í”„ë¼ì¸ ì‚¬ìš© ì˜ˆì œ
production_pipeline = ProductionRAGPipeline(vector_manager)

# ëŒ€ê·œëª¨ ë¬¸ì„œ ì‹œë®¬ë ˆì´ì…˜
large_document_set = []
for i in range(1000):  # 1000ê°œ ë¬¸ì„œ ì‹œë®¬ë ˆì´ì…˜
    large_document_set.append({
        'content': f"ë¬¸ì„œ {i}: Amazon S3 Vectorsë¥¼ í™œìš©í•œ ë‹¤ì–‘í•œ ì‚¬ìš© ì‚¬ë¡€ì™€ ìµœì í™” ë°©ë²•ì— ëŒ€í•œ ë‚´ìš©ì…ë‹ˆë‹¤.",
        'metadata': {
            'doc_id': f'doc_{i}',
            'category': 'technical' if i % 2 == 0 else 'business',
            'created_date': '2025-07-16'
        }
    })

# processed_count = production_pipeline.process_document_batch(large_document_set)
# print(f"ì´ {processed_count}ê°œ ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ")
```

### 9.2 ì‹¤ì‹œê°„ RAG ì„œë¹„ìŠ¤

```python
from flask import Flask, request, jsonify
import logging

app = Flask(__name__)
logging.basicConfig(level=logging.INFO)

class RAGService:
    def __init__(self):
        self.vector_manager = S3VectorManager()
        self.embedder = DocumentEmbedder(self.vector_manager)
        self.search_system = SemanticSearch(self.vector_manager, self.embedder)
        self.bucket_name = os.getenv('S3_VECTOR_BUCKET_NAME')
        self.index_name = os.getenv('S3_VECTOR_INDEX_NAME')
    
    def search_documents(self, query: str, top_k: int = 5, filters: Dict = None):
        """ë¬¸ì„œ ê²€ìƒ‰ API"""
        try:
            results = self.search_system.search(
                query=query,
                bucket_name=self.bucket_name,
                index_name=self.index_name,
                top_k=top_k,
                filter_conditions=filters
            )
            
            return {
                'status': 'success',
                'query': query,
                'results': results,
                'count': len(results)
            }
        except Exception as e:
            logging.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return {
                'status': 'error',
                'message': str(e)
            }

# RAG ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
rag_service = RAGService()

@app.route('/search', methods=['POST'])
def search_endpoint():
    """ê²€ìƒ‰ API ì—”ë“œí¬ì¸íŠ¸"""
    data = request.get_json()
    
    if not data or 'query' not in data:
        return jsonify({'error': 'query íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤'}), 400
    
    query = data['query']
    top_k = data.get('top_k', 5)
    filters = data.get('filters', None)
    
    result = rag_service.search_documents(query, top_k, filters)
    return jsonify(result)

@app.route('/health', methods=['GET'])
def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return jsonify({'status': 'healthy', 'service': 'S3 Vectors RAG API'})

if __name__ == '__main__':
    # ê°œë°œ ì„œë²„ ì‹¤í–‰
    # app.run(debug=True, host='0.0.0.0', port=5000)
    print("RAG ì„œë¹„ìŠ¤ ì¤€ë¹„ ì™„ë£Œ")
```

## 10. íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ë° ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

### 10.1 ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°

```python
class TroubleshootingGuide:
    @staticmethod
    def diagnose_search_performance():
        """ê²€ìƒ‰ ì„±ëŠ¥ ì§„ë‹¨"""
        checklist = """
        ê²€ìƒ‰ ì„±ëŠ¥ ì§„ë‹¨ ì²´í¬ë¦¬ìŠ¤íŠ¸:
        
        1. ë²¡í„° ì°¨ì› ìˆ˜ í™•ì¸
           - 1024ì°¨ì› (Titan V2) ê¶Œì¥
           - ë„ˆë¬´ ë†’ì€ ì°¨ì›ì€ ì„±ëŠ¥ ì €í•˜ ìœ ë°œ
        
        2. ì¸ë±ìŠ¤ í¬ê¸° ìµœì í™”
           - 10Mê°œ ì´í•˜ ë²¡í„° ê¶Œì¥
           - ëŒ€ìš©ëŸ‰ ë°ì´í„°ëŠ” ì—¬ëŸ¬ ì¸ë±ìŠ¤ë¡œ ë¶„í• 
        
        3. ê±°ë¦¬ ë©”íŠ¸ë¦­ ì„ íƒ
           - í…ìŠ¤íŠ¸ ì„ë² ë”©: Cosine ê¶Œì¥
           - ì´ë¯¸ì§€ ì„ë² ë”©: Euclidean ê³ ë ¤
        
        4. í•„í„° ì¡°ê±´ ìµœì í™”
           - ì¸ë±ì‹±ëœ ë©”íƒ€ë°ì´í„° í•„ë“œ ì‚¬ìš©
           - ë³µì¡í•œ ì¤‘ì²© ì¡°ê±´ í”¼í•˜ê¸°
        
        5. ë°°ì¹˜ í¬ê¸° ì¡°ì •
           - ê²€ìƒ‰: top_k 10-50 ê¶Œì¥
           - ì €ì¥: 100-1000 ë²¡í„°/ë°°ì¹˜
        """
        return checklist
    
    @staticmethod
    def common_errors():
        """ì¼ë°˜ì ì¸ ì˜¤ë¥˜ ë° í•´ê²°ë°©ë²•"""
        errors = {
            'DimensionMismatch': {
                'description': 'ë²¡í„° ì°¨ì› ë¶ˆì¼ì¹˜',
                'solution': 'ì¸ë±ìŠ¤ ìƒì„± ì‹œ ì§€ì •í•œ ì°¨ì›ê³¼ ë²¡í„° ì°¨ì› ì¼ì¹˜ í™•ì¸'
            },
            'InvalidDistanceMetric': {
                'description': 'ì˜ëª»ëœ ê±°ë¦¬ ë©”íŠ¸ë¦­',
                'solution': 'cosine ë˜ëŠ” euclideanë§Œ ì§€ì›'
            },
            'VectorSizeLimit': {
                'description': 'ë²¡í„° í¬ê¸° ì œí•œ ì´ˆê³¼',
                'solution': 'ë²¡í„°ë‹¹ ìµœëŒ€ 40KB, ë©”íƒ€ë°ì´í„° ìµœëŒ€ 40KB'
            },
            'IndexNotFound': {
                'description': 'ì¸ë±ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ',
                'solution': 'ë²¡í„° ë²„í‚·ê³¼ ì¸ë±ìŠ¤ ì´ë¦„ ì •í™•ì„± í™•ì¸'
            }
        }
        return errors

# ì§„ë‹¨ ë„êµ¬ ì‚¬ìš©
troubleshoot = TroubleshootingGuide()
print(troubleshoot.diagnose_search_performance())
```

### 10.2 ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

```python
class BestPractices:
    @staticmethod
    def embedding_optimization():
        """ì„ë² ë”© ìµœì í™” ê°€ì´ë“œ"""
        return """
        ì„ë² ë”© ìµœì í™” ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤:
        
        1. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
           - ì¼ê´€ëœ ì–¸ì–´ ë° í˜•ì‹ ìœ ì§€
           - HTML íƒœê·¸, íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
           - ì ì ˆí•œ ì²­í‚¹ (500-1000ì)
        
        2. ëª¨ë¸ ì„ íƒ
           - ë‹¤êµ­ì–´: Titan Text Multilingual
           - ì˜ì–´ ì „ìš©: Titan Text V2
           - ì½”ë“œ: CodeT5+ ì„ë² ë”©
        
        3. ë©”íƒ€ë°ì´í„° ì„¤ê³„
           - ê²€ìƒ‰ì— í•„ìš”í•œ í•„ë“œë§Œ í¬í•¨
           - ì¸ë±ì‹± ê°€ëŠ¥í•œ ë‹¨ìˆœ íƒ€ì… ì‚¬ìš©
           - í¬ê¸° ì œí•œ (40KB) ì¤€ìˆ˜
        
        4. ë°°ì¹˜ ì²˜ë¦¬
           - ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œ (10-20)
           - ì¬ì‹œë„ ë¡œì§ êµ¬í˜„
           - ì§„í–‰ë¥  ì¶”ì  ì‹œìŠ¤í…œ
        """
    
    @staticmethod
    def security_guidelines():
        """ë³´ì•ˆ ê°€ì´ë“œë¼ì¸"""
        return """
        ë³´ì•ˆ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤:
        
        1. IAM ê¶Œí•œ ìµœì†Œí™”
           - í•„ìš”í•œ S3 Vectors ì‘ì—…ë§Œ í—ˆìš©
           - ë¦¬ì†ŒìŠ¤ë³„ ì„¸ë¶„í™”ëœ ê¶Œí•œ
        
        2. ì•”í˜¸í™”
           - SSE-S3 ë˜ëŠ” SSE-KMS ì‚¬ìš©
           - ì „ì†¡ ì¤‘ ì•”í˜¸í™” (HTTPS)
        
        3. ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆ
           - VPC ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
           - í”„ë¼ì´ë¹— ì„œë¸Œë„· ë°°ì¹˜
        
        4. ê°ì‚¬ ë° ëª¨ë‹ˆí„°ë§
           - CloudTrail ë¡œê¹… í™œì„±í™”
           - CloudWatch ë©”íŠ¸ë¦­ ì„¤ì •
        """

# ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ ê°€ì´ë“œ ì¶œë ¥
best_practices = BestPractices()
print(best_practices.embedding_optimization())
print(best_practices.security_guidelines())
```

## ê²°ë¡ 

Amazon S3 VectorsëŠ” ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì˜ ë³µì¡ì„±ê³¼ ë¹„ìš© ë¶€ë‹´ì„ í•´ê²°í•˜ëŠ” í˜ì‹ ì ì¸ í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. ì´ íŠœí† ë¦¬ì–¼ì—ì„œ ë‹¤ë£¬ ë‚´ìš©ì„ í†µí•´:

### ì£¼ìš” ì„±ê³¼

1. **ë¹„ìš© íš¨ìœ¨ì„±**: ê¸°ì¡´ ë²¡í„° DB ëŒ€ë¹„ ìµœëŒ€ 90% ë¹„ìš© ì ˆê°
2. **í™•ì¥ì„±**: ìˆ˜ì²œë§Œ ê°œ ë²¡í„°ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ì²˜ë¦¬
3. **í†µí•©ì„±**: AWS AI/ML ì„œë¹„ìŠ¤ì™€ ì™„ë²½í•œ ì—°ë™
4. **ì„±ëŠ¥**: ì„œë¸Œì´ˆ ì¿¼ë¦¬ ì‘ë‹µ ì‹œê°„ ë‹¬ì„±

### ì‹¤ì œ ì ìš© ë¶„ì•¼

- **ê¸°ì—… ì§€ì‹ ê´€ë¦¬**: ì‚¬ë‚´ ë¬¸ì„œ ê²€ìƒ‰ ë° Q&A ì‹œìŠ¤í…œ
- **ê³ ê° ì§€ì›**: ìë™í™”ëœ FAQ ë° ì±—ë´‡ êµ¬ì¶•
- **ì½˜í…ì¸  ì¶”ì²œ**: ê°œì¸í™”ëœ ì½˜í…ì¸  ë°œê²¬ ì—”ì§„
- **ì—°êµ¬ ê°œë°œ**: ë…¼ë¬¸ ë° íŠ¹í—ˆ ìœ ì‚¬ë„ ê²€ìƒ‰

### ë‹¤ìŒ ë‹¨ê³„

1. **í”„ë¦¬ë·° ì‹ ì²­**: AWS ì½˜ì†”ì—ì„œ S3 Vectors í”„ë¦¬ë·° í™œì„±í™”
2. **íŒŒì¼ëŸ¿ í”„ë¡œì íŠ¸**: ì†Œê·œëª¨ ë°ì´í„°ì…‹ìœ¼ë¡œ POC ì§„í–‰
3. **ì„±ëŠ¥ í…ŒìŠ¤íŠ¸**: ì‹¤ì œ ì›Œí¬ë¡œë“œë¡œ ë²¤ì¹˜ë§ˆí¬ ìˆ˜í–‰
4. **ìš´ì˜ í™˜ê²½ êµ¬ì¶•**: ëª¨ë‹ˆí„°ë§ ë° ìë™í™” ì‹œìŠ¤í…œ êµ¬ì¶•

Amazon S3 VectorsëŠ” AI ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì¸í”„ë¼ ë³µì¡ì„±ì„ í¬ê²Œ ì¤„ì´ë©´ì„œë„ ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ì„±ëŠ¥ê³¼ í™•ì¥ì„±ì„ ì œê³µí•©ë‹ˆë‹¤. íŠ¹íˆ RAG ì‹œìŠ¤í…œ êµ¬ì¶•ì— ìˆì–´ì„œ ê²Œì„ ì²´ì¸ì €ê°€ ë  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.

---

**ì°¸ê³  ìë£Œ**
- [Amazon S3 Vectors ê³µì‹ ë°œí‘œ](https://aws.amazon.com/ko/blogs/aws/introducing-amazon-s3-vectors-first-cloud-storage-with-native-vector-support-at-scale/)
- [S3 Vectors ì‚¬ìš©ì ê°€ì´ë“œ](https://docs.aws.amazon.com/s3/latest/userguide/s3-vectors.html)
- [Bedrock Knowledge Bases ë¬¸ì„œ](https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base.html)
- [S3 Vectors Embed CLI](https://github.com/aws-samples/s3-vectors-embed-cli) 