---
title: "LandingAI Agentic Document Extraction ì™„ì „ ê°€ì´ë“œ: AI ê¸°ë°˜ PDF ë° ì´ë¯¸ì§€ ì²˜ë¦¬"
excerpt: "LandingAIì˜ Agentic Document Extraction ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•œ ì§€ëŠ¥í˜• ë¬¸ì„œ ì²˜ë¦¬ ë§ˆìŠ¤í„°í•˜ê¸°. ë³µì¡í•œ PDF, ì´ë¯¸ì§€, ë¬¸ì„œì—ì„œ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ AI íŒŒì‹± ê¸°ëŠ¥ìœ¼ë¡œ ì¶”ì¶œí•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤."
seo_title: "LandingAI Agentic Document Extraction íŠœí† ë¦¬ì–¼ - AI PDF ì²˜ë¦¬ ê°€ì´ë“œ"
seo_description: "LandingAIì˜ Agentic Document Extraction ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•œ AI ê¸°ë°˜ ë¬¸ì„œ ì²˜ë¦¬ ë°©ë²•ì„ í•™ìŠµí•˜ì„¸ìš”. ì½”ë“œ ì˜ˆì œ, ë°°ì¹˜ ì²˜ë¦¬, ì‹œê°í™” ê¸°ëŠ¥ì„ í¬í•¨í•œ ì™„ì „í•œ íŠœí† ë¦¬ì–¼ì…ë‹ˆë‹¤."
date: 2025-10-05
categories:
  - tutorials
tags:
  - LandingAI
  - ë¬¸ì„œì¶”ì¶œ
  - AI
  - PDFì²˜ë¦¬
  - Python
  - ë¨¸ì‹ ëŸ¬ë‹
  - OCR
  - ë¬¸ì„œAI
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
lang: ko
permalink: /ko/tutorials/agentic-document-extraction-complete-guide/
canonical_url: "https://thakicloud.github.io/ko/tutorials/agentic-document-extraction-complete-guide/"
---

â±ï¸ **ì˜ˆìƒ ì½ê¸° ì‹œê°„**: 12ë¶„

## ì†Œê°œ

ì˜¤ëŠ˜ë‚  ë°ì´í„° ì¤‘ì‹¬ ì„¸ìƒì—ì„œ PDF, ì´ë¯¸ì§€, ì°¨íŠ¸ì™€ ê°™ì€ ë³µì¡í•œ ë¬¸ì„œì—ì„œ êµ¬ì¡°í™”ëœ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ê²ƒì€ ê¸°ì—…ê³¼ ê°œë°œìë“¤ì—ê²Œ ì¤‘ìš”í•œ ê³¼ì œì…ë‹ˆë‹¤. ê¸°ì¡´ì˜ OCR ì†”ë£¨ì…˜ë“¤ì€ ì‹œê°ì ìœ¼ë¡œ ë³µì¡í•œ ë ˆì´ì•„ì›ƒ, í‘œ, í˜¼í•© ì½˜í…ì¸  ìœ í˜•ì„ ì²˜ë¦¬í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ë°”ë¡œ ì´ëŸ° ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ **LandingAIì˜ Agentic Document Extraction** ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë“±ì¥í–ˆìŠµë‹ˆë‹¤.

Agentic Document Extraction APIëŠ” ê³ ê¸‰ AIë¥¼ í™œìš©í•˜ì—¬ ì‹œê°ì ìœ¼ë¡œ ë³µì¡í•œ ë¬¸ì„œì—ì„œ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê³  ì •í™•í•œ ìš”ì†Œ ìœ„ì¹˜ì™€ í•¨ê»˜ ê³„ì¸µì  JSONì„ ë°˜í™˜í•˜ëŠ” ê°•ë ¥í•œ Python ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ê¸ˆìœµ ë³´ê³ ì„œ, ì—°êµ¬ ë…¼ë¬¸, ë‹¤ì¤‘ í˜ì´ì§€ ê¸°ìˆ  ë¬¸ì„œ ë“±ì„ ë‹¤ë£¨ë“  ìƒê´€ì—†ì´, ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ë¬¸ì„œ ì²˜ë¦¬ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

## Agentic Document Extractionì´ë€?

LandingAIì˜ Agentic Document Extractionì€ ë‹¤ìŒê³¼ ê°™ì€ ê¸°ëŠ¥ì— ë›°ì–´ë‚œ AI ê¸°ë°˜ ë¬¸ì„œ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤:

- **ë³µì¡í•œ ë ˆì´ì•„ì›ƒ ì´í•´**: í‘œ, ê·¸ë¦¼, ì°¨íŠ¸, í˜¼í•© ì½˜í…ì¸  ë ˆì´ì•„ì›ƒ ì²˜ë¦¬
- **ê¸´ ë¬¸ì„œ ì§€ì›**: ë‹¨ì¼ í˜¸ì¶œë¡œ 100í˜ì´ì§€ ì´ìƒì˜ PDF ì²˜ë¦¬
- **êµ¬ì¡°í™”ëœ ì¶œë ¥**: ì •í™•í•œ ìš”ì†Œ ìœ„ì¹˜ì™€ í•¨ê»˜ ê³„ì¸µì  JSON ë°˜í™˜
- **ì‹œê°ì  ê·¸ë¼ìš´ë”©**: ì¶”ì¶œëœ ì½˜í…ì¸ ì— ëŒ€í•œ ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ì œê³µ
- **ë°°ì¹˜ ì²˜ë¦¬**: ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì—¬ëŸ¬ ë¬¸ì„œ ë™ì‹œ ì²˜ë¦¬

### ì£¼ìš” ê¸°ëŠ¥

- ğŸ“¦ **ê°„ë‹¨í•œ ì„¤ì¹˜**: ì¶”ê°€ ì¢…ì†ì„± ì—†ì´ pip í•œ ì¤„ë¡œ ì„¤ì¹˜
- ğŸ—‚ï¸ **ë²”ìš© íŒŒì¼ ì§€ì›**: ëª¨ë“  ê¸¸ì´ì˜ PDF, ì´ë¯¸ì§€, URL
- ğŸ“š **ì—”í„°í”„ë¼ì´ì¦ˆ ê·œëª¨**: 1000í˜ì´ì§€ ì´ìƒ ë¬¸ì„œì˜ ìë™ ë¶„í•  ë° ë³‘ë ¬ ì²˜ë¦¬
- ğŸ§© **êµ¬ì¡°í™”ëœ ì¶œë ¥**: ê³„ì¸µì  JSONê³¼ ë Œë”ë§ ì¤€ë¹„ëœ ë§ˆí¬ë‹¤ìš´
- ğŸ‘ï¸ **ì‹œê°ì  ë””ë²„ê¹…**: ë°”ìš´ë”© ë°•ìŠ¤ ìŠ¤ë‹ˆí«ê³¼ ì „ì²´ í˜ì´ì§€ ì‹œê°í™”
- ğŸƒ **ë³‘ë ¬ ì²˜ë¦¬**: ìŠ¤ë ˆë“œ ê´€ë¦¬ê°€ í¬í•¨ëœ êµ¬ì„± ê°€ëŠ¥í•œ ë°°ì¹˜ ì²˜ë¦¬
- ğŸ”„ **ë³µì›ë ¥**: API ì˜¤ë¥˜ì— ëŒ€í•œ ì§€ìˆ˜ ë°±ì˜¤í”„ ìë™ ì¬ì‹œë„
- âš™ï¸ **ìœ ì—°í•œ êµ¬ì„±**: í”„ë¡œë•ì…˜ ë°°í¬ë¥¼ ìœ„í•œ í™˜ê²½ ê¸°ë°˜ ì„¤ì •

## ì „ì œ ì¡°ê±´ ë° ì„¤ì •

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

- Python 3.9, 3.10, 3.11, ë˜ëŠ” 3.12
- LandingAI API í‚¤ ([LandingAI](https://landing.ai/)ì—ì„œ íšë“)
- API í˜¸ì¶œì„ ìœ„í•œ ì¸í„°ë„· ì—°ê²°

### ì„¤ì¹˜

pipë¥¼ ì‚¬ìš©í•œ ì„¤ì¹˜ ê³¼ì •ì€ ê°„ë‹¨í•©ë‹ˆë‹¤:

```bash
# agentic-doc ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
pip install agentic-doc

# ì„¤ì¹˜ í™•ì¸
python -c "import agentic_doc; print('ì„¤ì¹˜ ì„±ê³µ!')"
```

### API í‚¤ êµ¬ì„±

LandingAI API í‚¤ë¥¼ íšë“í•œ í›„, í™˜ê²½ ë³€ìˆ˜ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤:

```bash
# í™˜ê²½ ë³€ìˆ˜ë¡œ API í‚¤ ì„¤ì •
export VISION_AGENT_API_KEY=your-api-key-here

# ë˜ëŠ” í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ì— .env íŒŒì¼ ìƒì„±
echo "VISION_AGENT_API_KEY=your-api-key-here" > .env
```

í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ì¼ë°˜ í…ìŠ¤íŠ¸ í™˜ê²½ ë³€ìˆ˜ë³´ë‹¤ëŠ” ë³´ì•ˆ ë¹„ë°€ ê´€ë¦¬ ì‹œìŠ¤í…œ ì‚¬ìš©ì„ ê³ ë ¤í•˜ì„¸ìš”.

## ê¸°ë³¸ ì‚¬ìš© ì˜ˆì œ

### ê°„ë‹¨í•œ ë¬¸ì„œ íŒŒì‹±

ê°€ì¥ ê¸°ë³¸ì ì¸ ì‚¬ìš©ë²•ì¸ ë‹¨ì¼ ë¬¸ì„œ íŒŒì‹±ë¶€í„° ì‹œì‘í•´ë³´ê² ìŠµë‹ˆë‹¤:

```python
from agentic_doc.parse import parse

# ë¡œì»¬ PDF íŒŒì¼ íŒŒì‹±
results = parse("path/to/your/document.pdf")

# URLì—ì„œ íŒŒì‹±
results = parse("https://example.com/document.pdf")

# ì´ë¯¸ì§€ íŒŒì‹±
results = parse("path/to/your/image.jpg")

# íŒŒì‹±ëœ ì½˜í…ì¸  ì ‘ê·¼
parsed_doc = results[0]
print(f"ë¬¸ì„œ ì œëª©: {parsed_doc.title}")
print(f"ì²­í¬ ìˆ˜: {len(parsed_doc.chunks)}")
print(f"ë§ˆí¬ë‹¤ìš´ ì½˜í…ì¸ : {parsed_doc.markdown}")
```

### ê²°ê³¼ êµ¬ì¡° ì´í•´í•˜ê¸°

ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì£¼ìš” êµ¬ì„± ìš”ì†Œë¥¼ ê°€ì§„ êµ¬ì¡°í™”ëœ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤:

```python
from agentic_doc.parse import parse

results = parse("document.pdf")
parsed_doc = results[0]

# ë¬¸ì„œ ë©”íƒ€ë°ì´í„°
print(f"ì œëª©: {parsed_doc.title}")
print(f"í˜ì´ì§€ ìˆ˜: {parsed_doc.page_count}")
print(f"ì²˜ë¦¬ ì‹œê°„: {parsed_doc.processing_time}")

# ì½˜í…ì¸  ì²­í¬ ë°˜ë³µ
for i, chunk in enumerate(parsed_doc.chunks):
    print(f"ì²­í¬ {i}:")
    print(f"  ìœ í˜•: {chunk.chunk_type}")
    print(f"  ì½˜í…ì¸ : {chunk.content[:100]}...")  # ì²« 100ì
    print(f"  í˜ì´ì§€: {chunk.page}")
    print(f"  ë°”ìš´ë”© ë°•ìŠ¤: {chunk.grounding[0].bbox if chunk.grounding else 'N/A'}")
    print("---")

# ì „ì²´ ë§ˆí¬ë‹¤ìš´ í‘œí˜„ ê°€ì ¸ì˜¤ê¸°
markdown_content = parsed_doc.markdown
print("ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ëœ ì „ì²´ ë¬¸ì„œ:")
print(markdown_content)
```

## ê³ ê¸‰ ê¸°ëŠ¥

### ëŒ€ìš©ëŸ‰ PDF íŒŒì¼ ì²˜ë¦¬

ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ë›°ì–´ë‚œ ê¸°ëŠ¥ ì¤‘ í•˜ë‚˜ëŠ” ëŒ€ìš©ëŸ‰ ë¬¸ì„œë¥¼ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ëŠ¥ë ¥ì…ë‹ˆë‹¤:

```python
from agentic_doc.parse import parse

# ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ëŒ€ìš©ëŸ‰ PDFë¥¼ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤
# ê´€ë¦¬ ê°€ëŠ¥í•œ ì²­í¬ë¡œ ë¶„í• í•˜ê³  ë³‘ë ¬ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤
results = parse("very-large-document.pdf")

parsed_doc = results[0]
print(f"{parsed_doc.page_count}í˜ì´ì§€ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤")

# ì²˜ë¦¬ ì˜¤ë¥˜ í™•ì¸
if parsed_doc.errors:
    print("ì²˜ë¦¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:")
    for error in parsed_doc.errors:
        print(f"  í˜ì´ì§€ {error.page}: {error.message}")
```

### ì—¬ëŸ¬ ë¬¸ì„œ ë°°ì¹˜ ì²˜ë¦¬

êµ¬ì„± ê°€ëŠ¥í•œ ë³‘ë ¬ì„±ìœ¼ë¡œ ì—¬ëŸ¬ ë¬¸ì„œë¥¼ ë™ì‹œì— ì²˜ë¦¬í•©ë‹ˆë‹¤:

```python
from agentic_doc.parse import parse

# ì—¬ëŸ¬ ë¬¸ì„œë¥¼ ë°°ì¹˜ë¡œ ì²˜ë¦¬
document_paths = [
    "document1.pdf",
    "document2.pdf", 
    "https://example.com/document3.pdf",
    "image.jpg"
]

# ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ë°°ì¹˜ ì²˜ë¦¬
results = parse(document_paths)

# ê²°ê³¼ ì²˜ë¦¬
for i, parsed_doc in enumerate(results):
    print(f"ë¬¸ì„œ {i+1}: {parsed_doc.title}")
    print(f"  í˜ì´ì§€: {parsed_doc.page_count}")
    print(f"  ì²­í¬: {len(parsed_doc.chunks)}")
    
    # ì˜¤ë¥˜ í™•ì¸
    if parsed_doc.errors:
        print(f"  ì˜¤ë¥˜: {len(parsed_doc.errors)}")
```

### ì‹œê°ì  ê·¸ë¼ìš´ë”© ë° ë””ë²„ê¹…

ì½˜í…ì¸ ê°€ ë°œê²¬ëœ ì‹œê°ì  ì˜ì—­ì„ ì¶”ì¶œí•˜ê³  ì €ì¥í•©ë‹ˆë‹¤:

```python
from agentic_doc.parse import parse

# ë¬¸ì„œ íŒŒì‹± ë° ê·¸ë¼ìš´ë”© ì´ë¯¸ì§€ ì €ì¥
results = parse(
    "document.pdf",
    grounding_save_dir="./grounding_images"
)

parsed_doc = results[0]

# ì €ì¥ëœ ê·¸ë¼ìš´ë”© ì´ë¯¸ì§€ ê²½ë¡œ ì¶œë ¥
for chunk in parsed_doc.chunks:
    for grounding in chunk.grounding:
        if grounding.image_path:
            print(f"ê·¸ë¼ìš´ë”©ì´ ì €ì¥ë¨: {grounding.image_path}")
```

### ë¬¸ì„œ ì‹œê°í™”

ì¶”ì¶œ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ëŠ” ì£¼ì„ì´ ë‹¬ë¦° ì‹œê°í™”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:

```python
from agentic_doc.parse import parse
from agentic_doc.utils import viz_parsed_document
from agentic_doc.config import VisualizationConfig
from agentic_doc.schema import ChunkType

# ë¬¸ì„œ íŒŒì‹±
results = parse("document.pdf")
parsed_doc = results[0]

# ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì‹œê°í™” ìƒì„±
images = viz_parsed_document(
    "document.pdf",
    parsed_doc,
    output_dir="./visualizations"
)

# ì‹œê°í™” ëª¨ì–‘ ì‚¬ìš©ì ì •ì˜
viz_config = VisualizationConfig(
    thickness=3,  # ë” ë‘êº¼ìš´ ë°”ìš´ë”© ë°•ìŠ¤
    text_bg_opacity=0.9,  # ë” ë¶ˆíˆ¬ëª…í•œ í…ìŠ¤íŠ¸ ë°°ê²½
    font_scale=0.8,  # ë” í° í…ìŠ¤íŠ¸
    color_map={
        ChunkType.TITLE: (255, 0, 0),    # ì œëª©ì€ ë¹¨ê°„ìƒ‰
        ChunkType.TEXT: (0, 255, 0),     # í…ìŠ¤íŠ¸ëŠ” ë…¹ìƒ‰
        ChunkType.TABLE: (0, 0, 255),    # í‘œëŠ” íŒŒë€ìƒ‰
    }
)

# ì‚¬ìš©ì ì •ì˜ ì‹œê°í™” ìƒì„±
custom_images = viz_parsed_document(
    "document.pdf",
    parsed_doc,
    output_dir="./custom_visualizations",
    viz_config=viz_config
)

print(f"{len(custom_images)}ê°œì˜ ì‹œê°í™” ì´ë¯¸ì§€ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤")
```

## êµ¬ì„± ë° ìµœì í™”

### í™˜ê²½ êµ¬ì„±

ë¼ì´ë¸ŒëŸ¬ë¦¬ ë™ì‘ì„ ì‚¬ìš©ì ì •ì˜í•˜ê¸° ìœ„í•œ `.env` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```bash
# .env íŒŒì¼ êµ¬ì„±
VISION_AGENT_API_KEY=your-api-key-here

# ë³‘ë ¬ì„± ì„¤ì •
BATCH_SIZE=4          # ë³‘ë ¬ë¡œ ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜
MAX_WORKERS=5         # ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ì²˜ë¦¬ë¥¼ ìœ„í•œ íŒŒì¼ë‹¹ ìŠ¤ë ˆë“œ ìˆ˜

# ì¬ì‹œë„ êµ¬ì„±
MAX_RETRIES=100       # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
MAX_RETRY_WAIT_TIME=60  # ì¬ì‹œë„ë‹¹ ìµœëŒ€ ëŒ€ê¸° ì‹œê°„(ì´ˆ)

# ë¡œê¹… êµ¬ì„±
RETRY_LOGGING_STYLE=log_msg  # ì˜µì…˜: log_msg, inline_block, none
```

### ì„±ëŠ¥ ìµœì í™”

```python
import os
from agentic_doc.parse import parse

# í”„ë¡œê·¸ë˜ë° ë°©ì‹ìœ¼ë¡œ ì„±ëŠ¥ ì„¤ì • êµ¬ì„±
os.environ['BATCH_SIZE'] = '6'
os.environ['MAX_WORKERS'] = '8'
os.environ['MAX_RETRIES'] = '50'

# ìµœì í™”ëœ ì„¤ì •ìœ¼ë¡œ ë¬¸ì„œ ì²˜ë¦¬
results = parse(["doc1.pdf", "doc2.pdf", "doc3.pdf"])
```

### ê³ ê¸‰ íŒŒì‹± ì˜µì…˜

```python
from agentic_doc.parse import parse

# ì‚¬ìš©ì ì •ì˜ ì˜µì…˜ìœ¼ë¡œ ê³ ê¸‰ íŒŒì‹±
results = parse(
    "document.pdf",
    include_marginalia=False,        # í—¤ë”/í‘¸í„° ì œì™¸
    include_metadata_in_markdown=False,  # ê¹”ë”í•œ ë§ˆí¬ë‹¤ìš´ ì¶œë ¥
    grounding_save_dir="./groundings"    # ì‹œê°ì  ê·¸ë¼ìš´ë”© ì €ì¥
)

parsed_doc = results[0]
print(f"ê¹”ë”í•œ ì½˜í…ì¸  ì¶”ì¶œë¨: {len(parsed_doc.chunks)}ê°œ ì²­í¬")
```

## ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë¬¸ì œ í•´ê²°

### ê°•ë ¥í•œ ì˜¤ë¥˜ ì²˜ë¦¬

```python
from agentic_doc.parse import parse
import logging

# ìƒì„¸í•œ ë¡œê¹… í™œì„±í™”
logging.basicConfig(level=logging.INFO)

try:
    results = parse("problematic-document.pdf")
    parsed_doc = results[0]
    
    # íŒŒì‹± ì˜¤ë¥˜ í™•ì¸
    if parsed_doc.errors:
        print("ë¬¸ì„œê°€ ì˜¤ë¥˜ì™€ í•¨ê»˜ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤:")
        for error in parsed_doc.errors:
            print(f"  í˜ì´ì§€ {error.page}: {error.error_code} - {error.message}")
    else:
        print("ë¬¸ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
except Exception as e:
    print(f"ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    # API í‚¤ ë¬¸ì œ, ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ ë“± ì²˜ë¦¬
```

### ì¼ë°˜ì ì¸ ë¬¸ì œ ë° í•´ê²°ì±…

```python
# ì†ë„ ì œí•œì„ ìš°ì•„í•˜ê²Œ ì²˜ë¦¬
import os
from agentic_doc.parse import parse

# ì†ë„ ì œí•œëœ ê³„ì •ì„ ìœ„í•œ ë³‘ë ¬ì„± ê°ì†Œ
os.environ['BATCH_SIZE'] = '1'
os.environ['MAX_WORKERS'] = '2'
os.environ['RETRY_LOGGING_STYLE'] = 'inline_block'

try:
    results = parse("large-document.pdf")
    print("ì²˜ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤")
except Exception as e:
    if "rate limit" in str(e).lower():
        print("ì†ë„ ì œí•œ ì´ˆê³¼. BATCH_SIZEì™€ MAX_WORKERS ê°ì†Œë¥¼ ê³ ë ¤í•˜ì„¸ìš”")
    elif "api key" in str(e).lower():
        print("API í‚¤ ë¬¸ì œ. VISION_AGENT_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”")
    else:
        print(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
```

## ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€

### ê¸ˆìœµ ë¬¸ì„œ ì²˜ë¦¬

```python
from agentic_doc.parse import parse
import json

def process_financial_reports(report_paths):
    """ê¸ˆìœµ ë³´ê³ ì„œë¥¼ ì²˜ë¦¬í•˜ê³  ì£¼ìš” ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    results = parse(report_paths)
    
    financial_data = []
    for i, parsed_doc in enumerate(results):
        doc_data = {
            'filename': report_paths[i],
            'title': parsed_doc.title,
            'page_count': parsed_doc.page_count,
            'tables': [],
            'key_figures': []
        }
        
        # í‘œì™€ ìˆ˜ì¹˜ ë°ì´í„° ì¶”ì¶œ
        for chunk in parsed_doc.chunks:
            if chunk.chunk_type.name == 'TABLE':
                doc_data['tables'].append(chunk.content)
            elif any(keyword in chunk.content.lower() 
                    for keyword in ['ë§¤ì¶œ', 'ìˆ˜ìµ', 'ì†ì‹¤', 'ì›', '%']):
                doc_data['key_figures'].append(chunk.content)
        
        financial_data.append(doc_data)
    
    return financial_data

# ë¶„ê¸°ë³„ ë³´ê³ ì„œ ì²˜ë¦¬
reports = ['q1_report.pdf', 'q2_report.pdf', 'q3_report.pdf']
financial_analysis = process_financial_reports(reports)

# êµ¬ì¡°í™”ëœ ë°ì´í„° ì €ì¥
with open('financial_analysis.json', 'w', encoding='utf-8') as f:
    json.dump(financial_analysis, f, indent=2, ensure_ascii=False)
```

### ì—°êµ¬ ë…¼ë¬¸ ë¶„ì„

```python
from agentic_doc.parse import parse
import re

def analyze_research_papers(paper_urls):
    """ì—°êµ¬ ë…¼ë¬¸ì„ ë¶„ì„í•˜ê³  ì´ˆë¡, ê²°ë¡ ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    results = parse(paper_urls)
    
    analysis = []
    for i, parsed_doc in enumerate(results):
        paper_analysis = {
            'url': paper_urls[i],
            'title': parsed_doc.title,
            'abstract': None,
            'conclusion': None,
            'references_count': 0,
            'figures_count': 0
        }
        
        for chunk in parsed_doc.chunks:
            content_lower = chunk.content.lower()
            
            # ì´ˆë¡ ì¶”ì¶œ
            if 'abstract' in content_lower and not paper_analysis['abstract']:
                paper_analysis['abstract'] = chunk.content
            
            # ê²°ë¡  ì¶”ì¶œ
            if any(word in content_lower for word in ['conclusion', 'summary', 'findings']):
                paper_analysis['conclusion'] = chunk.content
            
            # ì°¸ê³ ë¬¸í—Œê³¼ ê·¸ë¦¼ ìˆ˜ ê³„ì‚°
            if 'reference' in content_lower or 'bibliography' in content_lower:
                paper_analysis['references_count'] += len(re.findall(r'\[\d+\]', chunk.content))
            
            if chunk.chunk_type.name in ['FIGURE', 'IMAGE']:
                paper_analysis['figures_count'] += 1
        
        analysis.append(paper_analysis)
    
    return analysis

# ì—°êµ¬ ë…¼ë¬¸ ë¶„ì„
paper_urls = [
    'https://arxiv.org/pdf/2301.00001.pdf',
    'https://arxiv.org/pdf/2301.00002.pdf'
]

research_analysis = analyze_research_papers(paper_urls)
for paper in research_analysis:
    print(f"ì œëª©: {paper['title']}")
    print(f"ê·¸ë¦¼: {paper['figures_count']}")
    print(f"ì°¸ê³ ë¬¸í—Œ: {paper['references_count']}")
    print("---")
```

## ëª¨ë²” ì‚¬ë¡€ ë° íŒ

### ì„±ëŠ¥ ìµœì í™”

1. **ë°°ì¹˜ ì²˜ë¦¬**: ë” ë‚˜ì€ ì²˜ë¦¬ëŸ‰ì„ ìœ„í•´ ì—¬ëŸ¬ ë¬¸ì„œë¥¼ í•¨ê»˜ ì²˜ë¦¬
2. **ë³‘ë ¬ êµ¬ì„±**: API ì œí•œì— ë”°ë¼ `BATCH_SIZE`ì™€ `MAX_WORKERS` ì¡°ì •
3. **ì˜¤ë¥˜ ì²˜ë¦¬**: ê²°ê³¼ì—ì„œ ì²˜ë¦¬ ì˜¤ë¥˜ë¥¼ í•­ìƒ í™•ì¸
4. **ë¦¬ì†ŒìŠ¤ ê´€ë¦¬**: ë””ë²„ê¹…ì´ í•„ìš”í•œ ê²½ìš°ì—ë§Œ ê·¸ë¼ìš´ë”© ì´ë¯¸ì§€ ì‚¬ìš©

### í”„ë¡œë•ì…˜ ë°°í¬

```python
import os
from agentic_doc.parse import parse
import logging

# í”„ë¡œë•ì…˜ êµ¬ì„±
def setup_production_config():
    """í”„ë¡œë•ì…˜ ì‚¬ìš©ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ êµ¬ì„±."""
    os.environ['BATCH_SIZE'] = '2'  # ì•ˆì •ì„±ì„ ìœ„í•œ ë³´ìˆ˜ì  ì„¤ì •
    os.environ['MAX_WORKERS'] = '3'
    os.environ['MAX_RETRIES'] = '10'
    os.environ['RETRY_LOGGING_STYLE'] = 'none'  # ë¡œê·¸ ë…¸ì´ì¦ˆ ê°ì†Œ
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.WARNING,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )

def process_documents_safely(document_paths):
    """í¬ê´„ì ì¸ ì˜¤ë¥˜ ì²˜ë¦¬ë¡œ ë¬¸ì„œë¥¼ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    setup_production_config()
    
    successful_results = []
    failed_documents = []
    
    try:
        results = parse(document_paths)
        
        for i, result in enumerate(results):
            if result.errors:
                failed_documents.append({
                    'path': document_paths[i],
                    'errors': result.errors
                })
            else:
                successful_results.append(result)
                
    except Exception as e:
        logging.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return None, document_paths
    
    return successful_results, failed_documents

# í”„ë¡œë•ì…˜ì—ì„œ ì‚¬ìš©
documents = ['doc1.pdf', 'doc2.pdf', 'doc3.pdf']
success, failures = process_documents_safely(documents)

if success:
    print(f"{len(success)}ê°œ ë¬¸ì„œë¥¼ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤")
if failures:
    print(f"{len(failures)}ê°œ ë¬¸ì„œ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
```

## ê²°ë¡ 

LandingAIì˜ Agentic Document Extraction ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” AI ê¸°ë°˜ ë¬¸ì„œ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œ ì¤‘ìš”í•œ ë°œì „ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ë³µì¡í•œ ë ˆì´ì•„ì›ƒì„ ì²˜ë¦¬í•˜ê³ , ëŒ€ìš©ëŸ‰ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ë©°, ì‹œê°ì  ê·¸ë¼ìš´ë”©ê³¼ í•¨ê»˜ êµ¬ì¡°í™”ëœ ì¶œë ¥ì„ ì œê³µí•˜ëŠ” ëŠ¥ë ¥ì€ í˜„ëŒ€ ë°ì´í„° ì¶”ì¶œ ì›Œí¬í”Œë¡œìš°ì—ì„œ ê·€ì¤‘í•œ ë„êµ¬ê°€ ë©ë‹ˆë‹¤.

### ì£¼ìš” ìš”ì 

- **ì—”í„°í”„ë¼ì´ì¦ˆ ì¤€ë¹„**: ìë™ ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ ëª¨ë“  í¬ê¸°ì˜ ë¬¸ì„œ ì²˜ë¦¬
- **AI ê¸°ë°˜**: ë³µì¡í•œ ë¬¸ì„œ ë ˆì´ì•„ì›ƒì˜ ê³ ê¸‰ ì´í•´
- **ê°œë°œì ì¹œí™”ì **: ê°•ë ¥í•œ êµ¬ì„± ì˜µì…˜ì„ ê°€ì§„ ê°„ë‹¨í•œ API
- **í”„ë¡œë•ì…˜ ì¤€ë¹„**: ë‚´ì¥ëœ ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ê³¼ ì˜¤ë¥˜ ì²˜ë¦¬
- **ìœ ì—°í•œ ì¶œë ¥**: êµ¬ì¡°í™”ëœ JSONê³¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹

### ë‹¤ìŒ ë‹¨ê³„

1. **ì‹¤í—˜**: ìì‹ ì˜ ë¬¸ì„œë¡œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”
2. **ìµœì í™”**: íŠ¹ì • ì‚¬ìš© ì‚¬ë¡€ì— ë§ê²Œ êµ¬ì„±ì„ ë¯¸ì„¸ ì¡°ì •í•˜ì„¸ìš”
3. **í†µí•©**: ê¸°ì¡´ ì›Œí¬í”Œë¡œìš°ì— ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ êµ¬ì¶•í•˜ì„¸ìš”
4. **í™•ì¥**: í”„ë¡œë•ì…˜ ì›Œí¬ë¡œë“œë¥¼ ìœ„í•œ ë°°ì¹˜ ì²˜ë¦¬ë¥¼ í™œìš©í•˜ì„¸ìš”

ë¬¸ì„œ ì²˜ë¦¬ì˜ ë¯¸ë˜ê°€ ì—¬ê¸°ì— ìˆìœ¼ë©°, LandingAIì˜ Agentic Document Extractionì„ í†µí•´ ê°€ì¥ ë³µì¡í•œ ë¬¸ì„œ ì²˜ë¦¬ ê³¼ì œë„ ìì‹  ìˆê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ì¥ë¹„ë¥¼ ê°–ì¶”ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.

---

**ë¦¬ì†ŒìŠ¤:**
- [LandingAI Agentic Document Extraction GitHub](https://github.com/landing-ai/agentic-doc)
- [ê³µì‹ ë¬¸ì„œ](https://landing.ai/agentic-document-extraction)
- [API ë¬¸ì„œ](https://landing.ai/docs)
- [API í‚¤ ë°›ê¸°](https://landing.ai/)

*ì¦ê±°ìš´ ë¬¸ì„œ ì²˜ë¦¬ ë˜ì„¸ìš”! ğŸš€*
