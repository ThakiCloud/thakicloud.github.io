---
title: "Voice-Proë¡œ YouTube ë‹¤êµ­ì–´ ì½˜í…ì¸  ìë™í™” ì™„ì „ ê°€ì´ë“œ - ìŒì„±ë³µì œë¶€í„° ë²ˆì—­ê¹Œì§€"
excerpt: "Voice-Proë¥¼ í™œìš©í•˜ì—¬ YouTube ë¹„ë””ì˜¤ì˜ ìë§‰ ìƒì„±, ë‹¤êµ­ì–´ ë²ˆì—­, ìŒì„± ë³µì œë¥¼ í†µí•œ ë‹¤êµ­ì–´ ë”ë¹™ê¹Œì§€ ì™„ì „ ìë™í™”í•˜ëŠ” ë‹¨ê³„ë³„ ê°€ì´ë“œì…ë‹ˆë‹¤."
seo_title: "Voice-Pro YouTube ë‹¤êµ­ì–´ ì½˜í…ì¸  ìë™í™” íŠœí† ë¦¬ì–¼ - Thaki Cloud"
seo_description: "Voice-Pro ì˜¤í”ˆì†ŒìŠ¤ ë„êµ¬ë¡œ YouTube ë¹„ë””ì˜¤ë¥¼ ë‹¤êµ­ì–´ë¡œ ìë™ ë³€í™˜í•˜ëŠ” ë°©ë²•. ìŒì„±ë³µì œ, ìë§‰ìƒì„±, ë²ˆì—­, ë”ë¹™ê¹Œì§€ ì™„ì „ ê°€ì´ë“œ"
date: 2025-06-27
categories: 
  - tutorials
  - dev
tags: 
  - Voice-Pro
  - YouTube
  - ë‹¤êµ­ì–´
  - TTS
  - ìŒì„±ë³µì œ
  - Whisper
  - F5-TTS
  - CosyVoice
author_profile: true
toc: true
toc_label: YouTube ë‹¤êµ­ì–´ ìë™í™” ê°€ì´ë“œ
canonical_url: "https://thakicloud.github.io/tutorials/dev/voice-pro-youtube-multilingual-automation-guide/"
---

YouTube ê¸€ë¡œë²Œ ì½˜í…ì¸  ì œì‘ìë“¤ì´ ê°€ì¥ ì–´ë ¤ì›Œí•˜ëŠ” ê²ƒ ì¤‘ í•˜ë‚˜ê°€ **ë‹¤êµ­ì–´ ì½˜í…ì¸  ìƒì„±**ì…ë‹ˆë‹¤. í•˜ë‚˜ì˜ ë¹„ë””ì˜¤ë¥¼ ì—¬ëŸ¬ ì–¸ì–´ë¡œ ë²ˆì—­í•˜ê³  ë”ë¹™í•˜ëŠ” ì‘ì—…ì€ ì‹œê°„ê³¼ ë¹„ìš©ì´ ë§ì´ ë“œëŠ” ì‘ì—…ì´ì—ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ **Voice-Pro** ì˜¤í”ˆì†ŒìŠ¤ ë„êµ¬ë¥¼ í™œìš©í•˜ë©´ ì´ ëª¨ë“  ê³¼ì •ì„ ìë™í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ ê°€ì´ë“œì—ì„œëŠ” Voice-Proë¥¼ ì‚¬ìš©í•˜ì—¬ YouTube ë¹„ë””ì˜¤ì˜ **ìë§‰ ìƒì„±**, **ë‹¤êµ­ì–´ ë²ˆì—­**, **ìŒì„± ë³µì œ**ë¥¼ í†µí•œ **ë‹¤êµ­ì–´ ë”ë¹™**ê¹Œì§€ ì™„ì „ ìë™í™”í•˜ëŠ” ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.

## Voice-Pro í”„ë¡œì íŠ¸ ê°œìš”

**Voice-Pro**ëŠ” í•œêµ­ì˜ ABUSì—ì„œ ê°œë°œí•œ ì¢…í•©ì ì¸ ìŒì„± ì²˜ë¦¬ ë„êµ¬ë¡œ, ë‹¤ìŒê³¼ ê°™ì€ í•µì‹¬ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:

### í•µì‹¬ ê¸°ëŠ¥

- **ğŸ™ï¸ TTS (Text-to-Speech)**: Edge-TTS, Kokoro
- **ğŸ”Š Voice Cloning**: E2 & F5-TTS, CosyVoiceë¥¼ í†µí•œ ì œë¡œìƒ· ìŒì„± ë³µì œ
- **ğŸ“ STT (Speech-to-Text)**: Whisper ê¸°ë°˜ ê³ ì •ë°€ ìŒì„± ì¸ì‹
- **ğŸ“¹ YouTube ì²˜ë¦¬**: yt-dlpë¥¼ í†µí•œ ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
- **ğŸµ ìŒì„± ë¶„ë¦¬**: Demucsë¥¼ í†µí•œ ë³´ì»¬/ë°°ê²½ìŒ ë¶„ë¦¬
- **ğŸŒ ë‹¤êµ­ì–´ ë²ˆì—­**: Deep-Translator ê¸°ë°˜ ë‹¤êµ­ì–´ ì§€ì›

### ë²„ì „ë³„ ì œí•œì‚¬í•­

| ê¸°ëŠ¥ | Trial Version | Contributor Version | Subscription Version |
|------|---------------|-------------------|-------------------|
| ë¯¸ë””ì–´ ê¸¸ì´ ì œí•œ | 60ì´ˆ | ë¬´ì œí•œ | ë¬´ì œí•œ |
| ë²ˆì—­ ì„œë¹„ìŠ¤ | Google Translate | Google Translate | Azure Translate |
| TTS ì„œë¹„ìŠ¤ | Edge TTS | Edge TTS | Azure TTS |

## ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ ë° ì„¤ì¹˜

### í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­

- **CPU**: Intel i5 ì´ìƒ ë˜ëŠ” ë™ê¸‰ AMD í”„ë¡œì„¸ì„œ
- **GPU**: NVIDIA GPU (CUDA ì§€ì›) - ìŒì„± ë³µì œ ì‘ì—…ì— ê¶Œì¥
- **RAM**: ìµœì†Œ 8GB, ê¶Œì¥ 16GB ì´ìƒ
- **ì €ì¥ê³µê°„**: ìµœì†Œ 10GB (ëª¨ë¸ íŒŒì¼ í¬í•¨)

### ì†Œí”„íŠ¸ì›¨ì–´ ìš”êµ¬ì‚¬í•­

- **OS**: Windows 10/11, macOS, Linux
- **Python**: 3.8-3.11 (3.10 ê¶Œì¥)
- **CUDA**: 11.8 ì´ìƒ (GPU ê°€ì† ì‚¬ìš© ì‹œ)

### ì„¤ì¹˜ ê³¼ì •

#### 1. ì €ì¥ì†Œ í´ë¡ 

```bash
git clone https://github.com/abus-aikorea/voice-pro.git
cd voice-pro
```

#### 2. Python í™˜ê²½ ì„¤ì •

```bash
# Conda í™˜ê²½ ìƒì„± (ê¶Œì¥)
conda create -n voice-pro python=3.10
conda activate voice-pro

# ë˜ëŠ” venv ì‚¬ìš©
python -m venv voice-pro-env
# Windows
voice-pro-env\Scripts\activate
# macOS/Linux
source voice-pro-env/bin/activate
```

#### 3. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
# CPU ë²„ì „ (ê¸°ë³¸)
pip install -r requirements-voice-cpu.txt

# GPU ë²„ì „ (CUDA ì§€ì›)
pip install -r requirements-voice-gpu.txt
```

#### 4. Gradio ì›¹ ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰

```bash
python app/main.py
```

ì‹¤í–‰ í›„ ë¸Œë¼ìš°ì €ì—ì„œ `http://localhost:7860`ìœ¼ë¡œ ì ‘ì†í•©ë‹ˆë‹¤.

## ë‹¨ê³„ë³„ YouTube ë‹¤êµ­ì–´ ì½˜í…ì¸  ìƒì„± ê°€ì´ë“œ

### 1ë‹¨ê³„: YouTube ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ë° ì¤€ë¹„

#### ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•œ ë‹¤ìš´ë¡œë“œ

1. **Voice-Pro ì›¹ ì¸í„°í˜ì´ìŠ¤** ì ‘ì†
2. **"YouTube Download"** íƒ­ ì„ íƒ
3. YouTube URL ì…ë ¥
4. ë‹¤ìš´ë¡œë“œ ì˜µì…˜ ì„¤ì •:
   - **í’ˆì§ˆ**: 1080p (ê¶Œì¥)
   - **ì˜¤ë””ì˜¤ í˜•ì‹**: WAV ë˜ëŠ” MP3
   - **ë¹„ë””ì˜¤ í˜•ì‹**: MP4

```python
# í”„ë¡œê·¸ë˜ë° ë°©ì‹ ë‹¤ìš´ë¡œë“œ ì˜ˆì œ
import yt_dlp
import os

def download_youtube_video(url, output_path="./downloads"):
    ydl_opts = {
        'format': 'best[height<=1080]',
        'outtmpl': f'{output_path}/%(title)s.%(ext)s',
        'writesubtitles': True,
        'writeautomaticsub': True,
        'subtitleslangs': ['ko', 'en'],
    }
    
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        ydl.download([url])
        
# ì‚¬ìš© ì˜ˆì œ
youtube_url = "https://www.youtube.com/watch?v=example"
download_youtube_video(youtube_url)
```

#### ì˜¤ë””ì˜¤ ì¶”ì¶œ ë° ì „ì²˜ë¦¬

Voice-ProëŠ” ìë™ìœ¼ë¡œ ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:

1. **ë¹„ë””ì˜¤ì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ**
2. **ë…¸ì´ì¦ˆ ì œê±°** (ì„ íƒì‚¬í•­)
3. **ìŒì„±/ë°°ê²½ìŒ ë¶„ë¦¬** (Demucs ì‚¬ìš©)

### 2ë‹¨ê³„: ìŒì„± ì¸ì‹ ë° ìë§‰ ìƒì„±

#### Whisper ëª¨ë¸ ì„¤ì •

Voice-ProëŠ” ë‹¤ì–‘í•œ Whisper ëª¨ë¸ì„ ì§€ì›í•©ë‹ˆë‹¤:

- **tiny**: ê°€ì¥ ë¹ ë¦„, ì •í™•ë„ ë‚®ìŒ
- **base**: ê· í˜•ì¡íŒ ì„±ëŠ¥
- **small**: ì¢‹ì€ í’ˆì§ˆ
- **medium**: ë†’ì€ ì •í™•ë„
- **large**: ìµœê³  ì •í™•ë„ (ê¶Œì¥)

#### ìë§‰ ìƒì„± ê³¼ì •

1. **ëª¨ë¸ ì„ íƒ**: Large-v3 (ìµœì‹  ëª¨ë¸)
2. **ì–¸ì–´ ì„¤ì •**: ì›ë³¸ ì–¸ì–´ ì„ íƒ (ì˜ˆ: í•œêµ­ì–´)
3. **íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë°€ë„**: Word-level (ê¶Œì¥)
4. **ì¶œë ¥ í˜•ì‹**: SRT, VTT, JSON

```python
# Whisperë¥¼ í†µí•œ ìë§‰ ìƒì„± ì˜ˆì œ
import whisper
from whisper_timestamped import transcribe_timestamped

def generate_subtitles(audio_file, model_size="large-v3"):
    model = whisper.load_model(model_size)
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ê°€ í¬í•¨ëœ ì „ì‚¬
    result = transcribe_timestamped(
        model, 
        audio_file,
        language="ko",  # ì›ë³¸ ì–¸ì–´
        verbose=True
    )
    
    return result

# SRT íŒŒì¼ ìƒì„±
def create_srt_file(transcription, output_file):
    with open(output_file, 'w', encoding='utf-8') as f:
        for i, segment in enumerate(transcription['segments']):
            start_time = format_timestamp(segment['start'])
            end_time = format_timestamp(segment['end'])
            text = segment['text'].strip()
            
            f.write(f"{i+1}\n")
            f.write(f"{start_time} --> {end_time}\n")
            f.write(f"{text}\n\n")

def format_timestamp(seconds):
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millisecs = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"
```

### 3ë‹¨ê³„: ë‹¤êµ­ì–´ ë²ˆì—­ ì²˜ë¦¬

#### ì§€ì› ì–¸ì–´ ë° ë²ˆì—­ ì—”ì§„

Voice-ProëŠ” ë‹¤ìŒ ë²ˆì—­ ì„œë¹„ìŠ¤ë¥¼ ì§€ì›í•©ë‹ˆë‹¤:

**ë¬´ë£Œ ë²„ì „:**
- Google Translate (100+ ì–¸ì–´)
- DeepL (ì œí•œì )

**ìœ ë£Œ ë²„ì „:**
- Azure Translator (90+ ì–¸ì–´)
- Google Cloud Translation

#### ë²ˆì—­ ì›Œí¬í”Œë¡œìš°

1. **ëŒ€ìƒ ì–¸ì–´ ì„ íƒ**
2. **ë²ˆì—­ í’ˆì§ˆ ì„¤ì •**
3. **ë¬¸ë§¥ ë³´ì¡´ ì˜µì…˜**
4. **ì „ë¬¸ ìš©ì–´ ì‚¬ì „** (ì„ íƒì‚¬í•­)

```python
# ë‹¤êµ­ì–´ ë²ˆì—­ ì˜ˆì œ
from deep_translator import GoogleTranslator
import json

def translate_subtitles(srt_content, target_languages):
    translations = {}
    
    for lang_code in target_languages:
        translator = GoogleTranslator(source='ko', target=lang_code)
        translated_segments = []
        
        for segment in parse_srt(srt_content):
            translated_text = translator.translate(segment['text'])
            translated_segments.append({
                'start': segment['start'],
                'end': segment['end'],
                'text': translated_text
            })
        
        translations[lang_code] = translated_segments
    
    return translations

# ì§€ì› ì–¸ì–´ ëª©ë¡
SUPPORTED_LANGUAGES = {
    'en': 'English',
    'ja': 'Japanese', 
    'zh': 'Chinese',
    'es': 'Spanish',
    'fr': 'French',
    'de': 'German',
    'it': 'Italian',
    'pt': 'Portuguese',
    'ru': 'Russian',
    'ar': 'Arabic'
}
```

### 4ë‹¨ê³„: ìŒì„± ë³µì œ ë° ë”ë¹™ ìƒì„±

Voice-Proì˜ ê°€ì¥ ê°•ë ¥í•œ ê¸°ëŠ¥ ì¤‘ í•˜ë‚˜ëŠ” **ì œë¡œìƒ· ìŒì„± ë³µì œ**ì…ë‹ˆë‹¤.

#### ì§€ì›í•˜ëŠ” ìŒì„± ë³µì œ ëª¨ë¸

1. **F5-TTS**: ê³ í’ˆì§ˆ ì œë¡œìƒ· TTS
2. **E2-TTS**: ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„
3. **CosyVoice**: ë‹¤êµ­ì–´ íŠ¹í™”
4. **Edge-TTS**: ì•ˆì •ì ì¸ í’ˆì§ˆ

#### ìŒì„± ë³µì œ ê³¼ì •

##### 4-1: ë ˆí¼ëŸ°ìŠ¤ ìŒì„± ì¤€ë¹„

```python
# ë ˆí¼ëŸ°ìŠ¤ ìŒì„± ì¶”ì¶œ ë° ì „ì²˜ë¦¬
def prepare_reference_audio(video_file, start_time, duration=10):
    """
    ì›ë³¸ ë¹„ë””ì˜¤ì—ì„œ í™”ìì˜ ê¹¨ë—í•œ ìŒì„± êµ¬ê°„ ì¶”ì¶œ
    
    Args:
        video_file: ì›ë³¸ ë¹„ë””ì˜¤ íŒŒì¼
        start_time: ì¶”ì¶œ ì‹œì‘ ì‹œê°„ (ì´ˆ)
        duration: ì¶”ì¶œ ê¸¸ì´ (ì´ˆ, 5-15ì´ˆ ê¶Œì¥)
    """
    import ffmpeg
    
    output_file = "reference_voice.wav"
    
    (
        ffmpeg
        .input(video_file, ss=start_time, t=duration)
        .output(output_file, acodec='pcm_s16le', ar=22050, ac=1)
        .overwrite_output()
        .run()
    )
    
    return output_file
```

##### 4-2: F5-TTSë¥¼ í†µí•œ ìŒì„± ë³µì œ

```python
# F5-TTS ìŒì„± ë³µì œ êµ¬í˜„
def clone_voice_f5tts(reference_audio, target_text, target_language='en'):
    """
    F5-TTSë¥¼ ì‚¬ìš©í•œ ìŒì„± ë³µì œ
    
    Args:
        reference_audio: ë ˆí¼ëŸ°ìŠ¤ ìŒì„± íŒŒì¼
        target_text: ìƒì„±í•  í…ìŠ¤íŠ¸
        target_language: ëŒ€ìƒ ì–¸ì–´
    """
    from f5_tts import F5TTS
    
    # F5-TTS ëª¨ë¸ ë¡œë“œ
    model = F5TTS(
        model_type="F5-TTS",
        ckpt_file="path/to/model.safetensors",
        vocab_file="path/to/vocab.txt"
    )
    
    # ìŒì„± ìƒì„±
    generated_audio = model.infer(
        ref_audio=reference_audio,
        ref_text="ë ˆí¼ëŸ°ìŠ¤ í…ìŠ¤íŠ¸",  # ë ˆí¼ëŸ°ìŠ¤ ìŒì„±ì˜ í…ìŠ¤íŠ¸
        gen_text=target_text,
        target_lang=target_language,
        cross_fade_duration=0.15
    )
    
    return generated_audio
```

##### 4-3: CosyVoiceë¥¼ í†µí•œ ë‹¤êµ­ì–´ ë”ë¹™

```python
# CosyVoice ë‹¤êµ­ì–´ ìŒì„± ìƒì„±
def generate_multilingual_dubbing(reference_audio, translations):
    """
    CosyVoiceë¥¼ ì‚¬ìš©í•œ ë‹¤êµ­ì–´ ë”ë¹™ ìƒì„±
    
    Args:
        reference_audio: ë ˆí¼ëŸ°ìŠ¤ ìŒì„±
        translations: ë²ˆì—­ëœ ìë§‰ ë°ì´í„°
    """
    from cosyvoice import CosyVoice
    
    model = CosyVoice('path/to/cosyvoice/model')
    dubbed_audios = {}
    
    for lang_code, segments in translations.items():
        audio_segments = []
        
        for segment in segments:
            # ê° ìë§‰ êµ¬ê°„ë³„ ìŒì„± ìƒì„±
            audio = model.inference_sft(
                tts_text=segment['text'],
                spk_id='reference_speaker',
                lang=lang_code
            )
            
            audio_segments.append({
                'audio': audio,
                'start': segment['start'],
                'end': segment['end']
            })
        
        dubbed_audios[lang_code] = audio_segments
    
    return dubbed_audios
```

### 5ë‹¨ê³„: ìµœì¢… ë¹„ë””ì˜¤ í•©ì„± ë° ì¶œë ¥

#### ì˜¤ë””ì˜¤ íƒ€ì´ë° ë™ê¸°í™”

```python
# ì˜¤ë””ì˜¤ ë™ê¸°í™” ë° ë¹„ë””ì˜¤ í•©ì„±
def synchronize_and_merge(original_video, dubbed_audio_segments, output_file):
    """
    ë”ë¹™ëœ ì˜¤ë””ì˜¤ì™€ ì›ë³¸ ë¹„ë””ì˜¤ ë™ê¸°í™”
    
    Args:
        original_video: ì›ë³¸ ë¹„ë””ì˜¤ íŒŒì¼
        dubbed_audio_segments: ë”ë¹™ ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸
        output_file: ì¶œë ¥ íŒŒì¼ëª…
    """
    import ffmpeg
    from pydub import AudioSegment
    
    # ì „ì²´ ê¸¸ì´ì˜ ë¬´ìŒ ì˜¤ë””ì˜¤ ìƒì„±
    video_info = ffmpeg.probe(original_video)
    duration = float(video_info['streams'][0]['duration'])
    
    final_audio = AudioSegment.silent(duration=int(duration * 1000))
    
    # ê° ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì ì ˆí•œ ìœ„ì¹˜ì— ì‚½ì…
    for segment in dubbed_audio_segments:
        start_ms = int(segment['start'] * 1000)
        audio_data = AudioSegment.from_wav(segment['audio'])
        
        # ì˜¤ë””ì˜¤ ê¸¸ì´ ì¡°ì • (íƒ€ì´ë° ë§ì¶¤)
        target_duration = int((segment['end'] - segment['start']) * 1000)
        if len(audio_data) != target_duration:
            audio_data = audio_data.speedup(
                playback_speed=len(audio_data) / target_duration
            )
        
        final_audio = final_audio.overlay(audio_data, position=start_ms)
    
    # ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥
    temp_audio = "temp_dubbed_audio.wav"
    final_audio.export(temp_audio, format="wav")
    
    # ë¹„ë””ì˜¤ì™€ ì˜¤ë””ì˜¤ í•©ì„±
    (
        ffmpeg
        .input(original_video)
        .input(temp_audio)
        .output(output_file, vcodec='copy', acodec='aac')
        .overwrite_output()
        .run()
    )
    
    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
    os.remove(temp_audio)
```

### 6ë‹¨ê³„: ìë™í™” íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

#### ì™„ì „ ìë™í™” ìŠ¤í¬ë¦½íŠ¸

```python
# í†µí•© ìë™í™” íŒŒì´í”„ë¼ì¸
class YouTubeMultilingualProcessor:
    def __init__(self, config):
        self.config = config
        self.setup_models()
    
    def setup_models(self):
        """í•„ìš”í•œ ëª¨ë¸ë“¤ ì´ˆê¸°í™”"""
        self.whisper_model = whisper.load_model("large-v3")
        self.f5_tts = F5TTS(self.config['f5_tts_config'])
        self.cosy_voice = CosyVoice(self.config['cosyvoice_config'])
    
    def process_video(self, youtube_url, target_languages):
        """ë©”ì¸ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
        
        # 1. YouTube ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
        video_path = self.download_video(youtube_url)
        
        # 2. ì˜¤ë””ì˜¤ ì¶”ì¶œ ë° ì „ì²˜ë¦¬
        audio_path = self.extract_audio(video_path)
        reference_audio = self.extract_reference_audio(audio_path)
        
        # 3. ìŒì„± ì¸ì‹ ë° ìë§‰ ìƒì„±
        transcription = self.transcribe_audio(audio_path)
        original_subtitles = self.create_subtitles(transcription)
        
        # 4. ë‹¤êµ­ì–´ ë²ˆì—­
        translations = self.translate_subtitles(
            original_subtitles, 
            target_languages
        )
        
        # 5. ìŒì„± ë³µì œ ë° ë”ë¹™ ìƒì„±
        dubbed_videos = {}
        for lang_code in target_languages:
            dubbed_audio = self.generate_dubbing(
                reference_audio,
                translations[lang_code],
                lang_code
            )
            
            # 6. ìµœì¢… ë¹„ë””ì˜¤ í•©ì„±
            output_file = f"output_{lang_code}.mp4"
            dubbed_videos[lang_code] = self.merge_video_audio(
                video_path,
                dubbed_audio,
                output_file
            )
        
        return dubbed_videos
    
    def download_video(self, url):
        """YouTube ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ"""
        # yt-dlp êµ¬í˜„
        pass
    
    def extract_audio(self, video_path):
        """ë¹„ë””ì˜¤ì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ"""
        # ffmpeg êµ¬í˜„
        pass
    
    def transcribe_audio(self, audio_path):
        """Whisperë¥¼ í†µí•œ ìŒì„± ì¸ì‹"""
        return whisper_timestamped.transcribe_timestamped(
            self.whisper_model, 
            audio_path
        )
    
    def translate_subtitles(self, subtitles, target_languages):
        """ë‹¤êµ­ì–´ ë²ˆì—­"""
        # Deep-Translator êµ¬í˜„
        pass
    
    def generate_dubbing(self, reference_audio, translated_segments, lang_code):
        """ìŒì„± ë³µì œë¥¼ í†µí•œ ë”ë¹™ ìƒì„±"""
        # F5-TTS ë˜ëŠ” CosyVoice êµ¬í˜„
        pass
    
    def merge_video_audio(self, video_path, audio_segments, output_file):
        """ë¹„ë””ì˜¤ì™€ ì˜¤ë””ì˜¤ í•©ì„±"""
        # ffmpeg êµ¬í˜„
        pass

# ì‚¬ìš© ì˜ˆì œ
config = {
    'f5_tts_config': {...},
    'cosyvoice_config': {...},
    'translation_service': 'google',
    'output_quality': 'high'
}

processor = YouTubeMultilingualProcessor(config)
results = processor.process_video(
    youtube_url="https://www.youtube.com/watch?v=example",
    target_languages=['en', 'ja', 'zh', 'es']
)
```

## ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€ ë° ì›Œí¬í”Œë¡œìš°

### ì‚¬ë¡€ 1: êµìœ¡ ì½˜í…ì¸  ë‹¤êµ­ì–´í™”

**ì‹œë‚˜ë¦¬ì˜¤**: í•œêµ­ì–´ ì˜¨ë¼ì¸ ê°•ì˜ë¥¼ ì˜ì–´, ì¼ë³¸ì–´, ì¤‘êµ­ì–´ë¡œ ë³€í™˜

```python
# êµìœ¡ ì½˜í…ì¸  íŠ¹í™” ì„¤ì •
education_config = {
    'whisper_model': 'large-v3',
    'translation_service': 'deepl',  # ì •í™•ë„ ìš°ì„ 
    'voice_clone_model': 'cosyvoice',  # ì•ˆì •ì„± ìš°ì„ 
    'speech_rate': 0.9,  # ì•½ê°„ ëŠë¦¬ê²Œ
    'add_pauses': True,  # êµ¬ê°„ë³„ íœ´ì§€ ì¶”ê°€
    'terminology_dict': 'education_terms.json'  # ì „ë¬¸ìš©ì–´ ì‚¬ì „
}

# ì²˜ë¦¬ ê³¼ì •
results = processor.process_video(
    youtube_url="https://www.youtube.com/watch?v=education_video",
    target_languages=['en', 'ja', 'zh'],
    config=education_config
)
```

### ì‚¬ë¡€ 2: ë§ˆì¼€íŒ… ì½˜í…ì¸  ê¸€ë¡œë²Œí™”

**ì‹œë‚˜ë¦¬ì˜¤**: ì œí’ˆ ì†Œê°œ ì˜ìƒì„ 10ê°œ ì–¸ì–´ë¡œ ë™ì‹œ ì œì‘

```python
# ë§ˆì¼€íŒ… ì½˜í…ì¸  íŠ¹í™” ì„¤ì •
marketing_config = {
    'voice_clone_model': 'f5_tts',  # í’ˆì§ˆ ìš°ì„ 
    'emotion_transfer': True,  # ê°ì • ì „ë‹¬ ê°•í™”
    'cultural_adaptation': True,  # ë¬¸í™”ì  ì ì‘
    'brand_terminology': 'brand_dict.json'
}

target_markets = [
    'en',  # ì˜ì–´ê¶Œ
    'es',  # ìŠ¤í˜ì¸ì–´ê¶Œ
    'pt',  # í¬ë¥´íˆ¬ê°ˆì–´ê¶Œ
    'fr',  # í”„ë‘ìŠ¤ì–´ê¶Œ
    'de',  # ë…ì¼ì–´ê¶Œ
    'ja',  # ì¼ë³¸
    'zh',  # ì¤‘êµ­
    'ar',  # ì•„ëì–´ê¶Œ
    'ru',  # ëŸ¬ì‹œì•„ì–´ê¶Œ
    'hi'   # íŒë””ì–´ê¶Œ
]

results = processor.process_video(
    youtube_url="https://www.youtube.com/watch?v=product_intro",
    target_languages=target_markets,
    config=marketing_config
)
```

## í’ˆì§ˆ ìµœì í™” ë° í›„ì²˜ë¦¬

### ìŒì„± í’ˆì§ˆ ê°œì„ 

```python
# ìŒì„± í’ˆì§ˆ í–¥ìƒ ê¸°ë²•
def enhance_voice_quality(audio_file):
    """ìŒì„± í’ˆì§ˆ í–¥ìƒ ì²˜ë¦¬"""
    from scipy import signal
    import librosa
    
    # 1. ë…¸ì´ì¦ˆ ì œê±°
    y, sr = librosa.load(audio_file)
    y_denoised = signal.wiener(y)
    
    # 2. ìŒì„± ì •ê·œí™”
    y_normalized = librosa.util.normalize(y_denoised)
    
    # 3. ìŒì„± í–¥ìƒ (Optional: RNNoise ë“± ì‚¬ìš©)
    # y_enhanced = rnnoise_process(y_normalized)
    
    return y_normalized, sr

# ë¦½ì‹±í¬ ì •í™•ë„ ê°œì„ 
def improve_lip_sync(video_file, audio_segments):
    """ë¦½ì‹±í¬ ì •í™•ë„ ê°œì„ """
    
    # 1. ë¹„ë””ì˜¤ì—ì„œ ì… ì›€ì§ì„ ë¶„ì„
    mouth_movements = analyze_mouth_movements(video_file)
    
    # 2. ì˜¤ë””ì˜¤ íƒ€ì´ë° ë¯¸ì„¸ ì¡°ì •
    adjusted_segments = []
    for segment, movement in zip(audio_segments, mouth_movements):
        adjusted_timing = calculate_optimal_timing(segment, movement)
        adjusted_segments.append(adjusted_timing)
    
    return adjusted_segments
```

### ë²ˆì—­ í’ˆì§ˆ ê²€ì¦

```python
# ë²ˆì—­ í’ˆì§ˆ ìë™ ê²€ì¦
def validate_translation_quality(original_text, translated_text, language):
    """ë²ˆì—­ í’ˆì§ˆ ìë™ ê²€ì¦"""
    
    # 1. ì—­ë²ˆì—­ì„ í†µí•œ í’ˆì§ˆ í™•ì¸
    back_translator = GoogleTranslator(source=language, target='ko')
    back_translated = back_translator.translate(translated_text)
    
    # 2. ìœ ì‚¬ë„ ê³„ì‚° (BLEU, ROUGE ë“±)
    similarity_score = calculate_similarity(original_text, back_translated)
    
    # 3. ì „ë¬¸ìš©ì–´ ì¼ê´€ì„± ê²€ì‚¬
    terminology_check = verify_terminology_consistency(
        translated_text, 
        language
    )
    
    return {
        'similarity_score': similarity_score,
        'terminology_consistent': terminology_check,
        'quality_rating': 'high' if similarity_score > 0.8 else 'medium'
    }
```

## ë°°ì¹˜ ì²˜ë¦¬ ë° ëŒ€ìš©ëŸ‰ ì²˜ë¦¬

### ë©€í‹° í”„ë¡œì„¸ì‹± ìµœì í™”

```python
# ëŒ€ìš©ëŸ‰ ë¹„ë””ì˜¤ ë°°ì¹˜ ì²˜ë¦¬
from multiprocessing import Pool
import concurrent.futures

class BatchProcessor:
    def __init__(self, max_workers=4):
        self.max_workers = max_workers
        self.processor = YouTubeMultilingualProcessor(config)
    
    def process_video_list(self, video_urls, target_languages):
        """ì—¬ëŸ¬ ë¹„ë””ì˜¤ ë™ì‹œ ì²˜ë¦¬"""
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = []
            
            for url in video_urls:
                future = executor.submit(
                    self.processor.process_video,
                    url,
                    target_languages
                )
                futures.append((url, future))
            
            results = {}
            for url, future in futures:
                try:
                    results[url] = future.result(timeout=3600)  # 1ì‹œê°„ íƒ€ì„ì•„ì›ƒ
                except Exception as e:
                    print(f"Error processing {url}: {e}")
                    results[url] = None
            
            return results
    
    def process_channel(self, channel_url, target_languages, max_videos=10):
        """ì±„ë„ ì „ì²´ ë¹„ë””ì˜¤ ì²˜ë¦¬"""
        
        # ì±„ë„ì—ì„œ ë¹„ë””ì˜¤ URL ëª©ë¡ ì¶”ì¶œ
        video_urls = self.extract_channel_videos(channel_url, max_videos)
        
        # ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰
        return self.process_video_list(video_urls, target_languages)

# ì‚¬ìš© ì˜ˆì œ
batch_processor = BatchProcessor(max_workers=2)
results = batch_processor.process_channel(
    channel_url="https://www.youtube.com/@example_channel",
    target_languages=['en', 'ja', 'zh'],
    max_videos=5
)
```

## ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### ì²˜ë¦¬ ìƒíƒœ ì¶”ì 

```python
# ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
import logging
from tqdm import tqdm

class ProcessingMonitor:
    def __init__(self):
        self.setup_logging()
        self.progress_bar = None
    
    def setup_logging(self):
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('voice_pro_processing.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def start_processing(self, total_videos):
        self.progress_bar = tqdm(total=total_videos, desc="Processing videos")
        self.logger.info(f"Starting batch processing of {total_videos} videos")
    
    def update_progress(self, video_url, status, language=None):
        if self.progress_bar:
            self.progress_bar.update(1)
        
        message = f"Video: {video_url}, Status: {status}"
        if language:
            message += f", Language: {language}"
        
        self.logger.info(message)
    
    def log_error(self, error_msg, video_url=None):
        error_log = f"Error: {error_msg}"
        if video_url:
            error_log += f" (Video: {video_url})"
        
        self.logger.error(error_log)
    
    def finish_processing(self):
        if self.progress_bar:
            self.progress_bar.close()
        self.logger.info("Batch processing completed")

# ì‚¬ìš© ì˜ˆì œ
monitor = ProcessingMonitor()
monitor.start_processing(len(video_urls))

for url in video_urls:
    try:
        monitor.update_progress(url, "downloading")
        # ì²˜ë¦¬ ì½”ë“œ...
        monitor.update_progress(url, "completed")
    except Exception as e:
        monitor.log_error(str(e), url)

monitor.finish_processing()
```

## ë¹„ìš© ìµœì í™” ì „ëµ

### í´ë¼ìš°ë“œ vs ë¡œì»¬ ì²˜ë¦¬ ë¹„êµ

| í•­ëª© | ë¡œì»¬ ì²˜ë¦¬ | í´ë¼ìš°ë“œ ì²˜ë¦¬ |
|------|----------|--------------|
| ì´ˆê¸° ë¹„ìš© | ë†’ìŒ (í•˜ë“œì›¨ì–´) | ë‚®ìŒ |
| ìš´ì˜ ë¹„ìš© | ë‚®ìŒ (ì „ê¸°ë£Œë§Œ) | ë†’ìŒ (ì‚¬ìš©ëŸ‰ ê¸°ë°˜) |
| í™•ì¥ì„± | ì œí•œì  | ë¬´ì œí•œ |
| ì²˜ë¦¬ ì†ë„ | í•˜ë“œì›¨ì–´ ì˜ì¡´ | ê³ ì„±ëŠ¥ |
| ë°ì´í„° ë³´ì•ˆ | ë†’ìŒ | ì„œë¹„ìŠ¤ ì˜ì¡´ |

### ë¹„ìš© íš¨ìœ¨ì ì¸ ì²˜ë¦¬ ì „ëµ

```python
# ë¹„ìš© ìµœì í™” ì „ëµ
class CostOptimizedProcessor:
    def __init__(self):
        self.cost_tracker = {
            'api_calls': 0,
            'processing_time': 0,
            'estimated_cost': 0.0
        }
    
    def choose_optimal_strategy(self, video_duration, target_languages):
        """ìµœì  ì²˜ë¦¬ ì „ëµ ì„ íƒ"""
        
        # ì§§ì€ ë¹„ë””ì˜¤: ë¡œì»¬ ì²˜ë¦¬
        if video_duration < 600:  # 10ë¶„ ë¯¸ë§Œ
            return 'local'
        
        # ë§ì€ ì–¸ì–´: í´ë¼ìš°ë“œ ë³‘ë ¬ ì²˜ë¦¬
        elif len(target_languages) > 5:
            return 'cloud_parallel'
        
        # ì¤‘ê°„ ê·œëª¨: í•˜ì´ë¸Œë¦¬ë“œ
        else:
            return 'hybrid'
    
    def estimate_processing_cost(self, strategy, video_duration, languages):
        """ì²˜ë¦¬ ë¹„ìš© ì˜ˆì¸¡"""
        
        costs = {
            'local': 0.0,  # ì „ê¸°ë£Œë§Œ
            'cloud_parallel': video_duration * len(languages) * 0.05,
            'hybrid': video_duration * len(languages) * 0.03
        }
        
        return costs.get(strategy, 0.0)
```

## ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### ì¼ë°˜ì ì¸ ì˜¤ë¥˜ ë° í•´ê²°ì±…

#### 1. ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜

```python
# ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •
def optimize_memory_usage():
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”"""
    
    # 1. ë°°ì¹˜ í¬ê¸° ì¡°ì •
    batch_size = 1 if torch.cuda.get_device_properties(0).total_memory < 8e9 else 4
    
    # 2. ëª¨ë¸ ì •ë°€ë„ ì¡°ì •
    torch_dtype = torch.float16  # ë©”ëª¨ë¦¬ ì ˆì•½
    
    # 3. ìºì‹œ ì •ë¦¬
    torch.cuda.empty_cache()
    
    return {
        'batch_size': batch_size,
        'torch_dtype': torch_dtype
    }
```

#### 2. ìŒì„± í’ˆì§ˆ ì €í•˜

```python
# ìŒì„± í’ˆì§ˆ ê°œì„ 
def improve_audio_quality():
    """ìŒì„± í’ˆì§ˆ ê°œì„  ì„¤ì •"""
    
    return {
        'sample_rate': 24000,  # ë†’ì€ ìƒ˜í”Œë§ ë ˆì´íŠ¸
        'bit_depth': 16,
        'noise_reduction': True,
        'voice_enhancement': True,
        'reference_audio_length': 15  # ë” ê¸´ ë ˆí¼ëŸ°ìŠ¤
    }
```

#### 3. ë™ê¸°í™” ë¬¸ì œ

```python
# ë¦½ì‹±í¬ ê°œì„ 
def fix_synchronization_issues():
    """ë™ê¸°í™” ë¬¸ì œ í•´ê²°"""
    
    return {
        'timing_adjustment': True,
        'speed_matching': True,
        'pause_detection': True,
        'fine_tuning': True
    }
```

## ê³ ê¸‰ ê¸°ëŠ¥ ë° ì»¤ìŠ¤í„°ë§ˆì´ì§•

### ì‚¬ìš©ì ì •ì˜ ëª¨ë¸ í•™ìŠµ

```python
# ì‚¬ìš©ì ì •ì˜ ìŒì„± ëª¨ë¸ íŒŒì¸íŠœë‹
class CustomVoiceTrainer:
    def __init__(self, base_model='f5_tts'):
        self.base_model = base_model
    
    def prepare_training_data(self, voice_samples, transcripts):
        """í•™ìŠµ ë°ì´í„° ì¤€ë¹„"""
        
        # 1. ìŒì„± ë°ì´í„° ì „ì²˜ë¦¬
        processed_audio = []
        for sample in voice_samples:
            audio = self.preprocess_audio(sample)
            processed_audio.append(audio)
        
        # 2. í…ìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬
        clean_transcripts = []
        for transcript in transcripts:
            clean_text = self.clean_text(transcript)
            clean_transcripts.append(clean_text)
        
        return processed_audio, clean_transcripts
    
    def fine_tune_model(self, audio_data, text_data, epochs=100):
        """ëª¨ë¸ íŒŒì¸íŠœë‹"""
        
        # F5-TTS íŒŒì¸íŠœë‹ êµ¬í˜„
        # ì‹¤ì œ êµ¬í˜„ì€ F5-TTS ë¬¸ì„œ ì°¸ì¡°
        pass

# ì‚¬ìš© ì˜ˆì œ
trainer = CustomVoiceTrainer()
trainer.fine_tune_model(voice_samples, transcripts)
```

### API ì„œë²„ êµ¬ì¶•

```python
# FastAPI ê¸°ë°˜ ì›¹ ì„œë¹„ìŠ¤
from fastapi import FastAPI, BackgroundTasks
import uvicorn

app = FastAPI(title="Voice-Pro API Server")

@app.post("/process_video")
async def process_video_endpoint(
    background_tasks: BackgroundTasks,
    youtube_url: str,
    target_languages: list[str]
):
    """ë¹„ë””ì˜¤ ì²˜ë¦¬ API ì—”ë“œí¬ì¸íŠ¸"""
    
    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬
    background_tasks.add_task(
        process_video_background,
        youtube_url,
        target_languages
    )
    
    return {"message": "Processing started", "status": "queued"}

@app.get("/status/{job_id}")
async def get_processing_status(job_id: str):
    """ì²˜ë¦¬ ìƒíƒœ í™•ì¸"""
    
    # ì²˜ë¦¬ ìƒíƒœ ë°˜í™˜
    return {"job_id": job_id, "status": "processing"}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

## ê²°ë¡  ë° í–¥í›„ ì „ë§

Voice-Proë¥¼ í™œìš©í•œ YouTube ë‹¤êµ­ì–´ ì½˜í…ì¸  ìë™í™”ëŠ” **ê¸€ë¡œë²Œ ì½˜í…ì¸  ì œì‘ì˜ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„**ì„ ì œì‹œí•©ë‹ˆë‹¤. ì´ ë„êµ¬ë¥¼ í†µí•´:

### ë‹¬ì„± ê°€ëŠ¥í•œ ëª©í‘œ

1. **ìƒì‚°ì„± í–¥ìƒ**: ìˆ˜ë™ ì‘ì—… ëŒ€ë¹„ **90% ì‹œê°„ ë‹¨ì¶•**
2. **ë¹„ìš© ì ˆê°**: ì „ë¬¸ ë”ë¹™ ì„œë¹„ìŠ¤ ëŒ€ë¹„ **80% ë¹„ìš© ì ˆì•½**
3. **í’ˆì§ˆ ì¼ê´€ì„±**: AI ê¸°ë°˜ ì¼ê´€ëœ í’ˆì§ˆ ìœ ì§€
4. **í™•ì¥ì„±**: ë¬´ì œí•œ ì–¸ì–´ ë° ë¹„ë””ì˜¤ ì²˜ë¦¬

### ì œí•œì‚¬í•­ ë° ê³ ë ¤ì‚¬í•­

1. **í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­**: GPU í•„ìˆ˜ (ê³ í’ˆì§ˆ ì²˜ë¦¬ ì‹œ)
2. **í•™ìŠµ ê³¡ì„ **: ì´ˆê¸° ì„¤ì • ë° ìµœì í™” í•„ìš”
3. **ì–¸ì–´ë³„ í’ˆì§ˆ ì°¨ì´**: ì¼ë¶€ ì–¸ì–´ëŠ” ì¶”ê°€ íŠœë‹ í•„ìš”
4. **ì €ì‘ê¶Œ ê³ ë ¤**: YouTube ì½˜í…ì¸  ì‚¬ìš© ì‹œ ê¶Œë¦¬ í™•ì¸ í•„ìš”

### í–¥í›„ ê°œë°œ ë°©í–¥

1. **ì‹¤ì‹œê°„ ì²˜ë¦¬**: ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ë‹¤êµ­ì–´ ì§€ì›
2. **ê°ì • ì „ë‹¬**: ë” ì •êµí•œ ê°ì • í‘œí˜„ ë³µì œ
3. **ë¬¸í™”ì  ì ì‘**: ì§€ì—­ë³„ ë¬¸í™” íŠ¹ì„± ë°˜ì˜
4. **ëª¨ë°”ì¼ ìµœì í™”**: ìŠ¤ë§ˆíŠ¸í°ì—ì„œë„ ì²˜ë¦¬ ê°€ëŠ¥í•œ ê²½ëŸ‰í™”

Voice-ProëŠ” ë‹¨ìˆœí•œ ë„êµ¬ë¥¼ ë„˜ì–´ **ê¸€ë¡œë²Œ ì½˜í…ì¸  ìƒíƒœê³„ì˜ ë¯¼ì£¼í™”**ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” í˜ì‹ ì ì¸ í”Œë«í¼ì…ë‹ˆë‹¤. ê°œì¸ í¬ë¦¬ì—ì´í„°ë¶€í„° ëŒ€í˜• ë¯¸ë””ì–´ ê¸°ì—…ê¹Œì§€, ëª¨ë“  ê·œëª¨ì˜ ì½˜í…ì¸  ì œì‘ìê°€ ì–¸ì–´ì˜ ì¥ë²½ ì—†ì´ ì „ ì„¸ê³„ ì˜¤ë””ì–¸ìŠ¤ì™€ ì†Œí†µí•  ìˆ˜ ìˆëŠ” ë¯¸ë˜ë¥¼ ì—´ì–´ê°€ê³  ìˆìŠµë‹ˆë‹¤.

## ì°¸ê³  ìë£Œ ë° ì¶”ê°€ í•™ìŠµ

- [Voice-Pro GitHub ì €ì¥ì†Œ](https://github.com/abus-aikorea/voice-pro)
- [F5-TTS ê³µì‹ ë¬¸ì„œ](https://github.com/SWivid/F5-TTS)
- [CosyVoice í”„ë¡œì íŠ¸](https://github.com/FunAudioLLM/CosyVoice)
- [Whisper ëª¨ë¸ ê°€ì´ë“œ](https://github.com/openai/whisper)
- [yt-dlp ì‚¬ìš©ë²•](https://github.com/yt-dlp/yt-dlp)
- [Demucs ìŒì„± ë¶„ë¦¬](https://github.com/facebookresearch/demucs)

**ğŸ¯ ì‹¤ìŠµ í”„ë¡œì íŠ¸**: ì´ ê°€ì´ë“œë¥¼ ë”°ë¼ ì—¬ëŸ¬ë¶„ë§Œì˜ YouTube ì±„ë„ì„ ë‹¤êµ­ì–´ë¡œ í™•ì¥í•´ë³´ì„¸ìš”! 