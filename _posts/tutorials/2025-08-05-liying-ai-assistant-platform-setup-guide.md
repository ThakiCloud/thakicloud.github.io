---
title: "LiYing: ì˜¤í”ˆì†ŒìŠ¤ AI ì–´ì‹œìŠ¤í„´íŠ¸ í”Œë«í¼ ì™„ì „ êµ¬ì¶• ê°€ì´ë“œ"
excerpt: "ë‹¤êµ­ì–´ ì§€ì› AI ì–´ì‹œìŠ¤í„´íŠ¸ í”Œë«í¼ LiYingì˜ ì„¤ì¹˜ë¶€í„° ì»¤ìŠ¤í„°ë§ˆì´ì§•ê¹Œì§€! ìŒì„± ì¸ì‹, ìì—°ì–´ ì²˜ë¦¬, ì‘ì—… ìë™í™”ë¥¼ í†µí•©í•œ ì§€ëŠ¥í˜• ì–´ì‹œìŠ¤í„´íŠ¸ êµ¬ì¶• ë°©ë²•"
seo_title: "LiYing AI ì–´ì‹œìŠ¤í„´íŠ¸ í”Œë«í¼ ì™„ì „ ì„¤ì • ê°€ì´ë“œ - Thaki Cloud"
seo_description: "ì˜¤í”ˆì†ŒìŠ¤ LiYing AI ì–´ì‹œìŠ¤í„´íŠ¸ í”Œë«í¼ êµ¬ì¶• ë°©ë²•. ìŒì„± ì¸ì‹, NLP, ì‘ì—… ìë™í™”, í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œì„ í™œìš©í•œ ë§ì¶¤í˜• AI ì–´ì‹œìŠ¤í„´íŠ¸ ê°œë°œ ê°€ì´ë“œ"
date: 2025-08-05
last_modified_at: 2025-08-05
categories:
  - tutorials
tags:
  - liying
  - ai-assistant
  - natural-language-processing
  - voice-recognition
  - automation
  - python
  - machine-learning
  - chatbot
  - open-source
  - nlp
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
toc_icon: "cog"
toc_sticky: true
canonical_url: "https://thakicloud.github.io/tutorials/liying-ai-assistant-platform-setup-guide/"
reading_time: true
---

â±ï¸ **ì˜ˆìƒ ì½ê¸° ì‹œê°„**: 19ë¶„

## ì„œë¡ 

í˜„ëŒ€ì˜ ë””ì§€í„¸ ì›Œí¬í”Œë¡œìš°ì—ì„œ **AI ì–´ì‹œìŠ¤í„´íŠ¸**ëŠ” í•„ìˆ˜ì ì¸ ë„êµ¬ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ê¸°ì¡´ì˜ ìƒìš© ì†”ë£¨ì…˜ë“¤ì€ ë°ì´í„° í”„ë¼ì´ë²„ì‹œ ë¬¸ì œ, ë†’ì€ ë¹„ìš©, ì œí•œì ì¸ ì»¤ìŠ¤í„°ë§ˆì´ì§• ë“±ì˜ í•œê³„ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ **ê¸°ì—… ë‚´ë¶€ ì •ë³´**ë‚˜ **ë¯¼ê°í•œ ë°ì´í„°**ë¥¼ ë‹¤ë£¨ëŠ” í™˜ê²½ì—ì„œëŠ” ì™¸ë¶€ AI ì„œë¹„ìŠ¤ ì‚¬ìš©ì´ ì œì•½ë˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.

[LiYing](https://github.com/aoguai/LiYing)ì€ ì´ëŸ° ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” **ì˜¤í”ˆì†ŒìŠ¤ AI ì–´ì‹œìŠ¤í„´íŠ¸ í”Œë«í¼**ì…ë‹ˆë‹¤. **Python ê¸°ë°˜**ìœ¼ë¡œ êµ¬ì¶•ë˜ì–´ ìˆìœ¼ë©°, **ëª¨ë“ˆì‹ ì•„í‚¤í…ì²˜**ë¥¼ í†µí•´ í•„ìš”í•œ ê¸°ëŠ¥ë§Œ ì„ íƒì ìœ¼ë¡œ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. **ì˜¨í”„ë ˆë¯¸ìŠ¤ ë°°í¬**ë¥¼ ì§€ì›í•˜ì—¬ ë°ì´í„° ë³´ì•ˆì„ ë³´ì¥í•˜ë©´ì„œë„, **í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œ**ì„ í†µí•´ ë¬´í•œíˆ í™•ì¥ ê°€ëŠ¥í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ë²ˆ ê°€ì´ë“œì—ì„œëŠ” LiYingì˜ ì„¤ì¹˜ë¶€í„° ê³ ê¸‰ ì»¤ìŠ¤í„°ë§ˆì´ì§•ê¹Œì§€, ì‹¤ë¬´ì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” ì™„ì „í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ êµ¬ì¶• ë°©ë²•ì„ ë‹¤ë£¨ê² ìŠµë‹ˆë‹¤.

## LiYing í•µì‹¬ ê¸°ëŠ¥

### ğŸ§  ì§€ëŠ¥í˜• ëŒ€í™” ì‹œìŠ¤í…œ

LiYingì€ **ê³ ê¸‰ ìì—°ì–´ ì²˜ë¦¬(NLP)**ë¥¼ í†µí•´ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

#### ëŒ€í™” ì—”ì§„ ì•„í‚¤í…ì²˜
```python
# core/conversation/engine.py
class ConversationEngine:
    def __init__(self, config):
        self.config = config
        self.nlp_processor = NLPProcessor(config.nlp)
        self.intent_classifier = IntentClassifier(config.intents)
        self.entity_extractor = EntityExtractor(config.entities)
        self.response_generator = ResponseGenerator(config.responses)
        self.context_manager = ContextManager()
    
    async def process_message(self, user_input, session_id):
        """ì‚¬ìš©ì ë©”ì‹œì§€ ì²˜ë¦¬"""
        
        # 1. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        cleaned_input = self.nlp_processor.preprocess(user_input)
        
        # 2. ì˜ë„ ë¶„ë¥˜
        intent = await self.intent_classifier.classify(cleaned_input)
        
        # 3. ê°œì²´ëª… ì¶”ì¶œ
        entities = await self.entity_extractor.extract(cleaned_input)
        
        # 4. ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
        context = self.context_manager.update_context(
            session_id, intent, entities
        )
        
        # 5. ì‘ë‹µ ìƒì„±
        response = await self.response_generator.generate(
            intent, entities, context
        )
        
        return {
            'intent': intent,
            'entities': entities,
            'response': response,
            'context': context,
            'confidence': intent.confidence
        }
```

#### ë‹¤êµ­ì–´ ì§€ì› ì‹œìŠ¤í…œ
```python
# core/i18n/language_manager.py
class LanguageManager:
    def __init__(self):
        self.supported_languages = {
            'ko': 'í•œêµ­ì–´',
            'en': 'English',
            'zh': 'ä¸­æ–‡',
            'ja': 'æ—¥æœ¬èª',
            'es': 'EspaÃ±ol',
            'fr': 'FranÃ§ais',
            'de': 'Deutsch'
        }
        self.language_models = {}
        self.load_language_models()
    
    def detect_language(self, text):
        """ì–¸ì–´ ìë™ ê°ì§€"""
        from langdetect import detect, detect_langs
        
        try:
            detected = detect(text)
            confidence_scores = detect_langs(text)
            
            return {
                'language': detected,
                'confidence': max([lang.prob for lang in confidence_scores]),
                'alternatives': [
                    {'lang': lang.lang, 'prob': lang.prob} 
                    for lang in confidence_scores[:3]
                ]
            }
        except:
            return {'language': 'en', 'confidence': 0.5, 'alternatives': []}
    
    def translate_response(self, text, target_language):
        """ì‘ë‹µ ë²ˆì—­"""
        if target_language not in self.supported_languages:
            return text
        
        # ë²ˆì—­ ì„œë¹„ìŠ¤ ì—°ë™ (Google Translate, DeepL, ë“±)
        translated = self.translation_service.translate(
            text, target_language
        )
        
        return translated
```

### ğŸ¤ ìŒì„± ì¸ì‹ ë° í•©ì„±

**ì‹¤ì‹œê°„ ìŒì„± ì²˜ë¦¬**ë¡œ í•¸ì¦ˆí”„ë¦¬ ìƒí˜¸ì‘ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

#### ìŒì„± ì¸ì‹ ì—”ì§„
```python
# modules/speech/recognition.py
import speech_recognition as sr
import pyaudio
import wave
import asyncio

class SpeechRecognitionEngine:
    def __init__(self, config):
        self.config = config
        self.recognizer = sr.Recognizer()
        self.microphone = sr.Microphone()
        self.setup_microphone()
    
    def setup_microphone(self):
        """ë§ˆì´í¬ ì„¤ì • ìµœì í™”"""
        with self.microphone as source:
            # ì£¼ë³€ ì†ŒìŒ ìˆ˜ì¤€ ì¡°ì •
            self.recognizer.adjust_for_ambient_noise(source, duration=1)
            
        # ì¸ì‹ íŒŒë¼ë¯¸í„° ì¡°ì •
        self.recognizer.energy_threshold = 300
        self.recognizer.dynamic_energy_threshold = True
        self.recognizer.pause_threshold = 0.8
        self.recognizer.phrase_threshold = 0.3
        self.recognizer.non_speaking_duration = 0.8
    
    async def listen_continuously(self, callback):
        """ì—°ì† ìŒì„± ì¸ì‹"""
        def audio_callback(recognizer, audio):
            try:
                # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìŒì„± ì¸ì‹ ì²˜ë¦¬
                asyncio.create_task(self.process_audio(audio, callback))
            except Exception as e:
                print(f"ìŒì„± ì¸ì‹ ì˜¤ë¥˜: {e}")
        
        # ë°±ê·¸ë¼ìš´ë“œ ë¦¬ìŠ¤ë‹ ì‹œì‘
        stop_listening = self.recognizer.listen_in_background(
            self.microphone, audio_callback, phrase_time_limit=5
        )
        
        return stop_listening
    
    async def process_audio(self, audio, callback):
        """ìŒì„± ë°ì´í„° ì²˜ë¦¬"""
        try:
            # ì—¬ëŸ¬ STT ì—”ì§„ ë³‘ë ¬ ì²˜ë¦¬
            recognition_results = await asyncio.gather(
                self.recognize_with_google(audio),
                self.recognize_with_whisper(audio),
                self.recognize_with_wav2vec2(audio),
                return_exceptions=True
            )
            
            # ìµœê³  ì‹ ë¢°ë„ ê²°ê³¼ ì„ íƒ
            best_result = self.select_best_recognition(recognition_results)
            
            if best_result and best_result['confidence'] > 0.7:
                await callback(best_result)
                
        except Exception as e:
            print(f"ìŒì„± ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    
    async def recognize_with_whisper(self, audio):
        """OpenAI Whisper ìŒì„± ì¸ì‹"""
        import whisper
        
        # ìŒì„± ë°ì´í„°ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
            tmp_file.write(audio.get_wav_data())
            tmp_file_path = tmp_file.name
        
        try:
            # Whisper ëª¨ë¸ ë¡œë“œ (ìºì‹œë¨)
            model = whisper.load_model("base")
            
            # ìŒì„± ì¸ì‹ ì‹¤í–‰
            result = model.transcribe(tmp_file_path, language='ko')
            
            return {
                'text': result['text'].strip(),
                'confidence': 0.9,  # WhisperëŠ” ì‹ ë¢°ë„ ì ìˆ˜ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŒ
                'engine': 'whisper'
            }
        finally:
            os.unlink(tmp_file_path)
```

#### ìŒì„± í•©ì„± ì‹œìŠ¤í…œ
```python
# modules/speech/synthesis.py
import pyttsx3
import asyncio
from gtts import gTTS
import pygame

class TextToSpeechEngine:
    def __init__(self, config):
        self.config = config
        self.tts_engine = pyttsx3.init()
        self.setup_voice()
        pygame.mixer.init()
    
    def setup_voice(self):
        """ìŒì„± ì„¤ì •"""
        voices = self.tts_engine.getProperty('voices')
        
        # í•œêµ­ì–´ ìŒì„± ì°¾ê¸°
        korean_voice = None
        for voice in voices:
            if 'korean' in voice.name.lower() or 'ko' in voice.id.lower():
                korean_voice = voice
                break
        
        if korean_voice:
            self.tts_engine.setProperty('voice', korean_voice.id)
        
        # ìŒì„± ì†ë„ ë° ë³¼ë¥¨ ì„¤ì •
        self.tts_engine.setProperty('rate', self.config.speech_rate or 200)
        self.tts_engine.setProperty('volume', self.config.speech_volume or 0.9)
    
    async def speak(self, text, language='ko'):
        """í…ìŠ¤íŠ¸ ìŒì„± ë³€í™˜ ë° ì¬ìƒ"""
        if self.config.use_online_tts:
            await self.speak_with_gtts(text, language)
        else:
            await self.speak_with_pyttsx3(text)
    
    async def speak_with_gtts(self, text, language='ko'):
        """Google TTS ì‚¬ìš©"""
        try:
            tts = gTTS(text=text, lang=language, slow=False)
            
            with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as tmp_file:
                tts.save(tmp_file.name)
                
                # ì˜¤ë””ì˜¤ ì¬ìƒ
                pygame.mixer.music.load(tmp_file.name)
                pygame.mixer.music.play()
                
                # ì¬ìƒ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
                while pygame.mixer.music.get_busy():
                    await asyncio.sleep(0.1)
                
                os.unlink(tmp_file.name)
                
        except Exception as e:
            print(f"TTS ì˜¤ë¥˜: {e}")
            # í´ë°±ìœ¼ë¡œ ë¡œì»¬ TTS ì‚¬ìš©
            await self.speak_with_pyttsx3(text)
    
    async def speak_with_pyttsx3(self, text):
        """ë¡œì»¬ TTS ì—”ì§„ ì‚¬ìš©"""
        def speak_sync():
            self.tts_engine.say(text)
            self.tts_engine.runAndWait()
        
        # ë¹„ë™ê¸°ë¡œ ìŒì„± ì¶œë ¥
        await asyncio.get_event_loop().run_in_executor(None, speak_sync)
```

### ğŸ”§ í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œ

**í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜**ë¡œ ë¬´í•œí•œ ê¸°ëŠ¥ ì¶”ê°€ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

#### í”ŒëŸ¬ê·¸ì¸ ë§¤ë‹ˆì €
```python
# core/plugins/manager.py
import importlib
import inspect
from typing import Dict, List, Any

class PluginManager:
    def __init__(self, config):
        self.config = config
        self.plugins: Dict[str, Any] = {}
        self.plugin_hooks: Dict[str, List[callable]] = {}
        self.load_plugins()
    
    def load_plugins(self):
        """í”ŒëŸ¬ê·¸ì¸ ìë™ ë¡œë“œ"""
        plugin_dir = self.config.plugin_directory
        
        for plugin_file in os.listdir(plugin_dir):
            if plugin_file.endswith('.py') and not plugin_file.startswith('_'):
                plugin_name = plugin_file[:-3]
                self.load_plugin(plugin_name)
    
    def load_plugin(self, plugin_name):
        """ê°œë³„ í”ŒëŸ¬ê·¸ì¸ ë¡œë“œ"""
        try:
            # í”ŒëŸ¬ê·¸ì¸ ëª¨ë“ˆ ë™ì  import
            plugin_module = importlib.import_module(f'plugins.{plugin_name}')
            
            # í”ŒëŸ¬ê·¸ì¸ í´ë˜ìŠ¤ ì°¾ê¸°
            for name, obj in inspect.getmembers(plugin_module):
                if (inspect.isclass(obj) and 
                    hasattr(obj, 'plugin_info') and
                    obj != BasePlugin):
                    
                    # í”ŒëŸ¬ê·¸ì¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                    plugin_instance = obj(self.config)
                    self.plugins[plugin_name] = plugin_instance
                    
                    # í›… ë“±ë¡
                    self.register_plugin_hooks(plugin_instance)
                    
                    print(f"âœ… í”ŒëŸ¬ê·¸ì¸ ë¡œë“œë¨: {plugin_name}")
                    break
                    
        except Exception as e:
            print(f"âŒ í”ŒëŸ¬ê·¸ì¸ ë¡œë“œ ì‹¤íŒ¨ ({plugin_name}): {e}")
    
    def register_plugin_hooks(self, plugin):
        """í”ŒëŸ¬ê·¸ì¸ í›… ë“±ë¡"""
        plugin_info = plugin.plugin_info
        
        for hook_name in plugin_info.get('hooks', []):
            if hook_name not in self.plugin_hooks:
                self.plugin_hooks[hook_name] = []
            
            hook_method = getattr(plugin, f'on_{hook_name}', None)
            if hook_method:
                self.plugin_hooks[hook_name].append(hook_method)
    
    async def execute_hook(self, hook_name, *args, **kwargs):
        """í›… ì‹¤í–‰"""
        results = []
        
        if hook_name in self.plugin_hooks:
            for hook_method in self.plugin_hooks[hook_name]:
                try:
                    result = await hook_method(*args, **kwargs)
                    results.append(result)
                except Exception as e:
                    print(f"í›… ì‹¤í–‰ ì˜¤ë¥˜ ({hook_name}): {e}")
        
        return results

# ê¸°ë³¸ í”ŒëŸ¬ê·¸ì¸ í´ë˜ìŠ¤
class BasePlugin:
    plugin_info = {
        'name': 'Base Plugin',
        'version': '1.0.0',
        'description': 'Base plugin class',
        'hooks': []
    }
    
    def __init__(self, config):
        self.config = config
    
    async def initialize(self):
        """í”ŒëŸ¬ê·¸ì¸ ì´ˆê¸°í™”"""
        pass
    
    async def cleanup(self):
        """í”ŒëŸ¬ê·¸ì¸ ì •ë¦¬"""
        pass
```

## ì„¤ì¹˜ ë° í™˜ê²½ êµ¬ì„±

### 1. ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

#### í•˜ë“œì›¨ì–´ ê¶Œì¥ ì‚¬ì–‘
```bash
# ìµœì†Œ ì‚¬ì–‘
CPU: 2ì½”ì–´ ì´ìƒ
RAM: 4GB ì´ìƒ
Storage: 10GB ì´ìƒ

# ê¶Œì¥ ì‚¬ì–‘ (ìŒì„± ì²˜ë¦¬ í¬í•¨)
CPU: 4ì½”ì–´ ì´ìƒ (ë˜ëŠ” GPU ì§€ì›)
RAM: 8GB ì´ìƒ
Storage: 20GB ì´ìƒ (ëª¨ë¸ ìºì‹œ í¬í•¨)
GPU: NVIDIA GPU (CUDA ì§€ì›) - ì„ íƒì‚¬í•­
```

#### ì†Œí”„íŠ¸ì›¨ì–´ ìš”êµ¬ì‚¬í•­
```bash
# Python ë²„ì „
Python 3.8+ (3.9+ ê¶Œì¥)

# ìš´ì˜ì²´ì œ
Ubuntu 20.04+ / macOS 10.15+ / Windows 10+

# ì‹œìŠ¤í…œ ì˜ì¡´ì„± í™•ì¸
python --version
pip --version
git --version
```

### 2. ê¸°ë³¸ ì„¤ì¹˜

#### ì €ì¥ì†Œ í´ë¡  ë° ì˜ì¡´ì„± ì„¤ì¹˜
```bash
# í”„ë¡œì íŠ¸ í´ë¡ 
git clone https://github.com/aoguai/LiYing.git
cd LiYing

# Python ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv liying-env

# ê°€ìƒí™˜ê²½ í™œì„±í™”
# macOS/Linux:
source liying-env/bin/activate
# Windows:
# liying-env\Scripts\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install --upgrade pip
pip install -r requirements.txt

# ê°œë°œ ë„êµ¬ ì„¤ì¹˜ (ì„ íƒì‚¬í•­)
pip install -r requirements-dev.txt
```

#### ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜ (Ubuntu/Debian)
```bash
# ìŒì„± ì²˜ë¦¬ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
sudo apt update
sudo apt install -y \
    portaudio19-dev \
    python3-pyaudio \
    espeak espeak-data \
    libespeak1 libespeak-dev \
    festival festvox-kallpc16k \
    alsa-utils pulseaudio

# FFmpeg (ìŒì„±/ë¹„ë””ì˜¤ ì²˜ë¦¬)
sudo apt install -y ffmpeg

# ê¸°íƒ€ ìœ í‹¸ë¦¬í‹°
sudo apt install -y \
    build-essential \
    python3-dev \
    libffi-dev \
    libssl-dev
```

#### macOS ì˜ì¡´ì„± ì„¤ì¹˜
```bash
# Homebrew ì‚¬ìš©
brew install portaudio
brew install espeak
brew install ffmpeg

# PyAudio ì„¤ì¹˜ (macOS íŠ¹ë³„ ì²˜ë¦¬)
pip install --global-option='build_ext' \
    --global-option='-I/opt/homebrew/include' \
    --global-option='-L/opt/homebrew/lib' \
    pyaudio
```

### 3. ì„¤ì • íŒŒì¼ êµ¬ì„±

#### ê¸°ë³¸ ì„¤ì • íŒŒì¼ ìƒì„±
```yaml
# config/config.yaml
app:
  name: "LiYing Assistant"
  version: "1.0.0"
  debug: true
  log_level: "INFO"

# ë‹¤êµ­ì–´ ì„¤ì •
i18n:
  default_language: "ko"
  supported_languages:
    - "ko"
    - "en"
    - "zh"
    - "ja"
  auto_detect: true

# ìŒì„± ì¸ì‹ ì„¤ì •
speech:
  recognition:
    engine: "whisper"  # google, whisper, wav2vec2
    language: "ko"
    timeout: 5
    phrase_time_limit: 5
    energy_threshold: 300
  
  synthesis:
    engine: "gtts"  # gtts, pyttsx3, espeak
    language: "ko"
    rate: 200
    volume: 0.9
    use_online_tts: true

# NLP ì„¤ì •
nlp:
  model_name: "klue/bert-base"  # í•œêµ­ì–´ ëª¨ë¸
  max_sequence_length: 512
  batch_size: 32
  cache_dir: "models/cache"

# ëŒ€í™” ì„¤ì •
conversation:
  max_context_length: 10
  confidence_threshold: 0.7
  response_timeout: 30
  enable_context_memory: true

# í”ŒëŸ¬ê·¸ì¸ ì„¤ì •
plugins:
  directory: "plugins"
  auto_load: true
  enabled_plugins:
    - "weather"
    - "calendar"
    - "timer"
    - "calculator"
    - "web_search"

# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
database:
  type: "sqlite"  # sqlite, postgresql, mysql
  path: "data/liying.db"
  # host: "localhost"
  # port: 5432
  # username: "liying"
  # password: "password"
  # database: "liying"

# ë³´ì•ˆ ì„¤ì •
security:
  enable_auth: false
  secret_key: "your-secret-key-here"
  session_timeout: 3600
  rate_limit: 100  # ë¶„ë‹¹ ìš”ì²­ ìˆ˜

# API ì„¤ì •
api:
  host: "0.0.0.0"
  port: 8000
  enable_cors: true
  enable_docs: true

# ë¡œê¹… ì„¤ì •
logging:
  level: "INFO"
  file: "logs/liying.log"
  max_size: "10MB"
  backup_count: 5
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
```

#### í™˜ê²½ë³„ ì„¤ì • íŒŒì¼
```bash
# ê°œë°œ í™˜ê²½
cp config/config.yaml config/config.dev.yaml

# í”„ë¡œë•ì…˜ í™˜ê²½
cp config/config.yaml config/config.prod.yaml

# í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì • íŒŒì¼ ì§€ì •
export LIYING_CONFIG=config/config.dev.yaml
```

### 4. ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”

#### SQLite ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • (ê¸°ë³¸)
```python
# scripts/init_database.py
import sqlite3
import os

def create_database():
    """ë°ì´í„°ë² ì´ìŠ¤ ë° ê¸°ë³¸ í…Œì´ë¸” ìƒì„±"""
    
    # ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs('data', exist_ok=True)
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
    conn = sqlite3.connect('data/liying.db')
    cursor = conn.cursor()
    
    # ì‚¬ìš©ì í…Œì´ë¸”
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS users (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            username VARCHAR(50) UNIQUE NOT NULL,
            email VARCHAR(100),
            preferences TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            last_active TIMESTAMP
        )
    ''')
    
    # ëŒ€í™” ì„¸ì…˜ í…Œì´ë¸”
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS conversations (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            session_id VARCHAR(100) NOT NULL,
            user_id INTEGER,
            message_type VARCHAR(20) NOT NULL,
            content TEXT NOT NULL,
            intent VARCHAR(50),
            entities TEXT,
            confidence REAL,
            timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (user_id) REFERENCES users (id)
        )
    ''')
    
    # í”ŒëŸ¬ê·¸ì¸ ì„¤ì • í…Œì´ë¸”
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS plugin_settings (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            plugin_name VARCHAR(50) NOT NULL,
            user_id INTEGER,
            settings TEXT,
            enabled BOOLEAN DEFAULT 1,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (user_id) REFERENCES users (id)
        )
    ''')
    
    # ì‹œìŠ¤í…œ ë¡œê·¸ í…Œì´ë¸”
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS system_logs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            level VARCHAR(20),
            module VARCHAR(50),
            message TEXT,
            metadata TEXT,
            timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # ì¸ë±ìŠ¤ ìƒì„±
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_conversations_session ON conversations(session_id)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_conversations_timestamp ON conversations(timestamp)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_users_username ON users(username)')
    
    conn.commit()
    conn.close()
    
    print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")

if __name__ == "__main__":
    create_database()
```

```bash
# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤í–‰
python scripts/init_database.py
```

## ê¸°ë³¸ ì‚¬ìš©ë²•

### 1. AI ì–´ì‹œìŠ¤í„´íŠ¸ ì‹œì‘

#### ëª…ë ¹í–‰ ì¸í„°í˜ì´ìŠ¤
```python
# main.py
import asyncio
from core.assistant import LiYingAssistant
from core.config import load_config

async def main():
    """LiYing ì–´ì‹œìŠ¤í„´íŠ¸ ì‹œì‘"""
    
    # ì„¤ì • ë¡œë“œ
    config = load_config()
    
    # ì–´ì‹œìŠ¤í„´íŠ¸ ì´ˆê¸°í™”
    assistant = LiYingAssistant(config)
    await assistant.initialize()
    
    print("ğŸ¤– LiYing AI ì–´ì‹œìŠ¤í„´íŠ¸ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("ìŒì„±ìœ¼ë¡œ ë§í•˜ê±°ë‚˜ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”. 'quit'ìœ¼ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    
    # ìŒì„± ì¸ì‹ ì‹œì‘
    if config.speech.recognition.enabled:
        stop_listening = await assistant.start_voice_recognition()
        print("ğŸ¤ ìŒì„± ì¸ì‹ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    try:
        # ë©”ì¸ ë£¨í”„
        while True:
            user_input = input("\nì‚¬ìš©ì: ")
            
            if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                break
            
            if user_input.strip():
                response = await assistant.process_message(user_input)
                print(f"LiYing: {response['text']}")
                
                # ìŒì„± ì‘ë‹µ
                if config.speech.synthesis.enabled:
                    await assistant.speak(response['text'])
    
    except KeyboardInterrupt:
        print("\nì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤...")
    
    finally:
        # ì •ë¦¬
        if config.speech.recognition.enabled:
            stop_listening(wait_for_stop=False)
        await assistant.cleanup()

if __name__ == "__main__":
    asyncio.run(main())
```

#### ì›¹ ì¸í„°í˜ì´ìŠ¤
```python
# web_app.py
from fastapi import FastAPI, WebSocket, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse
import asyncio
import json

app = FastAPI(title="LiYing AI Assistant")

# ì •ì  íŒŒì¼ ì„œë¹™
app.mount("/static", StaticFiles(directory="web/static"), name="static")

# ì–´ì‹œìŠ¤í„´íŠ¸ ì¸ìŠ¤í„´ìŠ¤
assistant = None

@app.on_event("startup")
async def startup_event():
    global assistant
    config = load_config()
    assistant = LiYingAssistant(config)
    await assistant.initialize()

@app.get("/", response_class=HTMLResponse)
async def get_home():
    """ë©”ì¸ í˜ì´ì§€"""
    with open("web/templates/index.html", "r", encoding="utf-8") as f:
        return HTMLResponse(content=f.read())

@app.post("/api/chat")
async def chat_endpoint(message: dict):
    """ì±„íŒ… API"""
    user_message = message.get("message", "")
    session_id = message.get("session_id", "default")
    
    if not user_message:
        raise HTTPException(status_code=400, detail="ë©”ì‹œì§€ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
    
    try:
        response = await assistant.process_message(user_message, session_id)
        return response
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """ì‹¤ì‹œê°„ ì±„íŒ… WebSocket"""
    await websocket.accept()
    session_id = f"ws_{id(websocket)}"
    
    try:
        while True:
            # í´ë¼ì´ì–¸íŠ¸ ë©”ì‹œì§€ ìˆ˜ì‹ 
            data = await websocket.receive_text()
            message_data = json.loads(data)
            
            if message_data["type"] == "message":
                user_message = message_data["content"]
                
                # ë©”ì‹œì§€ ì²˜ë¦¬
                response = await assistant.process_message(user_message, session_id)
                
                # ì‘ë‹µ ì „ì†¡
                await websocket.send_text(json.dumps({
                    "type": "response",
                    "content": response["text"],
                    "intent": response["intent"],
                    "confidence": response["confidence"]
                }))
            
            elif message_data["type"] == "voice_data":
                # ìŒì„± ë°ì´í„° ì²˜ë¦¬
                audio_data = message_data["audio"]
                text = await assistant.speech_to_text(audio_data)
                
                if text:
                    response = await assistant.process_message(text, session_id)
                    await websocket.send_text(json.dumps({
                        "type": "voice_response",
                        "transcription": text,
                        "response": response["text"]
                    }))
    
    except Exception as e:
        print(f"WebSocket ì˜¤ë¥˜: {e}")
    finally:
        # ì—°ê²° ì •ë¦¬
        await assistant.cleanup_session(session_id)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)
```

### 2. í”ŒëŸ¬ê·¸ì¸ ê°œë°œ

#### ë‚ ì”¨ ì •ë³´ í”ŒëŸ¬ê·¸ì¸
```python
# plugins/weather.py
import aiohttp
import json
from core.plugins.manager import BasePlugin

class WeatherPlugin(BasePlugin):
    plugin_info = {
        'name': 'Weather Plugin',
        'version': '1.0.0',
        'description': 'ë‚ ì”¨ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” í”ŒëŸ¬ê·¸ì¸',
        'hooks': ['message_processed'],
        'intents': ['weather_query'],
        'entities': ['location', 'date']
    }
    
    def __init__(self, config):
        super().__init__(config)
        self.api_key = config.plugins.weather.api_key
        self.api_url = "https://api.openweathermap.org/data/2.5"
    
    async def on_message_processed(self, intent, entities, context):
        """ë©”ì‹œì§€ ì²˜ë¦¬ í›„ í›…"""
        if intent.name == 'weather_query':
            return await self.get_weather_info(entities)
        return None
    
    async def get_weather_info(self, entities):
        """ë‚ ì”¨ ì •ë³´ ì¡°íšŒ"""
        location = self.extract_location(entities)
        if not location:
            return {
                'text': 'ì–´ë–¤ ì§€ì—­ì˜ ë‚ ì”¨ë¥¼ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?',
                'needs_clarification': True
            }
        
        try:
            # OpenWeatherMap API í˜¸ì¶œ
            async with aiohttp.ClientSession() as session:
                url = f"{self.api_url}/weather"
                params = {
                    'q': location,
                    'appid': self.api_key,
                    'units': 'metric',
                    'lang': 'kr'
                }
                
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        return self.format_weather_response(data)
                    else:
                        return {
                            'text': f'{location}ì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                            'error': True
                        }
        
        except Exception as e:
            return {
                'text': 'ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
                'error': str(e)
            }
    
    def format_weather_response(self, weather_data):
        """ë‚ ì”¨ ì‘ë‹µ í¬ë§·íŒ…"""
        city = weather_data['name']
        country = weather_data['sys']['country']
        temp = weather_data['main']['temp']
        feels_like = weather_data['main']['feels_like']
        humidity = weather_data['main']['humidity']
        description = weather_data['weather'][0]['description']
        
        response_text = f"""
        {city}, {country}ì˜ í˜„ì¬ ë‚ ì”¨ì…ë‹ˆë‹¤:
        
        ğŸŒ¡ï¸ ê¸°ì˜¨: {temp}Â°C (ì²´ê°ì˜¨ë„: {feels_like}Â°C)
        ğŸ’§ ìŠµë„: {humidity}%
        â˜ï¸ ë‚ ì”¨: {description}
        """
        
        return {
            'text': response_text.strip(),
            'weather_data': weather_data,
            'success': True
        }
    
    def extract_location(self, entities):
        """ì—”í‹°í‹°ì—ì„œ ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ"""
        for entity in entities:
            if entity['type'] == 'location':
                return entity['value']
        return None
```

#### ì¼ì • ê´€ë¦¬ í”ŒëŸ¬ê·¸ì¸
```python
# plugins/calendar.py
import datetime
import sqlite3
from core.plugins.manager import BasePlugin

class CalendarPlugin(BasePlugin):
    plugin_info = {
        'name': 'Calendar Plugin',
        'version': '1.0.0',
        'description': 'ì¼ì • ê´€ë¦¬ í”ŒëŸ¬ê·¸ì¸',
        'hooks': ['message_processed'],
        'intents': ['schedule_create', 'schedule_query', 'schedule_delete'],
        'entities': ['datetime', 'event_title', 'duration']
    }
    
    def __init__(self, config):
        super().__init__(config)
        self.db_path = config.database.path
        self.setup_database()
    
    def setup_database(self):
        """ì¼ì • í…Œì´ë¸” ìƒì„±"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS events (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                title VARCHAR(200) NOT NULL,
                description TEXT,
                start_time TIMESTAMP NOT NULL,
                end_time TIMESTAMP,
                user_id INTEGER,
                reminder_minutes INTEGER DEFAULT 15,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
    
    async def on_message_processed(self, intent, entities, context):
        """ë©”ì‹œì§€ ì²˜ë¦¬ í›„ í›…"""
        if intent.name == 'schedule_create':
            return await self.create_event(entities, context)
        elif intent.name == 'schedule_query':
            return await self.query_events(entities, context)
        elif intent.name == 'schedule_delete':
            return await self.delete_event(entities, context)
        return None
    
    async def create_event(self, entities, context):
        """ì¼ì • ìƒì„±"""
        title = self.extract_entity_value(entities, 'event_title')
        datetime_str = self.extract_entity_value(entities, 'datetime')
        duration = self.extract_entity_value(entities, 'duration') or 60
        
        if not title:
            return {
                'text': 'ì¼ì •ì˜ ì œëª©ì„ ì•Œë ¤ì£¼ì„¸ìš”.',
                'needs_clarification': True
            }
        
        if not datetime_str:
            return {
                'text': 'ì–¸ì œ ì¼ì •ì„ ë§Œë“œì‹œê² ìŠµë‹ˆê¹Œ?',
                'needs_clarification': True
            }
        
        try:
            # ë‚ ì§œ/ì‹œê°„ íŒŒì‹±
            start_time = self.parse_datetime(datetime_str)
            end_time = start_time + datetime.timedelta(minutes=int(duration))
            
            # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO events (title, start_time, end_time, user_id)
                VALUES (?, ?, ?, ?)
            ''', (title, start_time, end_time, context.get('user_id', 1)))
            
            event_id = cursor.lastrowid
            conn.commit()
            conn.close()
            
            return {
                'text': f'ì¼ì • "{title}"ì„(ë¥¼) {start_time.strftime("%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„")}ì— ë“±ë¡í–ˆìŠµë‹ˆë‹¤.',
                'event_id': event_id,
                'success': True
            }
        
        except Exception as e:
            return {
                'text': 'ì¼ì • ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
                'error': str(e)
            }
    
    async def query_events(self, entities, context):
        """ì¼ì • ì¡°íšŒ"""
        date_filter = self.extract_entity_value(entities, 'datetime')
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        if date_filter:
            # íŠ¹ì • ë‚ ì§œì˜ ì¼ì •
            target_date = self.parse_datetime(date_filter).date()
            cursor.execute('''
                SELECT title, start_time, end_time
                FROM events
                WHERE DATE(start_time) = ?
                ORDER BY start_time
            ''', (target_date,))
        else:
            # ì˜¤ëŠ˜ì˜ ì¼ì •
            today = datetime.date.today()
            cursor.execute('''
                SELECT title, start_time, end_time
                FROM events
                WHERE DATE(start_time) = ?
                ORDER BY start_time
            ''', (today,))
        
        events = cursor.fetchall()
        conn.close()
        
        if not events:
            return {
                'text': 'ë“±ë¡ëœ ì¼ì •ì´ ì—†ìŠµë‹ˆë‹¤.',
                'events': []
            }
        
        # ì‘ë‹µ í¬ë§·íŒ…
        response_lines = ['ì˜¤ëŠ˜ì˜ ì¼ì •ì…ë‹ˆë‹¤:']
        for title, start_time, end_time in events:
            start_dt = datetime.datetime.fromisoformat(start_time)
            end_dt = datetime.datetime.fromisoformat(end_time) if end_time else None
            
            time_str = start_dt.strftime('%H:%M')
            if end_dt:
                time_str += f' - {end_dt.strftime("%H:%M")}'
            
            response_lines.append(f'â€¢ {time_str}: {title}')
        
        return {
            'text': '\n'.join(response_lines),
            'events': events,
            'success': True
        }
    
    def parse_datetime(self, datetime_str):
        """ë‚ ì§œ/ì‹œê°„ ë¬¸ìì—´ íŒŒì‹±"""
        # ê°„ë‹¨í•œ íŒŒì‹± ì˜ˆì œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ íŒŒì‹± í•„ìš”)
        now = datetime.datetime.now()
        
        if 'ì˜¤ëŠ˜' in datetime_str:
            base_date = now.date()
        elif 'ë‚´ì¼' in datetime_str:
            base_date = now.date() + datetime.timedelta(days=1)
        elif 'ëª¨ë ˆ' in datetime_str:
            base_date = now.date() + datetime.timedelta(days=2)
        else:
            base_date = now.date()
        
        # ì‹œê°„ ì¶”ì¶œ (ì˜ˆ: "ì˜¤í›„ 3ì‹œ", "15ì‹œ", "3ì‹œ 30ë¶„")
        import re
        time_match = re.search(r'(\d{1,2})ì‹œ?\s*(\d{1,2}ë¶„?)?', datetime_str)
        
        if time_match:
            hour = int(time_match.group(1))
            minute = int(time_match.group(2).replace('ë¶„', '')) if time_match.group(2) else 0
            
            # ì˜¤í›„ ì²˜ë¦¬
            if 'ì˜¤í›„' in datetime_str and hour < 12:
                hour += 12
        else:
            hour, minute = now.hour, now.minute
        
        return datetime.datetime.combine(base_date, datetime.time(hour, minute))
    
    def extract_entity_value(self, entities, entity_type):
        """íŠ¹ì • íƒ€ì…ì˜ ì—”í‹°í‹° ê°’ ì¶”ì¶œ"""
        for entity in entities:
            if entity['type'] == entity_type:
                return entity['value']
        return None
```

## ê³ ê¸‰ ì»¤ìŠ¤í„°ë§ˆì´ì§•

### 1. ì»¤ìŠ¤í…€ NLP ëª¨ë¸ í›ˆë ¨

#### ì˜ë„ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨
```python
# training/intent_classifier.py
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from transformers import TrainingArguments, Trainer
import torch

class IntentClassifierTrainer:
    def __init__(self, model_name='klue/bert-base'):
        self.model_name = model_name
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = None
        self.label_to_id = {}
        self.id_to_label = {}
    
    def prepare_data(self, data_path):
        """í›ˆë ¨ ë°ì´í„° ì¤€ë¹„"""
        # CSV íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ
        df = pd.read_csv(data_path)
        
        # ë¼ë²¨ ì¸ì½”ë”©
        unique_labels = df['intent'].unique()
        self.label_to_id = {label: idx for idx, label in enumerate(unique_labels)}
        self.id_to_label = {idx: label for label, idx in self.label_to_id.items()}
        
        # ë°ì´í„° ë¶„í• 
        train_texts, val_texts, train_labels, val_labels = train_test_split(
            df['text'].tolist(),
            df['intent'].tolist(),
            test_size=0.2,
            random_state=42,
            stratify=df['intent']
        )
        
        # í† í°í™”
        train_encodings = self.tokenizer(
            train_texts, truncation=True, padding=True, max_length=128
        )
        val_encodings = self.tokenizer(
            val_texts, truncation=True, padding=True, max_length=128
        )
        
        # ë¼ë²¨ ID ë³€í™˜
        train_label_ids = [self.label_to_id[label] for label in train_labels]
        val_label_ids = [self.label_to_id[label] for label in val_labels]
        
        return (train_encodings, train_label_ids), (val_encodings, val_label_ids)
    
    def create_model(self, num_labels):
        """ëª¨ë¸ ìƒì„±"""
        self.model = AutoModelForSequenceClassification.from_pretrained(
            self.model_name, 
            num_labels=num_labels
        )
    
    def train(self, train_data, val_data, output_dir='models/intent_classifier'):
        """ëª¨ë¸ í›ˆë ¨"""
        train_encodings, train_labels = train_data
        val_encodings, val_labels = val_data
        
        # ë°ì´í„°ì…‹ í´ë˜ìŠ¤
        class IntentDataset(torch.utils.data.Dataset):
            def __init__(self, encodings, labels):
                self.encodings = encodings
                self.labels = labels
            
            def __getitem__(self, idx):
                item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
                item['labels'] = torch.tensor(self.labels[idx])
                return item
            
            def __len__(self):
                return len(self.labels)
        
        # ë°ì´í„°ì…‹ ìƒì„±
        train_dataset = IntentDataset(train_encodings, train_labels)
        val_dataset = IntentDataset(val_encodings, val_labels)
        
        # í›ˆë ¨ ì„¤ì •
        training_args = TrainingArguments(
            output_dir=output_dir,
            num_train_epochs=3,
            per_device_train_batch_size=16,
            per_device_eval_batch_size=64,
            warmup_steps=500,
            weight_decay=0.01,
            logging_dir=f'{output_dir}/logs',
            evaluation_strategy='epoch',
            save_strategy='epoch',
            load_best_model_at_end=True,
            metric_for_best_model='eval_loss',
            greater_is_better=False
        )
        
        # íŠ¸ë ˆì´ë„ˆ ìƒì„±
        trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=val_dataset,
            tokenizer=self.tokenizer
        )
        
        # í›ˆë ¨ ì‹¤í–‰
        trainer.train()
        
        # ëª¨ë¸ ì €ì¥
        trainer.save_model()
        self.tokenizer.save_pretrained(output_dir)
        
        # ë¼ë²¨ ë§¤í•‘ ì €ì¥
        import json
        with open(f'{output_dir}/label_mapping.json', 'w', encoding='utf-8') as f:
            json.dump({
                'label_to_id': self.label_to_id,
                'id_to_label': self.id_to_label
            }, f, ensure_ascii=False, indent=2)
    
    def evaluate(self, test_data):
        """ëª¨ë¸ í‰ê°€"""
        from sklearn.metrics import classification_report, confusion_matrix
        
        test_encodings, test_labels = test_data
        predictions = []
        
        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì˜ˆì¸¡
        for i in range(0, len(test_labels), 32):
            batch_texts = test_encodings[i:i+32]
            batch_encodings = self.tokenizer(
                batch_texts, truncation=True, padding=True, 
                max_length=128, return_tensors='pt'
            )
            
            with torch.no_grad():
                outputs = self.model(**batch_encodings)
                batch_predictions = torch.argmax(outputs.logits, dim=-1)
                predictions.extend(batch_predictions.tolist())
        
        # í‰ê°€ ë©”íŠ¸ë¦­ ê³„ì‚°
        report = classification_report(
            test_labels, predictions,
            target_names=list(self.label_to_id.keys()),
            output_dict=True
        )
        
        return report

# ì‚¬ìš© ì˜ˆì œ
def train_intent_model():
    """ì˜ë„ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì˜ˆì œ"""
    
    # í›ˆë ¨ ë°ì´í„° ì˜ˆì œ (CSV í˜•ì‹)
    training_data = """
text,intent
ì•ˆë…•í•˜ì„¸ìš”,greeting
ì•ˆë…•íˆ ê°€ì„¸ìš”,farewell
ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ?,weather_query
ì„œìš¸ ë‚ ì”¨ ì•Œë ¤ì¤˜,weather_query
ë‚´ì¼ ë¹„ ì˜¬ê¹Œ?,weather_query
ì¼ì • ì¶”ê°€í•´ì¤˜,schedule_create
ì˜¤í›„ 3ì‹œ íšŒì˜ ë“±ë¡,schedule_create
ì˜¤ëŠ˜ ì¼ì • ë­ì•¼?,schedule_query
ë‚´ì¼ ì¼ì • ì•Œë ¤ì¤˜,schedule_query
íƒ€ì´ë¨¸ 5ë¶„ ì„¤ì •,timer_set
ì•ŒëŒ 8ì‹œì— ë§ì¶°ì¤˜,alarm_set
ê³„ì‚°í•´ì¤˜ 123 ê³±í•˜ê¸° 456,calculation
ëª‡ ì‹œì•¼?,time_query
ì§€ê¸ˆ ëª‡ ì‹œ?,time_query
"""
    
    # ì„ì‹œ ë°ì´í„° íŒŒì¼ ìƒì„±
    with open('training_data.csv', 'w', encoding='utf-8') as f:
        f.write(training_data.strip())
    
    # íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”
    trainer = IntentClassifierTrainer()
    
    # ë°ì´í„° ì¤€ë¹„
    train_data, val_data = trainer.prepare_data('training_data.csv')
    
    # ëª¨ë¸ ìƒì„±
    num_labels = len(trainer.label_to_id)
    trainer.create_model(num_labels)
    
    # í›ˆë ¨ ì‹¤í–‰
    trainer.train(train_data, val_data)
    
    print("âœ… ì˜ë„ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")

if __name__ == "__main__":
    train_intent_model()
```

### 2. ì‹¤ì‹œê°„ ëŒ€í™” ê°œì„ 

#### ì»¨í…ìŠ¤íŠ¸ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ
```python
# core/memory/context_manager.py
import json
import datetime
from typing import Dict, List, Any

class ContextManager:
    def __init__(self, max_context_length=10):
        self.max_context_length = max_context_length
        self.user_contexts: Dict[str, List[Dict]] = {}
        self.global_context: Dict[str, Any] = {}
    
    def update_context(self, session_id: str, intent: Dict, entities: List[Dict], response: str):
        """ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸"""
        
        if session_id not in self.user_contexts:
            self.user_contexts[session_id] = []
        
        context_item = {
            'timestamp': datetime.datetime.now().isoformat(),
            'intent': intent,
            'entities': entities,
            'response': response,
            'turn_id': len(self.user_contexts[session_id]) + 1
        }
        
        # ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        self.user_contexts[session_id].append(context_item)
        
        # ìµœëŒ€ ê¸¸ì´ ìœ ì§€
        if len(self.user_contexts[session_id]) > self.max_context_length:
            self.user_contexts[session_id] = self.user_contexts[session_id][-self.max_context_length:]
        
        # ê¸€ë¡œë²Œ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
        self.update_global_context(intent, entities)
        
        return self.get_context(session_id)
    
    def get_context(self, session_id: str) -> Dict:
        """í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ"""
        user_context = self.user_contexts.get(session_id, [])
        
        # ìµœê·¼ ëŒ€í™”ì—ì„œ ì¤‘ìš”í•œ ì •ë³´ ì¶”ì¶œ
        recent_entities = self.extract_recent_entities(user_context)
        conversation_topic = self.infer_conversation_topic(user_context)
        user_preferences = self.extract_user_preferences(user_context)
        
        return {
            'session_id': session_id,
            'conversation_history': user_context,
            'recent_entities': recent_entities,
            'conversation_topic': conversation_topic,
            'user_preferences': user_preferences,
            'global_context': self.global_context,
            'context_length': len(user_context)
        }
    
    def extract_recent_entities(self, context_history: List[Dict]) -> Dict:
        """ìµœê·¼ ì–¸ê¸‰ëœ ì—”í‹°í‹° ì¶”ì¶œ"""
        entity_tracker = {}
        
        # ìµœê·¼ 3í„´ì˜ ëŒ€í™”ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ
        recent_turns = context_history[-3:] if len(context_history) >= 3 else context_history
        
        for turn in recent_turns:
            for entity in turn.get('entities', []):
                entity_type = entity['type']
                entity_value = entity['value']
                
                if entity_type not in entity_tracker:
                    entity_tracker[entity_type] = []
                
                # ì¤‘ë³µ ì œê±° ë° ìµœì‹  ê°’ ìš°ì„ 
                if entity_value not in [e['value'] for e in entity_tracker[entity_type]]:
                    entity_tracker[entity_type].append({
                        'value': entity_value,
                        'confidence': entity.get('confidence', 1.0),
                        'turn_id': turn['turn_id']
                    })
        
        return entity_tracker
    
    def infer_conversation_topic(self, context_history: List[Dict]) -> str:
        """ëŒ€í™” ì£¼ì œ ì¶”ë¡ """
        if not context_history:
            return 'general'
        
        # ìµœê·¼ ì˜ë„ë“¤ì„ ë¶„ì„í•˜ì—¬ ì£¼ì œ ì¶”ë¡ 
        recent_intents = [turn['intent']['name'] for turn in context_history[-5:]]
        
        topic_mapping = {
            'weather': ['weather_query', 'weather_forecast'],
            'schedule': ['schedule_create', 'schedule_query', 'schedule_delete'],
            'timer': ['timer_set', 'timer_cancel', 'alarm_set'],
            'calculation': ['calculation', 'math_operation'],
            'general': ['greeting', 'farewell', 'thanks', 'help']
        }
        
        topic_scores = {}
        for topic, intents in topic_mapping.items():
            score = sum(1 for intent in recent_intents if intent in intents)
            topic_scores[topic] = score
        
        # ê°€ì¥ ì ìˆ˜ê°€ ë†’ì€ ì£¼ì œ ë°˜í™˜
        return max(topic_scores, key=topic_scores.get) if topic_scores else 'general'
    
    def extract_user_preferences(self, context_history: List[Dict]) -> Dict:
        """ì‚¬ìš©ì ì„ í˜¸ë„ ì¶”ì¶œ"""
        preferences = {
            'preferred_language': 'ko',
            'time_format': '24h',
            'location': None,
            'reminder_preferences': {},
            'communication_style': 'formal'
        }
        
        # ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì„ í˜¸ë„ íŒ¨í„´ ë¶„ì„
        for turn in context_history:
            entities = turn.get('entities', [])
            
            # ìœ„ì¹˜ ì„ í˜¸ë„
            for entity in entities:
                if entity['type'] == 'location':
                    preferences['location'] = entity['value']
            
            # ì–¸ì–´ íŒ¨í„´ ë¶„ì„ (ë¹„ê²©ì‹ì²´ ì‚¬ìš© ì—¬ë¶€)
            response_text = turn.get('response', '')
            if any(pattern in response_text for pattern in ['ã…‹ã…‹', '~', 'â™ª']):
                preferences['communication_style'] = 'casual'
        
        return preferences
    
    def should_clarify(self, intent: Dict, entities: List[Dict], context: Dict) -> bool:
        """ì¶”ê°€ ëª…í™•í™”ê°€ í•„ìš”í•œì§€ íŒë‹¨"""
        
        # ì˜ë„ ì‹ ë¢°ë„ê°€ ë‚®ì€ ê²½ìš°
        if intent.get('confidence', 0) < 0.7:
            return True
        
        # í•„ìˆ˜ ì—”í‹°í‹°ê°€ ëˆ„ë½ëœ ê²½ìš°
        required_entities = self.get_required_entities(intent['name'])
        present_entities = [e['type'] for e in entities]
        
        missing_entities = set(required_entities) - set(present_entities)
        if missing_entities:
            return True
        
        # ëª¨í˜¸í•œ ì°¸ì¡°ê°€ ìˆëŠ” ê²½ìš°
        if self.has_ambiguous_references(entities, context):
            return True
        
        return False
    
    def get_required_entities(self, intent_name: str) -> List[str]:
        """ì˜ë„ë³„ í•„ìˆ˜ ì—”í‹°í‹° ì •ì˜"""
        requirements = {
            'weather_query': ['location'],
            'schedule_create': ['datetime', 'event_title'],
            'timer_set': ['duration'],
            'alarm_set': ['datetime'],
            'calculation': ['expression']
        }
        
        return requirements.get(intent_name, [])
    
    def has_ambiguous_references(self, entities: List[Dict], context: Dict) -> bool:
        """ëª¨í˜¸í•œ ì°¸ì¡° ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        # ì˜ˆ: "ê·¸ê²ƒ", "ì €ê¸°", "ì•„ê¹Œ ë§í•œ" ë“±ì˜ ì§€ì‹œì–´ ì²˜ë¦¬
        ambiguous_patterns = ['ê·¸ê²ƒ', 'ì €ê²ƒ', 'ì—¬ê¸°', 'ì €ê¸°', 'ì•„ê¹Œ', 'ë°©ê¸ˆ']
        
        for entity in entities:
            if any(pattern in entity['value'] for pattern in ambiguous_patterns):
                return True
        
        return False
```

### 3. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”

#### ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
```python
# core/monitoring/performance_monitor.py
import time
import psutil
import asyncio
from collections import defaultdict, deque
import logging

class PerformanceMonitor:
    def __init__(self, config):
        self.config = config
        self.metrics = defaultdict(deque)
        self.logger = logging.getLogger(__name__)
        self.alert_thresholds = {
            'response_time': 5.0,  # ì´ˆ
            'memory_usage': 80.0,   # %
            'cpu_usage': 80.0,      # %
            'error_rate': 5.0       # %
        }
    
    async def start_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        asyncio.create_task(self.collect_system_metrics())
        asyncio.create_task(self.analyze_performance())
    
    async def collect_system_metrics(self):
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        while True:
            try:
                # CPU ì‚¬ìš©ë¥ 
                cpu_percent = psutil.cpu_percent(interval=1)
                self.record_metric('cpu_usage', cpu_percent)
                
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
                memory = psutil.virtual_memory()
                self.record_metric('memory_usage', memory.percent)
                
                # ë””ìŠ¤í¬ ì‚¬ìš©ë¥ 
                disk = psutil.disk_usage('/')
                self.record_metric('disk_usage', disk.percent)
                
                # ë„¤íŠ¸ì›Œí¬ I/O
                network = psutil.net_io_counters()
                self.record_metric('network_bytes_sent', network.bytes_sent)
                self.record_metric('network_bytes_recv', network.bytes_recv)
                
                await asyncio.sleep(10)  # 10ì´ˆë§ˆë‹¤ ìˆ˜ì§‘
                
            except Exception as e:
                self.logger.error(f"ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(10)
    
    def record_metric(self, metric_name: str, value: float):
        """ë©”íŠ¸ë¦­ ê¸°ë¡"""
        timestamp = time.time()
        
        # ìµœëŒ€ 1000ê°œ ë°ì´í„° í¬ì¸íŠ¸ ìœ ì§€
        if len(self.metrics[metric_name]) >= 1000:
            self.metrics[metric_name].popleft()
        
        self.metrics[metric_name].append({
            'timestamp': timestamp,
            'value': value
        })
        
        # ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ì•Œë¦¼
        if value > self.alert_thresholds.get(metric_name, float('inf')):
            self.send_alert(metric_name, value)
    
    def measure_execution_time(self, func_name: str):
        """ì‹¤í–‰ ì‹œê°„ ì¸¡ì • ë°ì½”ë ˆì´í„°"""
        def decorator(func):
            async def wrapper(*args, **kwargs):
                start_time = time.time()
                try:
                    result = await func(*args, **kwargs)
                    execution_time = time.time() - start_time
                    self.record_metric(f'{func_name}_execution_time', execution_time)
                    return result
                except Exception as e:
                    execution_time = time.time() - start_time
                    self.record_metric(f'{func_name}_execution_time', execution_time)
                    self.record_metric(f'{func_name}_error', 1)
                    raise
            return wrapper
        return decorator
    
    async def analyze_performance(self):
        """ì„±ëŠ¥ ë¶„ì„ ë° ìµœì í™” ì œì•ˆ"""
        while True:
            try:
                await asyncio.sleep(60)  # 1ë¶„ë§ˆë‹¤ ë¶„ì„
                
                analysis = self.generate_performance_report()
                
                if analysis['issues']:
                    self.logger.warning(f"ì„±ëŠ¥ ì´ìŠˆ ê°ì§€: {analysis['issues']}")
                    
                    # ìë™ ìµœì í™” ì‹œë„
                    await self.auto_optimize(analysis)
                
            except Exception as e:
                self.logger.error(f"ì„±ëŠ¥ ë¶„ì„ ì˜¤ë¥˜: {e}")
    
    def generate_performance_report(self) -> Dict:
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        current_time = time.time()
        last_hour = current_time - 3600  # ì§€ë‚œ 1ì‹œê°„
        
        report = {
            'timestamp': current_time,
            'metrics': {},
            'issues': [],
            'recommendations': []
        }
        
        for metric_name, data_points in self.metrics.items():
            recent_data = [
                dp for dp in data_points 
                if dp['timestamp'] >= last_hour
            ]
            
            if recent_data:
                values = [dp['value'] for dp in recent_data]
                report['metrics'][metric_name] = {
                    'avg': sum(values) / len(values),
                    'max': max(values),
                    'min': min(values),
                    'count': len(values)
                }
                
                # ì´ìŠˆ ê°ì§€
                avg_value = report['metrics'][metric_name]['avg']
                threshold = self.alert_thresholds.get(metric_name)
                
                if threshold and avg_value > threshold:
                    report['issues'].append(f'{metric_name} í‰ê· ê°’ ì„ê³„ê°’ ì´ˆê³¼: {avg_value:.2f}')
        
        # ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±
        report['recommendations'] = self.generate_recommendations(report['metrics'])
        
        return report
    
    def generate_recommendations(self, metrics: Dict) -> List[str]:
        """ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # CPU ì‚¬ìš©ë¥  ìµœì í™”
        if 'cpu_usage' in metrics and metrics['cpu_usage']['avg'] > 70:
            recommendations.append('CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ëŠ˜ë¦¬ê±°ë‚˜ ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.')
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ìµœì í™”
        if 'memory_usage' in metrics and metrics['memory_usage']['avg'] > 75:
            recommendations.append('ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ìºì‹œ í¬ê¸°ë¥¼ ì¤„ì´ê±°ë‚˜ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ì„ ìµœì í™”í•˜ì„¸ìš”.')
        
        # ì‘ë‹µ ì‹œê°„ ìµœì í™”
        if 'response_time' in metrics and metrics['response_time']['avg'] > 3:
            recommendations.append('ì‘ë‹µ ì‹œê°„ì´ ëŠë¦½ë‹ˆë‹¤. ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ë‚˜ ì™¸ë¶€ API í˜¸ì¶œì„ ìµœì í™”í•˜ì„¸ìš”.')
        
        return recommendations
    
    async def auto_optimize(self, analysis: Dict):
        """ìë™ ìµœì í™” ìˆ˜í–‰"""
        metrics = analysis['metrics']
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        if 'memory_usage' in metrics and metrics['memory_usage']['avg'] > 80:
            import gc
            gc.collect()
            self.logger.info("ìë™ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ìˆ˜í–‰ë¨")
        
        # ìºì‹œ ì •ë¦¬
        if hasattr(self, 'cache_manager'):
            await self.cache_manager.cleanup_old_entries()
            self.logger.info("ìºì‹œ ì •ë¦¬ ìˆ˜í–‰ë¨")
    
    def send_alert(self, metric_name: str, value: float):
        """ì•Œë¦¼ ë°œì†¡"""
        message = f"âš ï¸ {metric_name} ì„ê³„ê°’ ì´ˆê³¼: {value:.2f}"
        
        # ë¡œê·¸ ê¸°ë¡
        self.logger.warning(message)
        
        # ì´ë©”ì¼/ìŠ¬ë™ ì•Œë¦¼ (ì„¤ì •ëœ ê²½ìš°)
        if self.config.alerts.email_enabled:
            asyncio.create_task(self.send_email_alert(message))
        
        if self.config.alerts.slack_enabled:
            asyncio.create_task(self.send_slack_alert(message))
    
    def get_metrics_dashboard_data(self) -> Dict:
        """ëŒ€ì‹œë³´ë“œìš© ë©”íŠ¸ë¦­ ë°ì´í„°"""
        dashboard_data = {}
        
        for metric_name, data_points in self.metrics.items():
            if data_points:
                latest_data = list(data_points)[-100:]  # ìµœê·¼ 100ê°œ
                dashboard_data[metric_name] = {
                    'timestamps': [dp['timestamp'] for dp in latest_data],
                    'values': [dp['value'] for dp in latest_data],
                    'current': latest_data[-1]['value'] if latest_data else 0
                }
        
        return dashboard_data
```

## ê²°ë¡ 

LiYingì€ **í”„ë¼ì´ë²„ì‹œì™€ ì»¤ìŠ¤í„°ë§ˆì´ì§•ì„ ëª¨ë‘ ë§Œì¡±**í•˜ëŠ” ì°¨ì„¸ëŒ€ AI ì–´ì‹œìŠ¤í„´íŠ¸ í”Œë«í¼ì…ë‹ˆë‹¤. ì˜¤í”ˆì†ŒìŠ¤ì˜ íˆ¬ëª…ì„±ê³¼ ì˜¨í”„ë ˆë¯¸ìŠ¤ ë°°í¬ì˜ ë³´ì•ˆì„±ì„ ê²°í•©í•˜ì—¬, ê¸°ì—…ê³¼ ê°œì¸ ëª¨ë‘ì—ê²Œ **ì™„ì „íˆ ì œì–´ ê°€ëŠ¥í•œ AI ì†”ë£¨ì…˜**ì„ ì œê³µí•©ë‹ˆë‹¤.

### ğŸ¯ í•µì‹¬ ê°€ì¹˜

1. **ë°ì´í„° ì£¼ê¶Œ**: ëª¨ë“  ë°ì´í„°ê°€ ë‚´ë¶€ì—ì„œ ì²˜ë¦¬ë˜ì–´ ì™„ì „í•œ í”„ë¼ì´ë²„ì‹œ ë³´ì¥
2. **ë¬´í•œ í™•ì¥ì„±**: í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œìœ¼ë¡œ ì–´ë–¤ ê¸°ëŠ¥ì´ë“  ì¶”ê°€ ê°€ëŠ¥
3. **ë‹¤êµ­ì–´ ì§€ì›**: ê¸€ë¡œë²Œ í™˜ê²½ì—ì„œë„ ìì—°ìŠ¤ëŸ¬ìš´ ì˜ì‚¬ì†Œí†µ
4. **ì‹¤ì‹œê°„ í•™ìŠµ**: ì‚¬ìš©í• ìˆ˜ë¡ ë” ì •í™•í•´ì§€ëŠ” ì ì‘í˜• AI

### ğŸš€ í™œìš© ë¶„ì•¼

- **ê¸°ì—… í™˜ê²½**: ë‚´ë¶€ ì—…ë¬´ ìë™í™”, ì§ì› ì§€ì›, ë°ì´í„° ë¶„ì„
- **ê°œë°œíŒ€**: ì½”ë“œ ë¦¬ë·°, ë¬¸ì„œí™”, í”„ë¡œì íŠ¸ ê´€ë¦¬ ì§€ì›
- **êµìœ¡ ê¸°ê´€**: ë§ì¶¤í˜• í•™ìŠµ ì§€ì›, ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ
- **ì˜ë£Œ ê¸°ê´€**: í™˜ì ìƒë‹´, ì˜ë£Œ ì •ë³´ ê²€ìƒ‰ (ê·œì • ì¤€ìˆ˜)

### ğŸ’¡ í˜ì‹  í¬ì¸íŠ¸

1. **ëª¨ë“ˆì‹ ì•„í‚¤í…ì²˜**: í•„ìš”í•œ ê¸°ëŠ¥ë§Œ ì„ íƒì  êµ¬ì„±
2. **ì‹¤ì‹œê°„ ì»¨í…ìŠ¤íŠ¸**: ëŒ€í™” íë¦„ì„ ê¸°ì–µí•˜ëŠ” ì§€ëŠ¥í˜• ë©”ëª¨ë¦¬
3. **ë©€í‹°ëª¨ë‹¬ ì§€ì›**: í…ìŠ¤íŠ¸, ìŒì„±, ì´ë¯¸ì§€ í†µí•© ì²˜ë¦¬
4. **ì„±ëŠ¥ ìµœì í™”**: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ê³¼ ìë™ íŠœë‹

### ğŸ”® ë¯¸ë˜ ë°œì „ ë°©í–¥

- **ì—£ì§€ ì»´í“¨íŒ…**: ë”ìš± ë¹ ë¥¸ ë¡œì»¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ê²½ëŸ‰í™”
- **ì—°í•© í•™ìŠµ**: ê°œì¸ì •ë³´ ë³´í˜¸í•˜ë©´ì„œ ì§‘ë‹¨ ì§€ëŠ¥ í–¥ìƒ
- **AR/VR í†µí•©**: ëª°ì…í˜• í™˜ê²½ì—ì„œì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸
- **IoT ì—°ë™**: ìŠ¤ë§ˆíŠ¸ í™ˆ/ì˜¤í”¼ìŠ¤ì™€ì˜ ì™„ì „í•œ í†µí•©

LiYingì„ í†µí•´ **ì§„ì •í•œ ì˜ë¯¸ì˜ ê°œì¸í™”ëœ AI ì–´ì‹œìŠ¤í„´íŠ¸**ë¥¼ êµ¬ì¶•í•˜ê³ , **ë°ì´í„° ì£¼ê¶Œì„ ì§€í‚¤ë©´ì„œë„ ìµœì²¨ë‹¨ AI ê¸°ìˆ **ì˜ í˜œíƒì„ ëˆ„ë ¤ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤. ì˜¤í”ˆì†ŒìŠ¤ AIì˜ ë¬´í•œí•œ ê°€ëŠ¥ì„±ì„ ê²½í—˜í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤! ğŸ¤–ğŸš€âœ¨

---

> **ì°¸ê³  ìë£Œ**
> - [LiYing GitHub Repository](https://github.com/aoguai/LiYing)
> - [Python ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë° ê°€ì´ë“œ](https://docs.python.org/3/library/asyncio.html)
> - [Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¬¸ì„œ](https://huggingface.co/docs/transformers)
> - [FastAPI ê³µì‹ ë¬¸ì„œ](https://fastapi.tiangolo.com)