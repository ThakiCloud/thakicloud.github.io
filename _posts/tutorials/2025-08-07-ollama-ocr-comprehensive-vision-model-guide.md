---
title: "Ollama-OCR: ë¡œì»¬ ë¹„ì „ ëª¨ë¸ë¡œ ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ì „ ë§ˆìŠ¤í„° ê°€ì´ë“œ"
excerpt: "LLaVA, Llama 3.2 Vision, Granite3.2 ë“± ë‹¤ì–‘í•œ ë¹„ì „ ëª¨ë¸ì„ í™œìš©í•œ OCR ì†”ë£¨ì…˜. PDF, ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œë¶€í„° Streamlit ì›¹ì•±ê¹Œì§€"
seo_title: "Ollama-OCR ì™„ì „ ê°€ì´ë“œ - ë¡œì»¬ ë¹„ì „ ëª¨ë¸ OCR ì†”ë£¨ì…˜ - Thaki Cloud"
seo_description: "Ollama-OCRë¡œ LLaVA, Llama 3.2 Vision, Granite3.2 ëª¨ë¸ì„ í™œìš©í•œ ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ. PDF, ì´ë¯¸ì§€ ë°°ì¹˜ ì²˜ë¦¬, Streamlit ì›¹ì•± êµ¬ì¶•ê¹Œì§€ ì™„ì „ ê°€ì´ë“œ"
date: 2025-08-07
last_modified_at: 2025-08-07
categories:
  - tutorials
tags:
  - ollama-ocr
  - vision-models
  - ocr
  - llava
  - llama-vision
  - granite-vision
  - document-processing
  - streamlit
  - python
  - local-ai
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
toc_icon: "eye"
toc_sticky: true
canonical_url: "https://thakicloud.github.io/tutorials/ollama-ocr-comprehensive-vision-model-guide/"
reading_time: true
---

â±ï¸ **ì˜ˆìƒ ì½ê¸° ì‹œê°„**: 20ë¶„

## ì„œë¡ 

ê¸°ì¡´ì˜ OCR(ê´‘í•™ ë¬¸ì ì¸ì‹) ì†”ë£¨ì…˜ë“¤ì€ **ë³µì¡í•œ ë ˆì´ì•„ì›ƒì´ë‚˜ ë‹¤ì–‘í•œ í°íŠ¸ì—ì„œ ì •í™•ë„ê°€ ë–¨ì–´ì§€ëŠ”** í•œê³„ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ í…Œì´ë¸”, ì°¨íŠ¸, í˜¼í•©ëœ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ì½˜í…ì¸ ì—ì„œëŠ” ë§Œì¡±ìŠ¤ëŸ¬ìš´ ê²°ê³¼ë¥¼ ì–»ê¸° ì–´ë ¤ì› ìŠµë‹ˆë‹¤.

[Ollama-OCR](https://github.com/imanoop7/Ollama-OCR)ì€ ì´ëŸ° ë¬¸ì œë¥¼ **ìµœì‹  ë¹„ì „-ì–¸ì–´ ëª¨ë¸(Vision-Language Models)**ë¡œ í•´ê²°í•˜ëŠ” í˜ì‹ ì ì¸ ì†”ë£¨ì…˜ì…ë‹ˆë‹¤. **LLaVA, Llama 3.2 Vision, Granite3.2** ë“± ë‹¤ì–‘í•œ ëª¨ë¸ì„ ì§€ì›í•˜ë©°, **ì™„ì „íˆ ë¡œì»¬ í™˜ê²½**ì—ì„œ ì‹¤í–‰ë˜ì–´ ë°ì´í„° í”„ë¼ì´ë²„ì‹œë¥¼ ë³´ì¥í•©ë‹ˆë‹¤.

ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” Ollama-OCRì˜ ì„¤ì¹˜ë¶€í„° ê³ ê¸‰ í™œìš©ê¹Œì§€, ì‹¤ì œ ë¬¸ì„œ ì²˜ë¦¬ ì˜ˆì œì™€ í•¨ê»˜ ì™„ì „í•œ OCR ì†”ë£¨ì…˜ êµ¬ì¶•ë²•ì„ ë‹¤ë£¨ê² ìŠµë‹ˆë‹¤.

### Ollama-OCRì˜ í˜ì‹ ì  íŠ¹ì§•

- ğŸ¤– **ë‹¤ì–‘í•œ ë¹„ì „ ëª¨ë¸**: LLaVA, Llama 3.2, Granite3.2, Moondream, MiniCPM-V ì§€ì›
- ğŸ“„ **PDF + ì´ë¯¸ì§€**: ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ì˜ í†µí•© ì²˜ë¦¬
- ğŸ¯ **ë‹¤ì¤‘ ì¶œë ¥ í˜•ì‹**: Markdown, JSON, êµ¬ì¡°í™”ëœ ë°ì´í„°, í‘œ ì¶”ì¶œ
- âš¡ **ë°°ì¹˜ ì²˜ë¦¬**: ëŒ€ëŸ‰ ë¬¸ì„œ ë³‘ë ¬ ì²˜ë¦¬ ì§€ì›
- ğŸŒ **ì›¹ ì¸í„°í˜ì´ìŠ¤**: Streamlit ê¸°ë°˜ ì‚¬ìš©ì ì¹œí™”ì  UI
- ğŸ”’ **ì™„ì „ ë¡œì»¬**: í´ë¼ìš°ë“œ ì—†ì´ í”„ë¼ì´ë²„ì‹œ ë³´ì¥

## í™˜ê²½ ìš”êµ¬ì‚¬í•­ ë° ì„¤ì¹˜

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

```bash
# í•˜ë“œì›¨ì–´ ê¶Œì¥ì‚¬í•­
- RAM: ìµœì†Œ 8GB, ê¶Œì¥ 16GB+
- GPU: NVIDIA GPU (ì„ íƒì , ì„±ëŠ¥ í–¥ìƒ)
- ë””ìŠ¤í¬: 10GB+ ì—¬ìœ  ê³µê°„ (ëª¨ë¸ ì €ì¥ìš©)

# ì†Œí”„íŠ¸ì›¨ì–´ ìš”êµ¬ì‚¬í•­
- Python 3.8+
- Ollama
- CUDA (GPU ì‚¬ìš©ì‹œ)
```

### macOS í…ŒìŠ¤íŠ¸ í™˜ê²½

```bash
# ì‹œìŠ¤í…œ ì •ë³´ í™•ì¸
system_profiler SPSoftwareDataType | grep "System Version"
# System Version: macOS 15.0.0

# Python ë²„ì „ í™•ì¸
python3 --version
# Python 3.11.5

# ë©”ëª¨ë¦¬ í™•ì¸
system_profiler SPHardwareDataType | grep "Memory"
# Memory: 32 GB
```

### 1ë‹¨ê³„: Ollama ì„¤ì¹˜

```bash
# macOSì—ì„œ Homebrewë¡œ ì„¤ì¹˜
brew install ollama

# ë˜ëŠ” ê³µì‹ ì‚¬ì´íŠ¸ì—ì„œ ì§ì ‘ ë‹¤ìš´ë¡œë“œ
# https://ollama.ai/download

# Ollama ì„œë¹„ìŠ¤ ì‹œì‘
ollama serve

# ì„¤ì¹˜ í™•ì¸
ollama --version
```

### 2ë‹¨ê³„: ë¹„ì „ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

```bash
# í•„ìˆ˜ ë¹„ì „ ëª¨ë¸ë“¤ ë‹¤ìš´ë¡œë“œ
echo "ğŸ¤– ë¹„ì „ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘..."

# Llama 3.2 Vision (ê¶Œì¥ - ê³ ì„±ëŠ¥)
ollama pull llama3.2-vision:11b

# Granite3.2 Vision (ë¬¸ì„œ ì²˜ë¦¬ íŠ¹í™”)
ollama pull granite3.2-vision

# LLaVA (ë¹ ë¥¸ ì²˜ë¦¬)
ollama pull llava

# Moondream (ê²½ëŸ‰ ëª¨ë¸)
ollama pull moondream

# MiniCPM-V (ê³ í•´ìƒë„ ì§€ì›)
ollama pull minicpm-v

echo "âœ… ëª¨ë“  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ"
```

### 3ë‹¨ê³„: Ollama-OCR íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
# pipì„ í†µí•œ ì§ì ‘ ì„¤ì¹˜
pip install ollama-ocr

# ë˜ëŠ” ê°œë°œ ë²„ì „ ì„¤ì¹˜
git clone https://github.com/imanoop7/Ollama-OCR.git
cd Ollama-OCR
pip install -r requirements.txt
pip install -e .

# ì„¤ì¹˜ í™•ì¸
python -c "import ollama_ocr; print('âœ… Ollama-OCR ì„¤ì¹˜ ì™„ë£Œ')"
```

## ê¸°ë³¸ ì‚¬ìš©ë²•ê³¼ ì²« ë²ˆì§¸ OCR

### ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬

```python
from ollama_ocr import OCRProcessor
import os

# OCR í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
ocr = OCRProcessor(
    model_name='llama3.2-vision:11b',
    base_url="http://localhost:11434/api/generate"  # ê¸°ë³¸ Ollama URL
)

# ê¸°ë³¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
def basic_ocr_example():
    """ê¸°ë³¸ OCR ì‚¬ìš© ì˜ˆì œ"""
    
    # ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    result = ocr.process_image(
        image_path="input/sample_document.png",
        format_type="text",  # ê¸°ë³¸ í…ìŠ¤íŠ¸ í˜•ì‹
        language="Korean"    # í•œêµ­ì–´ ë¬¸ì„œ ì²˜ë¦¬
    )
    
    print("=== ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ===")
    print(result)
    
    return result

# PDF ë¬¸ì„œ ì²˜ë¦¬
def pdf_ocr_example():
    """PDF ë¬¸ì„œ OCR ì˜ˆì œ"""
    
    result = ocr.process_image(
        image_path="input/business_report.pdf",
        format_type="markdown",  # ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ êµ¬ì¡° ë³´ì¡´
        language="Korean"
    )
    
    print("=== PDFì—ì„œ ì¶”ì¶œëœ ë‚´ìš© (ë§ˆí¬ë‹¤ìš´) ===")
    print(result)
    
    return result

if __name__ == "__main__":
    # ê¸°ë³¸ ì‚¬ìš©ë²• í…ŒìŠ¤íŠ¸
    basic_result = basic_ocr_example()
    pdf_result = pdf_ocr_example()
```

### ë‹¤ì–‘í•œ ì¶œë ¥ í˜•ì‹ í™œìš©

```python
def explore_output_formats():
    """ë‹¤ì–‘í•œ ì¶œë ¥ í˜•ì‹ í…ŒìŠ¤íŠ¸"""
    
    sample_image = "input/mixed_content.png"
    
    formats = {
        "text": "ìˆœìˆ˜ í…ìŠ¤íŠ¸",
        "markdown": "ë§ˆí¬ë‹¤ìš´ (êµ¬ì¡° ë³´ì¡´)",
        "json": "JSON êµ¬ì¡°í™” ë°ì´í„°",
        "structured": "êµ¬ì¡°í™”ëœ ê°ì²´",
        "key_value": "í‚¤-ê°’ ìŒ",
        "table": "í…Œì´ë¸” ë°ì´í„° ì¶”ì¶œ"
    }
    
    results = {}
    
    for format_type, description in formats.items():
        print(f"\nğŸ“‹ {description} í˜•ì‹ í…ŒìŠ¤íŠ¸...")
        
        try:
            result = ocr.process_image(
                image_path=sample_image,
                format_type=format_type,
                custom_prompt=f"ì´ ì´ë¯¸ì§€ì—ì„œ {description} í˜•ì‹ìœ¼ë¡œ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.",
                language="Korean"
            )
            
            results[format_type] = result
            print(f"âœ… {format_type} í˜•ì‹ ì„±ê³µ")
            print(f"ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°: {str(result)[:100]}...")
            
        except Exception as e:
            print(f"âŒ {format_type} í˜•ì‹ ì‹¤íŒ¨: {str(e)}")
    
    return results

# ì‹¤í–‰ ë° ê²°ê³¼ ë¹„êµ
format_results = explore_output_formats()

# íŠ¹ì • í˜•ì‹ ìƒì„¸ í™•ì¸
print("\n" + "="*50)
print("ğŸ“Š JSON í˜•ì‹ ìƒì„¸ ê²°ê³¼:")
print("="*50)
if 'json' in format_results:
    import json
    try:
        parsed_json = json.loads(format_results['json'])
        print(json.dumps(parsed_json, indent=2, ensure_ascii=False))
    except:
        print(format_results['json'])
```

## ê³ ê¸‰ ê¸°ëŠ¥: ë°°ì¹˜ ì²˜ë¦¬ì™€ ë³‘ë ¬í™”

### ëŒ€ëŸ‰ ë¬¸ì„œ ë°°ì¹˜ ì²˜ë¦¬

```python
import os
from pathlib import Path
import time

class AdvancedOCRProcessor:
    """ê³ ê¸‰ OCR ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, model_name='llama3.2-vision:11b', max_workers=4):
        self.ocr = OCRProcessor(
            model_name=model_name,
            max_workers=max_workers  # ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜
        )
        self.processed_count = 0
        self.total_count = 0
    
    def setup_batch_processing(self, input_dir, output_dir):
        """ë°°ì¹˜ ì²˜ë¦¬ í™˜ê²½ ì„¤ì •"""
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        
        # ì…ë ¥ íŒŒì¼ ëª©ë¡ ìƒì„±
        supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.pdf'}
        input_files = []
        
        for file_path in Path(input_dir).rglob('*'):
            if file_path.suffix.lower() in supported_formats:
                input_files.append(file_path)
        
        self.total_count = len(input_files)
        print(f"ğŸ“ ì²˜ë¦¬ ëŒ€ìƒ íŒŒì¼: {self.total_count}ê°œ")
        
        return input_files
    
    def process_batch_with_progress(self, input_dir, output_dir, format_type="markdown"):
        """ì§„í–‰ë¥  ì¶”ì ê³¼ í•¨ê»˜ ë°°ì¹˜ ì²˜ë¦¬"""
        
        input_files = self.setup_batch_processing(input_dir, output_dir)
        
        # ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰
        start_time = time.time()
        
        batch_results = self.ocr.process_batch(
            input_path=input_dir,
            format_type=format_type,
            recursive=True,  # í•˜ìœ„ ë””ë ‰í† ë¦¬ í¬í•¨
            preprocess=True,  # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í™œì„±í™”
            custom_prompt="ë¬¸ì„œì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ê³ , í‘œì™€ êµ¬ì¡°ë¥¼ ë³´ì¡´í•´ì£¼ì„¸ìš”.",
            language="Korean"
        )
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        # ê²°ê³¼ ì €ì¥ ë° í†µê³„
        self.save_batch_results(batch_results, output_dir)
        self.print_batch_statistics(batch_results, processing_time)
        
        return batch_results
    
    def save_batch_results(self, batch_results, output_dir):
        """ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ ì €ì¥"""
        
        results_file = Path(output_dir) / "batch_results.txt"
        summary_file = Path(output_dir) / "processing_summary.json"
        
        # ê°œë³„ íŒŒì¼ ê²°ê³¼ ì €ì¥
        for file_path, text in batch_results['results'].items():
            output_filename = Path(file_path).stem + "_extracted.txt"
            output_path = Path(output_dir) / output_filename
            
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(f"ì›ë³¸ íŒŒì¼: {file_path}\n")
                f.write("="*50 + "\n")
                f.write(text)
        
        # í†µí•© ê²°ê³¼ íŒŒì¼
        with open(results_file, 'w', encoding='utf-8') as f:
            for file_path, text in batch_results['results'].items():
                f.write(f"\n{'='*60}\n")
                f.write(f"íŒŒì¼: {file_path}\n")
                f.write(f"{'='*60}\n")
                f.write(text)
                f.write("\n")
        
        # ì²˜ë¦¬ ìš”ì•½ JSON
        import json
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(batch_results['statistics'], f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_dir}")
    
    def print_batch_statistics(self, batch_results, processing_time):
        """ë°°ì¹˜ ì²˜ë¦¬ í†µê³„ ì¶œë ¥"""
        
        stats = batch_results['statistics']
        
        print("\n" + "="*50)
        print("ğŸ“Š ë°°ì¹˜ ì²˜ë¦¬ í†µê³„")
        print("="*50)
        print(f"ğŸ“ ì „ì²´ íŒŒì¼: {stats['total']}ê°œ")
        print(f"âœ… ì„±ê³µ: {stats['successful']}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {stats['failed']}ê°œ")
        print(f"â±ï¸  ì´ ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
        print(f"ğŸ“ˆ í‰ê·  ì²˜ë¦¬ ì‹œê°„: {processing_time/max(stats['total'], 1):.2f}ì´ˆ/íŒŒì¼")
        print(f"ğŸ¯ ì„±ê³µë¥ : {stats['successful']/max(stats['total'], 1)*100:.1f}%")
        
        if stats['failed'] > 0:
            print(f"\nâš ï¸  ì‹¤íŒ¨í•œ íŒŒì¼ë“¤:")
            for file_path in batch_results.get('failed_files', []):
                print(f"   - {file_path}")

# ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    # ê³ ê¸‰ OCR í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    advanced_ocr = AdvancedOCRProcessor(
        model_name='llama3.2-vision:11b',
        max_workers=4  # CPU ì½”ì–´ ìˆ˜ì— ë§ê²Œ ì¡°ì •
    )
    
    # ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰
    batch_results = advanced_ocr.process_batch_with_progress(
        input_dir="input/documents",
        output_dir="output/batch_results",
        format_type="markdown"
    )
```

### ì„±ëŠ¥ ìµœì í™” ë°°ì¹˜ ì²˜ë¦¬

```python
import concurrent.futures
import threading
from queue import Queue

class OptimizedBatchProcessor:
    """ìµœì í™”ëœ ë°°ì¹˜ ì²˜ë¦¬ê¸°"""
    
    def __init__(self, model_name='granite3.2-vision', max_workers=4):
        self.model_name = model_name
        self.max_workers = max_workers
        self.progress_queue = Queue()
        
    def create_ocr_pool(self):
        """OCR í”„ë¡œì„¸ì„œ í’€ ìƒì„±"""
        ocr_pool = []
        for i in range(self.max_workers):
            ocr = OCRProcessor(
                model_name=self.model_name,
                base_url=f"http://localhost:11434/api/generate"
            )
            ocr_pool.append(ocr)
        return ocr_pool
    
    def process_single_file(self, file_info, ocr_processor):
        """ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬"""
        file_path, format_type, custom_prompt = file_info
        
        try:
            start_time = time.time()
            
            result = ocr_processor.process_image(
                image_path=file_path,
                format_type=format_type,
                custom_prompt=custom_prompt,
                language="Korean"
            )
            
            processing_time = time.time() - start_time
            
            return {
                'file_path': file_path,
                'result': result,
                'success': True,
                'processing_time': processing_time,
                'error': None
            }
            
        except Exception as e:
            return {
                'file_path': file_path,
                'result': None,
                'success': False,
                'processing_time': 0,
                'error': str(e)
            }
    
    def optimized_batch_process(self, file_list, format_type="markdown", custom_prompt=None):
        """ìµœì í™”ëœ ë°°ì¹˜ ì²˜ë¦¬"""
        
        ocr_pool = self.create_ocr_pool()
        results = []
        
        # íŒŒì¼ ì •ë³´ ì¤€ë¹„
        file_infos = [(file_path, format_type, custom_prompt) for file_path in file_list]
        
        print(f"ğŸš€ {len(file_list)}ê°œ íŒŒì¼ ìµœì í™” ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘...")
        print(f"âš™ï¸  ì›Œì»¤ ìˆ˜: {self.max_workers}")
        
        # ThreadPoolExecutorë¡œ ë³‘ë ¬ ì²˜ë¦¬
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # ê° ì›Œì»¤ì— OCR í”„ë¡œì„¸ì„œ í• ë‹¹
            future_to_file = {}
            
            for i, file_info in enumerate(file_infos):
                ocr_processor = ocr_pool[i % len(ocr_pool)]
                future = executor.submit(self.process_single_file, file_info, ocr_processor)
                future_to_file[future] = file_info[0]
            
            # ê²°ê³¼ ìˆ˜ì§‘
            completed = 0
            for future in concurrent.futures.as_completed(future_to_file):
                file_path = future_to_file[future]
                try:
                    result = future.result()
                    results.append(result)
                    completed += 1
                    
                    # ì§„í–‰ë¥  ì¶œë ¥
                    progress = (completed / len(file_list)) * 100
                    status = "âœ…" if result['success'] else "âŒ"
                    print(f"{status} [{completed}/{len(file_list)}] ({progress:.1f}%) - {Path(file_path).name}")
                    
                except Exception as e:
                    print(f"âŒ {file_path} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        return results

# ì‚¬ìš© ì˜ˆì œ
def run_optimized_batch():
    """ìµœì í™”ëœ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰"""
    
    # ì²˜ë¦¬í•  íŒŒì¼ ëª©ë¡ ìƒì„±
    input_directory = "input/large_batch"
    file_list = []
    
    for ext in ['*.jpg', '*.png', '*.pdf']:
        file_list.extend(Path(input_directory).glob(ext))
    
    # ìµœì í™”ëœ í”„ë¡œì„¸ì„œ ìƒì„±
    optimizer = OptimizedBatchProcessor(
        model_name='granite3.2-vision',  # ë¬¸ì„œ ì²˜ë¦¬ì— íŠ¹í™”ëœ ëª¨ë¸
        max_workers=6  # CPU ì„±ëŠ¥ì— ë§ê²Œ ì¡°ì •
    )
    
    # ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰
    results = optimizer.optimized_batch_process(
        file_list=file_list,
        format_type="structured",
        custom_prompt="ì´ ë¬¸ì„œì—ì„œ ì œëª©, ë³¸ë¬¸, í‘œ, ì£¼ìš” ë°ì´í„°ë¥¼ êµ¬ì¡°í™”í•˜ì—¬ ì¶”ì¶œí•´ì£¼ì„¸ìš”."
    )
    
    # ê²°ê³¼ ë¶„ì„
    successful = [r for r in results if r['success']]
    failed = [r for r in results if not r['success']]
    
    print(f"\nğŸ“Š ìµœì í™” ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ")
    print(f"âœ… ì„±ê³µ: {len(successful)}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {len(failed)}ê°œ")
    print(f"â±ï¸  í‰ê·  ì²˜ë¦¬ ì‹œê°„: {sum(r['processing_time'] for r in successful)/len(successful):.2f}ì´ˆ")
    
    return results

if __name__ == "__main__":
    results = run_optimized_batch()
```

## ë‹¤ì–‘í•œ ë¹„ì „ ëª¨ë¸ ë¹„êµì™€ ìµœì  ì„ íƒ

### ëª¨ë¸ë³„ íŠ¹ì„± ë¶„ì„

```python
class VisionModelComparator:
    """ë¹„ì „ ëª¨ë¸ ë¹„êµ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.models = {
            'llama3.2-vision:11b': {
                'description': 'ê³ ì„±ëŠ¥ ë²”ìš© ë¹„ì „-ì–¸ì–´ ëª¨ë¸',
                'strengths': ['ë†’ì€ ì •í™•ë„', 'ë³µì¡í•œ ë ˆì´ì•„ì›ƒ ì²˜ë¦¬', 'ë‹¤êµ­ì–´ ì§€ì›'],
                'use_cases': ['ì¤‘ìš” ë¬¸ì„œ', 'ë³µì¡í•œ í‘œ', 'ë‹¤êµ­ì–´ ë¬¸ì„œ'],
                'memory_usage': 'High (11GB)',
                'speed': 'Medium'
            },
            'granite3.2-vision': {
                'description': 'ë¬¸ì„œ ì²˜ë¦¬ íŠ¹í™” ëª¨ë¸',
                'strengths': ['í‘œ ì¸ì‹ ë›°ì–´ë‚¨', 'ì°¨íŠ¸ í•´ì„', 'ë¬¸ì„œ êµ¬ì¡° ë³´ì¡´'],
                'use_cases': ['ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì„œ', 'ì¬ë¬´ ë³´ê³ ì„œ', 'ê¸°ìˆ  ë¬¸ì„œ'],
                'memory_usage': 'Medium',
                'speed': 'Fast'
            },
            'llava': {
                'description': 'ë¹ ë¥¸ ì²˜ë¦¬ì†ë„ì˜ ê²½ëŸ‰ ëª¨ë¸',
                'strengths': ['ë¹ ë¥¸ ì†ë„', 'ë‚®ì€ ë©”ëª¨ë¦¬', 'ì‹¤ì‹œê°„ ì²˜ë¦¬'],
                'use_cases': ['ëŒ€ëŸ‰ ì²˜ë¦¬', 'ì‹¤ì‹œê°„ OCR', 'í”„ë¡œí† íƒ€ì´í•‘'],
                'memory_usage': 'Low',
                'speed': 'Very Fast'
            },
            'moondream': {
                'description': 'ì—£ì§€ ë””ë°”ì´ìŠ¤ìš© ì´ˆê²½ëŸ‰ ëª¨ë¸',
                'strengths': ['ë§¤ìš° ë¹ ë¦„', 'ìµœì†Œ ë©”ëª¨ë¦¬', 'ëª¨ë°”ì¼ ìµœì í™”'],
                'use_cases': ['ëª¨ë°”ì¼ ì•±', 'ì—£ì§€ ì»´í“¨íŒ…', 'ì‹¤ì‹œê°„ ìŠ¤ìº”'],
                'memory_usage': 'Very Low',
                'speed': 'Very Fast'
            },
            'minicpm-v': {
                'description': 'ê³ í•´ìƒë„ ì´ë¯¸ì§€ íŠ¹í™” ëª¨ë¸',
                'strengths': ['ê³ í•´ìƒë„ ì§€ì›', 'ì„¸ë°€í•œ í…ìŠ¤íŠ¸', '1.8M í”½ì…€'],
                'use_cases': ['ê³ í•´ìƒë„ ìŠ¤ìº”', 'ì‘ì€ ê¸€ì”¨', 'ìƒì„¸ ë„ë©´'],
                'memory_usage': 'Medium',
                'speed': 'Medium'
            }
        }
    
    def compare_models_on_sample(self, image_path):
        """ìƒ˜í”Œ ì´ë¯¸ì§€ë¡œ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ"""
        
        results = {}
        
        for model_name, model_info in self.models.items():
            print(f"\nğŸ¤– {model_name} í…ŒìŠ¤íŠ¸ ì¤‘...")
            
            try:
                # OCR í”„ë¡œì„¸ì„œ ìƒì„±
                ocr = OCRProcessor(model_name=model_name)
                
                # ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
                start_time = time.time()
                
                result = ocr.process_image(
                    image_path=image_path,
                    format_type="text",
                    language="Korean"
                )
                
                processing_time = time.time() - start_time
                
                results[model_name] = {
                    'result': result,
                    'processing_time': processing_time,
                    'success': True,
                    'model_info': model_info
                }
                
                print(f"âœ… ì™„ë£Œ ({processing_time:.2f}ì´ˆ)")
                print(f"ğŸ“„ ì¶”ì¶œ ê¸¸ì´: {len(result)} ì")
                
            except Exception as e:
                results[model_name] = {
                    'result': None,
                    'processing_time': 0,
                    'success': False,
                    'error': str(e),
                    'model_info': model_info
                }
                print(f"âŒ ì‹¤íŒ¨: {str(e)}")
        
        return results
    
    def generate_comparison_report(self, comparison_results):
        """ë¹„êµ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±"""
        
        print("\n" + "="*60)
        print("ğŸ“Š ë¹„ì „ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë³´ê³ ì„œ")
        print("="*60)
        
        # ì„±ê³µí•œ ëª¨ë¸ë“¤ë§Œ í•„í„°ë§
        successful_models = {k: v for k, v in comparison_results.items() if v['success']}
        
        if not successful_models:
            print("âŒ ì„±ê³µí•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì²˜ë¦¬ ì‹œê°„ ìˆœ ì •ë ¬
        sorted_by_speed = sorted(successful_models.items(), key=lambda x: x[1]['processing_time'])
        
        print("\nğŸƒâ€â™‚ï¸ ì²˜ë¦¬ ì†ë„ ìˆœìœ„:")
        for i, (model_name, result) in enumerate(sorted_by_speed, 1):
            print(f"{i}. {model_name}: {result['processing_time']:.2f}ì´ˆ")
        
        # ì¶”ì¶œ í…ìŠ¤íŠ¸ ê¸¸ì´ ìˆœ ì •ë ¬ (ì •í™•ë„ ëŒ€ë¦¬ ì§€í‘œ)
        sorted_by_length = sorted(successful_models.items(), key=lambda x: len(x[1]['result']), reverse=True)
        
        print("\nğŸ“ ì¶”ì¶œ í…ìŠ¤íŠ¸ ê¸¸ì´ ìˆœìœ„:")
        for i, (model_name, result) in enumerate(sorted_by_length, 1):
            print(f"{i}. {model_name}: {len(result['result'])} ì")
        
        # ëª¨ë¸ë³„ ìƒì„¸ ì •ë³´
        print("\nğŸ” ëª¨ë¸ë³„ ìƒì„¸ ë¶„ì„:")
        for model_name, result in successful_models.items():
            model_info = result['model_info']
            print(f"\nğŸ“± {model_name}")
            print(f"   ì„¤ëª…: {model_info['description']}")
            print(f"   ê°•ì : {', '.join(model_info['strengths'])}")
            print(f"   ìš©ë„: {', '.join(model_info['use_cases'])}")
            print(f"   ë©”ëª¨ë¦¬: {model_info['memory_usage']}")
            print(f"   ì†ë„: {model_info['speed']}")
            print(f"   ì‹¤ì œ ì²˜ë¦¬ì‹œê°„: {result['processing_time']:.2f}ì´ˆ")
            print(f"   í…ìŠ¤íŠ¸ ì¶”ì¶œëŸ‰: {len(result['result'])} ì")
    
    def recommend_model(self, use_case, priority='balanced'):
        """ì‚¬ìš© ì‚¬ë¡€ì— ë”°ë¥¸ ëª¨ë¸ ì¶”ì²œ"""
        
        recommendations = {
            'business_documents': {
                'primary': 'granite3.2-vision',
                'alternative': 'llama3.2-vision:11b',
                'reason': 'ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì„œì™€ í‘œ ì²˜ë¦¬ì— íŠ¹í™”ë¨'
            },
            'high_volume': {
                'primary': 'llava',
                'alternative': 'moondream',
                'reason': 'ë¹ ë¥¸ ì²˜ë¦¬ì†ë„ë¡œ ëŒ€ëŸ‰ ë¬¸ì„œ ì²˜ë¦¬ì— ì í•©'
            },
            'high_accuracy': {
                'primary': 'llama3.2-vision:11b',
                'alternative': 'granite3.2-vision',
                'reason': 'ìµœê³  í’ˆì§ˆì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì •í™•ë„'
            },
            'mobile_edge': {
                'primary': 'moondream',
                'alternative': 'llava',
                'reason': 'ë‚®ì€ ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­ìœ¼ë¡œ ëª¨ë°”ì¼/ì—£ì§€ í™˜ê²½ ì í•©'
            },
            'high_resolution': {
                'primary': 'minicpm-v',
                'alternative': 'llama3.2-vision:11b',
                'reason': 'ê³ í•´ìƒë„ ì´ë¯¸ì§€ì™€ ì‘ì€ í…ìŠ¤íŠ¸ ì²˜ë¦¬ì— ìµœì í™”'
            }
        }
        
        if use_case in recommendations:
            rec = recommendations[use_case]
            print(f"\nğŸ¯ {use_case} ìš©ë„ ëª¨ë¸ ì¶”ì²œ:")
            print(f"1ìˆœìœ„: {rec['primary']}")
            print(f"2ìˆœìœ„: {rec['alternative']}")
            print(f"ì´ìœ : {rec['reason']}")
            return rec
        else:
            print(f"âŒ '{use_case}' ì‚¬ìš© ì‚¬ë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ì‚¬ìš© ê°€ëŠ¥í•œ ì¼€ì´ìŠ¤:", list(recommendations.keys()))
            return None

# ì‚¬ìš© ì˜ˆì œ
def run_model_comparison():
    """ëª¨ë¸ ë¹„êµ ì‹¤í–‰"""
    
    comparator = VisionModelComparator()
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¡œ ëª¨ë¸ ë¹„êµ
    sample_image = "input/test_document.png"
    
    print("ğŸ“Š ë¹„ì „ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì‹œì‘...")
    comparison_results = comparator.compare_models_on_sample(sample_image)
    
    # ë¹„êµ ë³´ê³ ì„œ ìƒì„±
    comparator.generate_comparison_report(comparison_results)
    
    # ì‚¬ìš© ì‚¬ë¡€ë³„ ì¶”ì²œ
    print("\n" + "="*50)
    print("ğŸ¯ ì‚¬ìš© ì‚¬ë¡€ë³„ ëª¨ë¸ ì¶”ì²œ")
    print("="*50)
    
    use_cases = ['business_documents', 'high_volume', 'high_accuracy', 'mobile_edge', 'high_resolution']
    
    for use_case in use_cases:
        comparator.recommend_model(use_case)

if __name__ == "__main__":
    run_model_comparison()
```

## Streamlit ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¶•

### ì‚¬ìš©ì ì¹œí™”ì  ì›¹ ì¸í„°í˜ì´ìŠ¤

```python
import streamlit as st
import tempfile
import os
from pathlib import Path
import zipfile
import io

def create_streamlit_app():
    """Streamlit OCR ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    st.set_page_config(
        page_title="Ollama OCR ì›¹ ì•±",
        page_icon="ğŸ‘ï¸",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("ğŸ‘ï¸ Ollama OCR - ë¡œì»¬ ë¹„ì „ ëª¨ë¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
    st.markdown("**ë‹¤ì–‘í•œ ë¹„ì „ ëª¨ë¸ì„ í™œìš©í•œ ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì†”ë£¨ì…˜**")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # ëª¨ë¸ ì„ íƒ
        model_options = {
            'llama3.2-vision:11b': 'ğŸ¯ Llama 3.2 Vision (ê³ ì„±ëŠ¥)',
            'granite3.2-vision': 'ğŸ“Š Granite 3.2 (ë¬¸ì„œ íŠ¹í™”)',
            'llava': 'âš¡ LLaVA (ë¹ ë¥¸ ì²˜ë¦¬)',
            'moondream': 'ğŸ“± Moondream (ê²½ëŸ‰)',
            'minicpm-v': 'ğŸ” MiniCPM-V (ê³ í•´ìƒë„)'
        }
        
        selected_model = st.selectbox(
            "ë¹„ì „ ëª¨ë¸ ì„ íƒ",
            options=list(model_options.keys()),
            format_func=lambda x: model_options[x],
            index=1  # granite3.2-visionì„ ê¸°ë³¸ê°’ìœ¼ë¡œ
        )
        
        # ì¶œë ¥ í˜•ì‹ ì„ íƒ
        format_options = {
            'text': 'ğŸ“ ìˆœìˆ˜ í…ìŠ¤íŠ¸',
            'markdown': 'ğŸ“‹ ë§ˆí¬ë‹¤ìš´',
            'json': 'ğŸ—‚ï¸ JSON',
            'structured': 'ğŸ—ï¸ êµ¬ì¡°í™”ëœ ë°ì´í„°',
            'key_value': 'ğŸ”‘ í‚¤-ê°’ ìŒ',
            'table': 'ğŸ“Š í…Œì´ë¸” ì¶”ì¶œ'
        }
        
        selected_format = st.selectbox(
            "ì¶œë ¥ í˜•ì‹",
            options=list(format_options.keys()),
            format_func=lambda x: format_options[x],
            index=1  # markdownì„ ê¸°ë³¸ê°’ìœ¼ë¡œ
        )
        
        # ì–¸ì–´ ì„¤ì •
        language = st.selectbox(
            "ë¬¸ì„œ ì–¸ì–´",
            options=['Korean', 'English', 'Japanese', 'Chinese', 'Auto'],
            index=0
        )
        
        # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸
        custom_prompt = st.text_area(
            "ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ (ì„ íƒì )",
            placeholder="ì˜ˆ: í‘œì™€ ì°¨íŠ¸ì˜ ë°ì´í„°ë¥¼ ì •í™•íˆ ì¶”ì¶œí•´ì£¼ì„¸ìš”.",
            height=100
        )
        
        # ê³ ê¸‰ ì˜µì…˜
        with st.expander("ğŸ”§ ê³ ê¸‰ ì˜µì…˜"):
            enable_preprocessing = st.checkbox("ì´ë¯¸ì§€ ì „ì²˜ë¦¬", value=True)
            confidence_threshold = st.slider("ì‹ ë¢°ë„ ì„ê³„ê°’", 0.0, 1.0, 0.7)
    
    # ë©”ì¸ ì˜ì—­
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.header("ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ")
        
        # íŒŒì¼ ì—…ë¡œë“œ
        uploaded_files = st.file_uploader(
            "ì´ë¯¸ì§€ ë˜ëŠ” PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
            type=['png', 'jpg', 'jpeg', 'bmp', 'tiff', 'pdf'],
            accept_multiple_files=True,
            help="ì§€ì› í˜•ì‹: PNG, JPG, JPEG, BMP, TIFF, PDF"
        )
        
        # ë°°ì¹˜ ì²˜ë¦¬ ì˜µì…˜
        if len(uploaded_files) > 1:
            batch_processing = st.checkbox("ë°°ì¹˜ ì²˜ë¦¬ ëª¨ë“œ", value=True)
            if batch_processing:
                max_workers = st.slider("ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜", 1, 8, 4)
        
        # ì²˜ë¦¬ ë²„íŠ¼
        if st.button("ğŸš€ OCR ì²˜ë¦¬ ì‹œì‘", type="primary", use_container_width=True):
            if uploaded_files:
                process_uploaded_files(
                    uploaded_files, 
                    selected_model, 
                    selected_format, 
                    language, 
                    custom_prompt,
                    enable_preprocessing
                )
            else:
                st.error("íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    
    with col2:
        st.header("ğŸ“‹ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
        
        # ê²°ê³¼ í‘œì‹œ ì˜ì—­ì€ process_uploaded_filesì—ì„œ ì²˜ë¦¬
        if 'ocr_results' not in st.session_state:
            st.info("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  OCR ì²˜ë¦¬ë¥¼ ì‹œì‘í•˜ì„¸ìš”.")
    
    # ì‚¬ìš©ë²• ì•ˆë‚´
    with st.expander("ğŸ“– ì‚¬ìš©ë²• ì•ˆë‚´"):
        st.markdown("""
        ### ê¸°ë³¸ ì‚¬ìš©ë²•
        1. **ëª¨ë¸ ì„ íƒ**: ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ìš©ë„ì— ë§ëŠ” ë¹„ì „ ëª¨ë¸ ì„ íƒ
        2. **íŒŒì¼ ì—…ë¡œë“œ**: ì²˜ë¦¬í•  ì´ë¯¸ì§€ë‚˜ PDF íŒŒì¼ ì—…ë¡œë“œ
        3. **ì˜µì…˜ ì„¤ì •**: ì¶œë ¥ í˜•ì‹, ì–¸ì–´, ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        4. **ì²˜ë¦¬ ì‹¤í–‰**: "OCR ì²˜ë¦¬ ì‹œì‘" ë²„íŠ¼ í´ë¦­
        
        ### ëª¨ë¸ë³„ íŠ¹ì§•
        - **Llama 3.2 Vision**: ë†’ì€ ì •í™•ë„, ë³µì¡í•œ ë¬¸ì„œ ì²˜ë¦¬ì— ì í•©
        - **Granite 3.2**: ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì„œ, í‘œ, ì°¨íŠ¸ ì²˜ë¦¬ì— íŠ¹í™”
        - **LLaVA**: ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„, ëŒ€ëŸ‰ ë¬¸ì„œ ì²˜ë¦¬ìš©
        - **Moondream**: ì´ˆê²½ëŸ‰, ì‹¤ì‹œê°„ ì²˜ë¦¬ìš©
        - **MiniCPM-V**: ê³ í•´ìƒë„ ì´ë¯¸ì§€, ì‘ì€ í…ìŠ¤íŠ¸ ì²˜ë¦¬ìš©
        
        ### íŒ
        - ë³µì¡í•œ ë¬¸ì„œëŠ” **Granite 3.2** ì¶”ì²œ
        - ë¹ ë¥¸ ì²˜ë¦¬ê°€ í•„ìš”í•˜ë©´ **LLaVA** ì¶”ì²œ
        - ê³ í•´ìƒë„ ìŠ¤ìº” ë¬¸ì„œëŠ” **MiniCPM-V** ì¶”ì²œ
        """)

def process_uploaded_files(uploaded_files, model_name, format_type, language, custom_prompt, enable_preprocessing):
    """ì—…ë¡œë“œëœ íŒŒì¼ë“¤ ì²˜ë¦¬"""
    
    with st.spinner("OCR ì²˜ë¦¬ ì¤‘..."):
        try:
            # OCR í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
            ocr = OCRProcessor(
                model_name=model_name,
                max_workers=4 if len(uploaded_files) > 1 else 1
            )
            
            results = {}
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i, uploaded_file in enumerate(uploaded_files):
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                progress = (i + 1) / len(uploaded_files)
                progress_bar.progress(progress)
                status_text.text(f"ì²˜ë¦¬ ì¤‘: {uploaded_file.name} ({i+1}/{len(uploaded_files)})")
                
                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
                    tmp_file.write(uploaded_file.getvalue())
                    tmp_file_path = tmp_file.name
                
                try:
                    # OCR ì²˜ë¦¬
                    result = ocr.process_image(
                        image_path=tmp_file_path,
                        format_type=format_type,
                        custom_prompt=custom_prompt if custom_prompt else None,
                        language=language if language != 'Auto' else None
                    )
                    
                    results[uploaded_file.name] = {
                        'success': True,
                        'result': result,
                        'error': None
                    }
                    
                except Exception as e:
                    results[uploaded_file.name] = {
                        'success': False,
                        'result': None,
                        'error': str(e)
                    }
                
                finally:
                    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                    os.unlink(tmp_file_path)
            
            # ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            st.session_state.ocr_results = results
            
            # ê²°ê³¼ í‘œì‹œ
            display_results(results, format_type)
            
        except Exception as e:
            st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def display_results(results, format_type):
    """ê²°ê³¼ í‘œì‹œ"""
    
    st.header("ğŸ“‹ OCR ê²°ê³¼")
    
    # í†µê³„ í‘œì‹œ
    successful = sum(1 for r in results.values() if r['success'])
    total = len(results)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ì´ íŒŒì¼", total)
    with col2:
        st.metric("ì„±ê³µ", successful)
    with col3:
        st.metric("ì‹¤íŒ¨", total - successful)
    
    # ê°œë³„ ê²°ê³¼ í‘œì‹œ
    for filename, result in results.items():
        with st.expander(f"ğŸ“„ {filename}"):
            if result['success']:
                st.success("ì²˜ë¦¬ ì™„ë£Œ")
                
                # ê²°ê³¼ í…ìŠ¤íŠ¸ í‘œì‹œ
                if format_type == 'json':
                    st.json(result['result'])
                elif format_type == 'markdown':
                    st.markdown(result['result'])
                else:
                    st.text_area(
                        "ì¶”ì¶œëœ í…ìŠ¤íŠ¸",
                        value=result['result'],
                        height=300,
                        key=f"result_{filename}"
                    )
                
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                st.download_button(
                    label="ğŸ’¾ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ",
                    data=result['result'],
                    file_name=f"{Path(filename).stem}_extracted.txt",
                    mime="text/plain",
                    key=f"download_{filename}"
                )
                
            else:
                st.error(f"ì²˜ë¦¬ ì‹¤íŒ¨: {result['error']}")
    
    # ì „ì²´ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
    if successful > 0:
        st.markdown("---")
        
        # ì „ì²´ ê²°ê³¼ë¥¼ ZIPìœ¼ë¡œ ì••ì¶•
        zip_buffer = io.BytesIO()
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            for filename, result in results.items():
                if result['success']:
                    text_filename = f"{Path(filename).stem}_extracted.txt"
                    zip_file.writestr(text_filename, result['result'])
        
        st.download_button(
            label="ğŸ“¦ ì „ì²´ ê²°ê³¼ ZIP ë‹¤ìš´ë¡œë“œ",
            data=zip_buffer.getvalue(),
            file_name="ocr_results.zip",
            mime="application/zip"
        )

# Streamlit ì•± ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
if __name__ == "__main__":
    create_streamlit_app()
```

### ì›¹ ì•± ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# íŒŒì¼: run_streamlit_app.sh
# Streamlit OCR ì›¹ ì•± ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

echo "ğŸŒ Ollama-OCR Streamlit ì›¹ ì•± ì‹œì‘"
echo "=================================="

# Ollama ì„œë¹„ìŠ¤ í™•ì¸
echo "ğŸ” Ollama ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸..."
if ! pgrep -f "ollama serve" > /dev/null; then
    echo "ğŸš€ Ollama ì„œë¹„ìŠ¤ ì‹œì‘ ì¤‘..."
    ollama serve &
    sleep 5
else
    echo "âœ… Ollama ì„œë¹„ìŠ¤ ì‹¤í–‰ ì¤‘"
fi

# í•„ìš”í•œ ëª¨ë¸ í™•ì¸
echo "ğŸ¤– ë¹„ì „ ëª¨ë¸ í™•ì¸ ì¤‘..."
MODELS=("llama3.2-vision:11b" "granite3.2-vision" "llava" "moondream" "minicpm-v")

for model in "${MODELS[@]}"; do
    if ollama list | grep -q "$model"; then
        echo "âœ… $model ì‚¬ìš© ê°€ëŠ¥"
    else
        echo "ğŸ“¥ $model ë‹¤ìš´ë¡œë“œ ì¤‘..."
        ollama pull "$model"
    fi
done

# Python íŒ¨í‚¤ì§€ í™•ì¸
echo "ğŸ“¦ Python íŒ¨í‚¤ì§€ í™•ì¸..."
pip install -q streamlit ollama-ocr

# ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
echo "ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±..."
mkdir -p input output

# Streamlit ì•± ì‹¤í–‰
echo "ğŸš€ Streamlit ì•± ì‹œì‘..."
streamlit run streamlit_ocr_app.py \
    --server.port 8501 \
    --server.address 0.0.0.0 \
    --server.headless true \
    --browser.gatherUsageStats false

echo "âœ… ì›¹ ì•±ì´ http://localhost:8501 ì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤."
```

## ì‹¤ì œ ë¬¸ì„œ ì²˜ë¦¬ ì˜ˆì œì™€ ê²°ê³¼ ë¶„ì„

### ë‹¤ì–‘í•œ ë¬¸ì„œ ìœ í˜•ë³„ ì²˜ë¦¬ ì‚¬ë¡€

```python
import json
from pathlib import Path
import matplotlib.pyplot as plt
from datetime import datetime

class DocumentProcessingExamples:
    """ì‹¤ì œ ë¬¸ì„œ ì²˜ë¦¬ ì˜ˆì œ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.ocr_processors = {
            'business': OCRProcessor(model_name='granite3.2-vision'),
            'general': OCRProcessor(model_name='llama3.2-vision:11b'),
            'fast': OCRProcessor(model_name='llava'),
            'precision': OCRProcessor(model_name='minicpm-v')
        }
    
    def process_business_invoice(self):
        """ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ë³´ì´ìŠ¤ ì²˜ë¦¬ ì˜ˆì œ"""
        
        print("ğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ë³´ì´ìŠ¤ ì²˜ë¦¬ ì˜ˆì œ")
        print("="*40)
        
        # ì¸ë³´ì´ìŠ¤ íŠ¹í™” í”„ë¡¬í”„íŠ¸
        invoice_prompt = """
        ì´ ì¸ë³´ì´ìŠ¤ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
        - íšŒì‚¬ëª… (company_name)
        - ì¸ë³´ì´ìŠ¤ ë²ˆí˜¸ (invoice_number)
        - ë‚ ì§œ (date)
        - ê³ ê° ì •ë³´ (customer_info)
        - í•­ëª©ë³„ ë‚´ì—­ (line_items: ìƒí’ˆëª…, ìˆ˜ëŸ‰, ë‹¨ê°€, ì´ì•¡)
        - ì„¸ê¸ˆ (tax)
        - ì´ ê¸ˆì•¡ (total_amount)
        - ê²°ì œ ì¡°ê±´ (payment_terms)
        """
        
        result = self.ocr_processors['business'].process_image(
            image_path="input/sample_invoice.pdf",
            format_type="json",
            custom_prompt=invoice_prompt,
            language="Korean"
        )
        
        try:
            invoice_data = json.loads(result)
            
            print("âœ… ì¸ë³´ì´ìŠ¤ ì²˜ë¦¬ ì„±ê³µ")
            print(f"íšŒì‚¬ëª…: {invoice_data.get('company_name', 'N/A')}")
            print(f"ì¸ë³´ì´ìŠ¤ ë²ˆí˜¸: {invoice_data.get('invoice_number', 'N/A')}")
            print(f"ì´ ê¸ˆì•¡: {invoice_data.get('total_amount', 'N/A')}")
            print(f"í•­ëª© ìˆ˜: {len(invoice_data.get('line_items', []))}")
            
            return invoice_data
            
        except json.JSONDecodeError:
            print("âŒ JSON íŒŒì‹± ì‹¤íŒ¨, ì›ì‹œ í…ìŠ¤íŠ¸:")
            print(result[:500] + "...")
            return result
    
    def process_financial_report(self):
        """ì¬ë¬´ ë³´ê³ ì„œ ì²˜ë¦¬ ì˜ˆì œ"""
        
        print("\nğŸ“Š ì¬ë¬´ ë³´ê³ ì„œ ì²˜ë¦¬ ì˜ˆì œ")
        print("="*40)
        
        financial_prompt = """
        ì´ ì¬ë¬´ ë³´ê³ ì„œì—ì„œ ë‹¤ìŒì„ êµ¬ì¡°í™”í•˜ì—¬ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
        1. ì£¼ìš” ì¬ë¬´ ì§€í‘œ (ë§¤ì¶œ, ì˜ì—…ì´ìµ, ìˆœì´ìµ ë“±)
        2. ì „ë…„ ëŒ€ë¹„ ì¦ê°ë¥ 
        3. ë¶€ë¬¸ë³„ ì„±ê³¼
        4. ì£¼ìš” ì´ë²¤íŠ¸ë‚˜ íŠ¹ì´ì‚¬í•­
        
        í‘œ í˜•íƒœì˜ ë°ì´í„°ëŠ” í‘œ êµ¬ì¡°ë¥¼ ìœ ì§€í•´ì£¼ì„¸ìš”.
        """
        
        result = self.ocr_processors['business'].process_image(
            image_path="input/financial_report.pdf",
            format_type="structured",
            custom_prompt=financial_prompt,
            language="Korean"
        )
        
        print("âœ… ì¬ë¬´ ë³´ê³ ì„œ ì²˜ë¦¬ ì™„ë£Œ")
        print("ì£¼ìš” ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:")
        print(result[:300] + "...")
        
        return result
    
    def process_academic_paper(self):
        """í•™ìˆ  ë…¼ë¬¸ ì²˜ë¦¬ ì˜ˆì œ"""
        
        print("\nğŸ“ í•™ìˆ  ë…¼ë¬¸ ì²˜ë¦¬ ì˜ˆì œ")
        print("="*40)
        
        academic_prompt = """
        ì´ í•™ìˆ  ë…¼ë¬¸ì—ì„œ ë‹¤ìŒì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
        - ì œëª© (title)
        - ì €ì (authors)
        - ì´ˆë¡ (abstract)
        - ì£¼ìš” í‚¤ì›Œë“œ (keywords)
        - ì„¹ì…˜ë³„ í—¤ë”©ê³¼ ë‚´ìš© êµ¬ì¡°
        - ê·¸ë˜í”„ë‚˜ í‘œì˜ ìº¡ì…˜
        - ì°¸ê³ ë¬¸í—Œ (references)
        
        í•™ìˆ ì  í˜•ì‹ì„ ìœ ì§€í•˜ì—¬ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
        """
        
        result = self.ocr_processors['general'].process_image(
            image_path="input/research_paper.pdf",
            format_type="markdown",
            custom_prompt=academic_prompt,
            language="English"
        )
        
        print("âœ… í•™ìˆ  ë…¼ë¬¸ ì²˜ë¦¬ ì™„ë£Œ")
        
        # ì„¹ì…˜ë³„ ê¸¸ì´ ë¶„ì„
        sections = result.split('\n## ')
        print(f"ì´ ì„¹ì…˜ ìˆ˜: {len(sections)}")
        print("ì£¼ìš” ì„¹ì…˜ë“¤:")
        for i, section in enumerate(sections[:5]):
            section_title = section.split('\n')[0][:50]
            print(f"  {i+1}. {section_title}... ({len(section)} ì)")
        
        return result
    
    def process_technical_manual(self):
        """ê¸°ìˆ  ë§¤ë‰´ì–¼ ì²˜ë¦¬ ì˜ˆì œ"""
        
        print("\nğŸ”§ ê¸°ìˆ  ë§¤ë‰´ì–¼ ì²˜ë¦¬ ì˜ˆì œ")
        print("="*40)
        
        manual_prompt = """
        ì´ ê¸°ìˆ  ë§¤ë‰´ì–¼ì—ì„œ ë‹¤ìŒì„ ì²´ê³„ì ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
        - ëª©ì°¨ êµ¬ì¡°
        - ë‹¨ê³„ë³„ ì ˆì°¨ (numbered steps)
        - ì£¼ì˜ì‚¬í•­ì´ë‚˜ ê²½ê³  (warnings, cautions)
        - ë‹¤ì´ì–´ê·¸ë¨ì´ë‚˜ ê·¸ë¦¼ì˜ ì„¤ëª…
        - ê¸°ìˆ  ì‚¬ì–‘ (specifications)
        - ë¬¸ì œí•´ê²° ê°€ì´ë“œ (troubleshooting)
        
        ì ˆì°¨ë‚˜ ë‹¨ê³„ëŠ” ë²ˆí˜¸ë¥¼ ë§¤ê²¨ì„œ ëª…í™•íˆ êµ¬ë¶„í•´ì£¼ì„¸ìš”.
        """
        
        result = self.ocr_processors['precision'].process_image(
            image_path="input/technical_manual.pdf",
            format_type="structured",
            custom_prompt=manual_prompt,
            language="Korean"
        )
        
        print("âœ… ê¸°ìˆ  ë§¤ë‰´ì–¼ ì²˜ë¦¬ ì™„ë£Œ")
        
        # ë‹¨ê³„ë³„ ì ˆì°¨ ì¶”ì¶œ
        steps = [line for line in result.split('\n') if line.strip().startswith(('1.', '2.', '3.', '4.', '5.'))]
        print(f"ì¶”ì¶œëœ ë‹¨ê³„ ìˆ˜: {len(steps)}")
        
        return result
    
    def process_handwritten_notes(self):
        """ì†ê¸€ì”¨ ë…¸íŠ¸ ì²˜ë¦¬ ì˜ˆì œ"""
        
        print("\nâœï¸ ì†ê¸€ì”¨ ë…¸íŠ¸ ì²˜ë¦¬ ì˜ˆì œ")
        print("="*40)
        
        handwriting_prompt = """
        ì´ ì†ê¸€ì”¨ ë…¸íŠ¸ë¥¼ ì½ê³  ë‹¤ìŒê³¼ ê°™ì´ ì •ë¦¬í•´ì£¼ì„¸ìš”:
        - ê°€ë…ì„±ì´ ì¢‹ì€ íƒ€ì´í•‘ëœ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        - ë¶ˆë¶„ëª…í•œ ë¶€ë¶„ì€ [ë¶ˆëª…í™•] í‘œì‹œ
        - ë²ˆí˜¸ë‚˜ ëª©ë¡ì´ ìˆë‹¤ë©´ êµ¬ì¡°í™”
        - ì¤‘ìš”í•´ ë³´ì´ëŠ” ë¶€ë¶„ì€ **êµµê²Œ** í‘œì‹œ
        
        ì†ê¸€ì”¨ì˜ íŠ¹ì„±ìƒ ì™„ë²½í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë‹ˆ ë¬¸ë§¥ì„ ê³ ë ¤í•´ì„œ ì¶”ì¸¡í•´ì£¼ì„¸ìš”.
        """
        
        result = self.ocr_processors['general'].process_image(
            image_path="input/handwritten_notes.jpg",
            format_type="markdown",
            custom_prompt=handwriting_prompt,
            language="Korean"
        )
        
        print("âœ… ì†ê¸€ì”¨ ë…¸íŠ¸ ì²˜ë¦¬ ì™„ë£Œ")
        
        # ë¶ˆëª…í™•í•œ ë¶€ë¶„ í†µê³„
        unclear_count = result.count('[ë¶ˆëª…í™•]')
        total_words = len(result.split())
        clarity_rate = ((total_words - unclear_count) / total_words) * 100 if total_words > 0 else 0
        
        print(f"ì´ ë‹¨ì–´ ìˆ˜: {total_words}")
        print(f"ë¶ˆëª…í™•í•œ ë¶€ë¶„: {unclear_count}")
        print(f"ëª…í™•ë„: {clarity_rate:.1f}%")
        
        return result

# ì„±ëŠ¥ í‰ê°€ í´ë˜ìŠ¤
class OCRPerformanceEvaluator:
    """OCR ì„±ëŠ¥ í‰ê°€ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.test_results = {}
    
    def evaluate_accuracy_by_document_type(self):
        """ë¬¸ì„œ ìœ í˜•ë³„ ì •í™•ë„ í‰ê°€"""
        
        document_processor = DocumentProcessingExamples()
        
        test_cases = [
            ('business_invoice', document_processor.process_business_invoice),
            ('financial_report', document_processor.process_financial_report),
            ('academic_paper', document_processor.process_academic_paper),
            ('technical_manual', document_processor.process_technical_manual),
            ('handwritten_notes', document_processor.process_handwritten_notes)
        ]
        
        print("\nğŸ“ˆ ë¬¸ì„œ ìœ í˜•ë³„ ì„±ëŠ¥ í‰ê°€")
        print("="*50)
        
        for doc_type, process_func in test_cases:
            print(f"\nğŸ” {doc_type} í‰ê°€ ì¤‘...")
            
            start_time = datetime.now()
            
            try:
                result = process_func()
                processing_time = (datetime.now() - start_time).total_seconds()
                
                # ê¸°ë³¸ í’ˆì§ˆ ì§€í‘œ ê³„ì‚°
                text_length = len(str(result))
                word_count = len(str(result).split())
                
                self.test_results[doc_type] = {
                    'success': True,
                    'processing_time': processing_time,
                    'text_length': text_length,
                    'word_count': word_count,
                    'words_per_second': word_count / processing_time if processing_time > 0 else 0
                }
                
                print(f"âœ… ì„±ê³µ - ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ, ë‹¨ì–´ìˆ˜: {word_count}")
                
            except Exception as e:
                self.test_results[doc_type] = {
                    'success': False,
                    'error': str(e),
                    'processing_time': 0
                }
                print(f"âŒ ì‹¤íŒ¨: {str(e)}")
        
        # ê²°ê³¼ ìš”ì•½
        self.generate_performance_report()
    
    def generate_performance_report(self):
        """ì„±ëŠ¥ í‰ê°€ ë³´ê³ ì„œ ìƒì„±"""
        
        print("\n" + "="*60)
        print("ğŸ“Š OCR ì„±ëŠ¥ í‰ê°€ ì¢…í•© ë³´ê³ ì„œ")
        print("="*60)
        
        successful_tests = {k: v for k, v in self.test_results.items() if v.get('success', False)}
        failed_tests = {k: v for k, v in self.test_results.items() if not v.get('success', False)}
        
        # ì „ì²´ í†µê³„
        total_tests = len(self.test_results)
        success_rate = len(successful_tests) / total_tests * 100 if total_tests > 0 else 0
        
        print(f"ğŸ¯ ì „ì²´ ì„±ê³µë¥ : {success_rate:.1f}% ({len(successful_tests)}/{total_tests})")
        
        if successful_tests:
            # ì„±ëŠ¥ ì§€í‘œ
            avg_time = sum(r['processing_time'] for r in successful_tests.values()) / len(successful_tests)
            avg_words = sum(r['word_count'] for r in successful_tests.values()) / len(successful_tests)
            avg_speed = sum(r['words_per_second'] for r in successful_tests.values()) / len(successful_tests)
            
            print(f"â±ï¸  í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.2f}ì´ˆ")
            print(f"ğŸ“ í‰ê·  ì¶”ì¶œ ë‹¨ì–´ ìˆ˜: {avg_words:.0f}ê°œ")
            print(f"ğŸš€ í‰ê·  ì²˜ë¦¬ ì†ë„: {avg_speed:.1f} ë‹¨ì–´/ì´ˆ")
            
            # ë¬¸ì„œ ìœ í˜•ë³„ ìƒì„¸ ê²°ê³¼
            print(f"\nğŸ“‹ ë¬¸ì„œ ìœ í˜•ë³„ ìƒì„¸ ê²°ê³¼:")
            print("-" * 60)
            print(f"{'ë¬¸ì„œ ìœ í˜•':<20} {'ì²˜ë¦¬ì‹œê°„':<10} {'ë‹¨ì–´ìˆ˜':<10} {'ì†ë„(w/s)':<12}")
            print("-" * 60)
            
            for doc_type, result in successful_tests.items():
                print(f"{doc_type:<20} {result['processing_time']:<10.2f} {result['word_count']:<10} {result['words_per_second']:<12.1f}")
        
        if failed_tests:
            print(f"\nâŒ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸:")
            for doc_type, result in failed_tests.items():
                print(f"   - {doc_type}: {result['error']}")

# ì‹¤ìš©ì ì¸ í™œìš© ì‚¬ë¡€
class PracticalUseCases:
    """ì‹¤ìš©ì ì¸ OCR í™œìš© ì‚¬ë¡€"""
    
    def __init__(self):
        self.ocr = OCRProcessor(model_name='granite3.2-vision')
    
    def receipt_expense_tracker(self, receipt_images):
        """ì˜ìˆ˜ì¦ ê¸°ë°˜ ê°€ê³„ë¶€ ê´€ë¦¬"""
        
        print("ğŸ§¾ ì˜ìˆ˜ì¦ ê°€ê³„ë¶€ ìë™í™”")
        print("="*30)
        
        expenses = []
        
        for receipt_path in receipt_images:
            expense_prompt = """
            ì´ ì˜ìˆ˜ì¦ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
            {
                "store_name": "ìƒì ëª…",
                "date": "ë‚ ì§œ (YYYY-MM-DD)",
                "total_amount": "ì´ ê¸ˆì•¡ (ìˆ«ìë§Œ)",
                "items": [
                    {"name": "ìƒí’ˆëª…", "price": "ê°€ê²©", "quantity": "ìˆ˜ëŸ‰"}
                ],
                "payment_method": "ê²°ì œìˆ˜ë‹¨",
                "category": "ì¹´í…Œê³ ë¦¬ (ì‹ë¹„/êµí†µë¹„/ì‡¼í•‘/ê¸°íƒ€)"
            }
            """
            
            try:
                result = self.ocr.process_image(
                    image_path=receipt_path,
                    format_type="json",
                    custom_prompt=expense_prompt,
                    language="Korean"
                )
                
                expense_data = json.loads(result)
                expenses.append(expense_data)
                
                print(f"âœ… {Path(receipt_path).name}: {expense_data.get('store_name', 'Unknown')} - {expense_data.get('total_amount', '0')}ì›")
                
            except Exception as e:
                print(f"âŒ {Path(receipt_path).name}: ì²˜ë¦¬ ì‹¤íŒ¨ - {str(e)}")
        
        # ì›”ë³„ ì§€ì¶œ ìš”ì•½
        if expenses:
            total_spending = sum(float(exp.get('total_amount', 0)) for exp in expenses if exp.get('total_amount'))
            print(f"\nğŸ’° ì´ ì§€ì¶œ: {total_spending:,.0f}ì›")
            
            # ì¹´í…Œê³ ë¦¬ë³„ ì§‘ê³„
            category_spending = {}
            for exp in expenses:
                category = exp.get('category', 'ê¸°íƒ€')
                amount = float(exp.get('total_amount', 0))
                category_spending[category] = category_spending.get(category, 0) + amount
            
            print("ğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ì§€ì¶œ:")
            for category, amount in sorted(category_spending.items(), key=lambda x: x[1], reverse=True):
                print(f"   {category}: {amount:,.0f}ì›")
        
        return expenses
    
    def business_card_organizer(self, card_images):
        """ëª…í•¨ ì •ë³´ ìë™ ì •ë¦¬"""
        
        print("ğŸ’³ ëª…í•¨ ì •ë³´ ìë™ ì •ë¦¬")
        print("="*25)
        
        contacts = []
        
        for card_path in card_images:
            card_prompt = """
            ì´ ëª…í•¨ì—ì„œ ì—°ë½ì²˜ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
            {
                "name": "ì´ë¦„",
                "company": "íšŒì‚¬ëª…",
                "position": "ì§ì±…",
                "department": "ë¶€ì„œ",
                "phone": "ì „í™”ë²ˆí˜¸",
                "mobile": "íœ´ëŒ€í°",
                "email": "ì´ë©”ì¼",
                "address": "ì£¼ì†Œ",
                "website": "ì›¹ì‚¬ì´íŠ¸"
            }
            """
            
            try:
                result = self.ocr.process_image(
                    image_path=card_path,
                    format_type="json",
                    custom_prompt=card_prompt,
                    language="Korean"
                )
                
                contact_data = json.loads(result)
                contacts.append(contact_data)
                
                print(f"âœ… {contact_data.get('name', 'Unknown')} ({contact_data.get('company', 'Unknown')})")
                
            except Exception as e:
                print(f"âŒ {Path(card_path).name}: ì²˜ë¦¬ ì‹¤íŒ¨ - {str(e)}")
        
        # CSVë¡œ ë‚´ë³´ë‚´ê¸°
        if contacts:
            csv_content = "ì´ë¦„,íšŒì‚¬,ì§ì±…,ë¶€ì„œ,ì „í™”ë²ˆí˜¸,íœ´ëŒ€í°,ì´ë©”ì¼,ì£¼ì†Œ,ì›¹ì‚¬ì´íŠ¸\n"
            for contact in contacts:
                csv_row = ",".join([
                    contact.get('name', ''),
                    contact.get('company', ''),
                    contact.get('position', ''),
                    contact.get('department', ''),
                    contact.get('phone', ''),
                    contact.get('mobile', ''),
                    contact.get('email', ''),
                    contact.get('address', ''),
                    contact.get('website', '')
                ])
                csv_content += csv_row + "\n"
            
            with open("output/business_cards.csv", "w", encoding="utf-8") as f:
                f.write(csv_content)
            
            print(f"ğŸ’¾ {len(contacts)}ê°œ ëª…í•¨ ì •ë³´ë¥¼ business_cards.csvë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        
        return contacts
    
    def document_digitization_workflow(self, document_folder):
        """ë¬¸ì„œ ë””ì§€í„¸í™” ì›Œí¬í”Œë¡œìš°"""
        
        print("ğŸ“š ë¬¸ì„œ ë””ì§€í„¸í™” ì›Œí¬í”Œë¡œìš°")
        print("="*35)
        
        # ë¬¸ì„œ ìœ í˜• ìë™ ë¶„ë¥˜
        classification_prompt = """
        ì´ ë¬¸ì„œì˜ ìœ í˜•ì„ ë‹¤ìŒ ì¤‘ì—ì„œ ì„ íƒí•´ì£¼ì„¸ìš”:
        - invoice (ì¸ë³´ì´ìŠ¤/ì²­êµ¬ì„œ)
        - contract (ê³„ì•½ì„œ)
        - report (ë³´ê³ ì„œ)
        - manual (ë§¤ë‰´ì–¼)
        - form (ì–‘ì‹/ì‹ ì²­ì„œ)
        - letter (ê³µë¬¸/ì„œì‹ )
        - other (ê¸°íƒ€)
        
        ì‘ë‹µì€ ë‹¨ì–´ í•˜ë‚˜ë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš”.
        """
        
        documents = list(Path(document_folder).glob("*"))
        organized_docs = {}
        
        for doc_path in documents:
            if doc_path.suffix.lower() in ['.jpg', '.png', '.pdf', '.jpeg']:
                try:
                    # 1ë‹¨ê³„: ë¬¸ì„œ ìœ í˜• ë¶„ë¥˜
                    doc_type = self.ocr.process_image(
                        image_path=str(doc_path),
                        format_type="text",
                        custom_prompt=classification_prompt,
                        language="Korean"
                    ).strip().lower()
                    
                    # 2ë‹¨ê³„: ìœ í˜•ë³„ ë§ì¶¤ ì¶”ì¶œ
                    if doc_type not in organized_docs:
                        organized_docs[doc_type] = []
                    
                    # ìœ í˜•ë³„ íŠ¹í™” í”„ë¡¬í”„íŠ¸
                    type_prompts = {
                        'invoice': "ì¸ë³´ì´ìŠ¤ ì •ë³´ë¥¼ êµ¬ì¡°í™”í•˜ì—¬ ì¶”ì¶œ: íšŒì‚¬ëª…, ë‚ ì§œ, ê¸ˆì•¡, í•­ëª©",
                        'contract': "ê³„ì•½ì„œ ì£¼ìš” ë‚´ìš© ì¶”ì¶œ: ë‹¹ì‚¬ì, ê³„ì•½ì¼, ê³„ì•½ê¸°ê°„, ì£¼ìš” ì¡°ê±´",
                        'report': "ë³´ê³ ì„œ ìš”ì•½: ì œëª©, ì‘ì„±ì, ì£¼ìš” ë‚´ìš©, ê²°ë¡ ",
                        'manual': "ë§¤ë‰´ì–¼ êµ¬ì¡°í™”: ëª©ì°¨, ì£¼ìš” ì ˆì°¨, ì£¼ì˜ì‚¬í•­",
                        'form': "ì–‘ì‹ ì •ë³´ ì¶”ì¶œ: ì–‘ì‹ëª…, í•„ìˆ˜ í•­ëª©, ì‘ì„± ë‚´ìš©",
                        'letter': "ê³µë¬¸ ì •ë³´: ë°œì‹ ì²˜, ìˆ˜ì‹ ì²˜, ì œëª©, ì£¼ìš” ë‚´ìš©",
                        'other': "ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•˜ì—¬ ì¶”ì¶œ"
                    }
                    
                    specialized_prompt = type_prompts.get(doc_type, type_prompts['other'])
                    
                    content = self.ocr.process_image(
                        image_path=str(doc_path),
                        format_type="structured",
                        custom_prompt=specialized_prompt,
                        language="Korean"
                    )
                    
                    organized_docs[doc_type].append({
                        'filename': doc_path.name,
                        'path': str(doc_path),
                        'content': content
                    })
                    
                    print(f"âœ… {doc_path.name} â†’ {doc_type}")
                    
                except Exception as e:
                    print(f"âŒ {doc_path.name}: {str(e)}")
        
        # ìœ í˜•ë³„ ì •ë¦¬ ê²°ê³¼ ì €ì¥
        for doc_type, docs in organized_docs.items():
            if docs:
                output_dir = Path("output") / "organized_documents" / doc_type
                output_dir.mkdir(parents=True, exist_ok=True)
                
                # ìœ í˜•ë³„ ìš”ì•½ íŒŒì¼ ìƒì„±
                summary_file = output_dir / f"{doc_type}_summary.md"
                with open(summary_file, "w", encoding="utf-8") as f:
                    f.write(f"# {doc_type.title()} ë¬¸ì„œ ìš”ì•½\n\n")
                    f.write(f"ì´ {len(docs)}ê°œ ë¬¸ì„œ\n\n")
                    
                    for i, doc in enumerate(docs, 1):
                        f.write(f"## {i}. {doc['filename']}\n\n")
                        f.write(f"**ì›ë³¸ ê²½ë¡œ**: {doc['path']}\n\n")
                        f.write(f"**ì¶”ì¶œ ë‚´ìš©**:\n{doc['content']}\n\n")
                        f.write("---\n\n")
                
                print(f"ğŸ“ {doc_type}: {len(docs)}ê°œ ë¬¸ì„œ â†’ {output_dir}")
        
        return organized_docs

# ì‹¤í–‰ ì˜ˆì œ
def run_practical_examples():
    """ì‹¤ìš©ì ì¸ ì˜ˆì œ ì‹¤í–‰"""
    
    use_cases = PracticalUseCases()
    
    # 1. ì˜ìˆ˜ì¦ ê°€ê³„ë¶€ (ì˜ˆì œ ì˜ìˆ˜ì¦ ì´ë¯¸ì§€ê°€ ìˆë‹¤ê³  ê°€ì •)
    receipt_images = [
        "input/receipts/grocery_store.jpg",
        "input/receipts/restaurant.jpg",
        "input/receipts/gas_station.jpg"
    ]
    
    expenses = use_cases.receipt_expense_tracker(receipt_images)
    
    # 2. ëª…í•¨ ì •ë¦¬ (ì˜ˆì œ ëª…í•¨ ì´ë¯¸ì§€ê°€ ìˆë‹¤ê³  ê°€ì •)
    business_cards = [
        "input/business_cards/card1.jpg",
        "input/business_cards/card2.jpg"
    ]
    
    contacts = use_cases.business_card_organizer(business_cards)
    
    # 3. ë¬¸ì„œ ë””ì§€í„¸í™”
    organized_docs = use_cases.document_digitization_workflow("input/mixed_documents")
    
    print("\nğŸ‰ ëª¨ë“  ì‹¤ìš© ì˜ˆì œ ì™„ë£Œ!")
    print(f"ğŸ’° ì²˜ë¦¬ëœ ì˜ìˆ˜ì¦: {len(expenses)}ê°œ")
    print(f"ğŸ’³ ì •ë¦¬ëœ ëª…í•¨: {len(contacts)}ê°œ")
    print(f"ğŸ“š ë¶„ë¥˜ëœ ë¬¸ì„œ ìœ í˜•: {len(organized_docs)}ê°œ")

if __name__ == "__main__":
    # ë¬¸ì„œ ì²˜ë¦¬ ì˜ˆì œ ì‹¤í–‰
    print("ğŸš€ Ollama-OCR ì‹¤ì œ í™œìš© ì˜ˆì œ ì‹œì‘")
    print("="*50)
    
    # ì„±ëŠ¥ í‰ê°€
    evaluator = OCRPerformanceEvaluator()
    evaluator.evaluate_accuracy_by_document_type()
    
    # ì‹¤ìš©ì ì¸ í™œìš© ì‚¬ë¡€
    run_practical_examples()
```

## macOS í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ì™€ í™˜ê²½ êµ¬ì„±

### í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

```python
#!/usr/bin/env python3
"""
Ollama-OCR macOS í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì‹¤í–‰: python test_ollama_ocr.py
"""

import os
import sys
import subprocess
import time
import tempfile
from pathlib import Path
import requests
from PIL import Image, ImageDraw, ImageFont

class OllamaOCRTester:
    """Ollama-OCR í†µí•© í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.test_results = {}
        self.ollama_running = False
        
    def check_system_requirements(self):
        """ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸"""
        
        print("ğŸ” ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸...")
        
        # Python ë²„ì „ í™•ì¸
        python_version = sys.version_info
        if python_version.major >= 3 and python_version.minor >= 8:
            print(f"âœ… Python {python_version.major}.{python_version.minor}.{python_version.micro}")
        else:
            print(f"âŒ Python 3.8+ í•„ìš” (í˜„ì¬: {python_version.major}.{python_version.minor})")
            return False
        
        # ë©”ëª¨ë¦¬ í™•ì¸ (macOS)
        try:
            memory_info = subprocess.run(['sysctl', 'hw.memsize'], capture_output=True, text=True)
            if memory_info.returncode == 0:
                memory_bytes = int(memory_info.stdout.split(':')[1].strip())
                memory_gb = memory_bytes / (1024**3)
                print(f"ğŸ’¾ ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬: {memory_gb:.1f}GB")
                
                if memory_gb < 8:
                    print("âš ï¸  8GB ì´ìƒ ê¶Œì¥")
            else:
                print("âš ï¸  ë©”ëª¨ë¦¬ ì •ë³´ í™•ì¸ ì‹¤íŒ¨")
        except:
            print("âš ï¸  ë©”ëª¨ë¦¬ ì •ë³´ í™•ì¸ ë¶ˆê°€")
        
        # ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
        try:
            disk_info = subprocess.run(['df', '-h', '.'], capture_output=True, text=True)
            if disk_info.returncode == 0:
                lines = disk_info.stdout.strip().split('\n')
                if len(lines) > 1:
                    available = lines[1].split()[3]
                    print(f"ğŸ’½ ì‚¬ìš© ê°€ëŠ¥í•œ ë””ìŠ¤í¬: {available}")
        except:
            print("âš ï¸  ë””ìŠ¤í¬ ì •ë³´ í™•ì¸ ë¶ˆê°€")
        
        return True
    
    def check_ollama_installation(self):
        """Ollama ì„¤ì¹˜ ë° ì‹¤í–‰ ìƒíƒœ í™•ì¸"""
        
        print("\nğŸ¤– Ollama ì„¤ì¹˜ í™•ì¸...")
        
        # Ollama ëª…ë ¹ì–´ í™•ì¸
        try:
            result = subprocess.run(['ollama', '--version'], capture_output=True, text=True)
            if result.returncode == 0:
                print(f"âœ… Ollama ì„¤ì¹˜ë¨: {result.stdout.strip()}")
            else:
                print("âŒ Ollama ëª…ë ¹ì–´ ì‹¤í–‰ ì‹¤íŒ¨")
                return False
        except FileNotFoundError:
            print("âŒ Ollamaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("ì„¤ì¹˜ ë°©ë²•: brew install ollama")
            return False
        
        # Ollama ì„œë¹„ìŠ¤ ì‹¤í–‰ í™•ì¸
        try:
            response = requests.get('http://localhost:11434/api/tags', timeout=5)
            if response.status_code == 200:
                print("âœ… Ollama ì„œë¹„ìŠ¤ ì‹¤í–‰ ì¤‘")
                self.ollama_running = True
            else:
                print("âš ï¸  Ollama ì„œë¹„ìŠ¤ ì‘ë‹µ ì´ìƒ")
                return False
        except requests.exceptions.RequestException:
            print("âŒ Ollama ì„œë¹„ìŠ¤ê°€ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ")
            print("ì„œë¹„ìŠ¤ ì‹œì‘: ollama serve")
            return False
        
        return True
    
    def check_vision_models(self):
        """ë¹„ì „ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìƒíƒœ í™•ì¸"""
        
        print("\nğŸ‘ï¸ ë¹„ì „ ëª¨ë¸ í™•ì¸...")
        
        if not self.ollama_running:
            print("âŒ Ollama ì„œë¹„ìŠ¤ê°€ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ")
            return False
        
        required_models = [
            'llama3.2-vision:11b',
            'granite3.2-vision',
            'llava',
            'moondream',
            'minicpm-v'
        ]
        
        try:
            response = requests.get('http://localhost:11434/api/tags')
            if response.status_code == 200:
                installed_models = response.json()
                model_names = [model['name'] for model in installed_models.get('models', [])]
                
                available_models = []
                for model in required_models:
                    if any(model in installed_name for installed_name in model_names):
                        print(f"âœ… {model}")
                        available_models.append(model)
                    else:
                        print(f"âŒ {model} (ë‹¤ìš´ë¡œë“œ í•„ìš”)")
                
                if available_models:
                    print(f"\nì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {len(available_models)}ê°œ")
                    return available_models
                else:
                    print("\nâš ï¸  ì‚¬ìš© ê°€ëŠ¥í•œ ë¹„ì „ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                    return False
            else:
                print("âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨")
                return False
        except requests.exceptions.RequestException as e:
            print(f"âŒ ëª¨ë¸ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def install_python_packages(self):
        """Python íŒ¨í‚¤ì§€ ì„¤ì¹˜"""
        
        print("\nğŸ“¦ Python íŒ¨í‚¤ì§€ í™•ì¸...")
        
        packages = ['ollama-ocr', 'Pillow', 'requests', 'streamlit']
        
        for package in packages:
            try:
                if package == 'ollama-ocr':
                    import ollama_ocr
                elif package == 'Pillow':
                    from PIL import Image
                elif package == 'requests':
                    import requests
                elif package == 'streamlit':
                    import streamlit
                
                print(f"âœ… {package}")
                
            except ImportError:
                print(f"ğŸ“¥ {package} ì„¤ì¹˜ ì¤‘...")
                try:
                    subprocess.run([sys.executable, '-m', 'pip', 'install', package], 
                                  capture_output=True, check=True)
                    print(f"âœ… {package} ì„¤ì¹˜ ì™„ë£Œ")
                except subprocess.CalledProcessError as e:
                    print(f"âŒ {package} ì„¤ì¹˜ ì‹¤íŒ¨: {str(e)}")
                    return False
        
        return True
    
    def create_test_images(self):
        """í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ ìƒì„±"""
        
        print("\nğŸ–¼ï¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±...")
        
        test_dir = Path("test_images")
        test_dir.mkdir(exist_ok=True)
        
        # 1. ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€
        img1 = Image.new('RGB', (800, 200), 'white')
        draw1 = ImageDraw.Draw(img1)
        
        # ê¸°ë³¸ í°íŠ¸ ì‚¬ìš© (macOSì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í°íŠ¸)
        try:
            font = ImageFont.truetype("/System/Library/Fonts/Arial.ttf", 32)
        except:
            font = ImageFont.load_default()
        
        draw1.text((50, 50), "Hello World OCR Test", fill='black', font=font)
        draw1.text((50, 100), "ì•ˆë…•í•˜ì„¸ìš” OCR í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤", fill='black', font=font)
        
        img1_path = test_dir / "simple_text.png"
        img1.save(img1_path)
        print(f"âœ… ìƒì„±: {img1_path}")
        
        # 2. ë³µì¡í•œ ë ˆì´ì•„ì›ƒ ì´ë¯¸ì§€
        img2 = Image.new('RGB', (600, 400), 'white')
        draw2 = ImageDraw.Draw(img2)
        
        # ì œëª©
        draw2.text((50, 30), "OCR ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ", fill='black', font=font)
        
        # ë³¸ë¬¸
        lines = [
            "1. ì²« ë²ˆì§¸ í•­ëª©ì…ë‹ˆë‹¤.",
            "2. ë‘ ë²ˆì§¸ í•­ëª©ì…ë‹ˆë‹¤.",
            "   - í•˜ìœ„ í•­ëª© A",
            "   - í•˜ìœ„ í•­ëª© B",
            "3. ì„¸ ë²ˆì§¸ í•­ëª©ì…ë‹ˆë‹¤."
        ]
        
        y_pos = 80
        for line in lines:
            draw2.text((50, y_pos), line, fill='black', font=font)
            y_pos += 40
        
        # í…Œì´ë¸” í˜•íƒœ
        draw2.rectangle([400, 100, 550, 200], outline='black', width=2)
        draw2.text((410, 110), "í•­ëª©", fill='black', font=font)
        draw2.text((410, 140), "ê°’", fill='black', font=font)
        draw2.text((410, 170), "100", fill='black', font=font)
        
        img2_path = test_dir / "complex_layout.png"
        img2.save(img2_path)
        print(f"âœ… ìƒì„±: {img2_path}")
        
        # 3. ìˆ«ìì™€ íŠ¹ìˆ˜ë¬¸ì ì´ë¯¸ì§€
        img3 = Image.new('RGB', (500, 300), 'white')
        draw3 = ImageDraw.Draw(img3)
        
        test_text = [
            "ì „í™”ë²ˆí˜¸: 010-1234-5678",
            "ì´ë©”ì¼: test@example.com",
            "ë‚ ì§œ: 2025-08-07",
            "ê¸ˆì•¡: â‚©1,234,567",
            "ì£¼ì†Œ: ì„œìš¸ì‹œ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ 123"
        ]
        
        y_pos = 50
        for text in test_text:
            draw3.text((30, y_pos), text, fill='black', font=font)
            y_pos += 40
        
        img3_path = test_dir / "special_chars.png"
        img3.save(img3_path)
        print(f"âœ… ìƒì„±: {img3_path}")
        
        return [img1_path, img2_path, img3_path]
    
    def test_basic_ocr(self, test_images, available_models):
        """ê¸°ë³¸ OCR ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        
        print("\nğŸ§ª ê¸°ë³¸ OCR ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸...")
        
        from ollama_ocr import OCRProcessor
        
        # ê°€ì¥ ë¹ ë¥¸ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸
        test_model = 'llava' if 'llava' in available_models else available_models[0]
        
        try:
            ocr = OCRProcessor(model_name=test_model)
            
            for i, image_path in enumerate(test_images):
                print(f"\nğŸ“‹ í…ŒìŠ¤íŠ¸ {i+1}: {image_path.name}")
                
                start_time = time.time()
                
                result = ocr.process_image(
                    image_path=str(image_path),
                    format_type="text",
                    language="Korean"
                )
                
                processing_time = time.time() - start_time
                
                print(f"â±ï¸  ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
                print(f"ğŸ“„ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ({len(result)} ì):")
                print(f"   {result[:100]}..." if len(result) > 100 else f"   {result}")
                
                self.test_results[f"basic_test_{i+1}"] = {
                    'success': True,
                    'model': test_model,
                    'image': str(image_path),
                    'processing_time': processing_time,
                    'text_length': len(result),
                    'extracted_text': result
                }
            
            print("âœ… ê¸°ë³¸ OCR í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ ê¸°ë³¸ OCR í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def test_format_outputs(self, test_images, available_models):
        """ë‹¤ì–‘í•œ ì¶œë ¥ í˜•ì‹ í…ŒìŠ¤íŠ¸"""
        
        print("\nğŸ“Š ì¶œë ¥ í˜•ì‹ í…ŒìŠ¤íŠ¸...")
        
        from ollama_ocr import OCRProcessor
        
        test_model = 'granite3.2-vision' if 'granite3.2-vision' in available_models else available_models[0]
        
        formats = ['text', 'markdown', 'json', 'structured']
        
        try:
            ocr = OCRProcessor(model_name=test_model)
            test_image = test_images[1]  # ë³µì¡í•œ ë ˆì´ì•„ì›ƒ ì´ë¯¸ì§€ ì‚¬ìš©
            
            for format_type in formats:
                print(f"\nğŸ” {format_type} í˜•ì‹ í…ŒìŠ¤íŠ¸...")
                
                start_time = time.time()
                
                result = ocr.process_image(
                    image_path=str(test_image),
                    format_type=format_type,
                    language="Korean"
                )
                
                processing_time = time.time() - start_time
                
                print(f"â±ï¸  ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
                print(f"ğŸ“ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°: {str(result)[:150]}...")
                
                self.test_results[f"format_{format_type}"] = {
                    'success': True,
                    'format': format_type,
                    'processing_time': processing_time,
                    'result_length': len(str(result))
                }
            
            print("âœ… ì¶œë ¥ í˜•ì‹ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ ì¶œë ¥ í˜•ì‹ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def test_batch_processing(self, test_images, available_models):
        """ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        
        print("\nâš¡ ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸...")
        
        from ollama_ocr import OCRProcessor
        
        test_model = 'llava' if 'llava' in available_models else available_models[0]
        
        try:
            ocr = OCRProcessor(model_name=test_model, max_workers=2)
            
            # ì„ì‹œ ë””ë ‰í† ë¦¬ì— í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë³µì‚¬
            with tempfile.TemporaryDirectory() as temp_dir:
                temp_images = []
                for i, img_path in enumerate(test_images):
                    temp_img_path = Path(temp_dir) / f"batch_test_{i}.png"
                    temp_img_path.write_bytes(img_path.read_bytes())
                    temp_images.append(temp_img_path)
                
                start_time = time.time()
                
                batch_results = ocr.process_batch(
                    input_path=temp_dir,
                    format_type="text",
                    recursive=False,
                    preprocess=True,
                    language="Korean"
                )
                
                processing_time = time.time() - start_time
                
                stats = batch_results['statistics']
                
                print(f"â±ï¸  ì´ ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
                print(f"ğŸ“Š ì²˜ë¦¬ í†µê³„:")
                print(f"   - ì´ íŒŒì¼: {stats['total']}ê°œ")
                print(f"   - ì„±ê³µ: {stats['successful']}ê°œ")
                print(f"   - ì‹¤íŒ¨: {stats['failed']}ê°œ")
                print(f"   - í‰ê·  ì‹œê°„: {processing_time/max(stats['total'], 1):.2f}ì´ˆ/íŒŒì¼")
                
                self.test_results['batch_processing'] = {
                    'success': True,
                    'total_time': processing_time,
                    'statistics': stats
                }
                
                print("âœ… ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
                return True
        
        except Exception as e:
            print(f"âŒ ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def generate_test_report(self):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±"""
        
        print("\n" + "="*60)
        print("ğŸ“Š Ollama-OCR í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³´ê³ ì„œ")
        print("="*60)
        
        total_tests = len(self.test_results)
        successful_tests = sum(1 for result in self.test_results.values() if result.get('success', False))
        
        print(f"ğŸ¯ ì „ì²´ ì„±ê³µë¥ : {successful_tests/total_tests*100:.1f}% ({successful_tests}/{total_tests})")
        
        # ê¸°ë³¸ OCR í…ŒìŠ¤íŠ¸ ê²°ê³¼
        basic_tests = {k: v for k, v in self.test_results.items() if k.startswith('basic_test')}
        if basic_tests:
            print(f"\nğŸ“‹ ê¸°ë³¸ OCR í…ŒìŠ¤íŠ¸:")
            avg_time = sum(r['processing_time'] for r in basic_tests.values()) / len(basic_tests)
            avg_length = sum(r['text_length'] for r in basic_tests.values()) / len(basic_tests)
            print(f"   í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.2f}ì´ˆ")
            print(f"   í‰ê·  í…ìŠ¤íŠ¸ ê¸¸ì´: {avg_length:.0f}ì")
        
        # í˜•ì‹ë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼
        format_tests = {k: v for k, v in self.test_results.items() if k.startswith('format_')}
        if format_tests:
            print(f"\nğŸ“Š ì¶œë ¥ í˜•ì‹ë³„ ì„±ëŠ¥:")
            for test_name, result in format_tests.items():
                format_name = test_name.split('_')[1]
                print(f"   {format_name}: {result['processing_time']:.2f}ì´ˆ")
        
        # ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼
        if 'batch_processing' in self.test_results:
            batch_result = self.test_results['batch_processing']
            print(f"\nâš¡ ë°°ì¹˜ ì²˜ë¦¬ ì„±ëŠ¥:")
            print(f"   ì´ ì²˜ë¦¬ ì‹œê°„: {batch_result['total_time']:.2f}ì´ˆ")
            print(f"   ì„±ê³µë¥ : {batch_result['statistics']['successful']}/{batch_result['statistics']['total']}")
        
        # ì‹œìŠ¤í…œ ì •ë³´
        print(f"\nğŸ–¥ï¸ í…ŒìŠ¤íŠ¸ í™˜ê²½:")
        print(f"   OS: macOS")
        print(f"   Python: {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}")
        print(f"   í…ŒìŠ¤íŠ¸ ì‹œê°„: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # ê¶Œì¥ì‚¬í•­
        print(f"\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
        if successful_tests == total_tests:
            print("   ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µí–ˆìŠµë‹ˆë‹¤! ë°”ë¡œ ì‚¬ìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        elif successful_tests > total_tests * 0.7:
            print("   âœ… ëŒ€ë¶€ë¶„ì˜ ê¸°ëŠ¥ì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.")
            print("   âš ï¸  ì¼ë¶€ ì‹¤íŒ¨í•œ ê¸°ëŠ¥ì€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œë‚˜ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        else:
            print("   âš ï¸  ì—¬ëŸ¬ ê¸°ëŠ¥ì—ì„œ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            print("   ğŸ”§ Ollama ì„¤ì¹˜, ëª¨ë¸ ë‹¤ìš´ë¡œë“œ, ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    def run_full_test(self):
        """ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        
        print("ğŸš€ Ollama-OCR macOS í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("="*50)
        
        # 1. ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸
        if not self.check_system_requirements():
            print("âŒ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ ë¯¸ì¶©ì¡±")
            return False
        
        # 2. Ollama í™•ì¸
        if not self.check_ollama_installation():
            print("âŒ Ollama ì„¤ì¹˜/ì‹¤í–‰ ë¬¸ì œ")
            return False
        
        # 3. ë¹„ì „ ëª¨ë¸ í™•ì¸
        available_models = self.check_vision_models()
        if not available_models:
            print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ë¹„ì „ ëª¨ë¸ ì—†ìŒ")
            return False
        
        # 4. Python íŒ¨í‚¤ì§€ ì„¤ì¹˜
        if not self.install_python_packages():
            print("âŒ Python íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì‹¤íŒ¨")
            return False
        
        # 5. í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
        test_images = self.create_test_images()
        
        # 6. ê¸°ë³¸ OCR í…ŒìŠ¤íŠ¸
        self.test_basic_ocr(test_images, available_models)
        
        # 7. ì¶œë ¥ í˜•ì‹ í…ŒìŠ¤íŠ¸
        self.test_format_outputs(test_images, available_models)
        
        # 8. ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
        self.test_batch_processing(test_images, available_models)
        
        # 9. í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„±
        self.generate_test_report()
        
        return True

if __name__ == "__main__":
    tester = OllamaOCRTester()
    tester.run_full_test()
```

### ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# íŒŒì¼: benchmark_ollama_ocr.sh
# Ollama-OCR ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ìŠ¤í¬ë¦½íŠ¸

echo "ğŸ“Š Ollama-OCR ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘"
echo "=================================="

# ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘
echo "ğŸ–¥ï¸ ì‹œìŠ¤í…œ ì •ë³´:"
echo "- OS: $(uname -s) $(uname -r)"
echo "- CPU: $(sysctl -n machdep.cpu.brand_string)"
echo "- ë©”ëª¨ë¦¬: $(sysctl -n hw.memsize | awk '{print $1/1024/1024/1024 " GB"}')"
echo "- Python: $(python3 --version)"

# Ollama ìƒíƒœ í™•ì¸
echo ""
echo "ğŸ¤– Ollama ìƒíƒœ í™•ì¸:"
if pgrep -f "ollama serve" > /dev/null; then
    echo "âœ… Ollama ì„œë¹„ìŠ¤ ì‹¤í–‰ ì¤‘"
else
    echo "ğŸš€ Ollama ì„œë¹„ìŠ¤ ì‹œì‘ ì¤‘..."
    ollama serve &
    sleep 10
fi

# ë²¤ì¹˜ë§ˆí¬ìš© í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
python3 << EOF
import subprocess
import time
import json
from pathlib import Path

# í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
results_dir = Path("benchmark_results")
results_dir.mkdir(exist_ok=True)

# ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
print("âš¡ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘...")

models = ['llava', 'granite3.2-vision', 'llama3.2-vision:11b']
image_sizes = ['small', 'medium', 'large']
formats = ['text', 'markdown', 'json']

benchmark_results = {}

for model in models:
    if model not in benchmark_results:
        benchmark_results[model] = {}
    
    for size in image_sizes:
        for format_type in formats:
            test_key = f"{size}_{format_type}"
            
            print(f"ğŸ” {model} - {test_key} í…ŒìŠ¤íŠ¸...")
            
            start_time = time.time()
            
            # ì‹¤ì œ OCR í…ŒìŠ¤íŠ¸ (í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ í•„ìš”)
            # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
            time.sleep(0.5)  # ì‹œë®¬ë ˆì´ì…˜ ì§€ì—°
            
            end_time = time.time()
            processing_time = end_time - start_time
            
            benchmark_results[model][test_key] = {
                'processing_time': processing_time,
                'success': True
            }

# ê²°ê³¼ ì €ì¥
with open(results_dir / "benchmark_results.json", "w") as f:
    json.dump(benchmark_results, f, indent=2)

print("âœ… ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ")
print(f"ğŸ“Š ê²°ê³¼ ì €ì¥: {results_dir}/benchmark_results.json")
EOF

echo ""
echo "ğŸ¯ ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ"
echo "ê²°ê³¼ íŒŒì¼: benchmark_results/benchmark_results.json"
```

## troubleshooting ë° ìµœì í™” ê°€ì´ë“œ

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œ í•´ê²°

```python
class OllamaOCRTroubleshooter:
    """Ollama-OCR ë¬¸ì œ í•´ê²° ë„ìš°ë¯¸"""
    
    def __init__(self):
        self.common_issues = {}
    
    def diagnose_ollama_connection(self):
        """Ollama ì—°ê²° ë¬¸ì œ ì§„ë‹¨"""
        
        print("ğŸ” Ollama ì—°ê²° ìƒíƒœ ì§„ë‹¨...")
        
        # 1. Ollama ì„œë¹„ìŠ¤ ì‹¤í–‰ í™•ì¸
        try:
            import psutil
            ollama_processes = [p for p in psutil.process_iter() if 'ollama' in p.name().lower()]
            
            if ollama_processes:
                print("âœ… Ollama í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì¤‘")
                for proc in ollama_processes:
                    print(f"   PID: {proc.pid}, ë©”ëª¨ë¦¬: {proc.memory_info().rss / 1024 / 1024:.1f}MB")
            else:
                print("âŒ Ollama í”„ë¡œì„¸ìŠ¤ ì—†ìŒ")
                print("í•´ê²°ë°©ë²•: ollama serve ëª…ë ¹ìœ¼ë¡œ ì„œë¹„ìŠ¤ ì‹œì‘")
                return False
        except ImportError:
            print("âš ï¸  psutil íŒ¨í‚¤ì§€ ì—†ìŒ (pip install psutil)")
        
        # 2. API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
        try:
            import requests
            response = requests.get('http://localhost:11434/api/tags', timeout=10)
            
            if response.status_code == 200:
                models = response.json().get('models', [])
                print(f"âœ… API ì •ìƒ ({len(models)}ê°œ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥)")
                return True
            else:
                print(f"âŒ API ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
                return False
                
        except requests.exceptions.ConnectException:
            print("âŒ Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨")
            print("í•´ê²°ë°©ë²•:")
            print("1. ollama serve ì‹¤í–‰")
            print("2. í¬íŠ¸ 11434ê°€ ì‚¬ìš© ì¤‘ì¸ì§€ í™•ì¸")
            print("3. ë°©í™”ë²½ ì„¤ì • í™•ì¸")
            return False
        
        except requests.exceptions.Timeout:
            print("âŒ ì—°ê²° íƒ€ì„ì•„ì›ƒ")
            print("í•´ê²°ë°©ë²•: ì„œë²„ ì¬ì‹œì‘ ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ í™•ì¸")
            return False
    
    def diagnose_model_issues(self):
        """ëª¨ë¸ ê´€ë ¨ ë¬¸ì œ ì§„ë‹¨"""
        
        print("\nğŸ¤– ëª¨ë¸ ë¬¸ì œ ì§„ë‹¨...")
        
        try:
            import requests
            response = requests.get('http://localhost:11434/api/tags')
            
            if response.status_code == 200:
                models_data = response.json()
                models = models_data.get('models', [])
                
                if not models:
                    print("âŒ ì„¤ì¹˜ëœ ëª¨ë¸ ì—†ìŒ")
                    print("í•´ê²°ë°©ë²•:")
                    print("ollama pull llama3.2-vision:11b")
                    print("ollama pull granite3.2-vision")
                    return False
                
                # ë¹„ì „ ëª¨ë¸ í™•ì¸
                vision_models = []
                for model in models:
                    model_name = model['name']
                    if any(keyword in model_name.lower() for keyword in ['vision', 'llava', 'granite', 'minicpm']):
                        vision_models.append(model_name)
                        print(f"âœ… {model_name}")
                
                if not vision_models:
                    print("âŒ ë¹„ì „ ëª¨ë¸ ì—†ìŒ")
                    print("í•´ê²°ë°©ë²•: ë¹„ì „ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í•„ìš”")
                    return False
                
                print(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ë¹„ì „ ëª¨ë¸: {len(vision_models)}ê°œ")
                return True
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def diagnose_memory_issues(self):
        """ë©”ëª¨ë¦¬ ê´€ë ¨ ë¬¸ì œ ì§„ë‹¨"""
        
        print("\nğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì§„ë‹¨...")
        
        try:
            import psutil
            
            # ì „ì²´ ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬
            memory = psutil.virtual_memory()
            print(f"ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬: {memory.total / 1024**3:.1f}GB")
            print(f"ì‚¬ìš© ì¤‘: {memory.used / 1024**3:.1f}GB ({memory.percent:.1f}%)")
            print(f"ì‚¬ìš© ê°€ëŠ¥: {memory.available / 1024**3:.1f}GB")
            
            # Ollama í”„ë¡œì„¸ìŠ¤ ë©”ëª¨ë¦¬
            ollama_memory = 0
            for proc in psutil.process_iter():
                if 'ollama' in proc.name().lower():
                    try:
                        ollama_memory += proc.memory_info().rss
                    except:
                        pass
            
            if ollama_memory > 0:
                print(f"Ollama ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {ollama_memory / 1024**2:.1f}MB")
            
            # ë©”ëª¨ë¦¬ ë¶€ì¡± ê²½ê³ 
            if memory.available < 2 * 1024**3:  # 2GB ë¯¸ë§Œ
                print("âš ï¸  ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤")
                print("í•´ê²°ë°©ë²•:")
                print("1. ë¶ˆí•„ìš”í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ")
                print("2. ê°€ë²¼ìš´ ëª¨ë¸ ì‚¬ìš© (llava, moondream)")
                print("3. ë°°ì¹˜ ì²˜ë¦¬ ì‹œ ì›Œì»¤ ìˆ˜ ì¤„ì´ê¸°")
                return False
            
            return True
            
        except ImportError:
            print("âš ï¸  psutil íŒ¨í‚¤ì§€ë¡œ ì •í™•í•œ ì§„ë‹¨ ë¶ˆê°€")
            return True
    
    def diagnose_performance_issues(self):
        """ì„±ëŠ¥ ê´€ë ¨ ë¬¸ì œ ì§„ë‹¨"""
        
        print("\nâš¡ ì„±ëŠ¥ ë¬¸ì œ ì§„ë‹¨...")
        
        # CPU í™•ì¸
        try:
            import psutil
            cpu_count = psutil.cpu_count()
            cpu_percent = psutil.cpu_percent(interval=1)
            
            print(f"CPU ì½”ì–´ ìˆ˜: {cpu_count}")
            print(f"CPU ì‚¬ìš©ë¥ : {cpu_percent:.1f}%")
            
            if cpu_percent > 80:
                print("âš ï¸  CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤")
                print("í•´ê²°ë°©ë²•:")
                print("1. ë°°ì¹˜ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜ ì¤„ì´ê¸°")
                print("2. ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")
        except:
            pass
        
        # ì„±ëŠ¥ ìµœì í™” ì œì•ˆ
        performance_tips = [
            "ğŸ’¡ ì„±ëŠ¥ ìµœì í™” íŒ:",
            "1. ë¬¸ì„œ ìœ í˜•ì— ë§ëŠ” ëª¨ë¸ ì„ íƒ:",
            "   - ì¼ë°˜ ë¬¸ì„œ: llava (ë¹ ë¦„)",
            "   - ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì„œ: granite3.2-vision",
            "   - ê³ ì •ë°€ í•„ìš”: llama3.2-vision:11b",
            "",
            "2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬:",
            "   - ì ì ˆí•œ í•´ìƒë„ë¡œ ë¦¬ì‚¬ì´ì¦ˆ",
            "   - ëª…ì•” ëŒ€ë¹„ ì¡°ì •",
            "   - ë…¸ì´ì¦ˆ ì œê±°",
            "",
            "3. ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”:",
            "   - CPU ì½”ì–´ ìˆ˜ì— ë§ëŠ” ì›Œì»¤ ì„¤ì •",
            "   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§",
            "   - ì ì ˆí•œ ì²­í¬ í¬ê¸°"
        ]
        
        for tip in performance_tips:
            print(tip)
        
        return True
    
    def auto_fix_common_issues(self):
        """ì¼ë°˜ì ì¸ ë¬¸ì œ ìë™ ìˆ˜ì •"""
        
        print("\nğŸ”§ ìë™ ë¬¸ì œ í•´ê²° ì‹œë„...")
        
        # 1. Ollama ì„œë¹„ìŠ¤ ì‹œì‘
        if not self.diagnose_ollama_connection():
            print("ğŸš€ Ollama ì„œë¹„ìŠ¤ ìë™ ì‹œì‘ ì‹œë„...")
            try:
                import subprocess
                subprocess.Popen(['ollama', 'serve'])
                time.sleep(5)
                
                if self.diagnose_ollama_connection():
                    print("âœ… Ollama ì„œë¹„ìŠ¤ ì‹œì‘ ì„±ê³µ")
                else:
                    print("âŒ ìë™ ì‹œì‘ ì‹¤íŒ¨")
            except Exception as e:
                print(f"âŒ ìë™ ì‹œì‘ ì‹¤íŒ¨: {str(e)}")
        
        # 2. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
        try:
            import ollama_ocr
        except ImportError:
            print("ğŸ“¦ ollama-ocr íŒ¨í‚¤ì§€ ìë™ ì„¤ì¹˜...")
            try:
                import subprocess
                subprocess.run([sys.executable, '-m', 'pip', 'install', 'ollama-ocr'], check=True)
                print("âœ… ollama-ocr ì„¤ì¹˜ ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ ìë™ ì„¤ì¹˜ ì‹¤íŒ¨: {str(e)}")
        
        # 3. ê¸°ë³¸ ë¹„ì „ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
        if not self.diagnose_model_issues():
            print("ğŸ¤– ê¸°ë³¸ ë¹„ì „ ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ...")
            try:
                import subprocess
                subprocess.run(['ollama', 'pull', 'llava'], check=True)
                print("âœ… llava ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    
    def generate_health_report(self):
        """ì „ì²´ ìƒíƒœ ê²€ì§„ ë³´ê³ ì„œ"""
        
        print("\n" + "="*50)
        print("ğŸ¥ Ollama-OCR ì‹œìŠ¤í…œ ìƒíƒœ ê²€ì§„")
        print("="*50)
        
        checks = [
            ("Ollama ì—°ê²°", self.diagnose_ollama_connection),
            ("ëª¨ë¸ ìƒíƒœ", self.diagnose_model_issues),
            ("ë©”ëª¨ë¦¬ ìƒíƒœ", self.diagnose_memory_issues),
            ("ì„±ëŠ¥ ìƒíƒœ", self.diagnose_performance_issues)
        ]
        
        passed_checks = 0
        total_checks = len(checks)
        
        for check_name, check_func in checks:
            try:
                if check_func():
                    passed_checks += 1
                    status = "âœ… ì •ìƒ"
                else:
                    status = "âŒ ë¬¸ì œ"
            except Exception as e:
                status = f"âš ï¸ ì˜¤ë¥˜: {str(e)}"
            
            print(f"{check_name}: {status}")
        
        health_score = (passed_checks / total_checks) * 100
        print(f"\nğŸ¯ ì‹œìŠ¤í…œ ê±´ê°•ë„: {health_score:.0f}% ({passed_checks}/{total_checks})")
        
        if health_score >= 75:
            print("ğŸ’š ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤!")
        elif health_score >= 50:
            print("ğŸ’› ì¼ë¶€ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            print("â¤ï¸ ë¬¸ì œ í•´ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            print("auto_fix_common_issues() ì‹¤í–‰ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")

# ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    troubleshooter = OllamaOCRTroubleshooter()
    
    # ìë™ ë¬¸ì œ í•´ê²° ì‹œë„
    troubleshooter.auto_fix_common_issues()
    
    # ì „ì²´ ìƒíƒœ ê²€ì§„
    troubleshooter.generate_health_report()
```

## ê²°ë¡ 

Ollama-OCRì€ **ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ë˜ëŠ” ê°•ë ¥í•œ OCR ì†”ë£¨ì…˜**ìœ¼ë¡œ, ë°ì´í„° í”„ë¼ì´ë²„ì‹œë¥¼ ë³´ì¥í•˜ë©´ì„œë„ **í´ë¼ìš°ë“œ API ìˆ˜ì¤€ì˜ ì •í™•ë„**ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ë¹„ì „ ëª¨ë¸ì„ ì§€ì›í•˜ì—¬ ì‚¬ìš©ìì˜ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” ìµœì ì˜ ì„ íƒì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

### í•µì‹¬ ì¥ì 

- ğŸ”’ **ì™„ì „í•œ í”„ë¼ì´ë²„ì‹œ**: ëª¨ë“  ì²˜ë¦¬ê°€ ë¡œì»¬ì—ì„œ ì‹¤í–‰
- ğŸ¤– **ë‹¤ì–‘í•œ ëª¨ë¸**: ìš©ë„ë³„ ìµœì í™”ëœ 5ê°€ì§€ ë¹„ì „ ëª¨ë¸
- ğŸ“„ **ê´‘ë²”ìœ„í•œ ì§€ì›**: PDF, ì´ë¯¸ì§€, ë‹¤ì–‘í•œ ì¶œë ¥ í˜•ì‹
- âš¡ **ê³ ì„±ëŠ¥**: ë°°ì¹˜ ì²˜ë¦¬ì™€ ë³‘ë ¬í™” ì§€ì›
- ğŸŒ **ì‚¬ìš©ì ì¹œí™”ì **: Streamlit ì›¹ ì¸í„°í˜ì´ìŠ¤ ì œê³µ

### í™œìš© ë¶„ì•¼

1. **ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì„œ ì²˜ë¦¬**: ì¸ë³´ì´ìŠ¤, ê³„ì•½ì„œ, ë³´ê³ ì„œ ìë™í™”
2. **ê°œì¸ ë¬¸ì„œ ê´€ë¦¬**: ì˜ìˆ˜ì¦ ê°€ê³„ë¶€, ëª…í•¨ ì •ë¦¬
3. **ì—°êµ¬ ë° í•™ìˆ **: ë…¼ë¬¸, ê¸°ìˆ  ë¬¸ì„œ ë””ì§€í„¸í™”
4. **ë²•ë¬´ ë° í–‰ì •**: ê³µë¬¸ì„œ, ì–‘ì‹ ì²˜ë¦¬ ìë™í™”

### ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ

| ìš©ë„ | ì¶”ì²œ ëª¨ë¸ | íŠ¹ì§• |
|------|-----------|------|
| **ì¼ë°˜ ë¬¸ì„œ** | LLaVA | ë¹ ë¥¸ ì†ë„, ë‚®ì€ ë¦¬ì†ŒìŠ¤ |
| **ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì„œ** | Granite3.2 | í‘œ/ì°¨íŠ¸ íŠ¹í™”, ë¬¸ì„œ êµ¬ì¡° ë³´ì¡´ |
| **ê³ ì •ë°€ ì‘ì—…** | Llama 3.2 Vision | ìµœê³  ì •í™•ë„, ë³µì¡í•œ ë ˆì´ì•„ì›ƒ |
| **ëª¨ë°”ì¼/ì—£ì§€** | Moondream | ì´ˆê²½ëŸ‰, ì‹¤ì‹œê°„ ì²˜ë¦¬ |
| **ê³ í•´ìƒë„** | MiniCPM-V | ì‘ì€ í…ìŠ¤íŠ¸, ìƒì„¸í•œ ë‚´ìš© |

### ì‹œì‘í•˜ê¸°

```bash
# 1ë¶„ ë§Œì— ì‹œì‘í•˜ê¸°
brew install ollama
ollama serve &
ollama pull llava
pip install ollama-ocr

python -c "
from ollama_ocr import OCRProcessor
ocr = OCRProcessor(model_name='llava')
print('ğŸš€ Ollama-OCR ì¤€ë¹„ ì™„ë£Œ!')
"
```

**Ollama-OCRê³¼ í•¨ê»˜ ë¬¸ì„œ ì²˜ë¦¬ ìë™í™”ì˜ ìƒˆë¡œìš´ ì°¨ì›ì„ ê²½í—˜í•´ë³´ì„¸ìš”.** í´ë¼ìš°ë“œì— ì˜ì¡´í•˜ì§€ ì•Šê³ ë„ **ì „ë¬¸ì ì¸ ìˆ˜ì¤€ì˜ OCR ì†”ë£¨ì…˜**ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì¶”ê°€ í•™ìŠµ ìë£Œ

ë” ë§ì€ AI ë„êµ¬ ê°€ì´ë“œëŠ” ë¸”ë¡œê·¸ì—ì„œ í™•ì¸í•˜ì„¸ìš”:
- [DeepAgents ì‹¬ì¸µ AI ì—ì´ì „íŠ¸ ê°€ì´ë“œ](https://thakicloud.github.io/tutorials/deepagents-comprehensive-deep-ai-agents-guide/)
- [SnapAI AI ì•„ì´ì½˜ ìƒì„± ê°€ì´ë“œ](https://thakicloud.github.io/tutorials/snapai-ai-icon-generation-complete-guide/)

---

ğŸ’¡ **Pro Tip**: ì´ ê°€ì´ë“œì˜ ëª¨ë“  ì˜ˆì œëŠ” ì‹¤ì œ macOS í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì´ ìˆë‹¤ë©´ [GitHub Issues](https://github.com/imanoop7/Ollama-OCR/issues)ì—ì„œ ì»¤ë®¤ë‹ˆí‹°ì™€ ì†Œí†µí•˜ì„¸ìš”!
