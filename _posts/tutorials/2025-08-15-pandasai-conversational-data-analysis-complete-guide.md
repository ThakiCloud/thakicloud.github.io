---
title: "PandasAI: ìì—°ì–´ë¡œ ë°ì´í„° ë¶„ì„í•˜ëŠ” ëŒ€í™”í˜• AI í”Œë«í¼ ì™„ì „ ê°€ì´ë“œ"
excerpt: "PandasAIë¡œ SQL, CSV, Parquet ë°ì´í„°ë¥¼ ìì—°ì–´ë¡œ ì§ˆë¬¸í•˜ê³  ë¶„ì„í•˜ëŠ” ë°©ë²•. LLMê³¼ RAGë¥¼ í™œìš©í•œ í˜ì‹ ì ì¸ ë°ì´í„° ë¶„ì„ ë„êµ¬ì˜ ì„¤ì¹˜ë¶€í„° ê³ ê¸‰ í™œìš©ê¹Œì§€ ì™„ë²½ ì •ë¦¬"
seo_title: "PandasAI ëŒ€í™”í˜• ë°ì´í„° ë¶„ì„ ì™„ì „ ê°€ì´ë“œ - Python LLM RAG - Thaki Cloud"
seo_description: "PandasAIë¡œ ìì—°ì–´ ì§ˆë¬¸ë§Œìœ¼ë¡œ ë°ì´í„° ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•. ì„¤ì¹˜ë¶€í„° Docker ìƒŒë“œë°•ìŠ¤, ë‹¤ì¤‘ DataFrame, ì‹œê°í™”ê¹Œì§€ macOS í…ŒìŠ¤íŠ¸ ì˜ˆì œ í¬í•¨"
date: 2025-08-15
last_modified_at: 2025-08-15
categories:
  - tutorials
tags:
  - pandasai
  - data-analysis
  - llm
  - rag
  - natural-language
  - data-science
  - pandas
  - openai
  - conversational-ai
  - python
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
toc_icon: "cog"
toc_sticky: true
canonical_url: "https://thakicloud.github.io/tutorials/pandasai-conversational-data-analysis-complete-guide/"
reading_time: true
---

â±ï¸ **ì˜ˆìƒ ì½ê¸° ì‹œê°„**: 15ë¶„

## ê°œìš”

**[PandasAI](https://github.com/sinaptik-ai/pandas-ai)**ëŠ” ë°ì´í„° ë¶„ì„ì„ í˜ì‹ ì ìœ¼ë¡œ ê°„ì†Œí™”í•˜ëŠ” Python í”Œë«í¼ì…ë‹ˆë‹¤. ë³µì¡í•œ pandas ì½”ë“œë‚˜ SQL ì¿¼ë¦¬ë¥¼ ì‘ì„±í•˜ëŠ” ëŒ€ì‹ , **ìì—°ì–´ë¡œ ì§ˆë¬¸í•˜ê¸°ë§Œ í•˜ë©´ AIê°€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µ**í•©ë‹ˆë‹¤. 21.8k ìŠ¤íƒ€ë¥¼ ë°›ì€ ì´ ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ëŠ” LLM(Large Language Model)ê³¼ RAG(Retrieval Augmented Generation) ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ë¹„ì „ë¬¸ê°€ë„ ì‰½ê²Œ ë°ì´í„° ë¶„ì„ì„ í•  ìˆ˜ ìˆê²Œ ë„ì™€ì¤ë‹ˆë‹¤.

### ğŸ¯ PandasAIì˜ í•µì‹¬ ê°€ì¹˜

- **ìì—°ì–´ ê¸°ë°˜ ë°ì´í„° ì§ˆì˜**: "ë§¤ì¶œì´ ê°€ì¥ ë†’ì€ ìƒìœ„ 5ê°œ êµ­ê°€ëŠ”?"
- **ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ ì§€ì›**: SQL, CSV, Parquet, Excel ë“±
- **AI ê¸°ë°˜ ì‹œê°í™”**: ì°¨íŠ¸ì™€ ê·¸ë˜í”„ ìë™ ìƒì„±
- **ë¹„ì „ë¬¸ê°€ ì¹œí™”ì **: ì½”ë”© ì§€ì‹ ì—†ì´ë„ ë°ì´í„° ë¶„ì„ ê°€ëŠ¥
- **í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜**: ë‹¤ì¤‘ DataFrame ë° ë³µì¡í•œ ë¶„ì„ ì§€ì›

### ğŸš€ ì£¼ìš” íŠ¹ì§•

**ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤**:
- ìì—°ì–´ë¡œ ë°ì´í„°ì— ì§ˆë¬¸
- ë§¥ë½ì„ ì´í•´í•˜ëŠ” ì—°ì†ì  ëŒ€í™”
- ì¦‰ê°ì ì¸ ë‹µë³€ê³¼ ì‹œê°í™”

**ì•ˆì „í•œ ì‹¤í–‰ í™˜ê²½**:
- Docker ìƒŒë“œë°•ìŠ¤ ì§€ì›
- ì•…ì„± ì½”ë“œ ì‹¤í–‰ ë°©ì§€
- ê²©ë¦¬ëœ í™˜ê²½ì—ì„œ ì•ˆì „í•œ ë¶„ì„

**ë‹¤ì–‘í•œ LLM ì§€ì›**:
- OpenAI GPT ëª¨ë¸
- Claude, Gemini ë“± ì£¼ìš” LLM
- ë¡œì»¬ LLM ëª¨ë¸ë„ ì§€ì›

## ì„¤ì¹˜ ë° í™˜ê²½ êµ¬ì„±

### ğŸ“‹ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

```bash
# Python ë²„ì „ ìš”êµ¬ì‚¬í•­
Python 3.8+ < 3.12

# ê¶Œì¥ í™˜ê²½
- macOS 10.15+, Ubuntu 18.04+, Windows 10+
- 8GB+ RAM (ëŒ€ìš©ëŸ‰ ë°ì´í„° ë¶„ì„ ì‹œ)
- ì¸í„°ë„· ì—°ê²° (LLM API ì‚¬ìš©)
```

### ğŸ”§ ê¸°ë³¸ ì„¤ì¹˜

#### pipë¥¼ í†µí•œ ì„¤ì¹˜
```bash
# ìµœì‹  ë² íƒ€ ë²„ì „ ì„¤ì¹˜ (ê¶Œì¥)
pip install "pandasai>=3.0.0b2"

# ì¶”ê°€ ì˜ì¡´ì„± íŒ¨í‚¤ì§€
pip install openai pandas matplotlib seaborn plotly
```

#### Poetryë¥¼ í†µí•œ ì„¤ì¹˜
```bash
# Poetry ì‚¬ìš©ììš©
poetry add "pandasai>=3.0.0b2"
poetry add openai pandas matplotlib seaborn plotly
```

#### Docker ìƒŒë“œë°•ìŠ¤ ì„¤ì¹˜ (ì„ íƒì‚¬í•­)
```bash
# ë³´ì•ˆ ê°•í™”ë¥¼ ìœ„í•œ Docker ìƒŒë“œë°•ìŠ¤
pip install "pandasai-docker"

# Docker ì„¤ì¹˜ í™•ì¸
docker --version
```

### ğŸ”‘ API í‚¤ ì„¤ì •

#### OpenAI API í‚¤ ì„¤ì •
```bash
# í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì • (ê¶Œì¥)
export OPENAI_API_KEY="your-openai-api-key-here"

# ë˜ëŠ” .env íŒŒì¼ ìƒì„±
echo "OPENAI_API_KEY=your-openai-api-key-here" > .env
```

#### ê¸°íƒ€ LLM ì„¤ì •
```bash
# Claude API
export ANTHROPIC_API_KEY="your-claude-api-key"

# Google Gemini
export GOOGLE_API_KEY="your-gemini-api-key"

# Azure OpenAI
export AZURE_OPENAI_API_KEY="your-azure-key"
export AZURE_OPENAI_ENDPOINT="your-azure-endpoint"
```

## í•µì‹¬ ê¸°ëŠ¥ ë° ì‚¬ìš©ë²•

### ğŸš€ ê¸°ë³¸ ì‚¬ìš©ë²•

#### ê°„ë‹¨í•œ ë°ì´í„° ë¶„ì„
```python
import pandasai as pai
from pandasai_openai.openai import OpenAI

# LLM ì„¤ì •
llm = OpenAI("OPEN_AI_API_KEY")  # ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ ë¡œë“œ

pai.config.set({
    "llm": llm
})

# ìƒ˜í”Œ ë°ì´í„° ìƒì„±
df = pai.DataFrame({
    "country": ["United States", "United Kingdom", "France", "Germany", "Italy", "Spain", "Canada", "Australia", "Japan", "China"],
    "revenue": [5000, 3200, 2900, 4100, 2300, 2100, 2500, 2600, 4500, 7000]
})

# ìì—°ì–´ë¡œ ì§ˆë¬¸í•˜ê¸°
result = df.chat('Which are the top 5 countries by sales?')
print(result)
# ì¶œë ¥: China, United States, Japan, Germany, Australia
```

#### ë³µì¡í•œ ê³„ì‚° ì§ˆì˜
```python
# ìˆ˜ì¹˜ ê³„ì‚° ì§ˆë¬¸
total_sales = df.chat(
    "What is the total sales for the top 3 countries by sales?"
)
print(total_sales)
# ì¶œë ¥: The total sales for the top 3 countries by sales is 16500.

# í‰ê·  ë° í†µê³„ ì§ˆë¬¸
average_revenue = df.chat(
    "What is the average revenue? Also tell me the median and standard deviation."
)
print(average_revenue)

# ì¡°ê±´ë¶€ í•„í„°ë§
european_sales = df.chat(
    "What is the total revenue for European countries only?"
)
print(european_sales)
```

### ğŸ“Š ì‹œê°í™” ê¸°ëŠ¥

#### ìë™ ì°¨íŠ¸ ìƒì„±
```python
# íˆìŠ¤í† ê·¸ë¨ ìƒì„±
df.chat(
    "Plot the histogram of countries showing for each one the revenue. Use different colors for each bar"
)

# íŒŒì´ ì°¨íŠ¸ ìƒì„±
df.chat(
    "Create a pie chart showing the revenue distribution by country"
)

# ë§‰ëŒ€ ê·¸ë˜í”„
df.chat(
    "Show me a bar chart of revenue by country, sorted from highest to lowest"
)

# ì‹œê³„ì—´ ë¶„ì„ (ë‚ ì§œ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
df.chat(
    "Plot the revenue trend over time with a line chart"
)
```

#### ê³ ê¸‰ ì‹œê°í™”
```python
# ë‹¤ì¤‘ ì‹œê°í™”
df.chat(
    """
    Create a dashboard with:
    1. A bar chart of top 5 countries by revenue
    2. A pie chart of revenue distribution
    3. A summary table with statistics
    """
)

# ì‚¬ìš©ì ì •ì˜ ìŠ¤íƒ€ì¼
df.chat(
    "Create a professional-looking chart with revenue by country. Use blue gradient colors and add data labels."
)
```

### ğŸ”— ë‹¤ì¤‘ DataFrame ë¶„ì„

#### ê´€ë ¨ ë°ì´í„° ê²°í•© ë¶„ì„
```python
import pandasai as pai
from pandasai_openai.openai import OpenAI

# ì§ì› ë°ì´í„°
employees_data = {
    'EmployeeID': [1, 2, 3, 4, 5],
    'Name': ['John', 'Emma', 'Liam', 'Olivia', 'William'],
    'Department': ['HR', 'Sales', 'IT', 'Marketing', 'Finance']
}

# ê¸‰ì—¬ ë°ì´í„°
salaries_data = {
    'EmployeeID': [1, 2, 3, 4, 5],
    'Salary': [5000, 6000, 4500, 7000, 5500]
}

llm = OpenAI()
pai.config.set({"llm": llm})

employees_df = pai.DataFrame(employees_data)
salaries_df = pai.DataFrame(salaries_data)

# ë‹¤ì¤‘ DataFrame ì§ˆì˜
result = pai.chat("Who gets paid the most?", employees_df, salaries_df)
print(result)
# ì¶œë ¥: Olivia gets paid the most.

# ë³µì¡í•œ ì¡°ì¸ ë¶„ì„
department_analysis = pai.chat(
    "What is the average salary by department? Show me in descending order.",
    employees_df, 
    salaries_df
)
print(department_analysis)
```

#### ê³ ê¸‰ ë‹¤ì¤‘ ë°ì´í„° ë¶„ì„
```python
# ë§¤ì¶œ ë°ì´í„°
sales_data = {
    'EmployeeID': [1, 2, 3, 4, 5],
    'Sales': [150000, 200000, 120000, 250000, 180000],
    'Quarter': ['Q1', 'Q1', 'Q1', 'Q1', 'Q1']
}

sales_df = pai.DataFrame(sales_data)

# ì„¸ ê°œ DataFrame ë™ì‹œ ë¶„ì„
comprehensive_analysis = pai.chat(
    """
    Analyze the relationship between department, salary, and sales performance. 
    Which department has the best ROI (sales vs salary cost)?
    """,
    employees_df, 
    salaries_df, 
    sales_df
)
print(comprehensive_analysis)
```

### ğŸ³ Docker ìƒŒë“œë°•ìŠ¤ í™œìš©

#### ë³´ì•ˆ ê°•í™”ëœ ì‹¤í–‰ í™˜ê²½
```python
import pandasai as pai
from pandasai_docker import DockerSandbox
from pandasai_openai.openai import OpenAI

# Docker ìƒŒë“œë°•ìŠ¤ ì´ˆê¸°í™”
sandbox = DockerSandbox()
sandbox.start()

try:
    # LLM ì„¤ì •
    llm = OpenAI()
    pai.config.set({"llm": llm})
    
    # ìœ„í—˜í•  ìˆ˜ ìˆëŠ” ë°ì´í„° ë¶„ì„ë„ ì•ˆì „í•˜ê²Œ ì‹¤í–‰
    df = pai.DataFrame({
        "user_data": ["sensitive_info_1", "sensitive_info_2"],
        "values": [100, 200]
    })
    
    # ìƒŒë“œë°•ìŠ¤ì—ì„œ ì•ˆì „í•˜ê²Œ ì‹¤í–‰
    result = pai.chat(
        "Analyze this data and create a summary report",
        df,
        sandbox=sandbox
    )
    print(result)
    
finally:
    # ìƒŒë“œë°•ìŠ¤ ì •ë¦¬
    sandbox.stop()
```

#### ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬
```python
# ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ì‹œ Docker í™œìš©
sandbox = DockerSandbox()
sandbox.start()

# ë©”ëª¨ë¦¬ ì œí•œ ì„¤ì •
sandbox.configure(memory_limit="4g", cpu_limit="2")

large_df = pai.read_csv("large_dataset.csv")  # ê°€ìƒì˜ ëŒ€ìš©ëŸ‰ íŒŒì¼

result = pai.chat(
    "Find patterns in this large dataset and summarize key insights",
    large_df,
    sandbox=sandbox
)

sandbox.stop()
```

## ì‹¤ì „ í™œìš© ì˜ˆì œ

### ğŸ“ˆ ë¹„ì¦ˆë‹ˆìŠ¤ ë°ì´í„° ë¶„ì„

#### ë§¤ì¶œ ë¶„ì„ ëŒ€ì‹œë³´ë“œ
```python
import pandasai as pai
import pandas as pd
from pandasai_openai.openai import OpenAI

# ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜
business_data = {
    'date': pd.date_range('2024-01-01', periods=365, freq='D'),
    'product': ['A', 'B', 'C'] * 122,  # 365ê°œ ìƒì„±ì„ ìœ„í•´ ë°˜ë³µ
    'sales': [100 + i*2 + (i%30)*10 for i in range(365)],
    'region': ['North', 'South', 'East', 'West'] * 91 + ['North'],
    'customer_type': ['B2B', 'B2C'] * 182 + ['B2B']
}

llm = OpenAI()
pai.config.set({"llm": llm})

business_df = pai.DataFrame(business_data)

# ì¢…í•© ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸
insights = business_df.chat(
    """
    Provide a comprehensive business analysis including:
    1. Monthly sales trends
    2. Best performing products
    3. Regional performance comparison
    4. B2B vs B2C customer analysis
    5. Recommendations for improvement
    """
)
print(insights)
```

#### ê³ ê° ì„¸ë¶„í™” ë¶„ì„
```python
# ê³ ê° ë°ì´í„° ì¤€ë¹„
customer_data = {
    'customer_id': range(1, 1001),
    'age': [25 + i%40 for i in range(1000)],
    'annual_spend': [1000 + i*5 + (i%100)*20 for i in range(1000)],
    'frequency': [1 + i%50 for i in range(1000)],
    'last_purchase_days': [1 + i%365 for i in range(1000)],
    'category_preference': ['Electronics', 'Fashion', 'Home', 'Sports'] * 250
}

customer_df = pai.DataFrame(customer_data)

# AI ê¸°ë°˜ ê³ ê° ì„¸ë¶„í™”
segmentation = customer_df.chat(
    """
    Perform customer segmentation analysis:
    1. Identify different customer segments based on spending and frequency
    2. Create customer personas for each segment
    3. Suggest targeted marketing strategies
    4. Show the distribution of customers across segments with visualization
    """
)
print(segmentation)
```

### ğŸ”¬ ë°ì´í„° ê³¼í•™ í™œìš©

#### í†µê³„ ë¶„ì„ ë° ê°€ì„¤ ê²€ì •
```python
# ì‹¤í—˜ ë°ì´í„° ìƒì„±
import numpy as np

experiment_data = {
    'group': ['A'] * 500 + ['B'] * 500,
    'conversion_rate': (
        list(np.random.normal(0.15, 0.05, 500)) +  # Aê·¸ë£¹
        list(np.random.normal(0.18, 0.05, 500))    # Bê·¸ë£¹
    ),
    'session_duration': (
        list(np.random.normal(120, 30, 500)) +  # Aê·¸ë£¹
        list(np.random.normal(135, 35, 500))    # Bê·¸ë£¹
    )
}

experiment_df = pai.DataFrame(experiment_data)

# AI ê¸°ë°˜ í†µê³„ ë¶„ì„
statistical_analysis = experiment_df.chat(
    """
    Perform A/B test analysis:
    1. Calculate statistical significance of conversion rate difference
    2. Analyze session duration differences
    3. Provide confidence intervals
    4. Create visualization showing the results
    5. Give business recommendations based on the results
    """
)
print(statistical_analysis)
```

#### ì˜ˆì¸¡ ëª¨ë¸ë§ ì§€ì›
```python
# ì‹œê³„ì—´ ë°ì´í„° ì¤€ë¹„
time_series_data = {
    'date': pd.date_range('2020-01-01', periods=1460, freq='D'),  # 4ë…„ê°„ ë°ì´í„°
    'sales': [
        1000 + 50*np.sin(i*2*np.pi/365) + 10*np.sin(i*2*np.pi/7) + np.random.normal(0, 20)
        for i in range(1460)
    ],
    'marketing_spend': [100 + i*0.1 + np.random.normal(0, 10) for i in range(1460)],
    'temperature': [20 + 15*np.sin((i-90)*2*np.pi/365) + np.random.normal(0, 3) for i in range(1460)]
}

ts_df = pai.DataFrame(time_series_data)

# AI ê¸°ë°˜ ì˜ˆì¸¡ ë¶„ì„
forecast_analysis = ts_df.chat(
    """
    Analyze this time series data and provide:
    1. Trend analysis and seasonality patterns
    2. Correlation between marketing spend, temperature, and sales
    3. Anomaly detection for unusual patterns
    4. Sales forecast for the next 30 days
    5. Visualization of trends and forecasts
    """
)
print(forecast_analysis)
```

### ğŸ¢ ì‹¤ë¬´ í™œìš© ì‹œë‚˜ë¦¬ì˜¤

#### ì¬ë¬´ ë³´ê³ ì„œ ìë™í™”
```python
# ì¬ë¬´ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜
financial_data = {
    'account': ['Revenue', 'COGS', 'Marketing', 'R&D', 'Admin', 'Interest'],
    'Q1_2024': [1000000, -400000, -150000, -200000, -100000, -25000],
    'Q2_2024': [1200000, -480000, -180000, -220000, -110000, -25000],
    'Q3_2024': [1150000, -460000, -170000, -210000, -105000, -25000],
    'Q4_2024': [1300000, -520000, -200000, -240000, -120000, -25000],
    'category': ['Income', 'COGS', 'OpEx', 'OpEx', 'OpEx', 'FinEx']
}

financial_df = pai.DataFrame(financial_data)

# ìë™ ì¬ë¬´ ë¶„ì„ ë³´ê³ ì„œ
financial_report = financial_df.chat(
    """
    Generate a comprehensive financial analysis report:
    1. Calculate quarterly profit margins and growth rates
    2. Analyze expense ratios and trends
    3. Create quarterly comparison charts
    4. Identify areas of concern and opportunities
    5. Provide executive summary with key recommendations
    """
)
print(financial_report)
```

#### HR ë°ì´í„° ë¶„ì„
```python
# HR ë°ì´í„° ì¤€ë¹„
hr_data = {
    'employee_id': range(1, 201),
    'department': ['Engineering', 'Sales', 'Marketing', 'HR', 'Finance'] * 40,
    'salary': [50000 + i*1000 + np.random.normal(0, 5000) for i in range(200)],
    'performance_score': [3 + np.random.normal(0, 0.8) for _ in range(200)],
    'years_at_company': [np.random.randint(1, 15) for _ in range(200)],
    'satisfaction_score': [3 + np.random.normal(0, 1) for _ in range(200)],
    'attrition_risk': ['Low', 'Medium', 'High'] * 66 + ['Low', 'Medium']
}

hr_df = pai.DataFrame(hr_data)

# HR ì¸ì‚¬ì´íŠ¸ ë¶„ì„
hr_insights = hr_df.chat(
    """
    Perform comprehensive HR analytics:
    1. Salary benchmarking by department and experience
    2. Performance vs satisfaction correlation analysis
    3. Attrition risk factors identification
    4. Department-wise retention strategies
    5. Diversity and equity analysis
    6. Create actionable recommendations for HR team
    """
)
print(hr_insights)
```

## macOS í…ŒìŠ¤íŠ¸ í™˜ê²½ êµ¬ì„±

### ğŸ§ª í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±

PandasAIì˜ ì‹¤ì œ ë™ì‘ì„ í™•ì¸í•˜ê¸° ìœ„í•œ macOS í…ŒìŠ¤íŠ¸ í™˜ê²½ì„ êµ¬ì„±í•´ë³´ê² ìŠµë‹ˆë‹¤.

#### í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# test-pandasai-setup.sh

echo "ğŸš€ PandasAI í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì • ì‹œì‘"
echo "=================================="

# ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸
echo "[INFO] ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸ ì¤‘..."

# Python ë²„ì „ í™•ì¸
PYTHON_VERSION=$(python3 --version 2>&1 | cut -d' ' -f2)
PYTHON_MAJOR=$(echo $PYTHON_VERSION | cut -d'.' -f1)
PYTHON_MINOR=$(echo $PYTHON_VERSION | cut -d'.' -f2)

if [ "$PYTHON_MAJOR" -eq 3 ] && [ "$PYTHON_MINOR" -ge 8 ] && [ "$PYTHON_MINOR" -lt 12 ]; then
    echo "[SUCCESS] Python ë²„ì „ í™•ì¸: $PYTHON_VERSION (ìš”êµ¬ì‚¬í•­ ì¶©ì¡±)"
else
    echo "[ERROR] Python 3.8-3.11 ë²„ì „ì´ í•„ìš”í•©ë‹ˆë‹¤. í˜„ì¬: $PYTHON_VERSION"
    echo "pyenvë‚˜ condaë¥¼ ì‚¬ìš©í•˜ì—¬ ì ì ˆí•œ Python ë²„ì „ì„ ì„¤ì¹˜í•˜ì„¸ìš”."
    exit 1
fi

# pip í™•ì¸
if command -v pip3 &> /dev/null; then
    PIP_VERSION=$(pip3 --version | cut -d' ' -f2)
    echo "[SUCCESS] pip ì„¤ì¹˜ë¨: $PIP_VERSION"
else
    echo "[ERROR] pip3ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ"
    exit 1
fi

# í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
TIMESTAMP=$(date +%Y%m%d-%H%M%S)
TEST_DIR="$HOME/pandasai-test-$TIMESTAMP"
mkdir -p "$TEST_DIR"
cd "$TEST_DIR"

echo "[INFO] í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±: $TEST_DIR"

# ê°€ìƒ í™˜ê²½ ìƒì„±
echo "[INFO] Python ê°€ìƒ í™˜ê²½ ìƒì„± ì¤‘..."
python3 -m venv venv
source venv/bin/activate

# PandasAI ì„¤ì¹˜
echo "[INFO] PandasAI ë° í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘..."
pip install --upgrade pip
pip install "pandasai>=3.0.0b2"
pip install openai pandas matplotlib seaborn plotly numpy
pip install jupyter ipykernel  # Jupyter notebook ì§€ì›

# API í‚¤ ì„¤ì • í™•ì¸
echo "[INFO] API í‚¤ ì„¤ì • í™•ì¸ ì¤‘..."
if [ -z "$OPENAI_API_KEY" ]; then
    echo "[WARNING] OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    echo "í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì„ì‹œë¡œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
    echo "export OPENAI_API_KEY='your-api-key-here'"
else
    echo "[SUCCESS] OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ ì„¤ì •ë¨"
fi

# ìƒ˜í”Œ ë°ì´í„° ìƒì„±
echo "[INFO] ìƒ˜í”Œ ë°ì´í„° íŒŒì¼ ìƒì„± ì¤‘..."

# CSV ìƒ˜í”Œ ë°ì´í„°
cat > sample_sales_data.csv << 'EOF'
country,revenue,quarter,product_category
United States,5000,Q1,Electronics
United Kingdom,3200,Q1,Electronics
France,2900,Q1,Fashion
Germany,4100,Q1,Electronics
Italy,2300,Q1,Fashion
Spain,2100,Q1,Fashion
Canada,2500,Q1,Electronics
Australia,2600,Q1,Electronics
Japan,4500,Q1,Electronics
China,7000,Q1,Electronics
United States,5500,Q2,Electronics
United Kingdom,3400,Q2,Electronics
France,3100,Q2,Fashion
Germany,4300,Q2,Electronics
Italy,2500,Q2,Fashion
EOF

# ì§ì› ë°ì´í„° CSV
cat > employee_data.csv << 'EOF'
employee_id,name,department,salary,performance_score,years_experience
1,John Smith,Engineering,75000,4.2,5
2,Emma Johnson,Sales,65000,4.5,3
3,Liam Brown,Engineering,80000,4.0,7
4,Olivia Davis,Marketing,70000,4.7,4
5,William Wilson,Finance,68000,4.1,6
6,Sophia Miller,Engineering,82000,4.6,8
7,James Garcia,Sales,62000,3.9,2
8,Isabella Martinez,Marketing,72000,4.4,5
9,Benjamin Anderson,Finance,71000,4.3,7
10,Mia Taylor,Engineering,85000,4.8,9
EOF

# ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
cat > test_basic_functionality.py << 'EOF'
#!/usr/bin/env python3
"""
PandasAI ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import sys
import pandas as pd

# OpenAI API í‚¤ í™•ì¸
if not os.getenv('OPENAI_API_KEY'):
    print("âš ï¸  OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("ì‹¤ì œ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ì„œëŠ” API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    print("export OPENAI_API_KEY='your-api-key-here'")
    sys.exit(1)

try:
    import pandasai as pai
    from pandasai_openai.openai import OpenAI
    print("âœ… PandasAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ì ¸ì˜¤ê¸° ì„±ê³µ")
except ImportError as e:
    print(f"âŒ PandasAI ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
    sys.exit(1)

def test_basic_dataframe():
    """ê¸°ë³¸ DataFrame ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª ê¸°ë³¸ DataFrame ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
    
    # LLM ì„¤ì •
    llm = OpenAI()
    pai.config.set({"llm": llm})
    
    # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    df = pai.DataFrame({
        "country": ["United States", "United Kingdom", "France", "Germany", "Italy"],
        "revenue": [5000, 3200, 2900, 4100, 2300]
    })
    
    print("ğŸ“Š ìƒ˜í”Œ ë°ì´í„°:")
    print(df.head())
    
    try:
        # ê°„ë‹¨í•œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
        result = df.chat('Which country has the highest revenue?')
        print(f"ğŸ” ì§ˆë¬¸: Which country has the highest revenue?")
        print(f"ğŸ’¬ ë‹µë³€: {result}")
        return True
    except Exception as e:
        print(f"âŒ ê¸°ë³¸ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_csv_loading():
    """CSV íŒŒì¼ ë¡œë”© í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª CSV íŒŒì¼ ë¡œë”© í…ŒìŠ¤íŠ¸")
    
    try:
        # CSV íŒŒì¼ ë¡œë“œ
        df = pai.read_csv('sample_sales_data.csv')
        print("ğŸ“„ CSV íŒŒì¼ ë¡œë“œ ì„±ê³µ")
        print(f"ë°ì´í„° í˜•íƒœ: {df.shape}")
        print(df.head())
        
        # CSV ë°ì´í„°ë¡œ ì§ˆë¬¸
        result = df.chat('What is the total revenue across all countries?')
        print(f"ğŸ” ì§ˆë¬¸: What is the total revenue across all countries?")
        print(f"ğŸ’¬ ë‹µë³€: {result}")
        return True
    except Exception as e:
        print(f"âŒ CSV í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_multiple_dataframes():
    """ë‹¤ì¤‘ DataFrame í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª ë‹¤ì¤‘ DataFrame í…ŒìŠ¤íŠ¸")
    
    try:
        # ì§ì› ë°ì´í„° ë¡œë“œ
        employees_df = pai.read_csv('employee_data.csv')
        
        # ë¶€ì„œë³„ ê¸‰ì—¬ ë°ì´í„° ìƒì„±
        dept_budget = pai.DataFrame({
            'department': ['Engineering', 'Sales', 'Marketing', 'Finance'],
            'budget': [500000, 300000, 250000, 200000]
        })
        
        print("ğŸ‘¥ ì§ì› ë°ì´í„°:")
        print(employees_df.head())
        print("\nğŸ’° ë¶€ì„œ ì˜ˆì‚° ë°ì´í„°:")
        print(dept_budget.head())
        
        # ë‹¤ì¤‘ DataFrame ì§ˆì˜
        result = pai.chat(
            "Which department has the best budget utilization (budget vs total salaries)?",
            employees_df,
            dept_budget
        )
        print(f"ğŸ” ì§ˆë¬¸: Which department has the best budget utilization?")
        print(f"ğŸ’¬ ë‹µë³€: {result}")
        return True
    except Exception as e:
        print(f"âŒ ë‹¤ì¤‘ DataFrame í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

if __name__ == "__main__":
    print("ğŸš€ PandasAI ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    tests = [
        test_basic_dataframe,
        test_csv_loading,
        test_multiple_dataframes
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        try:
            if test():
                passed += 1
                print("âœ… í…ŒìŠ¤íŠ¸ í†µê³¼")
            else:
                print("âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
    
    print("\n" + "=" * 50)
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼: {passed}/{total} í†µê³¼")
    
    if passed == total:
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print("âš ï¸  ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
EOF

# Jupyter ë…¸íŠ¸ë¶ ìƒ˜í”Œ ìƒì„±
cat > pandasai_tutorial.ipynb << 'EOF'
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PandasAI íŠœí† ë¦¬ì–¼ ë…¸íŠ¸ë¶\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ PandasAIì˜ ê¸°ë³¸ ê¸°ëŠ¥ì„ ë‹¨ê³„ë³„ë¡œ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ì ¸ì˜¤ê¸°\n",
    "import pandasai as pai\n",
    "from pandasai_openai.openai import OpenAI\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM ì„¤ì •\n",
    "llm = OpenAI()  # API í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ ë¡œë“œ\n",
    "pai.config.set({\"llm\": llm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒ˜í”Œ ë°ì´í„° ìƒì„±\n",
    "df = pai.DataFrame({\n",
    "    \"country\": [\"United States\", \"United Kingdom\", \"France\", \"Germany\", \"Italy\"],\n",
    "    \"revenue\": [5000, 3200, 2900, 4100, 2300]\n",
    "})\n",
    "\n",
    "print(\"ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìì—°ì–´ ì§ˆë¬¸ ì˜ˆì œ\n",
    "result = df.chat('Which are the top 3 countries by revenue?')\n",
    "print(f\"ë‹µë³€: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™” ì˜ˆì œ\n",
    "df.chat('Create a bar chart showing revenue by country')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
EOF

# Docker í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (ì„ íƒì‚¬í•­)
cat > test_docker_sandbox.py << 'EOF'
#!/usr/bin/env python3
"""
PandasAI Docker ìƒŒë“œë°•ìŠ¤ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import sys

def test_docker_availability():
    """Docker ì„¤ì¹˜ í™•ì¸"""
    import subprocess
    try:
        result = subprocess.run(['docker', '--version'], capture_output=True, text=True)
        if result.returncode == 0:
            print(f"âœ… Docker ì„¤ì¹˜ë¨: {result.stdout.strip()}")
            return True
        else:
            print("âŒ Dockerê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì‹¤í–‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return False
    except FileNotFoundError:
        print("âŒ Dockerê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False

def test_docker_sandbox():
    """Docker ìƒŒë“œë°•ìŠ¤ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    if not test_docker_availability():
        return False
    
    try:
        import pandasai as pai
        from pandasai_docker import DockerSandbox
        from pandasai_openai.openai import OpenAI
        
        print("ğŸ³ Docker ìƒŒë“œë°•ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        # ìƒŒë“œë°•ìŠ¤ ì´ˆê¸°í™”
        sandbox = DockerSandbox()
        sandbox.start()
        
        try:
            # LLM ì„¤ì •
            llm = OpenAI()
            pai.config.set({"llm": llm})
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„°
            df = pai.DataFrame({
                "category": ["A", "B", "C"],
                "values": [10, 20, 30]
            })
            
            # ìƒŒë“œë°•ìŠ¤ì—ì„œ ì‹¤í–‰
            result = pai.chat(
                "What is the sum of all values?",
                df,
                sandbox=sandbox
            )
            
            print(f"ğŸ” ì§ˆë¬¸: What is the sum of all values?")
            print(f"ğŸ’¬ ë‹µë³€: {result}")
            print("âœ… Docker ìƒŒë“œë°•ìŠ¤ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            return True
            
        finally:
            sandbox.stop()
            
    except ImportError:
        print("âŒ pandasai-docker íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("pip install pandasai-docker ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
        return False
    except Exception as e:
        print(f"âŒ Docker ìƒŒë“œë°•ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

if __name__ == "__main__":
    print("ğŸ³ Docker ìƒŒë“œë°•ìŠ¤ í…ŒìŠ¤íŠ¸")
    print("=" * 40)
    
    if not os.getenv('OPENAI_API_KEY'):
        print("âš ï¸  OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    if test_docker_sandbox():
        print("ğŸ‰ Docker ìƒŒë“œë°•ìŠ¤ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤!")
    else:
        print("âŒ Docker ìƒŒë“œë°•ìŠ¤ í…ŒìŠ¤íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
EOF

# ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬
chmod +x test_basic_functionality.py
chmod +x test_docker_sandbox.py

# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´ ëª¨ìŒ ìƒì„±
cat > quick_test_commands.txt << 'EOF'
# PandasAI ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´ ëª¨ìŒ

## ê¸°ë³¸ ì„¤ì •
source venv/bin/activate  # ê°€ìƒí™˜ê²½ í™œì„±í™”

## Python í…ŒìŠ¤íŠ¸
python test_basic_functionality.py  # ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
python test_docker_sandbox.py       # Docker ìƒŒë“œë°•ìŠ¤ í…ŒìŠ¤íŠ¸

## Jupyter ë…¸íŠ¸ë¶ ì‹¤í–‰
jupyter notebook pandasai_tutorial.ipynb

## íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸
pip list | grep pandas
pip show pandasai

## ëŒ€í™”í˜• Pythonìœ¼ë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
python3 -c "
import pandasai as pai
print('PandasAI ë²„ì „:', pai.__version__)
print('ì„¤ì¹˜ ì„±ê³µ!')
"

## CSV ë°ì´í„° í™•ì¸
head -5 sample_sales_data.csv
head -5 employee_data.csv

## í™˜ê²½ë³€ìˆ˜ í™•ì¸
echo $OPENAI_API_KEY | cut -c1-10  # API í‚¤ ì• 10ìë¦¬ë§Œ í‘œì‹œ
EOF

# í™˜ê²½ ì •ë³´ ì €ì¥
cat > test_environment_info.txt << EOF
PandasAI í…ŒìŠ¤íŠ¸ í™˜ê²½ ì •ë³´
========================

ìƒì„± ì‹œê°„: $(date)
Python ë²„ì „: $(python3 --version)
pip ë²„ì „: $(pip3 --version)
í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬: $TEST_DIR
ê°€ìƒí™˜ê²½: $TEST_DIR/venv

ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€:
$(pip list | grep -E "(pandas|numpy|matplotlib|seaborn|plotly)")

ì‹œìŠ¤í…œ ì •ë³´:
OS: $(uname -s)
ì•„í‚¤í…ì²˜: $(uname -m)
ë©”ëª¨ë¦¬: $(sysctl -n hw.memsize | awk '{print $1/1024/1024/1024 " GB"}' 2>/dev/null || echo "í™•ì¸ ë¶ˆê°€")

ìƒì„±ëœ íŒŒì¼ë“¤:
$(ls -la | grep -v "^d")
EOF

echo ""
echo "ğŸ‰ PandasAI í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì • ì™„ë£Œ!"
echo "================================="
echo ""
echo "ğŸ“ í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬: $TEST_DIR"
echo ""
echo "ğŸš€ ë‹¤ìŒ ë‹¨ê³„:"
echo "1. cd $TEST_DIR"
echo "2. source venv/bin/activate  # ê°€ìƒí™˜ê²½ í™œì„±í™”"
echo "3. export OPENAI_API_KEY='your-api-key-here'  # API í‚¤ ì„¤ì •"
echo "4. python test_basic_functionality.py  # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"
echo ""
echo "ğŸ“‹ ìƒì„±ëœ ìœ ìš©í•œ íŒŒì¼ë“¤:"
echo "- test_basic_functionality.py: ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"
echo "- test_docker_sandbox.py: Docker ìƒŒë“œë°•ìŠ¤ í…ŒìŠ¤íŠ¸"
echo "- pandasai_tutorial.ipynb: Jupyter ë…¸íŠ¸ë¶ íŠœí† ë¦¬ì–¼"
echo "- sample_sales_data.csv: ìƒ˜í”Œ ë°ì´í„°"
echo "- employee_data.csv: ì§ì› ë°ì´í„° ìƒ˜í”Œ"
echo "- quick_test_commands.txt: ë¹ ë¥¸ ëª…ë ¹ì–´ ì°¸ì¡°"
echo ""
echo "ğŸ’¡ íŒ:"
echo "- OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤ (https://platform.openai.com/api-keys)"
echo "- ê°€ìƒí™˜ê²½ì„ í™œì„±í™”í•œ í›„ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”"
echo "- Jupyter ë…¸íŠ¸ë¶ìœ¼ë¡œ ì¸í„°ë™í‹°ë¸Œí•œ í•™ìŠµì´ ê°€ëŠ¥í•©ë‹ˆë‹¤"

# ì‚¬ìš©ìì—ê²Œ API í‚¤ ì„¤ì • ì•ˆë‚´
echo ""
if [ -z "$OPENAI_API_KEY" ]; then
    echo "âš ï¸  OpenAI API í‚¤ë¥¼ ì„¤ì •í•˜ê³  í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•˜ì„¸ìš”:"
    echo "export OPENAI_API_KEY='your-api-key-here'"
    echo ""
    read -p "ì§€ê¸ˆ API í‚¤ë¥¼ ì…ë ¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        echo "API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì…ë ¥ì´ ìˆ¨ê²¨ì§‘ë‹ˆë‹¤):"
        read -s API_KEY
        export OPENAI_API_KEY="$API_KEY"
        echo "API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤."
        echo ""
        echo "ğŸ§ª ê¸°ë³¸ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): "
        read -n 1 -r
        echo
        if [[ $REPLY =~ ^[Yy]$ ]]; then
            echo "í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘..."
            python test_basic_functionality.py
        fi
    else
        echo "ë‚˜ì¤‘ì— API í‚¤ë¥¼ ì„¤ì •í•œ í›„ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”."
    fi
else
    echo "âœ… API í‚¤ê°€ ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
    echo ""
    read -p "ì§€ê¸ˆ ê¸°ë³¸ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        echo "í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘..."
        python test_basic_functionality.py
    fi
fi

echo ""
echo "ğŸ¯ í…ŒìŠ¤íŠ¸ ì™„ë£Œ í›„ í•  ì¼:"
echo "1. ìƒì„±ëœ ì°¨íŠ¸ì™€ ê²°ê³¼ í™•ì¸"
echo "2. ë‹¤ë¥¸ ì§ˆë¬¸ë“¤ë¡œ ì¶”ê°€ í…ŒìŠ¤íŠ¸"
echo "3. Jupyter ë…¸íŠ¸ë¶ìœ¼ë¡œ ê³ ê¸‰ ê¸°ëŠ¥ íƒìƒ‰"
echo "4. ì‹¤ì œ ë°ì´í„°ë¡œ í”„ë¡œì íŠ¸ ì‹œì‘"
```

### ğŸ”§ zshrc Aliases ì„¤ì •

PandasAIë¥¼ ë” íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ zsh aliases:

```bash
# ~/.zshrcì— ì¶”ê°€í•  PandasAI ê´€ë ¨ aliasë“¤

# PandasAI ê¸°ë³¸ ëª…ë ¹ì–´ ë‹¨ì¶•
alias pai-env="source venv/bin/activate"
alias pai-test="python test_basic_functionality.py"
alias pai-docker="python test_docker_sandbox.py"
alias pai-notebook="jupyter notebook pandasai_tutorial.ipynb"

# ê°€ìƒí™˜ê²½ ê´€ë¦¬
alias pai-setup="python3 -m venv venv && source venv/bin/activate && pip install 'pandasai>=3.0.0b2' openai pandas matplotlib seaborn plotly"
alias pai-activate="source venv/bin/activate"
alias pai-deactivate="deactivate"

# íŒ¨í‚¤ì§€ ê´€ë¦¬
alias pai-install="pip install 'pandasai>=3.0.0b2' openai pandas matplotlib seaborn plotly numpy jupyter"
alias pai-upgrade="pip install --upgrade 'pandasai>=3.0.0b2' openai pandas"
alias pai-packages="pip list | grep -E '(pandas|numpy|matplotlib|seaborn|plotly|openai)'"

# ë°ì´í„° íŒŒì¼ ê´€ë¦¬
alias pai-data="ls -la *.csv *.json *.parquet 2>/dev/null || echo 'No data files found'"
alias pai-sample="head -5 sample_sales_data.csv && echo '---' && head -5 employee_data.csv"

# ê°œë°œ ë„êµ¬
alias pai-python="python3 -i -c 'import pandasai as pai; from pandasai_openai.openai import OpenAI; print(\"PandasAI ready!\")'"
alias pai-version="python3 -c 'import pandasai as pai; print(f\"PandasAI version: {pai.__version__}\")'"

# API í‚¤ ê´€ë¦¬
alias pai-key-check="echo \$OPENAI_API_KEY | cut -c1-10"
alias pai-key-set="echo 'export OPENAI_API_KEY=your-key-here' >> ~/.zshrc && source ~/.zshrc"

# í”„ë¡œì íŠ¸ ê´€ë¦¬
alias pai-new="mkdir pandasai-project && cd pandasai-project && pai-setup"
alias pai-clean="rm -rf __pycache__ .pytest_cache *.pyc"

# í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ ê´€ë¦¬
alias pai-test-dir="cd ~/pandasai-test-* 2>/dev/null || echo 'No test directory found'"
alias pai-find-tests="find ~ -name 'pandasai-test-*' -type d 2>/dev/null"
```

#### Aliases ì ìš© ë°©ë²•

```bash
# zshrcì— aliases ì¶”ê°€
cat >> ~/.zshrc << 'EOF'

# PandasAI Development Aliases
alias pai-env="source venv/bin/activate"
alias pai-test="python test_basic_functionality.py"
alias pai-notebook="jupyter notebook pandasai_tutorial.ipynb"
alias pai-setup="python3 -m venv venv && source venv/bin/activate && pip install 'pandasai>=3.0.0b2' openai pandas matplotlib seaborn plotly"
alias pai-python="python3 -i -c 'import pandasai as pai; from pandasai_openai.openai import OpenAI; print(\"PandasAI ready!\")'"

EOF

# ì„¤ì • ì¬ë¡œë“œ
source ~/.zshrc

# ì‚¬ìš© ì˜ˆì‹œ
pai-setup           # ìƒˆ í”„ë¡œì íŠ¸ í™˜ê²½ ì„¤ì •
pai-env             # ê°€ìƒí™˜ê²½ í™œì„±í™”
pai-test            # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pai-notebook        # Jupyter ë…¸íŠ¸ë¶ ì‹¤í–‰
```

## ê³ ê¸‰ í™œìš© ë° ìµœì í™”

### âš¡ ì„±ëŠ¥ ìµœì í™”

#### ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬
```python
import pandasai as pai
from pandasai_openai.openai import OpenAI

# ì„±ëŠ¥ ìµœì í™” ì„¤ì •
pai.config.set({
    "llm": OpenAI(model="gpt-3.5-turbo"),  # ë¹ ë¥¸ ëª¨ë¸ ì‚¬ìš©
    "enable_cache": True,  # ê²°ê³¼ ìºì‹± í™œì„±í™”
    "max_size_csv": 100_000,  # CSV ìµœëŒ€ í–‰ ìˆ˜ ì œí•œ
    "sample_size": 5000,  # ìƒ˜í”Œë§ í¬ê¸° ì„¤ì •
})

# ëŒ€ìš©ëŸ‰ ë°ì´í„° ìƒ˜í”Œë§
large_df = pai.read_csv('large_dataset.csv')
result = large_df.chat(
    "Analyze the key patterns in this dataset and provide insights",
    sample=True  # ìë™ ìƒ˜í”Œë§ í™œì„±í™”
)
```

#### ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬
```python
# ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬
def analyze_large_dataset(file_path, chunk_size=10000):
    insights = []
    
    for chunk in pd.read_csv(file_path, chunksize=chunk_size):
        df = pai.DataFrame(chunk)
        chunk_insight = df.chat(
            "Summarize the key metrics in this data chunk"
        )
        insights.append(chunk_insight)
    
    # ìµœì¢… í†µí•© ë¶„ì„
    summary = "\n".join(insights)
    return summary
```

### ğŸ”§ ì»¤ìŠ¤í„°ë§ˆì´ì§•

#### ì»¤ìŠ¤í…€ LLM ì„¤ì •
```python
# Azure OpenAI ì‚¬ìš©
from pandasai_openai.azure_openai import AzureOpenAI

azure_llm = AzureOpenAI(
    azure_endpoint="your-azure-endpoint",
    api_key="your-azure-key",
    api_version="2024-02-15-preview",
    azure_deployment="your-deployment-name"
)

pai.config.set({"llm": azure_llm})

# Claude ì‚¬ìš© (Anthropic)
from pandasai_anthropic.claude import Claude

claude_llm = Claude(
    api_key="your-anthropic-key",
    model="claude-3-sonnet-20240229"
)

pai.config.set({"llm": claude_llm})
```

#### ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì„¤ì •
```python
# ë„ë©”ì¸ íŠ¹í™” í”„ë¡¬í”„íŠ¸
custom_config = {
    "custom_head": """
    You are a financial data analyst AI. When analyzing data:
    1. Focus on business metrics and KPIs
    2. Provide actionable insights
    3. Include statistical significance when relevant
    4. Use business terminology appropriately
    """,
    "custom_instructions": """
    Always provide:
    - Executive summary
    - Key findings with numbers
    - Recommendations for action
    - Risk factors to consider
    """
}

pai.config.set(custom_config)
```

### ğŸ›¡ï¸ ë³´ì•ˆ ë° ê±°ë²„ë„ŒìŠ¤

#### ë°ì´í„° ë³´ì•ˆ ì„¤ì •
```python
# ë¯¼ê°í•œ ë°ì´í„° ë§ˆìŠ¤í‚¹
pai.config.set({
    "enable_data_masking": True,
    "sensitive_columns": ["ssn", "credit_card", "password"],
    "masking_character": "*"
})

# ì¿¼ë¦¬ ë¡œê¹… ë° ê°ì‚¬
pai.config.set({
    "enable_logging": True,
    "log_level": "INFO",
    "audit_queries": True,
    "log_file": "pandasai_audit.log"
})
```

#### ì ‘ê·¼ ê¶Œí•œ ê´€ë¦¬
```python
# ì‚¬ìš©ì ê¶Œí•œ ê¸°ë°˜ ë°ì´í„° ì ‘ê·¼
class SecurePandasAI:
    def __init__(self, user_role):
        self.user_role = user_role
        self.configure_access()
    
    def configure_access(self):
        if self.user_role == "analyst":
            self.allowed_operations = ["read", "analyze", "visualize"]
        elif self.user_role == "admin":
            self.allowed_operations = ["read", "analyze", "visualize", "export"]
        else:
            self.allowed_operations = ["read"]
    
    def secure_chat(self, query, dataframe):
        if "export" in query.lower() and "export" not in self.allowed_operations:
            return "ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤: ë°ì´í„° ë‚´ë³´ë‚´ê¸° ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤."
        
        return dataframe.chat(query)

# ì‚¬ìš© ì˜ˆì‹œ
secure_ai = SecurePandasAI("analyst")
result = secure_ai.secure_chat("Analyze sales trends", df)
```

## ë¬¸ì œí•´ê²° ë° ë””ë²„ê¹…

### ğŸ” ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°

#### API í‚¤ ê´€ë ¨ ë¬¸ì œ
```python
import os
import pandasai as pai

def check_api_setup():
    """API ì„¤ì • í™•ì¸ í•¨ìˆ˜"""
    
    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    
    # API í‚¤ í˜•ì‹ í™•ì¸
    if not api_key.startswith('sk-'):
        print("âŒ OpenAI API í‚¤ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. 'sk-'ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.")
        return False
    
    # API ì—°ê²° í…ŒìŠ¤íŠ¸
    try:
        from pandasai_openai.openai import OpenAI
        llm = OpenAI()
        pai.config.set({"llm": llm})
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
        test_df = pai.DataFrame({"test": [1, 2, 3]})
        result = test_df.chat("What is the sum of the test column?")
        print("âœ… API ì—°ê²° ì„±ê³µ")
        return True
        
    except Exception as e:
        print(f"âŒ API ì—°ê²° ì‹¤íŒ¨: {e}")
        return False

# ì„¤ì • í™•ì¸ ì‹¤í–‰
check_api_setup()
```

#### ë©”ëª¨ë¦¬ ë¶€ì¡± ë¬¸ì œ
```python
# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
import psutil
import pandas as pd

def monitor_memory_usage(func):
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°"""
    def wrapper(*args, **kwargs):
        process = psutil.Process()
        mem_before = process.memory_info().rss / 1024 / 1024  # MB
        
        result = func(*args, **kwargs)
        
        mem_after = process.memory_info().rss / 1024 / 1024  # MB
        print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {mem_before:.1f}MB â†’ {mem_after:.1f}MB (ì¦ê°€: {mem_after-mem_before:.1f}MB)")
        
        return result
    return wrapper

@monitor_memory_usage
def analyze_large_data():
    large_df = pai.read_csv('large_file.csv')
    return large_df.chat("Provide summary statistics")
```

#### ì„±ëŠ¥ ìµœì í™” ë””ë²„ê¹…
```python
import time
import logging

# ìƒì„¸ ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.DEBUG)
pai.config.set({
    "verbose": True,
    "debug": True
})

def time_analysis(query, dataframe):
    """ë¶„ì„ ì‹œê°„ ì¸¡ì •"""
    start_time = time.time()
    
    result = dataframe.chat(query)
    
    end_time = time.time()
    execution_time = end_time - start_time
    
    print(f"ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„: {execution_time:.2f}ì´ˆ")
    print(f"ê²°ê³¼: {result}")
    
    return result, execution_time

# ì‚¬ìš© ì˜ˆì‹œ
df = pai.DataFrame({"sales": range(1000), "region": ["A", "B"] * 500})
result, time_taken = time_analysis("What is the average sales by region?", df)
```

## ê²°ë¡ 

**PandasAI**ëŠ” ë°ì´í„° ë¶„ì„ì˜ ì§„ì… ì¥ë²½ì„ í¬ê²Œ ë‚®ì¶”ëŠ” í˜ì‹ ì ì¸ ë„êµ¬ì…ë‹ˆë‹¤. ë³µì¡í•œ pandas ì½”ë“œë‚˜ SQL ì¿¼ë¦¬ë¥¼ ì‘ì„±í•  í•„ìš” ì—†ì´, **ìì—°ì–´ë¡œ ì§ˆë¬¸í•˜ê¸°ë§Œ í•˜ë©´ AIê°€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µ**í•©ë‹ˆë‹¤.

### ğŸ¯ í•µì‹¬ ê°€ì¹˜ ìš”ì•½

1. **ì ‘ê·¼ì„±**: ë¹„ì „ë¬¸ê°€ë„ ì‰½ê²Œ ë°ì´í„° ë¶„ì„ ê°€ëŠ¥
2. **íš¨ìœ¨ì„±**: ë³µì¡í•œ ë¶„ì„ë„ ëª‡ ë¶„ ì•ˆì— ì™„ë£Œ
3. **ì•ˆì „ì„±**: Docker ìƒŒë“œë°•ìŠ¤ë¡œ ë³´ì•ˆ ê°•í™”
4. **í™•ì¥ì„±**: ë‹¤ì–‘í•œ LLMê³¼ ë°ì´í„° ì†ŒìŠ¤ ì§€ì›
5. **ì‹¤ìš©ì„±**: ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì œ í•´ê²°ì— ì¦‰ì‹œ í™œìš©

### ğŸš€ í™œìš© ë¶„ì•¼

- **ë¹„ì¦ˆë‹ˆìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤**: ë§¤ì¶œ, ê³ ê°, ìš´ì˜ ë°ì´í„° ë¶„ì„
- **ë°ì´í„° ê³¼í•™**: íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ ë° ê°€ì„¤ ê²€ì •
- **êµìœ¡**: ë°ì´í„° ë¶„ì„ í•™ìŠµ ë° êµìœ¡ ë„êµ¬
- **ì—°êµ¬**: ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ ë° ì¸ì‚¬ì´íŠ¸ ë°œê²¬

### ğŸ’¡ ì„±ê³µì„ ìœ„í•œ íŒ

1. **ëª…í™•í•œ ì§ˆë¬¸**: êµ¬ì²´ì ì´ê³  ëª…í™•í•œ ì§ˆë¬¸ì¼ìˆ˜ë¡ ì •í™•í•œ ë‹µë³€
2. **ë°ì´í„° í’ˆì§ˆ**: ê¹¨ë—í•˜ê³  êµ¬ì¡°í™”ëœ ë°ì´í„°ê°€ ë” ë‚˜ì€ ê²°ê³¼ ìƒì„±
3. **ë°˜ë³µì  ì ‘ê·¼**: ì²« ë²ˆì§¸ ì§ˆë¬¸ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í›„ì† ì§ˆë¬¸ ì§„í–‰
4. **ê²°ê³¼ ê²€ì¦**: AI ê²°ê³¼ë¥¼ í•­ìƒ ë¹„íŒì ìœ¼ë¡œ ê²€í† í•˜ê³  ê²€ì¦

ì§€ê¸ˆ ë°”ë¡œ [PandasAI GitHub í”„ë¡œì íŠ¸](https://github.com/sinaptik-ai/pandas-ai)ë¥¼ í™•ì¸í•˜ê³ , ì—¬ëŸ¬ë¶„ì˜ ë°ì´í„° ë¶„ì„ ì›Œí¬í”Œë¡œìš°ì— PandasAIë¥¼ ë„ì…í•´ë³´ì„¸ìš”! ğŸš€

---

**ê´€ë ¨ ë§í¬:**
- [PandasAI GitHub Repository](https://github.com/sinaptik-ai/pandas-ai)
- [ê³µì‹ ì›¹ì‚¬ì´íŠ¸](https://pandas-ai.com)
- [ê³µì‹ ë¬¸ì„œ](https://docs.pandas-ai.com)
- [OpenAI API Keys](https://platform.openai.com/api-keys)
