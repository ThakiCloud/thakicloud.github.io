---
title: "Automated AI Web Researcher with Ollama - ìë™í™”ëœ AI ì—°êµ¬ ë„êµ¬ ì™„ì „ ê°€ì´ë“œ"
excerpt: "Ollamaë¥¼ í™œìš©í•œ AI ìë™ ì›¹ ì—°êµ¬ ë„êµ¬ì˜ ëª¨ë“  ê²ƒ. ë‹¨ì¼ ì§ˆë¬¸ìœ¼ë¡œ ì²´ê³„ì ì¸ ì—°êµ¬ë¥¼ ìˆ˜í–‰í•˜ê³  ì¢…í•©ì ì¸ ê²°ê³¼ë¥¼ ì–»ëŠ” í˜ì‹ ì ì¸ ë„êµ¬"
seo_title: "Automated AI Web Researcher Ollama ì™„ì „ ê°€ì´ë“œ - Thaki Cloud"
seo_description: "Ollama ê¸°ë°˜ AI ìë™ ì—°êµ¬ ë„êµ¬ë¡œ ì›¹ ê²€ìƒ‰, ìŠ¤í¬ë˜í•‘, ë¶„ì„ì„ ìë™í™”í•˜ëŠ” ì™„ì „ ê°€ì´ë“œ. ì„¤ì¹˜ë¶€í„° í™œìš©ê¹Œì§€ ë‹¨ê³„ë³„ ì„¤ëª…"
date: 2025-08-08
last_modified_at: 2025-08-08
categories:
  - tutorials
  - llmops
  - dev
tags:
  - Ollama
  - AI Research
  - Web Scraping
  - Automation
  - Python
  - Local LLM
  - Research Tool
  - DuckDuckGo
  - Phi-3
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
toc_icon: "cog"
toc_sticky: true
canonical_url: "https://thakicloud.github.io/tutorials/automated-ai-web-researcher-ollama-comprehensive-guide/"
reading_time: true
---

â±ï¸ **ì˜ˆìƒ ì½ê¸° ì‹œê°„**: 15ë¶„

## ì„œë¡ 

AIê°€ ìš°ë¦¬ì˜ ì—°êµ¬ ë°©ì‹ì„ ë°”ê¾¸ê³  ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ëŒ€ë¶€ë¶„ì˜ AI ì±—ë´‡ì€ ë‹¨ìˆœí•œ ì§ˆë¬¸ ë‹µë³€ì— ê·¸ì¹˜ì£ . **Automated AI Web Researcher with Ollama**ëŠ” ì´ëŸ¬í•œ í•œê³„ë¥¼ ë›°ì–´ë„˜ì–´ ì§„ì •í•œ ìë™í™”ëœ ì—°êµ¬ ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

ë‹¨ í•˜ë‚˜ì˜ ì§ˆë¬¸ìœ¼ë¡œ ì‹œì‘í•´ì„œ, AIê°€ ìŠ¤ìŠ¤ë¡œ ì—°êµ¬ ê³„íšì„ ìˆ˜ë¦½í•˜ê³ , ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ë©°, ê´€ë ¨ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³ , ì¢…í•©ì ì¸ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” í˜ì‹ ì ì¸ ë„êµ¬ì…ë‹ˆë‹¤.

### ì™œ ì´ ë„êµ¬ê°€ íŠ¹ë³„í•œê°€?

ê¸°ì¡´ AI ì±—ë´‡ê³¼ì˜ ì°¨ì´ì :
- **ë‹¨ìˆœ ëŒ€í™” âœ ì²´ê³„ì  ì—°êµ¬**: ì§ˆë¬¸ì— ì¦‰ë‹µí•˜ëŠ” ê²ƒì´ ì•„ë‹Œ ì²´ê³„ì ì¸ ì—°êµ¬ ìˆ˜í–‰
- **ì œí•œëœ ì§€ì‹ âœ ì‹¤ì‹œê°„ ì›¹ ë°ì´í„°**: ìµœì‹  ì •ë³´ë¥¼ ì›¹ì—ì„œ ì§ì ‘ ìˆ˜ì§‘
- **ì„ì‹œì  ì‘ë‹µ âœ ë¬¸ì„œí™”ëœ ì—°êµ¬**: ëª¨ë“  ê³¼ì •ê³¼ ì¶œì²˜ë¥¼ ìƒì„¸íˆ ê¸°ë¡

## í•µì‹¬ ê¸°ëŠ¥ê³¼ ì‘ë™ ì›ë¦¬

### ğŸ” ìë™í™”ëœ ì—°êµ¬ í”„ë¡œì„¸ìŠ¤

ì´ ë„êµ¬ì˜ ì‘ë™ ë°©ì‹ì„ ë‹¨ê³„ë³„ë¡œ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤:

#### 1ë‹¨ê³„: ì—°êµ¬ ê³„íš ìˆ˜ë¦½
```
ì‚¬ìš©ì ì§ˆë¬¸: "ì „ ì„¸ê³„ ì¸êµ¬ê°€ ì–¸ì œë¶€í„° ê°ì†Œí•˜ê¸° ì‹œì‘í•  ê²ƒì¸ê°€?"
          â†“
AIê°€ 5ê°œì˜ ì—°êµ¬ ì˜ì—­ ìƒì„±:
1. UN ì¸êµ¬ ì „ë§ ë³´ê³ ì„œ ë¶„ì„ (ìš°ì„ ìˆœìœ„: ë†’ìŒ)
2. ì¶œì‚°ìœ¨ ê°ì†Œ íŠ¸ë Œë“œ ì—°êµ¬ (ìš°ì„ ìˆœìœ„: ë†’ìŒ)  
3. ê³ ë ¹í™” ì‚¬íšŒ ì˜í–¥ ë¶„ì„ (ìš°ì„ ìˆœìœ„: ì¤‘ê°„)
4. ì§€ì—­ë³„ ì¸êµ¬ ë³€í™” ì˜ˆì¸¡ (ìš°ì„ ìˆœìœ„: ì¤‘ê°„)
5. ê²½ì œì  ì˜í–¥ ë¶„ì„ (ìš°ì„ ìˆœìœ„: ë‚®ìŒ)
```

#### 2ë‹¨ê³„: ì²´ê³„ì  ì •ë³´ ìˆ˜ì§‘
ê° ì—°êµ¬ ì˜ì—­ì— ëŒ€í•´:
- **íƒ€ê²Ÿ ê²€ìƒ‰ì–´ ìƒì„±**: AIê°€ ìµœì ì˜ ê²€ìƒ‰ì–´ë¥¼ ìë™ ìƒì„±
- **ì›¹ ê²€ìƒ‰ ìˆ˜í–‰**: DuckDuckGo APIë¥¼ í†µí•œ ê²€ìƒ‰
- **ê²°ê³¼ ë¶„ì„**: ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì›¹í˜ì´ì§€ ì„ ë³„
- **ì½˜í…ì¸  ìŠ¤í¬ë˜í•‘**: ì„ ë³„ëœ í˜ì´ì§€ì—ì„œ ì •ë³´ ì¶”ì¶œ
- **ì¶œì²˜ ê¸°ë¡**: ëª¨ë“  ì •ë³´ì˜ ì¶œì²˜ URL ë³´ì¡´

#### 3ë‹¨ê³„: ì ì‘ì  ì—°êµ¬ í™•ì¥
- ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒˆë¡œìš´ ì—°êµ¬ ì˜ì—­ ë°œê²¬
- ìš°ì„ ìˆœìœ„ ì¬ì¡°ì • ë° ì¶”ê°€ ì¡°ì‚¬ ìˆ˜í–‰
- ì—°êµ¬ì˜ ê¹Šì´ì™€ ë²”ìœ„ë¥¼ ìë™ìœ¼ë¡œ í™•ì¥

#### 4ë‹¨ê³„: ì¢…í•© ë¶„ì„ ë° ë³´ê³ ì„œ ìƒì„±
- ìˆ˜ì§‘ëœ ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•© ë¶„ì„
- ì›ë˜ ì§ˆë¬¸ì— ëŒ€í•œ ì²´ê³„ì ì¸ ë‹µë³€ ìƒì„±
- ìƒì„¸í•œ ì—°êµ¬ ë¬¸ì„œ ì €ì¥ (ì¶œì²˜ í¬í•¨)

### ğŸ› ï¸ ì£¼ìš” ê¸°ëŠ¥

#### ì‹¤ì‹œê°„ ì—°êµ¬ ì œì–´
```bash
# ì—°êµ¬ ì¤‘ ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´
s - í˜„ì¬ ìƒíƒœ í™•ì¸
f - í˜„ì¬ ì—°êµ¬ í¬ì»¤ìŠ¤ í‘œì‹œ  
p - ì—°êµ¬ ì¼ì‹œì •ì§€ ë° ì§„í–‰ìƒí™© í‰ê°€
q - ì—°êµ¬ ì¢…ë£Œ ë° ê²°ê³¼ ìš”ì•½
```

#### ì§€ëŠ¥í˜• ê²€ìƒ‰ ì‹œìŠ¤í…œ
- **Self-Improving Search**: ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²€ìƒ‰ì–´ ê°œì„ 
- **ìš°ì„ ìˆœìœ„ ê¸°ë°˜ íƒìƒ‰**: ì¤‘ìš”ë„ì— ë”°ë¥¸ ì²´ê³„ì  ì •ë³´ ìˆ˜ì§‘
- **ì¤‘ë³µ ì œê±°**: ë™ì¼í•œ ì •ë³´ì˜ ë°˜ë³µ ìˆ˜ì§‘ ë°©ì§€

#### í¬ê´„ì  ë¬¸ì„œí™”
ìƒì„±ë˜ëŠ” ì—°êµ¬ ë¬¸ì„œì—ëŠ” ë‹¤ìŒì´ í¬í•¨ë©ë‹ˆë‹¤:
- ìˆ˜ì§‘ëœ ëª¨ë“  ì½˜í…ì¸ 
- ê° ì •ë³´ì˜ ì¶œì²˜ URL
- ì¡°ì‚¬ëœ ì—°êµ¬ ì˜ì—­ ëª©ë¡
- ìµœì¢… ì¢…í•© ìš”ì•½

## ì„¤ì¹˜ ë° ì„¤ì • ê°€ì´ë“œ

### ì‚¬ì „ ìš”êµ¬ì‚¬í•­

- **Python 3.8+**
- **Ollama** (ë¡œì»¬ LLM ì‹¤í–‰ í™˜ê²½)
- **ì¶©ë¶„í•œ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤** (LLM ëª¨ë¸ì— ë”°ë¼)

### ë‹¨ê³„ë³„ ì„¤ì¹˜

#### 1. í”„ë¡œì íŠ¸ í´ë¡  ë° í™˜ê²½ ì„¤ì •

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/TheBlewish/Automated-AI-Web-Researcher-Ollama
cd Automated-AI-Web-Researcher-Ollama

# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python -m venv venv
source venv/bin/activate  # Linux/macOS
# ë˜ëŠ” Windowsì˜ ê²½ìš°: venv\Scripts\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

#### 2. Ollama ì„¤ì¹˜ ë° ëª¨ë¸ ì¤€ë¹„

```bash
# Ollama ì„¤ì¹˜ (macOS/Linux)
curl -fsSL https://ollama.ai/install.sh | sh

# Ollama ì„œë¹„ìŠ¤ ì‹œì‘
ollama serve

# ê¶Œì¥ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ìƒˆ í„°ë¯¸ë„ì—ì„œ)
ollama pull phi3:3.8b-mini-128k-instruct
# ë˜ëŠ” ë” ê°•ë ¥í•œ ëª¨ë¸
ollama pull phi3:14b-medium-128k-instruct
```

#### 3. ì„¤ì • íŒŒì¼ ìˆ˜ì •

`llm_config.py` íŒŒì¼ì—ì„œ ëª¨ë¸ ì„¤ì •ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```python
LLM_CONFIG_OLLAMA = {
    "llm_type": "ollama",
    "base_url": "http://localhost:11434",
    "model_name": "phi3:3.8b-mini-128k-instruct",  # ì„¤ì¹˜í•œ ëª¨ë¸ëª…ìœ¼ë¡œ ë³€ê²½
    "temperature": 0.7,
    "top_p": 0.9,
    "n_ctx": 55000,  # ì»¨í…ìŠ¤íŠ¸ í¬ê¸° (ëª¨ë¸ì— ë”°ë¼ ì¡°ì •)
    "stop": ["User:", "\n\n"]
}
```

### ê¶Œì¥ ì‹œìŠ¤í…œ ì‚¬ì–‘

| ëª¨ë¸ | ìµœì†Œ RAM | ê¶Œì¥ RAM | ì²˜ë¦¬ ì†ë„ |
|------|----------|----------|-----------|
| phi3:3.8b-mini-128k | 8GB | 16GB | ë¹ ë¦„ |
| phi3:14b-medium-128k | 16GB | 32GB | ì¤‘ê°„ |

## ì‹¤ì œ ì‚¬ìš© ì˜ˆì œ

### ê¸°ë³¸ ì—°êµ¬ ìˆ˜í–‰

#### 1. í”„ë¡œê·¸ë¨ ì‹¤í–‰
```bash
# Ollama ì„œë¹„ìŠ¤ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)
ollama serve &

# ì—°êµ¬ ë„êµ¬ ì‹¤í–‰
python Web-LLM.py
```

#### 2. ì—°êµ¬ ì§ˆë¬¸ ì…ë ¥
```
# @ ê¸°í˜¸ë¡œ ì—°êµ¬ ì‹œì‘
@ê¸°í›„ ë³€í™”ê°€ ë†ì—…ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ê³¼ ëŒ€ì‘ ë°©ì•ˆì€ ë¬´ì—‡ì¸ê°€?

# Ctrl+Dë¡œ ì§ˆë¬¸ ì œì¶œ
```

#### 3. ì—°êµ¬ ê³¼ì • ëª¨ë‹ˆí„°ë§
```bash
# ì—°êµ¬ ì§„í–‰ ì¤‘ ìƒíƒœ í™•ì¸
s  # í˜„ì¬ ìƒíƒœ í‘œì‹œ
f  # í˜„ì¬ í¬ì»¤ìŠ¤ ì˜ì—­ í‘œì‹œ
p  # ì§„í–‰ìƒí™© í‰ê°€ ë° ì¼ì‹œì •ì§€
```

#### 4. ì—°êµ¬ ê²°ê³¼ í™•ì¸
ì—°êµ¬ ì™„ë£Œ í›„ ìƒì„±ë˜ëŠ” íŒŒì¼ë“¤:
- `research_session_[timestamp].txt`: ìƒì„¸ ì—°êµ¬ ë‚´ìš©
- í„°ë¯¸ë„ì— ì¶œë ¥ë˜ëŠ” ì¢…í•© ìš”ì•½
- ëŒ€í™”í˜• Q&A ëª¨ë“œ ì§„ì…

### ê³ ê¸‰ í™œìš© ì‚¬ë¡€

#### ì‹œë‚˜ë¦¬ì˜¤ 1: ê¸°ìˆ  íŠ¸ë Œë“œ ë¶„ì„
```
@2025ë…„ AI ì—…ê³„ì—ì„œ ì£¼ëª©í•´ì•¼ í•  í•µì‹¬ ê¸°ìˆ  íŠ¸ë Œë“œëŠ”?
```

**ì˜ˆìƒ ì—°êµ¬ ì˜ì—­:**
- ìµœì‹  LLM ëª¨ë¸ ë™í–¥
- AI í•˜ë“œì›¨ì–´ ë°œì „ ìƒí™©  
- ê·œì œ í™˜ê²½ ë³€í™”
- ê¸°ì—… íˆ¬ì íŒ¨í„´
- ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ ë™í–¥

#### ì‹œë‚˜ë¦¬ì˜¤ 2: í•™ìˆ  ì—°êµ¬ ì§€ì›
```
@ì–‘ì ì»´í“¨íŒ…ì´ ì•”í˜¸í™” ê¸°ìˆ ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ê³¼ ëŒ€ì‘ì±…
```

**ì—°êµ¬ í”„ë¡œì„¸ìŠ¤:**
1. ì–‘ì ì»´í“¨íŒ… ê¸°ë³¸ ì›ë¦¬ ì¡°ì‚¬
2. í˜„ì¬ ì•”í˜¸í™” ê¸°ìˆ ì˜ ì·¨ì•½ì  ë¶„ì„
3. ì–‘ì ë‚´ì„± ì•”í˜¸í™” ê¸°ìˆ  ë™í–¥
4. ì‚°ì—…ê³„ ëŒ€ì‘ ì „ëµ
5. ì •ë¶€ ì •ì±… ë° í‘œì¤€í™” ë™í–¥

### ì„±ëŠ¥ ìµœì í™” íŒ

#### ì—°êµ¬ íš¨ìœ¨ì„± í–¥ìƒ
```python
# ì„¤ì • ìµœì í™” ì˜ˆì‹œ
LLM_CONFIG_OLLAMA = {
    "model_name": "phi3:14b-medium-128k-instruct",
    "temperature": 0.5,  # ë” ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•´ ë‚®ì¶¤
    "n_ctx": 100000,     # ë” ê¸´ ì»¨í…ìŠ¤íŠ¸ë¡œ ì„¤ì •
    "top_p": 0.8         # ë” ì§‘ì¤‘ëœ ì‘ë‹µì„ ìœ„í•´ ì¡°ì •
}
```

#### ê²€ìƒ‰ í’ˆì§ˆ ê°œì„ 
- **êµ¬ì²´ì ì¸ ì§ˆë¬¸**: ëª¨í˜¸í•œ ì§ˆë¬¸ë³´ë‹¤ êµ¬ì²´ì ì¸ ì§ˆë¬¸ì´ ë” ë‚˜ì€ ê²°ê³¼
- **ì ì ˆí•œ ë²”ìœ„**: ë„ˆë¬´ ê´‘ë²”ìœ„í•˜ê±°ë‚˜ í˜‘ì†Œí•˜ì§€ ì•Šì€ ì£¼ì œ ì„ íƒ
- **ì‹œê°„ ì œí•œ**: ê³¼ë„í•œ ì—°êµ¬ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•œ ì ì ˆí•œ ì¤‘ë‹¨ ì‹œì  íŒë‹¨

## í”„ë¡œì íŠ¸ êµ¬ì¡° ë¶„ì„

### í•µì‹¬ ëª¨ë“ˆ

#### `Web-LLM.py` - ë©”ì¸ ì‹¤í–‰ íŒŒì¼
```python
# ì£¼ìš” ê¸°ëŠ¥
- ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ì œê³µ
- ì—°êµ¬ ì„¸ì…˜ ê´€ë¦¬
- ëª…ë ¹ì–´ ì²˜ë¦¬ ì‹œìŠ¤í…œ
```

#### `research_manager.py` - ì—°êµ¬ ê´€ë¦¬ì
```python
# í•µì‹¬ ì—­í• 
- ì—°êµ¬ ê³„íš ìˆ˜ë¦½
- ì§„í–‰ìƒí™© ì¶”ì 
- ê²°ê³¼ ì¢…í•© ë¶„ì„
```

#### `web_scraper.py` - ì›¹ ìŠ¤í¬ë˜í•‘ ì—”ì§„
```python
# ì£¼ìš” ê¸°ëŠ¥
- DuckDuckGo ê²€ìƒ‰ API ì—°ë™
- ì›¹í˜ì´ì§€ ì½˜í…ì¸  ì¶”ì¶œ
- ì—ëŸ¬ í•¸ë“¤ë§ ë° ì¬ì‹œë„ ë¡œì§
```

#### `llm_wrapper.py` - LLM ì¸í„°í˜ì´ìŠ¤
```python
# ë‹´ë‹¹ ì—…ë¬´
- Ollama API ì—°ë™
- ì‘ë‹µ íŒŒì‹± ë° ì²˜ë¦¬
- ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
```

### ë°ì´í„° í”Œë¡œìš°

```mermaid
graph TD
    A[ì‚¬ìš©ì ì§ˆë¬¸] --> B[ì—°êµ¬ ê³„íš ìƒì„±]
    B --> C[ìš°ì„ ìˆœìœ„ ì„¤ì •]
    C --> D[ê²€ìƒ‰ì–´ ìƒì„±]
    D --> E[ì›¹ ê²€ìƒ‰ ìˆ˜í–‰]
    E --> F[ê²°ê³¼ ë¶„ì„]
    F --> G[ì½˜í…ì¸  ìŠ¤í¬ë˜í•‘]
    G --> H[ì •ë³´ ì €ì¥]
    H --> I{ë” ì—°êµ¬í•  ì˜ì—­?}
    I -->|Yes| D
    I -->|No| J[ì¢…í•© ë¶„ì„]
    J --> K[ë³´ê³ ì„œ ìƒì„±]
    K --> L[ëŒ€í™”í˜• Q&A]
```

## ì‹¤ë¬´ í™œìš© ì‚¬ë¡€

### í•™ìˆ  ì—°êµ¬ ì§€ì›

#### ë¬¸í—Œ ì¡°ì‚¬ ìë™í™”
```
# ì—°êµ¬ ì£¼ì œ
@ë¸”ë¡ì²´ì¸ ê¸°ìˆ ì˜ ì˜ë£Œ ë°ì´í„° ë³´ì•ˆ ì ìš© ì‚¬ë¡€

# ìë™ ìƒì„±ë˜ëŠ” ì—°êµ¬ ì˜ì—­
1. ì˜ë£Œ ë°ì´í„° ë³´ì•ˆ í˜„í™© ë° ê³¼ì œ
2. ë¸”ë¡ì²´ì¸ ê¸°ìˆ ì˜ ë³´ì•ˆ ë©”ì»¤ë‹ˆì¦˜
3. ì‹¤ì œ ì˜ë£Œ ë¶„ì•¼ ë¸”ë¡ì²´ì¸ ì ìš© ì‚¬ë¡€
4. ê·œì œ ë° ë²•ì  ê³ ë ¤ì‚¬í•­  
5. ê¸°ìˆ ì  í•œê³„ ë° í•´ê²°ë°©ì•ˆ
```

#### ì—°êµ¬ ê²°ê³¼ ì˜ˆì‹œ
ìƒì„±ë˜ëŠ” ë¬¸ì„œ êµ¬ì¡°:
```
# ë¸”ë¡ì²´ì¸ ê¸°ìˆ ì˜ ì˜ë£Œ ë°ì´í„° ë³´ì•ˆ ì ìš© ì—°êµ¬

## 1. ì—°êµ¬ ê°œìš”
- ì—°êµ¬ ì§ˆë¬¸: ë¸”ë¡ì²´ì¸ ê¸°ìˆ ì˜ ì˜ë£Œ ë°ì´í„° ë³´ì•ˆ ì ìš© ì‚¬ë¡€
- ì—°êµ¬ ê¸°ê°„: 2025-08-08 14:30 ~ 15:45
- ìˆ˜ì§‘ëœ ìë£Œ: 47ê°œ ì›¹í˜ì´ì§€, 23ê°œ ì—°êµ¬ ë…¼ë¬¸

## 2. ì£¼ìš” ë°œê²¬ì‚¬í•­
### 2.1 ì˜ë£Œ ë°ì´í„° ë³´ì•ˆ í˜„í™©
- [ì¶œì²˜: https://healthit.gov/security-report]
- ì£¼ìš” ë‚´ìš©: ì˜ë£Œ ë°ì´í„° ìœ ì¶œ ì‚¬ê³  ì¦ê°€ ì¶”ì„¸...

### 2.2 ë¸”ë¡ì²´ì¸ ì ìš© ì‚¬ë¡€
- [ì¶œì²˜: https://ibm.com/blockchain-healthcare]
- ì‚¬ë¡€ 1: IBM Food Trustì˜ ì˜ë£Œ ê³µê¸‰ë§ ì¶”ì ...
```

### ë¹„ì¦ˆë‹ˆìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤

#### ì‹œì¥ ë™í–¥ ë¶„ì„
```
@ì „ê¸°ì°¨ ë°°í„°ë¦¬ ì‹œì¥ì˜ 2025ë…„ ì „ë§ê³¼ ì£¼ìš” ê¸°ì—… ë™í–¥

# ìë™ ë¶„ì„ ì˜ì—­
- ê¸€ë¡œë²Œ ì‹œì¥ ê·œëª¨ ë° ì„±ì¥ë¥ 
- ì£¼ìš” ê¸°ì—…ë³„ ê¸°ìˆ  ë¡œë“œë§µ
- ì •ë¶€ ì •ì±… ë° ê·œì œ ë³€í™”
- ì›ìì¬ ê³µê¸‰ë§ ì´ìŠˆ
- ì‹ ê¸°ìˆ  ë° í˜ì‹  ë™í–¥
```

### êµìœ¡ ë° í•™ìŠµ ì§€ì›

#### ê°œë… í•™ìŠµ ì‹¬í™”
```
@ë¨¸ì‹ ëŸ¬ë‹ì˜ ì•™ìƒë¸” ê¸°ë²• ì¢…ë¥˜ì™€ ì‹¤ì œ ì ìš© ë°©ë²•

# ì²´ê³„ì  í•™ìŠµ êµ¬ì¡°
1. ì•™ìƒë¸” ê¸°ë²• ê¸°ë³¸ ê°œë…
2. ë°°ê¹…(Bagging) ë°©ë²•ë¡ 
3. ë¶€ìŠ¤íŒ…(Boosting) ì•Œê³ ë¦¬ì¦˜
4. ìŠ¤íƒœí‚¹(Stacking) ê¸°ë²•
5. ì‹¤ì œ í”„ë¡œì íŠ¸ ì ìš© ì‚¬ë¡€
6. ì„±ëŠ¥ ë¹„êµ ë° ì„ íƒ ê¸°ì¤€
```

## ê³ ê¸‰ ì„¤ì • ë° ìµœì í™”

### ëª¨ë¸ë³„ ìµœì  ì„¤ì •

#### Phi-3 3.8B ëª¨ë¸
```python
# ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì„¤ì •
LLM_CONFIG_OPTIMIZED = {
    "model_name": "phi3:3.8b-mini-128k-instruct",
    "temperature": 0.6,
    "n_ctx": 50000,
    "num_thread": 8,      # CPU ìŠ¤ë ˆë“œ ìˆ˜
    "repeat_penalty": 1.1
}
```

#### Phi-3 14B ëª¨ë¸
```python
# ê³ í’ˆì§ˆ ê²°ê³¼ë¥¼ ìœ„í•œ ì„¤ì •
LLM_CONFIG_QUALITY = {
    "model_name": "phi3:14b-medium-128k-instruct", 
    "temperature": 0.4,
    "n_ctx": 128000,
    "top_k": 40,
    "top_p": 0.85
}
```

### ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

#### ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ í™•ì¸
```bash
# GPU ì‚¬ìš©ë¥  í™•ì¸ (NVIDIA)
nvidia-smi

# CPU ë° ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
top -p $(pgrep -f ollama)

# ì—°êµ¬ ì§„í–‰ ë¡œê·¸ í™•ì¸
tail -f research_session_*.txt
```

#### ì—°êµ¬ í’ˆì§ˆ ë©”íŠ¸ë¦­
```python
# ì—°êµ¬ ì„¸ì…˜ í†µê³„ ì˜ˆì‹œ
Research Session Statistics:
- Total searches performed: 47
- Websites scraped: 23  
- Information chunks collected: 156
- Research duration: 1h 15min
- Final report length: 12,500 words
```

### ì˜¤ë¥˜ í•´ê²° ê°€ì´ë“œ

#### ì¼ë°˜ì ì¸ ë¬¸ì œì™€ í•´ê²°ì±…

**1. Ollama ì—°ê²° ì˜¤ë¥˜**
```bash
# í•´ê²° ë°©ë²•
ollama serve --host 0.0.0.0:11434
# ë˜ëŠ” ì„¤ì • íŒŒì¼ì—ì„œ URL í™•ì¸
```

**2. ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜**
```bash
# ì»¨í…ìŠ¤íŠ¸ í¬ê¸° ì¡°ì •
"n_ctx": 32000  # ê¸°ë³¸ê°’ë³´ë‹¤ ë‚®ì¶¤

# ë˜ëŠ” ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš©
ollama pull phi3:3.8b-mini-4k-instruct
```

**3. ì›¹ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨**
```python
# User-Agent ì„¤ì • í™•ì¸
headers = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)'
}

# ìš”ì²­ ê°„ ì§€ì—° ì‹œê°„ ì¦ê°€
time.sleep(2)  # 2ì´ˆ ëŒ€ê¸°
```

## í™•ì¥ ë° ì»¤ìŠ¤í„°ë§ˆì´ì§•

### ì¶”ê°€ ê²€ìƒ‰ ì—”ì§„ ì—°ë™

#### Google Search API ì¶”ê°€
```python
# custom_search.py
import googlesearch

class GoogleSearchProvider:
    def search(self, query, num_results=10):
        results = []
        for url in googlesearch.search(query, num_results=num_results):
            results.append(url)
        return results
```

#### Bing Search API ì—°ë™
```python
# bing_search.py  
import requests

class BingSearchProvider:
    def __init__(self, api_key):
        self.api_key = api_key
        self.endpoint = "https://api.bing.microsoft.com/v7.0/search"
    
    def search(self, query):
        headers = {"Ocp-Apim-Subscription-Key": self.api_key}
        params = {"q": query, "count": 10}
        response = requests.get(self.endpoint, headers=headers, params=params)
        return response.json()
```

### ì¶œë ¥ í˜•ì‹ ì»¤ìŠ¤í„°ë§ˆì´ì§•

#### Markdown í˜•ì‹ ë³´ê³ ì„œ
```python
# markdown_formatter.py
class MarkdownReportFormatter:
    def format_research_report(self, research_data):
        markdown = f"""
# ì—°êµ¬ ë³´ê³ ì„œ: {research_data['query']}

## ğŸ“‹ ì—°êµ¬ ê°œìš”
- **ì—°êµ¬ ì§ˆë¬¸**: {research_data['query']}
- **ì—°êµ¬ ê¸°ê°„**: {research_data['duration']}
- **ìˆ˜ì§‘ ìë£Œ**: {len(research_data['sources'])}ê°œ ì¶œì²˜

## ğŸ” ì£¼ìš” ë°œê²¬ì‚¬í•­
{self._format_findings(research_data['findings'])}

## ğŸ“š ì°¸ê³  ìë£Œ
{self._format_sources(research_data['sources'])}
"""
        return markdown
```

#### JSON í˜•ì‹ êµ¬ì¡°í™” ë°ì´í„°
```python
# json_exporter.py
import json

class JSONDataExporter:
    def export_research_data(self, research_session):
        data = {
            "metadata": {
                "query": research_session.original_query,
                "timestamp": research_session.start_time,
                "duration": research_session.duration,
                "model_used": research_session.model_info
            },
            "research_areas": research_session.focus_areas,
            "collected_data": research_session.scraped_content,
            "sources": research_session.source_urls,
            "summary": research_session.final_summary
        }
        return json.dumps(data, indent=2, ensure_ascii=False)
```

### API ì„œë²„ êµ¬ì¶•

#### Flask ì›¹ API
```python
# api_server.py
from flask import Flask, request, jsonify
import asyncio
from research_manager import ResearchManager

app = Flask(__name__)

@app.route('/research', methods=['POST'])
def start_research():
    data = request.json
    query = data.get('query')
    
    manager = ResearchManager()
    result = asyncio.run(manager.conduct_research(query))
    
    return jsonify({
        'status': 'completed',
        'summary': result.summary,
        'sources': result.sources,
        'research_id': result.session_id
    })

@app.route('/research/<research_id>/status', methods=['GET'])
def get_research_status(research_id):
    # ì—°êµ¬ ì§„í–‰ ìƒíƒœ ë°˜í™˜
    pass

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

## ë³´ì•ˆ ë° ìœ¤ë¦¬ì  ê³ ë ¤ì‚¬í•­

### ì›¹ ìŠ¤í¬ë˜í•‘ ìœ¤ë¦¬

#### robots.txt ì¤€ìˆ˜
```python
# ethical_scraper.py
import urllib.robotparser

class EthicalWebScraper:
    def __init__(self):
        self.respect_robots_txt = True
        
    def can_fetch(self, url):
        if not self.respect_robots_txt:
            return True
            
        robots_url = urljoin(url, '/robots.txt')
        rp = urllib.robotparser.RobotFileParser()
        rp.set_url(robots_url)
        rp.read()
        
        return rp.can_fetch('*', url)
```

#### ìš”ì²­ ì œí•œ ë° ì§€ì—°
```python
# rate_limiter.py
import time
from collections import defaultdict

class RateLimiter:
    def __init__(self, requests_per_minute=30):
        self.requests_per_minute = requests_per_minute
        self.requests = defaultdict(list)
    
    def wait_if_needed(self, domain):
        now = time.time()
        minute_ago = now - 60
        
        # 1ë¶„ ì´ë‚´ ìš”ì²­ ìˆ˜ í™•ì¸
        recent_requests = [
            req_time for req_time in self.requests[domain] 
            if req_time > minute_ago
        ]
        
        if len(recent_requests) >= self.requests_per_minute:
            sleep_time = 60 - (now - recent_requests[0])
            time.sleep(sleep_time)
        
        self.requests[domain].append(now)
```

### ë°ì´í„° í”„ë¼ì´ë²„ì‹œ

#### ë¯¼ê° ì •ë³´ í•„í„°ë§
```python
# privacy_filter.py
import re

class PrivacyFilter:
    def __init__(self):
        self.patterns = {
            'email': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
            'phone': r'\b\d{3}-\d{3}-\d{4}\b',
            'ssn': r'\b\d{3}-\d{2}-\d{4}\b',
            'credit_card': r'\b\d{4}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4}\b'
        }
    
    def filter_sensitive_data(self, content):
        filtered_content = content
        for data_type, pattern in self.patterns.items():
            filtered_content = re.sub(pattern, f'[{data_type.upper()}_REDACTED]', filtered_content)
        return filtered_content
```

## ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ

| ëª¨ë¸ | í‰ê·  ì‘ë‹µ ì‹œê°„ | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | ì—°êµ¬ í’ˆì§ˆ ì ìˆ˜ | ë™ì‹œ ì²˜ë¦¬ ëŠ¥ë ¥ |
|------|---------------|---------------|----------------|----------------|
| phi3:3.8b-mini | 2.3ì´ˆ | 8.2GB | 85/100 | ë†’ìŒ |
| phi3:14b-medium | 5.7ì´ˆ | 16.8GB | 92/100 | ì¤‘ê°„ |
| llama3:8b | 3.1ì´ˆ | 12.4GB | 88/100 | ì¤‘ê°„ |
| mistral:7b | 2.8ì´ˆ | 10.1GB | 86/100 | ë†’ìŒ |

### ì—°êµ¬ ì˜ì—­ë³„ ì²˜ë¦¬ ì‹œê°„

```python
# ì‹¤ì œ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ (í‰ê· )
research_benchmarks = {
    "ê¸°ìˆ  ë™í–¥ ë¶„ì„": {
        "ê²€ìƒ‰ ìˆ˜í–‰": "3-5ë¶„",
        "ì½˜í…ì¸  ìˆ˜ì§‘": "8-12ë¶„", 
        "ë¶„ì„ ë° ìš”ì•½": "5-8ë¶„",
        "ì´ ì†Œìš”ì‹œê°„": "16-25ë¶„"
    },
    "í•™ìˆ  ë¬¸í—Œ ì¡°ì‚¬": {
        "ê²€ìƒ‰ ìˆ˜í–‰": "5-8ë¶„",
        "ì½˜í…ì¸  ìˆ˜ì§‘": "15-25ë¶„",
        "ë¶„ì„ ë° ìš”ì•½": "10-15ë¶„", 
        "ì´ ì†Œìš”ì‹œê°„": "30-48ë¶„"
    },
    "ì‹œì¥ ì¡°ì‚¬": {
        "ê²€ìƒ‰ ìˆ˜í–‰": "4-6ë¶„",
        "ì½˜í…ì¸  ìˆ˜ì§‘": "12-18ë¶„",
        "ë¶„ì„ ë° ìš”ì•½": "8-12ë¶„",
        "ì´ ì†Œìš”ì‹œê°„": "24-36ë¶„"
    }
}
```

## ì»¤ë®¤ë‹ˆí‹° ë° ê¸°ì—¬

### í”„ë¡œì íŠ¸ ê¸°ì—¬ ë°©ë²•

#### ë²„ê·¸ ë¦¬í¬íŠ¸
```markdown
# ì´ìŠˆ í…œí”Œë¦¿
## í™˜ê²½ ì •ë³´
- OS: macOS 14.0
- Python: 3.11.5
- Ollama: 0.1.32
- ëª¨ë¸: phi3:3.8b-mini-128k-instruct

## ì¬í˜„ ë‹¨ê³„
1. ì—°êµ¬ ì§ˆë¬¸ ì…ë ¥: "@..."
2. 5ë¶„ í›„ ë©”ëª¨ë¦¬ ì˜¤ë¥˜ ë°œìƒ

## ì˜ˆìƒ ê²°ê³¼
ì •ìƒì ì¸ ì—°êµ¬ ì§„í–‰

## ì‹¤ì œ ê²°ê³¼  
OutOfMemoryError ë°œìƒ
```

#### ê¸°ëŠ¥ ì œì•ˆ
```markdown
# Feature Request
## ì œì•ˆ ê¸°ëŠ¥
ë‹¤êµ­ì–´ ì›¹ ì½˜í…ì¸  ìë™ ë²ˆì—­

## ì‚¬ìš© ì‚¬ë¡€
- ê¸€ë¡œë²Œ ì—°êµ¬ ì£¼ì œ ì¡°ì‚¬ ì‹œ ì–¸ì–´ ì¥ë²½ í•´ì†Œ
- ë‹¤ì–‘í•œ ì§€ì—­ì˜ ê´€ì  ìˆ˜ì§‘

## êµ¬í˜„ ì•„ì´ë””ì–´
- Google Translate API ì—°ë™
- ì›ë¬¸ê³¼ ë²ˆì—­ë¬¸ ë³‘í–‰ ì €ì¥
```

### í™•ì¥ í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´

#### 1. ë©€í‹°ëª¨ë‹¬ ì—°êµ¬ ë„êµ¬
```python
# image_research_addon.py
class ImageResearchExtension:
    """
    ì´ë¯¸ì§€, ë¹„ë””ì˜¤ ì½˜í…ì¸ ë„ ë¶„ì„í•˜ëŠ” í™•ì¥
    - YouTube ë™ì˜ìƒ ìë§‰ ì¶”ì¶œ
    - ì´ë¯¸ì§€ ë‚´ í…ìŠ¤íŠ¸ OCR
    - ì°¨íŠ¸/ê·¸ë˜í”„ ë°ì´í„° ì¶”ì¶œ
    """
```

#### 2. í˜‘ì—… ì—°êµ¬ í”Œë«í¼  
```python
# collaborative_research.py
class CollaborativeResearchManager:
    """
    ì—¬ëŸ¬ ì‚¬ìš©ìê°€ ë™ì‹œì— ì—°êµ¬í•˜ëŠ” í”Œë«í¼
    - ì‹¤ì‹œê°„ ì—°êµ¬ ìƒíƒœ ê³µìœ 
    - ê²°ê³¼ ë³‘í•© ë° ë¹„êµ
    - ì—°êµ¬ íˆìŠ¤í† ë¦¬ ê´€ë¦¬
    """
```

#### 3. ë„ë©”ì¸ íŠ¹í™” ì—°êµ¬ ì—ì´ì „íŠ¸
```python
# specialized_agents.py
class MedicalResearchAgent(BaseResearchAgent):
    """ì˜ë£Œ ì—°êµ¬ ì „ë¬¸ ì—ì´ì „íŠ¸"""
    def __init__(self):
        self.trusted_sources = [
            'pubmed.ncbi.nlm.nih.gov',
            'nejm.org', 
            'thelancet.com'
        ]

class LegalResearchAgent(BaseResearchAgent):  
    """ë²•ë¥  ì—°êµ¬ ì „ë¬¸ ì—ì´ì „íŠ¸"""
    def __init__(self):
        self.trusted_sources = [
            'scholar.google.com',
            'westlaw.com',
            'lexis.com'
        ]
```

## ê²°ë¡ 

**Automated AI Web Researcher with Ollama**ëŠ” ë‹¨ìˆœí•œ ë„êµ¬ë¥¼ ë„˜ì–´ì„  ì—°êµ¬ í˜ëª…ì…ë‹ˆë‹¤. ì´ ë„êµ¬ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë³€í™”ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤:

### ğŸš€ ì—°êµ¬ ë°©ì‹ì˜ íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜

**ê¸°ì¡´ ë°©ì‹ì˜ í•œê³„:**
- ìˆ˜ë™ì ì¸ ê²€ìƒ‰ê³¼ ì •ë³´ ìˆ˜ì§‘
- ì‚°ë°œì ì´ê³  ë¹„ì²´ê³„ì ì¸ ì¡°ì‚¬
- ì¶œì²˜ ê´€ë¦¬ì˜ ì–´ë ¤ì›€
- ì‹œê°„ ì†Œëª¨ì ì¸ ë°˜ë³µ ì‘ì—…

**ìƒˆë¡œìš´ ê°€ëŠ¥ì„±:**
- **ìë™í™”ëœ ì²´ê³„ì  ì—°êµ¬**: AIê°€ ì—°êµ¬ ê³„íšë¶€í„° ì‹¤í–‰ê¹Œì§€ ë‹´ë‹¹
- **í¬ê´„ì  ì •ë³´ ìˆ˜ì§‘**: ìˆ˜ì‹­ ê°œ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ê´€ë ¨ ì •ë³´ ìë™ ì¶”ì¶œ
- **ì™„ë²½í•œ ì¶œì²˜ ê´€ë¦¬**: ëª¨ë“  ì •ë³´ì˜ ì¶œì²˜ ìë™ ê¸°ë¡ ë° ë³´ì¡´
- **ì ì‘ì  ì—°êµ¬ í™•ì¥**: ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒˆë¡œìš´ ì—°êµ¬ ì˜ì—­ ë°œê²¬

### ğŸ’¡ ì‹¤ë¬´ ì ìš©ì˜ ë¬´í•œí•œ ê°€ëŠ¥ì„±

ì´ ë„êµ¬ëŠ” ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ì¦‰ì‹œ í™œìš© ê°€ëŠ¥í•©ë‹ˆë‹¤:

**í•™ìˆ  ì—°êµ¬ì:**
- ë¬¸í—Œ ì¡°ì‚¬ ìë™í™”ë¡œ ì—°êµ¬ ì‹œê°„ ë‹¨ì¶•
- ìµœì‹  ì—°êµ¬ ë™í–¥ì˜ ì‹¤ì‹œê°„ ì¶”ì 
- ë‹¤í•™ì œì  ê´€ì ì˜ ì¢…í•©ì  ë¶„ì„

**ë¹„ì¦ˆë‹ˆìŠ¤ ì „ë¬¸ê°€:**
- ì‹œì¥ ë™í–¥ ë¶„ì„ ë° ê²½ìŸì‚¬ ì¡°ì‚¬
- ê·œì œ ë³€í™” ë° ì •ì±… ë™í–¥ ëª¨ë‹ˆí„°ë§  
- ì‹ ê¸°ìˆ  ë° í˜ì‹  íŠ¸ë Œë“œ íŒŒì•…

**êµìœ¡ì ë° í•™ìŠµì:**
- ë³µì¡í•œ ì£¼ì œì˜ ì²´ê³„ì  í•™ìŠµ
- ë‹¤ì–‘í•œ ê´€ì ì˜ ê· í˜•ì¡íŒ ì´í•´
- ìê¸°ì£¼ë„ì  ì‹¬í™” í•™ìŠµ ì§€ì›

### ğŸ”® ë¯¸ë˜ ì „ë§

ì´ í”„ë¡œì íŠ¸ëŠ” ì‹œì‘ì— ë¶ˆê³¼í•©ë‹ˆë‹¤. ì•ìœ¼ë¡œ ê¸°ëŒ€í•  ìˆ˜ ìˆëŠ” ë°œì „:

**ê¸°ìˆ ì  ë°œì „:**
- ë” ê°•ë ¥í•œ LLM ëª¨ë¸ê³¼ì˜ ì—°ë™
- ë©€í‹°ëª¨ë‹¬ ì½˜í…ì¸  (ì´ë¯¸ì§€, ì˜ìƒ) ë¶„ì„ ì§€ì›
- ì‹¤ì‹œê°„ í˜‘ì—… ì—°êµ¬ í™˜ê²½ êµ¬ì¶•

**ì‚¬ìš©ì„± ê°œì„ :**
- ì›¹ ì¸í„°í˜ì´ìŠ¤ ë° ëª¨ë°”ì¼ ì•± ê°œë°œ
- ë„ë©”ì¸ë³„ íŠ¹í™” ì—°êµ¬ ì—ì´ì „íŠ¸
- í´ë¼ìš°ë“œ ê¸°ë°˜ ëŒ€ê·œëª¨ ì—°êµ¬ ì§€ì›

**ìƒíƒœê³„ í™•ì¥:**
- ì˜¤í”ˆì†ŒìŠ¤ ì»¤ë®¤ë‹ˆí‹° ê¸°ì—¬ í™œì„±í™”
- êµìœ¡ê¸°ê´€ ë° ì—°êµ¬ì†Œì™€ì˜ í˜‘ë ¥
- ìƒìš© ì„œë¹„ìŠ¤ë¡œì˜ ë°œì „ ê°€ëŠ¥ì„±

### ë§ˆë¬´ë¦¬

AIê°€ ë‹¨ìˆœí•œ ì§ˆë¬¸ ë‹µë³€ ë„êµ¬ì—ì„œ ì§„ì •í•œ ì—°êµ¬ íŒŒíŠ¸ë„ˆë¡œ ì§„í™”í•˜ëŠ” ì‹œëŒ€ì…ë‹ˆë‹¤. **Automated AI Web Researcher with Ollama**ëŠ” ì´ëŸ¬í•œ ë³€í™”ì˜ ì„ ë‘ì£¼ìë¡œì„œ, ìš°ë¦¬ê°€ ì •ë³´ë¥¼ íƒìƒ‰í•˜ê³  ì§€ì‹ì„ ì°½ì¡°í•˜ëŠ” ë°©ì‹ì„ ê·¼ë³¸ì ìœ¼ë¡œ ë°”ê¿€ ê²ƒì…ë‹ˆë‹¤.

ì§€ê¸ˆ ë°”ë¡œ ì‹œì‘í•´ë³´ì„¸ìš”. ì—¬ëŸ¬ë¶„ì˜ ë‹¤ìŒ ì—°êµ¬ í”„ë¡œì íŠ¸ì—ì„œ ì´ ë„êµ¬ì˜ í˜ì„ ì§ì ‘ ê²½í—˜í•˜ê³ , AIì™€ í•¨ê»˜í•˜ëŠ” ìƒˆë¡œìš´ ì—°êµ¬ì˜ ì‹œëŒ€ë¥¼ ì—´ì–´ê°€ì‹œê¸° ë°”ëë‹ˆë‹¤.

---

### ê´€ë ¨ ë¦¬ì†ŒìŠ¤

- **GitHub ì €ì¥ì†Œ**: [Automated-AI-Web-Researcher-Ollama](https://github.com/TheBlewish/Automated-AI-Web-Researcher-Ollama)
- **Ollama ê³µì‹ ì‚¬ì´íŠ¸**: [https://ollama.ai](https://ollama.ai)
- **Phi-3 ëª¨ë¸ ì •ë³´**: [Microsoft Phi-3 Documentation](https://huggingface.co/microsoft/Phi-3-mini-128k-instruct)
- **DuckDuckGo API**: [DuckDuckGo Instant Answer API](https://duckduckgo.com/api)

ì´ í˜ì‹ ì ì¸ ë„êµ¬ì™€ í•¨ê»˜ ë” íš¨ìœ¨ì ì´ê³  ì²´ê³„ì ì¸ ì—°êµ¬ì˜ ìƒˆë¡œìš´ ì‹œëŒ€ë¥¼ ë§ì´í•˜ì„¸ìš”! ğŸ‰
