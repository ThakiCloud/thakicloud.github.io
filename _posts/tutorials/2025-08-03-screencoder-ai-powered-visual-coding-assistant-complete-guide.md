---
title: "ScreenCoder: AI ê¸°ë°˜ ë¹„ì£¼ì–¼ ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ ì™„ì „ ê°€ì´ë“œ"
excerpt: "ìŠ¤í¬ë¦°ìƒ·ë§Œìœ¼ë¡œ ì½”ë“œë¥¼ ìë™ ìƒì„±í•˜ëŠ” ScreenCoderì˜ ì„¤ì¹˜ë¶€í„° ê³ ê¸‰ í™œìš©ê¹Œì§€, AI ë¹„ì „ ëª¨ë¸ì„ í™œìš©í•œ í˜ì‹ ì ì¸ ê°œë°œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì™„ì „ ì •ë³µí•©ë‹ˆë‹¤."
seo_title: "ScreenCoder AI ë¹„ì£¼ì–¼ ì½”ë”© ë„êµ¬ ì™„ì „ ê°€ì´ë“œ - í™”ë©´ì—ì„œ ì½”ë“œë¡œ - Thaki Cloud"
seo_description: "ScreenCoderë¡œ ìŠ¤í¬ë¦°ìƒ·, ë””ìì¸ ëª©ì—…, UI ì´ë¯¸ì§€ì—ì„œ ìë™ìœ¼ë¡œ HTML, CSS, React, Vue ì½”ë“œë¥¼ ìƒì„±í•˜ëŠ” ë°©ë²•ê³¼ ì‹¤ë¬´ í™œìš© ì „ëµì„ ìƒì„¸ ì„¤ëª…í•©ë‹ˆë‹¤."
date: 2025-08-03
last_modified_at: 2025-08-03
categories:
  - tutorials
  - dev
tags:
  - ScreenCoder
  - AI-ì½”ë”©
  - ë¹„ì£¼ì–¼-ì½”ë”©
  - ì½”ë“œìƒì„±
  - Computer-Vision
  - UI-to-Code
  - GPT-4V
  - Claude-Vision
  - í”„ë¡ íŠ¸ì—”ë“œ
  - ìë™í™”
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
toc_icon: "cog"
toc_sticky: true
canonical_url: "https://thakicloud.github.io/tutorials/screencoder-ai-powered-visual-coding-assistant-complete-guide/"
reading_time: true
---

â±ï¸ **ì˜ˆìƒ ì½ê¸° ì‹œê°„**: 16ë¶„

## ì„œë¡ 

**ìŠ¤í¬ë¦°ìƒ·ë§Œìœ¼ë¡œ ì½”ë“œê°€ ìë™ ìƒì„±ëœë‹¤ë©´?** [ScreenCoder](https://github.com/leigest519/ScreenCoder)ëŠ” ë°”ë¡œ ê·¸ ê¿ˆì„ í˜„ì‹¤ë¡œ ë§Œë“œëŠ” ë„êµ¬ì…ë‹ˆë‹¤. AI ë¹„ì „ ëª¨ë¸ì˜ ë°œì „ìœ¼ë¡œ ì´ì œ **ë””ìì¸ ëª©ì—…, UI ìŠ¤í¬ë¦°ìƒ·, ì‹¬ì§€ì–´ ì†ìœ¼ë¡œ ê·¸ë¦° ì™€ì´ì–´í”„ë ˆì„ê¹Œì§€ë„ ì™„ì „í•œ ì½”ë“œë¡œ ë³€í™˜**í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.

ë” ì´ìƒ ë””ìì¸ì„ ë³´ê³  í”½ì…€ í¼í™íŠ¸í•˜ê²Œ ì½”ë“œë¥¼ ì§¤ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. **ScreenCoderê°€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ HTML, CSS, React, Vue, Flutter ë“± ë‹¤ì–‘í•œ í”„ë ˆì„ì›Œí¬ì˜ ì½”ë“œë¥¼ ìë™ìœ¼ë¡œ ìƒì„±**í•´ë“œë¦½ë‹ˆë‹¤.

## ScreenCoderì˜ í˜ì‹ ì  íŠ¹ì§•

### ğŸ¯ ë¹„ì£¼ì–¼ ì½”ë”©ì˜ í˜ëª…

```
ê¸°ì¡´ ê°œë°œ í”„ë¡œì„¸ìŠ¤:
ë””ìì¸ â†’ ë¶„ì„ â†’ ìˆ˜ë™ ì½”ë”© â†’ í”½ì…€ í¼í™íŠ¸ ì¡°ì •

ScreenCoder í”„ë¡œì„¸ìŠ¤:
ì´ë¯¸ì§€ â†’ AI ë¶„ì„ â†’ ìë™ ì½”ë“œ ìƒì„± â†’ ë¯¸ì„¸ ì¡°ì •
```

### ğŸ¤– ì§€ì›í•˜ëŠ” AI ëª¨ë¸ë“¤

- **GPT-4 Vision (GPT-4V)**: OpenAIì˜ ìµœì²¨ë‹¨ ë¹„ì „ ëª¨ë¸
- **Claude 3.5 Vision**: Anthropicì˜ ê³ ì„±ëŠ¥ ë¹„ì „ ì´í•´
- **LLaVA**: ì˜¤í”ˆì†ŒìŠ¤ ë¹„ì „-ì–¸ì–´ ëª¨ë¸
- **Qwen-VL**: ë‹¤êµ­ì–´ ì§€ì› ë¹„ì „ ëª¨ë¸

### ğŸ“± ë‹¤ì–‘í•œ ì¶œë ¥ í˜•ì‹

- **HTML/CSS**: ìˆœìˆ˜ ì›¹ í‘œì¤€ ì½”ë“œ
- **React**: JSX ì»´í¬ë„ŒíŠ¸ + CSS
- **Vue.js**: SFC(Single File Component)
- **Flutter**: Dart ìœ„ì ¯ ì½”ë“œ
- **SwiftUI**: iOS ë„¤ì´í‹°ë¸Œ UI
- **Tailwind CSS**: ìœ í‹¸ë¦¬í‹° í¼ìŠ¤íŠ¸ CSS

## ì„¤ì¹˜ ë° í™˜ê²½ ì„¤ì •

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

```bash
# ì§€ì› ìš´ì˜ì²´ì œ
- Windows 10/11
- macOS 11.0+
- Ubuntu 20.04+

# Python í™˜ê²½
- Python 3.8 ì´ìƒ
- pip ë˜ëŠ” conda

# ê¶Œì¥ í•˜ë“œì›¨ì–´
- RAM: 8GB ì´ìƒ (16GB ê¶Œì¥)
- GPU: CUDA ì§€ì› GPU (ì„ íƒì‚¬í•­)
- ì¸í„°ë„·: API í˜¸ì¶œìš© ì•ˆì •ì  ì—°ê²°
```

### ScreenCoder ì„¤ì¹˜

#### ë°©ë²• 1: pip ì„¤ì¹˜ (ê¶Œì¥)

```bash
# ScreenCoder ì„¤ì¹˜
pip install screencoder

# ë˜ëŠ” ê°œë°œ ë²„ì „ ì„¤ì¹˜
pip install git+https://github.com/leigest519/ScreenCoder.git

# ì„ íƒì  ì˜ì¡´ì„± ì„¤ì¹˜ (ê³ ê¸‰ ê¸°ëŠ¥ìš©)
pip install "screencoder[all]"
```

#### ë°©ë²• 2: ì†ŒìŠ¤ ì½”ë“œì—ì„œ ì„¤ì¹˜

```bash
# ë¦¬í¬ì§€í† ë¦¬ í´ë¡ 
git clone https://github.com/leigest519/ScreenCoder.git
cd ScreenCoder

# ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)
python -m venv screencoder-env
source screencoder-env/bin/activate  # Windows: screencoder-env\Scripts\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# ê°œë°œ ëª¨ë“œë¡œ ì„¤ì¹˜
pip install -e .
```

#### ë°©ë²• 3: Docker ì„¤ì¹˜

```bash
# Docker ì´ë¯¸ì§€ ë¹Œë“œ
docker build -t screencoder .

# ì»¨í…Œì´ë„ˆ ì‹¤í–‰
docker run -it --rm \
  -v $(pwd)/images:/app/images \
  -v $(pwd)/output:/app/output \
  screencoder
```

### API í‚¤ ì„¤ì •

```bash
# .env íŒŒì¼ ìƒì„±
cat > .env << EOF
# OpenAI API í‚¤ (GPT-4V ì‚¬ìš©)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API í‚¤ (Claude Vision ì‚¬ìš©)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Google API í‚¤ (Gemini Vision ì‚¬ìš©, ì„ íƒì‚¬í•­)
GOOGLE_API_KEY=your_google_api_key_here

# ë¡œì»¬ ëª¨ë¸ ì„¤ì • (ì„ íƒì‚¬í•­)
OLLAMA_HOST=http://localhost:11434
LOCAL_VISION_MODEL=llava:13b
EOF
```

### ì´ˆê¸° ì„¤ì • ë° í…ŒìŠ¤íŠ¸

```python
# config_test.py
from screencoder import ScreenCoder
from screencoder.models import GPT4Vision, ClaudeVision
import os

def test_installation():
    """ì„¤ì¹˜ í…ŒìŠ¤íŠ¸"""
    
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    openai_key = os.getenv('OPENAI_API_KEY')
    anthropic_key = os.getenv('ANTHROPIC_API_KEY')
    
    print("ğŸ”§ ScreenCoder ì„¤ì¹˜ í…ŒìŠ¤íŠ¸")
    print(f"OpenAI API í‚¤: {'âœ… ì„¤ì •ë¨' if openai_key else 'âŒ ì—†ìŒ'}")
    print(f"Anthropic API í‚¤: {'âœ… ì„¤ì •ë¨' if anthropic_key else 'âŒ ì—†ìŒ'}")
    
    # ScreenCoder ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸
    try:
        if openai_key:
            gpt4v_model = GPT4Vision(api_key=openai_key)
            screencoder_gpt = ScreenCoder(model=gpt4v_model)
            print("âœ… GPT-4V ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
        
        if anthropic_key:
            claude_model = ClaudeVision(api_key=anthropic_key)
            screencoder_claude = ScreenCoder(model=claude_model)
            print("âœ… Claude Vision ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
        
        print("ğŸ‰ ScreenCoder ì„¤ì¹˜ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì„¤ì¹˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    test_installation()
```

## ê¸°ë³¸ ì‚¬ìš©ë²•

### 1. ì²« ë²ˆì§¸ ì½”ë“œ ìƒì„±

```python
# basic_example.py
from screencoder import ScreenCoder
from screencoder.models import GPT4Vision
from screencoder.outputs import HTMLOutput, ReactOutput

async def basic_code_generation():
    """ê¸°ë³¸ ì½”ë“œ ìƒì„± ì˜ˆì œ"""
    
    # 1. ScreenCoder ì´ˆê¸°í™”
    model = GPT4Vision()
    coder = ScreenCoder(model=model)
    
    # 2. ì´ë¯¸ì§€ì—ì„œ HTML ì½”ë“œ ìƒì„±
    html_result = await coder.generate_code(
        image_path="./examples/landing_page.png",
        output_format="html",
        include_css=True,
        responsive=True
    )
    
    print("ìƒì„±ëœ HTML ì½”ë“œ:")
    print(html_result.code)
    
    # 3. íŒŒì¼ë¡œ ì €ì¥
    html_result.save("./output/landing_page.html")
    
    # 4. React ì»´í¬ë„ŒíŠ¸ ìƒì„±
    react_result = await coder.generate_code(
        image_path="./examples/landing_page.png",
        output_format="react",
        component_name="LandingPage",
        use_typescript=True
    )
    
    print("\nìƒì„±ëœ React ì»´í¬ë„ŒíŠ¸:")
    print(react_result.code)
    
    react_result.save("./output/LandingPage.tsx")

# ì‹¤í–‰
import asyncio
asyncio.run(basic_code_generation())
```

### 2. ëª…ë ¹ì¤„ ì¸í„°í˜ì´ìŠ¤ ì‚¬ìš©

```bash
# ê¸°ë³¸ HTML ìƒì„±
screencoder generate \
  --input "./designs/homepage.png" \
  --output "./output/homepage.html" \
  --format html \
  --model gpt4v

# React ì»´í¬ë„ŒíŠ¸ ìƒì„±
screencoder generate \
  --input "./designs/dashboard.png" \
  --output "./output/Dashboard.tsx" \
  --format react \
  --typescript \
  --component-name Dashboard

# ì—¬ëŸ¬ ì´ë¯¸ì§€ ë°°ì¹˜ ì²˜ë¦¬
screencoder batch \
  --input-dir "./designs/" \
  --output-dir "./output/" \
  --format vue \
  --model claude-vision

# ì‹¤ì‹œê°„ ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜ ë° ë³€í™˜
screencoder capture \
  --format react \
  --auto-save \
  --watch-clipboard
```

### 3. ê³ ê¸‰ ì„¤ì • ë° í”„ë¡¬í”„íŠ¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•

```python
# advanced_config.py
from screencoder import ScreenCoder
from screencoder.models import GPT4Vision
from screencoder.prompts import CustomPrompt

class AdvancedScreenCoder:
    def __init__(self):
        self.model = GPT4Vision(
            temperature=0.1,  # ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•´ ë‚®ì€ ê°’
            max_tokens=4000,
            timeout=30
        )
        self.coder = ScreenCoder(model=self.model)
        
    async def generate_with_custom_prompt(self, image_path, requirements):
        """ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ë¡œ ì½”ë“œ ìƒì„±"""
        
        # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ìƒì„±
        custom_prompt = CustomPrompt(
            base_instruction="""
            ì´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì •í™•í•œ ì½”ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
            ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•´ì£¼ì„¸ìš”:
            """,
            requirements=requirements,
            style_guidelines="""
            - ì‹œë§¨í‹± HTML ì‚¬ìš©
            - ì ‘ê·¼ì„±(a11y) ê³ ë ¤
            - ëª¨ë°”ì¼ í¼ìŠ¤íŠ¸ ë””ìì¸
            - BEM CSS ë°©ë²•ë¡  ì ìš©
            """,
            additional_context="""
            ì´ ì½”ë“œëŠ” í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì‚¬ìš©ë  ì˜ˆì •ì…ë‹ˆë‹¤.
            ìµœê³  í’ˆì§ˆì˜ ì½”ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
            """
        )
        
        # ì½”ë“œ ìƒì„±
        result = await self.coder.generate_code(
            image_path=image_path,
            output_format="html",
            custom_prompt=custom_prompt,
            include_comments=True,
            optimize_performance=True
        )
        
        return result
    
    async def generate_component_with_props(self, image_path, component_config):
        """Propsì™€ ìƒíƒœë¥¼ ê³ ë ¤í•œ React ì»´í¬ë„ŒíŠ¸ ìƒì„±"""
        
        react_prompt = CustomPrompt(
            base_instruction=f"""
            ì´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ {component_config['name']} React ì»´í¬ë„ŒíŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
            """,
            requirements=[
                f"TypeScript ì‚¬ìš©: {component_config.get('typescript', True)}",
                f"Props ì¸í„°í˜ì´ìŠ¤ ì •ì˜",
                f"ìƒíƒœ ê´€ë¦¬: {component_config.get('state_management', 'useState')}",
                f"ìŠ¤íƒ€ì¼ë§: {component_config.get('styling', 'CSS Modules')}",
                "ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œë”© ìƒíƒœ í¬í•¨",
                "ì ‘ê·¼ì„± ì†ì„± ì¶”ê°€",
                "ì„±ëŠ¥ ìµœì í™” (memo, useCallback ë“±)"
            ],
            additional_context=f"""
            ì»´í¬ë„ŒíŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ìš©ë„ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤:
            {component_config.get('description', '')}
            
            ì¬ì‚¬ìš©ì„±ê³¼ í™•ì¥ì„±ì„ ê³ ë ¤í•˜ì—¬ ì„¤ê³„í•´ì£¼ì„¸ìš”.
            """
        )
        
        result = await self.coder.generate_code(
            image_path=image_path,
            output_format="react",
            custom_prompt=react_prompt,
            component_name=component_config['name'],
            use_typescript=component_config.get('typescript', True)
        )
        
        return result

# ì‚¬ìš© ì˜ˆì œ
async def advanced_example():
    """ê³ ê¸‰ ê¸°ëŠ¥ ì‚¬ìš© ì˜ˆì œ"""
    
    advanced_coder = AdvancedScreenCoder()
    
    # 1. ì»¤ìŠ¤í…€ ìš”êµ¬ì‚¬í•­ìœ¼ë¡œ HTML ìƒì„±
    html_requirements = [
        "ë°˜ì‘í˜• ë””ìì¸ (ëª¨ë°”ì¼, íƒœë¸”ë¦¿, ë°ìŠ¤í¬í†±)",
        "ë‹¤í¬ëª¨ë“œ ì§€ì›",
        "ì• ë‹ˆë©”ì´ì…˜ íš¨ê³¼ í¬í•¨",
        "SEO ìµœì í™”",
        "ì›¹ í‘œì¤€ ì¤€ìˆ˜"
    ]
    
    html_result = await advanced_coder.generate_with_custom_prompt(
        image_path="./designs/landing_page.png",
        requirements=html_requirements
    )
    
    # 2. ê³ ê¸‰ React ì»´í¬ë„ŒíŠ¸ ìƒì„±
    component_config = {
        "name": "ProductCard",
        "typescript": True,
        "state_management": "useState + useContext",
        "styling": "Styled Components",
        "description": "ì „ììƒê±°ë˜ ì‚¬ì´íŠ¸ì˜ ìƒí’ˆ ì¹´ë“œ ì»´í¬ë„ŒíŠ¸"
    }
    
    react_result = await advanced_coder.generate_component_with_props(
        image_path="./designs/product_card.png",
        component_config=component_config
    )
    
    print(f"HTML ì½”ë“œ ê¸¸ì´: {len(html_result.code)} ë¬¸ì")
    print(f"React ì»´í¬ë„ŒíŠ¸ ê¸¸ì´: {len(react_result.code)} ë¬¸ì")

asyncio.run(advanced_example())
```

## ì‹¤ë¬´ í”„ë¡œì íŠ¸: ë””ìì¸ ì‹œìŠ¤í…œ ìë™ ìƒì„±

### í”„ë¡œì íŠ¸ êµ¬ì¡°

```
design_system_generator/
â”œâ”€â”€ main.py                    # ë©”ì¸ ì‹¤í–‰ íŒŒì¼
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py           # í”„ë¡œì íŠ¸ ì„¤ì •
â”‚   â””â”€â”€ prompts.py            # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸
â”œâ”€â”€ generators/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ component_generator.py # ì»´í¬ë„ŒíŠ¸ ìƒì„±ê¸°
â”‚   â”œâ”€â”€ style_generator.py     # ìŠ¤íƒ€ì¼ ìƒì„±ê¸°
â”‚   â””â”€â”€ story_generator.py     # Storybook ìŠ¤í† ë¦¬ ìƒì„±
â”œâ”€â”€ processors/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ image_processor.py     # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
â”‚   â””â”€â”€ code_optimizer.py      # ì½”ë“œ ìµœì í™”
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ file_manager.py        # íŒŒì¼ ê´€ë¦¬
â”‚   â””â”€â”€ documentation.py       # ë¬¸ì„œ ìƒì„±
â”œâ”€â”€ designs/                   # ì…ë ¥ ë””ìì¸ íŒŒì¼ë“¤
â”œâ”€â”€ output/                    # ìƒì„±ëœ ì½”ë“œ
â””â”€â”€ requirements.txt
```

### í•µì‹¬ êµ¬í˜„

```python
# main.py
import asyncio
from pathlib import Path
from generators.component_generator import ComponentGenerator
from generators.style_generator import StyleGenerator
from generators.story_generator import StoryGenerator
from processors.image_processor import ImageProcessor
from outputs.file_manager import FileManager
from outputs.documentation import DocumentationGenerator

class DesignSystemGenerator:
    def __init__(self, config):
        self.config = config
        self.image_processor = ImageProcessor()
        self.component_generator = ComponentGenerator(config)
        self.style_generator = StyleGenerator(config)
        self.story_generator = StoryGenerator(config)
        self.file_manager = FileManager(config.output_dir)
        self.doc_generator = DocumentationGenerator()
    
    async def process_design_directory(self, designs_dir):
        """ë””ìì¸ ë””ë ‰í† ë¦¬ ì „ì²´ ì²˜ë¦¬"""
        
        design_files = list(Path(designs_dir).glob("*.png")) + \
                      list(Path(designs_dir).glob("*.jpg")) + \
                      list(Path(designs_dir).glob("*.jpeg"))
        
        print(f"ğŸ¨ {len(design_files)}ê°œì˜ ë””ìì¸ íŒŒì¼ ë°œê²¬")
        
        components = []
        
        for design_file in design_files:
            try:
                print(f"ğŸ“ ì²˜ë¦¬ ì¤‘: {design_file.name}")
                
                # 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                processed_image = await self.image_processor.process(design_file)
                
                # 2. ì»´í¬ë„ŒíŠ¸ ìœ í˜• ìë™ ê°ì§€
                component_type = await self.detect_component_type(processed_image)
                
                # 3. ì»´í¬ë„ŒíŠ¸ ì½”ë“œ ìƒì„±
                component = await self.component_generator.generate(
                    image_path=processed_image.path,
                    component_type=component_type,
                    name=design_file.stem
                )
                
                # 4. ìŠ¤íƒ€ì¼ ì‹œìŠ¤í…œ ìƒì„±
                styles = await self.style_generator.generate_styles(
                    component=component,
                    design_tokens=processed_image.design_tokens
                )
                
                # 5. Storybook ìŠ¤í† ë¦¬ ìƒì„±
                story = await self.story_generator.generate_story(
                    component=component,
                    variations=processed_image.variations
                )
                
                # 6. íŒŒì¼ ì €ì¥
                saved_files = await self.file_manager.save_component(
                    component=component,
                    styles=styles,
                    story=story
                )
                
                components.append({
                    'component': component,
                    'styles': styles,
                    'story': story,
                    'files': saved_files
                })
                
                print(f"âœ… {design_file.name} ì²˜ë¦¬ ì™„ë£Œ")
                
            except Exception as e:
                print(f"âŒ {design_file.name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        # 7. í†µí•© ë¬¸ì„œ ìƒì„±
        documentation = await self.doc_generator.generate_design_system_docs(
            components=components
        )
        
        await self.file_manager.save_documentation(documentation)
        
        print(f"ğŸ‰ ë””ìì¸ ì‹œìŠ¤í…œ ìƒì„± ì™„ë£Œ! {len(components)}ê°œ ì»´í¬ë„ŒíŠ¸")
        return components
    
    async def detect_component_type(self, processed_image):
        """ì´ë¯¸ì§€ ë¶„ì„ìœ¼ë¡œ ì»´í¬ë„ŒíŠ¸ ìœ í˜• ìë™ ê°ì§€"""
        
        detection_prompt = """
        ì´ UI ë””ìì¸ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì í•©í•œ ì»´í¬ë„ŒíŠ¸ ìœ í˜•ì„ íŒë‹¨í•´ì£¼ì„¸ìš”.
        
        ê°€ëŠ¥í•œ ìœ í˜•ë“¤:
        - button: ë²„íŠ¼ í˜•íƒœì˜ UI
        - card: ì¹´ë“œ í˜•íƒœì˜ ì»¨í…Œì´ë„ˆ
        - form: í¼ ì…ë ¥ ìš”ì†Œë“¤
        - navigation: ë„¤ë¹„ê²Œì´ì…˜ ë©”ë‰´
        - header: í—¤ë”/ìƒë‹¨ ì˜ì—­
        - modal: ëª¨ë‹¬/íŒì—… ì°½
        - list: ëª©ë¡/ë¦¬ìŠ¤íŠ¸ í˜•íƒœ
        - grid: ê·¸ë¦¬ë“œ ë ˆì´ì•„ì›ƒ
        - chart: ì°¨íŠ¸/ê·¸ë˜í”„
        - other: ê¸°íƒ€
        
        ì‘ë‹µ í˜•ì‹: {"type": "ì»´í¬ë„ŒíŠ¸_ìœ í˜•", "confidence": 0.95, "description": "ìƒì„¸ ì„¤ëª…"}
        """
        
        result = await self.component_generator.model.analyze_image(
            image_path=processed_image.path,
            prompt=detection_prompt
        )
        
        return result.parsed_json
    
    async def generate_design_tokens(self, components):
        """ë””ìì¸ í† í° ìë™ ì¶”ì¶œ ë° ìƒì„±"""
        
        # ëª¨ë“  ì»´í¬ë„ŒíŠ¸ì—ì„œ ê³µí†µ ë””ìì¸ í† í° ì¶”ì¶œ
        colors = set()
        fonts = set()
        spacing = set()
        borders = set()
        shadows = set()
        
        for comp in components:
            if comp['styles'].design_tokens:
                tokens = comp['styles'].design_tokens
                colors.update(tokens.get('colors', []))
                fonts.update(tokens.get('fonts', []))
                spacing.update(tokens.get('spacing', []))
                borders.update(tokens.get('borders', []))
                shadows.update(tokens.get('shadows', []))
        
        # ë””ìì¸ í† í° ì •ë¦¬ ë° ëª…ëª…
        design_tokens = {
            'colors': self.normalize_colors(colors),
            'typography': self.normalize_fonts(fonts),
            'spacing': self.normalize_spacing(spacing),
            'borders': self.normalize_borders(borders),
            'shadows': self.normalize_shadows(shadows)
        }
        
        # CSS ì»¤ìŠ¤í…€ í”„ë¡œí¼í‹° ìƒì„±
        css_tokens = self.generate_css_tokens(design_tokens)
        
        # JavaScript í† í° ê°ì²´ ìƒì„±
        js_tokens = self.generate_js_tokens(design_tokens)
        
        return {
            'tokens': design_tokens,
            'css': css_tokens,
            'javascript': js_tokens
        }

# generators/component_generator.py
from screencoder import ScreenCoder
from screencoder.models import GPT4Vision

class ComponentGenerator:
    def __init__(self, config):
        self.config = config
        self.model = GPT4Vision(
            api_key=config.openai_api_key,
            temperature=0.1
        )
        self.screencoder = ScreenCoder(model=self.model)
    
    async def generate(self, image_path, component_type, name):
        """ì»´í¬ë„ŒíŠ¸ ìƒì„±"""
        
        # ì»´í¬ë„ŒíŠ¸ ìœ í˜•ë³„ íŠ¹í™” í”„ë¡¬í”„íŠ¸
        type_specific_prompts = {
            'button': self.get_button_prompt(),
            'card': self.get_card_prompt(),
            'form': self.get_form_prompt(),
            'navigation': self.get_navigation_prompt(),
            'modal': self.get_modal_prompt(),
            'other': self.get_generic_prompt()
        }
        
        custom_prompt = type_specific_prompts.get(
            component_type['type'], 
            self.get_generic_prompt()
        )
        
        # React ì»´í¬ë„ŒíŠ¸ ìƒì„±
        react_result = await self.screencoder.generate_code(
            image_path=image_path,
            output_format="react",
            component_name=name,
            custom_prompt=custom_prompt,
            use_typescript=True,
            include_props_interface=True,
            include_tests=True
        )
        
        # Vue ì»´í¬ë„ŒíŠ¸ë„ ìƒì„± (ì„ íƒì‚¬í•­)
        vue_result = None
        if self.config.include_vue:
            vue_result = await self.screencoder.generate_code(
                image_path=image_path,
                output_format="vue",
                component_name=name,
                custom_prompt=custom_prompt,
                use_typescript=True
            )
        
        return {
            'name': name,
            'type': component_type,
            'react': react_result,
            'vue': vue_result,
            'metadata': {
                'created_at': datetime.now().isoformat(),
                'image_source': str(image_path),
                'generator_version': self.config.version
            }
        }
    
    def get_button_prompt(self):
        """ë²„íŠ¼ ì»´í¬ë„ŒíŠ¸ ì „ìš© í”„ë¡¬í”„íŠ¸"""
        return """
        ì´ ì´ë¯¸ì§€ëŠ” ë²„íŠ¼ UI ì»´í¬ë„ŒíŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•˜ëŠ” React ì»´í¬ë„ŒíŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:
        
        í•„ìˆ˜ ê¸°ëŠ¥:
        - variant prop (primary, secondary, outline, ghost)
        - size prop (small, medium, large)
        - disabled ìƒíƒœ ì§€ì›
        - loading ìƒíƒœ ì§€ì› (ìŠ¤í”¼ë„ˆ í¬í•¨)
        - icon ì§€ì› (ì•/ë’¤ ìœ„ì¹˜)
        - ì ‘ê·¼ì„± ì†ì„± (ARIA)
        - í‚¤ë³´ë“œ ë„¤ë¹„ê²Œì´ì…˜ ì§€ì›
        
        ìŠ¤íƒ€ì¼ë§:
        - CSS-in-JS ë˜ëŠ” styled-components ì‚¬ìš©
        - í˜¸ë²„, í¬ì»¤ìŠ¤, ì•¡í‹°ë¸Œ ìƒíƒœ ì •ì˜
        - íŠ¸ëœì§€ì…˜ ì• ë‹ˆë©”ì´ì…˜
        - ë°˜ì‘í˜• ë””ìì¸
        
        Props ì¸í„°í˜ì´ìŠ¤:
        - onClick: () => void
        - variant: 'primary' | 'secondary' | 'outline' | 'ghost'
        - size: 'small' | 'medium' | 'large'
        - disabled: boolean
        - loading: boolean
        - icon: ReactNode
        - iconPosition: 'left' | 'right'
        - children: ReactNode
        """
    
    def get_card_prompt(self):
        """ì¹´ë“œ ì»´í¬ë„ŒíŠ¸ ì „ìš© í”„ë¡¬í”„íŠ¸"""
        return """
        ì´ ì´ë¯¸ì§€ëŠ” ì¹´ë“œ UI ì»´í¬ë„ŒíŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•˜ëŠ” React ì»´í¬ë„ŒíŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:
        
        í•„ìˆ˜ ê¸°ëŠ¥:
        - header, body, footer ì„¹ì…˜ ì§€ì›
        - ì´ë¯¸ì§€ ì§€ì› (ì»¤ë²„ ì´ë¯¸ì§€)
        - ê·¸ë¦¼ì/ë³´ë” ìŠ¤íƒ€ì¼ ì˜µì…˜
        - í´ë¦­ ê°€ëŠ¥í•œ ì¹´ë“œ ì§€ì›
        - ë¡œë”© ìŠ¤ì¼ˆë ˆí†¤ ìƒíƒœ
        
        ë ˆì´ì•„ì›ƒ:
        - flexbox ë˜ëŠ” grid ì‚¬ìš©
        - ë°˜ì‘í˜• ë””ìì¸
        - ë‹¤ì–‘í•œ í¬ê¸° ì§€ì›
        
        Props ì¸í„°í˜ì´ìŠ¤:
        - title: string
        - description: string
        - image: string
        - actions: ReactNode[]
        - onClick: () => void
        - loading: boolean
        - variant: 'default' | 'outlined' | 'elevated'
        """

# processors/image_processor.py
import cv2
import numpy as np
from PIL import Image, ImageEnhance
import pytesseract

class ImageProcessor:
    def __init__(self):
        self.supported_formats = ['.png', '.jpg', '.jpeg', '.bmp', '.tiff']
    
    async def process(self, image_path):
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° ë¶„ì„"""
        
        # 1. ì´ë¯¸ì§€ ë¡œë“œ ë° ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        image = Image.open(image_path)
        image_info = {
            'path': str(image_path),
            'size': image.size,
            'mode': image.mode,
            'format': image.format
        }
        
        # 2. ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ
        enhanced_image = await self.enhance_image(image)
        
        # 3. í…ìŠ¤íŠ¸ ì¶”ì¶œ (OCR)
        extracted_text = await self.extract_text(enhanced_image)
        
        # 4. ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ì¶”ì¶œ
        color_palette = await self.extract_color_palette(enhanced_image)
        
        # 5. ë ˆì´ì•„ì›ƒ ë¶„ì„
        layout_analysis = await self.analyze_layout(enhanced_image)
        
        # 6. UI ìš”ì†Œ ê°ì§€
        ui_elements = await self.detect_ui_elements(enhanced_image)
        
        # 7. ë””ìì¸ í† í° ì¶”ì¶œ
        design_tokens = await self.extract_design_tokens(
            enhanced_image, 
            color_palette, 
            extracted_text
        )
        
        return ProcessedImage(
            path=image_path,
            info=image_info,
            enhanced_image=enhanced_image,
            text=extracted_text,
            colors=color_palette,
            layout=layout_analysis,
            ui_elements=ui_elements,
            design_tokens=design_tokens
        )
    
    async def enhance_image(self, image):
        """ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ"""
        
        # ëŒ€ë¹„ í–¥ìƒ
        enhancer = ImageEnhance.Contrast(image)
        enhanced = enhancer.enhance(1.2)
        
        # ì„ ëª…ë„ í–¥ìƒ
        enhancer = ImageEnhance.Sharpness(enhanced)
        enhanced = enhancer.enhance(1.1)
        
        # ë…¸ì´ì¦ˆ ì œê±° (OpenCV ì‚¬ìš©)
        cv_image = cv2.cvtColor(np.array(enhanced), cv2.COLOR_RGB2BGR)
        denoised = cv2.fastNlMeansDenoisingColored(cv_image, None, 10, 10, 7, 21)
        
        # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
        enhanced_final = Image.fromarray(cv2.cvtColor(denoised, cv2.COLOR_BGR2RGB))
        
        return enhanced_final
    
    async def extract_text(self, image):
        """OCRì„ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        
        try:
            # Tesseract OCR ì„¤ì •
            custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz!@#$%^&*()_+-=[]{}|;:,.<>?/~` '
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text_data = pytesseract.image_to_data(
                image, 
                config=custom_config,
                output_type=pytesseract.Output.DICT
            )
            
            # ì‹ ë¢°ë„ê°€ ë†’ì€ í…ìŠ¤íŠ¸ë§Œ í•„í„°ë§
            extracted_texts = []
            for i, confidence in enumerate(text_data['conf']):
                if int(confidence) > 60:  # 60% ì´ìƒ ì‹ ë¢°ë„
                    text = text_data['text'][i].strip()
                    if text:
                        extracted_texts.append({
                            'text': text,
                            'confidence': confidence,
                            'bbox': {
                                'x': text_data['left'][i],
                                'y': text_data['top'][i],
                                'width': text_data['width'][i],
                                'height': text_data['height'][i]
                            }
                        })
            
            return extracted_texts
            
        except Exception as e:
            print(f"OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    async def extract_color_palette(self, image, num_colors=8):
        """ì£¼ìš” ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ì¶”ì¶œ"""
        
        # ì´ë¯¸ì§€ë¥¼ RGB ë°°ì—´ë¡œ ë³€í™˜
        image_array = np.array(image)
        pixels = image_array.reshape(-1, 3)
        
        # K-means í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ ì£¼ìš” ìƒ‰ìƒ ì¶”ì¶œ
        from sklearn.cluster import KMeans
        
        kmeans = KMeans(n_clusters=num_colors, random_state=42)
        kmeans.fit(pixels)
        
        colors = kmeans.cluster_centers_.astype(int)
        
        # ìƒ‰ìƒì„ hex í˜•íƒœë¡œ ë³€í™˜
        hex_colors = []
        for color in colors:
            hex_color = '#{:02x}{:02x}{:02x}'.format(color[0], color[1], color[2])
            hex_colors.append(hex_color)
        
        # ìƒ‰ìƒ ì‚¬ìš© ë¹ˆë„ ê³„ì‚°
        labels = kmeans.labels_
        color_counts = np.bincount(labels)
        color_percentages = color_counts / len(pixels) * 100
        
        palette = []
        for i, (hex_color, percentage) in enumerate(zip(hex_colors, color_percentages)):
            palette.append({
                'hex': hex_color,
                'rgb': colors[i].tolist(),
                'percentage': round(percentage, 2),
                'name': self.get_color_name(colors[i])
            })
        
        # ì‚¬ìš© ë¹ˆë„ìˆœìœ¼ë¡œ ì •ë ¬
        palette.sort(key=lambda x: x['percentage'], reverse=True)
        
        return palette
    
    def get_color_name(self, rgb):
        """RGB ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒ‰ìƒ ì´ë¦„ ì¶”ì •"""
        
        color_names = {
            'white': [255, 255, 255],
            'black': [0, 0, 0],
            'red': [255, 0, 0],
            'green': [0, 255, 0],
            'blue': [0, 0, 255],
            'yellow': [255, 255, 0],
            'cyan': [0, 255, 255],
            'magenta': [255, 0, 255],
            'gray': [128, 128, 128]
        }
        
        min_distance = float('inf')
        closest_color = 'unknown'
        
        for name, color_rgb in color_names.items():
            distance = np.sqrt(sum((a - b) ** 2 for a, b in zip(rgb, color_rgb)))
            if distance < min_distance:
                min_distance = distance
                closest_color = name
        
        return closest_color

class ProcessedImage:
    def __init__(self, path, info, enhanced_image, text, colors, layout, ui_elements, design_tokens):
        self.path = path
        self.info = info
        self.enhanced_image = enhanced_image
        self.text = text
        self.colors = colors
        self.layout = layout
        self.ui_elements = ui_elements
        self.design_tokens = design_tokens
        self.variations = self.generate_variations()
    
    def generate_variations(self):
        """ì»´í¬ë„ŒíŠ¸ ë³€í˜• ìƒì„±"""
        variations = []
        
        # ìƒ‰ìƒ ë³€í˜•
        for color in self.colors[:3]:  # ìƒìœ„ 3ê°œ ìƒ‰ìƒ
            variations.append({
                'type': 'color',
                'name': f"{color['name']}_variant",
                'primary_color': color['hex']
            })
        
        # í¬ê¸° ë³€í˜•
        for size in ['small', 'medium', 'large']:
            variations.append({
                'type': 'size',
                'name': f"{size}_size",
                'size': size
            })
        
        return variations

# ì‹¤í–‰ ì˜ˆì œ
async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    from config.settings import Config
    
    # ì„¤ì • ë¡œë“œ
    config = Config()
    
    # ë””ìì¸ ì‹œìŠ¤í…œ ìƒì„±ê¸° ì´ˆê¸°í™”
    generator = DesignSystemGenerator(config)
    
    # ë””ìì¸ íŒŒì¼ë“¤ ì²˜ë¦¬
    components = await generator.process_design_directory("./designs/")
    
    # ë””ìì¸ í† í° ìƒì„±
    design_tokens = await generator.generate_design_tokens(components)
    
    print("ğŸ¨ ë””ìì¸ ì‹œìŠ¤í…œ ìë™ ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“¦ ìƒì„±ëœ ì»´í¬ë„ŒíŠ¸: {len(components)}ê°œ")
    print(f"ğŸ¯ ì¶”ì¶œëœ ë””ìì¸ í† í°: {len(design_tokens['tokens'])}ê°œ")

if __name__ == "__main__":
    asyncio.run(main())
```

## ê³ ê¸‰ í™œìš© ì‚¬ë¡€

### 1. ì‹¤ì‹œê°„ ë””ìì¸-ì½”ë“œ ë™ê¸°í™”

```python
# realtime_sync.py
import asyncio
import time
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
from screencoder import ScreenCoder

class DesignFileWatcher(FileSystemEventHandler):
    """ë””ìì¸ íŒŒì¼ ë³€ê²½ ê°ì§€"""
    
    def __init__(self, screencoder):
        self.screencoder = screencoder
        self.last_modified = {}
        self.debounce_time = 2  # 2ì´ˆ ë””ë°”ìš´ìŠ¤
    
    def on_modified(self, event):
        if event.is_directory:
            return
        
        file_path = event.src_path
        
        # ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì²˜ë¦¬
        if not any(file_path.endswith(ext) for ext in ['.png', '.jpg', '.jpeg']):
            return
        
        current_time = time.time()
        
        # ë””ë°”ìš´ìŠ¤ ì²˜ë¦¬
        if file_path in self.last_modified:
            if current_time - self.last_modified[file_path] < self.debounce_time:
                return
        
        self.last_modified[file_path] = current_time
        
        # ë¹„ë™ê¸° ì½”ë“œ ìƒì„± ì‹¤í–‰
        asyncio.create_task(self.regenerate_code(file_path))
    
    async def regenerate_code(self, file_path):
        """íŒŒì¼ ë³€ê²½ ì‹œ ì½”ë“œ ì¬ìƒì„±"""
        try:
            print(f"ğŸ”„ íŒŒì¼ ë³€ê²½ ê°ì§€: {file_path}")
            
            # ì½”ë“œ ì¬ìƒì„±
            result = await self.screencoder.generate_code(
                image_path=file_path,
                output_format="react",
                auto_save=True,
                notify_completion=True
            )
            
            print(f"âœ… ì½”ë“œ ì¬ìƒì„± ì™„ë£Œ: {result.output_path}")
            
            # ë¸Œë¼ìš°ì € ìë™ ìƒˆë¡œê³ ì¹¨ (ì„ íƒì‚¬í•­)
            await self.trigger_browser_refresh()
            
        except Exception as e:
            print(f"âŒ ì½”ë“œ ì¬ìƒì„± ì‹¤íŒ¨: {e}")
    
    async def trigger_browser_refresh(self):
        """ê°œë°œ ì„œë²„ ìë™ ìƒˆë¡œê³ ì¹¨"""
        # Hot Module Replacement ë˜ëŠ” ì›¹ì†Œì¼“ì„ í†µí•œ ìƒˆë¡œê³ ì¹¨
        pass

class RealtimeSyncManager:
    def __init__(self, watch_directory="./designs", output_directory="./src/components"):
        self.watch_dir = watch_directory
        self.output_dir = output_directory
        self.screencoder = ScreenCoder()
        
    async def start_watching(self):
        """ì‹¤ì‹œê°„ ê°ì‹œ ì‹œì‘"""
        
        # íŒŒì¼ ê°ì‹œì ì„¤ì •
        event_handler = DesignFileWatcher(self.screencoder)
        observer = Observer()
        observer.schedule(event_handler, self.watch_dir, recursive=True)
        
        # ê°ì‹œ ì‹œì‘
        observer.start()
        print(f"ğŸ‘€ ë””ìì¸ íŒŒì¼ ê°ì‹œ ì‹œì‘: {self.watch_dir}")
        
        try:
            while True:
                await asyncio.sleep(1)
        except KeyboardInterrupt:
            observer.stop()
            print("ğŸ“´ ê°ì‹œ ì¤‘ë‹¨")
        
        observer.join()

# ì‚¬ìš© ì˜ˆì œ
async def realtime_example():
    sync_manager = RealtimeSyncManager()
    await sync_manager.start_watching()

# asyncio.run(realtime_example())
```

### 2. Figma API ì—°ë™

```python
# figma_integration.py
import requests
import asyncio
from screencoder import ScreenCoder

class FigmaIntegration:
    """Figma APIì™€ ScreenCoder ì—°ë™"""
    
    def __init__(self, figma_token, screencoder):
        self.figma_token = figma_token
        self.screencoder = screencoder
        self.api_base = "https://api.figma.com/v1"
    
    async def export_figma_designs(self, file_key, component_names=None):
        """Figma ë””ìì¸ì„ ì´ë¯¸ì§€ë¡œ ë‚´ë³´ë‚´ê¸°"""
        
        # 1. Figma íŒŒì¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        file_info = await self.get_file_info(file_key)
        
        # 2. ì»´í¬ë„ŒíŠ¸ ëª©ë¡ ì¶”ì¶œ
        components = self.extract_components(file_info, component_names)
        
        # 3. ê° ì»´í¬ë„ŒíŠ¸ë¥¼ ì´ë¯¸ì§€ë¡œ ë‚´ë³´ë‚´ê¸°
        exported_images = []
        for component in components:
            image_url = await self.export_component_image(file_key, component['id'])
            
            # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            image_path = await self.download_image(image_url, component['name'])
            
            exported_images.append({
                'component': component,
                'image_path': image_path
            })
        
        return exported_images
    
    async def generate_code_from_figma(self, file_key, component_names=None):
        """Figma ë””ìì¸ì—ì„œ ì§ì ‘ ì½”ë“œ ìƒì„±"""
        
        # Figmaì—ì„œ ì´ë¯¸ì§€ ë‚´ë³´ë‚´ê¸°
        exported_images = await self.export_figma_designs(file_key, component_names)
        
        generated_components = []
        
        for item in exported_images:
            component_info = item['component']
            image_path = item['image_path']
            
            # ScreenCoderë¡œ ì½”ë“œ ìƒì„±
            result = await self.screencoder.generate_code(
                image_path=image_path,
                output_format="react",
                component_name=component_info['name'],
                include_figma_metadata=True,
                figma_component_id=component_info['id']
            )
            
            generated_components.append({
                'figma_component': component_info,
                'generated_code': result,
                'image_path': image_path
            })
        
        return generated_components
    
    async def get_file_info(self, file_key):
        """Figma íŒŒì¼ ì •ë³´ ì¡°íšŒ"""
        
        headers = {
            'X-Figma-Token': self.figma_token
        }
        
        response = requests.get(
            f"{self.api_base}/files/{file_key}",
            headers=headers
        )
        
        if response.status_code == 200:
            return response.json()
        else:
            raise Exception(f"Figma API ì˜¤ë¥˜: {response.status_code}")
    
    def extract_components(self, file_info, component_names=None):
        """íŒŒì¼ì—ì„œ ì»´í¬ë„ŒíŠ¸ ì¶”ì¶œ"""
        
        components = []
        
        def traverse_node(node):
            if node.get('type') == 'COMPONENT':
                component_name = node.get('name', '')
                
                # íŠ¹ì • ì»´í¬ë„ŒíŠ¸ë§Œ í•„í„°ë§
                if component_names is None or component_name in component_names:
                    components.append({
                        'id': node['id'],
                        'name': component_name,
                        'description': node.get('description', ''),
                        'metadata': node
                    })
            
            # ìì‹ ë…¸ë“œ íƒìƒ‰
            for child in node.get('children', []):
                traverse_node(child)
        
        # ëª¨ë“  í˜ì´ì§€ íƒìƒ‰
        for page in file_info['document']['children']:
            traverse_node(page)
        
        return components
    
    async def export_component_image(self, file_key, component_id):
        """ì»´í¬ë„ŒíŠ¸ë¥¼ ì´ë¯¸ì§€ë¡œ ë‚´ë³´ë‚´ê¸°"""
        
        headers = {
            'X-Figma-Token': self.figma_token
        }
        
        params = {
            'ids': component_id,
            'format': 'png',
            'scale': 2  # 2x í•´ìƒë„
        }
        
        response = requests.get(
            f"{self.api_base}/images/{file_key}",
            headers=headers,
            params=params
        )
        
        if response.status_code == 200:
            data = response.json()
            return data['images'][component_id]
        else:
            raise Exception(f"ì´ë¯¸ì§€ ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {response.status_code}")
    
    async def download_image(self, image_url, component_name):
        """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""
        
        response = requests.get(image_url)
        
        if response.status_code == 200:
            filename = f"./figma_exports/{component_name}.png"
            
            # ë””ë ‰í† ë¦¬ ìƒì„±
            import os
            os.makedirs(os.path.dirname(filename), exist_ok=True)
            
            with open(filename, 'wb') as f:
                f.write(response.content)
            
            return filename
        else:
            raise Exception(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {response.status_code}")

# ì‚¬ìš© ì˜ˆì œ
async def figma_example():
    """Figma ì—°ë™ ì˜ˆì œ"""
    
    figma_token = "your_figma_personal_access_token"
    screencoder = ScreenCoder()
    
    figma = FigmaIntegration(figma_token, screencoder)
    
    # Figma íŒŒì¼ì—ì„œ ì»´í¬ë„ŒíŠ¸ ì½”ë“œ ìƒì„±
    file_key = "your_figma_file_key"
    component_names = ["Button", "Card", "Modal"]  # íŠ¹ì • ì»´í¬ë„ŒíŠ¸ë§Œ ì²˜ë¦¬
    
    components = await figma.generate_code_from_figma(file_key, component_names)
    
    for comp in components:
        print(f"âœ… {comp['figma_component']['name']} ì»´í¬ë„ŒíŠ¸ ìƒì„± ì™„ë£Œ")
        print(f"ğŸ“ ì½”ë“œ íŒŒì¼: {comp['generated_code'].output_path}")

# asyncio.run(figma_example())
```

### 3. CI/CD íŒŒì´í”„ë¼ì¸ í†µí•©

```python
# ci_cd_integration.py
import os
import json
import subprocess
from pathlib import Path

class ScreenCoderCIPipeline:
    """CI/CD íŒŒì´í”„ë¼ì¸ì—ì„œ ScreenCoder í™œìš©"""
    
    def __init__(self, config_path="./screencoder-ci.json"):
        self.config = self.load_config(config_path)
        self.screencoder = ScreenCoder()
    
    def load_config(self, config_path):
        """CI ì„¤ì • ë¡œë“œ"""
        with open(config_path, 'r') as f:
            return json.load(f)
    
    async def process_changed_designs(self, changed_files):
        """ë³€ê²½ëœ ë””ìì¸ íŒŒì¼ë“¤ ì²˜ë¦¬"""
        
        generated_files = []
        
        for file_path in changed_files:
            if self.is_design_file(file_path):
                try:
                    # ì½”ë“œ ìƒì„±
                    result = await self.screencoder.generate_code(
                        image_path=file_path,
                        output_format=self.config['output_format'],
                        output_directory=self.config['output_directory']
                    )
                    
                    generated_files.append(result.output_path)
                    
                    # í’ˆì§ˆ ê²€ì‚¬
                    quality_check = await self.run_quality_checks(result.output_path)
                    
                    if not quality_check['passed']:
                        raise Exception(f"í’ˆì§ˆ ê²€ì‚¬ ì‹¤íŒ¨: {quality_check['errors']}")
                    
                except Exception as e:
                    print(f"âŒ {file_path} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    return False
        
        # Git ì»¤ë°‹
        if generated_files:
            await self.commit_generated_files(generated_files)
        
        return True
    
    def is_design_file(self, file_path):
        """ë””ìì¸ íŒŒì¼ ì—¬ë¶€ í™•ì¸"""
        design_extensions = ['.png', '.jpg', '.jpeg', '.figma']
        return any(file_path.endswith(ext) for ext in design_extensions)
    
    async def run_quality_checks(self, code_file_path):
        """ìƒì„±ëœ ì½”ë“œ í’ˆì§ˆ ê²€ì‚¬"""
        
        checks = []
        
        # 1. ESLint ê²€ì‚¬
        eslint_result = await self.run_eslint(code_file_path)
        checks.append(eslint_result)
        
        # 2. TypeScript ì»´íŒŒì¼ ê²€ì‚¬
        if code_file_path.endswith('.tsx'):
            ts_result = await self.run_typescript_check(code_file_path)
            checks.append(ts_result)
        
        # 3. ì ‘ê·¼ì„± ê²€ì‚¬
        a11y_result = await self.run_accessibility_check(code_file_path)
        checks.append(a11y_result)
        
        # 4. ì„±ëŠ¥ ê²€ì‚¬
        perf_result = await self.run_performance_check(code_file_path)
        checks.append(perf_result)
        
        # ëª¨ë“  ê²€ì‚¬ ê²°ê³¼ í†µí•©
        all_passed = all(check['passed'] for check in checks)
        errors = [error for check in checks for error in check.get('errors', [])]
        
        return {
            'passed': all_passed,
            'errors': errors,
            'details': checks
        }
    
    async def run_eslint(self, file_path):
        """ESLint ê²€ì‚¬ ì‹¤í–‰"""
        try:
            result = subprocess.run(
                ['npx', 'eslint', file_path, '--format', 'json'],
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                return {'passed': True, 'tool': 'eslint'}
            else:
                errors = json.loads(result.stdout)
                return {
                    'passed': False,
                    'tool': 'eslint',
                    'errors': errors
                }
        except Exception as e:
            return {
                'passed': False,
                'tool': 'eslint',
                'errors': [str(e)]
            }
    
    async def commit_generated_files(self, generated_files):
        """ìƒì„±ëœ íŒŒì¼ë“¤ Git ì»¤ë°‹"""
        
        # Git add
        for file_path in generated_files:
            subprocess.run(['git', 'add', file_path])
        
        # Git commit
        commit_message = f"ğŸ¤– ScreenCoder: {len(generated_files)}ê°œ ì»´í¬ë„ŒíŠ¸ ìë™ ìƒì„±"
        subprocess.run(['git', 'commit', '-m', commit_message])

# GitHub Actions ì›Œí¬í”Œë¡œìš° ì˜ˆì œ
github_workflow = """
# .github/workflows/screencoder.yml
name: ScreenCoder Auto Generation

on:
  push:
    paths:
      - 'designs/**'
      - 'figma-exports/**'
  pull_request:
    paths:
      - 'designs/**'

jobs:
  generate-code:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        
    - name: Install ScreenCoder
      run: |
        pip install screencoder
        
    - name: Install Node dependencies
      run: |
        npm install
        
    - name: Get changed files
      id: changed-files
      uses: tj-actions/changed-files@v35
      with:
        files: |
          designs/**
          figma-exports/**
          
    - name: Generate code from designs
      if: steps.changed-files.outputs.any_changed == 'true'
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      run: |
        python ci_cd_integration.py --changed-files="${{ steps.changed-files.outputs.all_changed_files }}"
        
    - name: Run tests
      run: |
        npm test
        
    - name: Run linting
      run: |
        npm run lint
        
    - name: Commit generated files
      if: steps.changed-files.outputs.any_changed == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add .
        git diff --staged --quiet || git commit -m "ğŸ¤– Auto-generated components from designs"
        git push
"""
```

## ì„±ëŠ¥ ìµœì í™” ë° ëª¨ë‹ˆí„°ë§

### 1. ì½”ë“œ ìƒì„± ì„±ëŠ¥ ìµœì í™”

```python
# performance_optimizer.py
import asyncio
import time
from concurrent.futures import ThreadPoolExecutor
from screencoder import ScreenCoder

class PerformanceOptimizer:
    def __init__(self, max_workers=4):
        self.max_workers = max_workers
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.generation_cache = {}
    
    async def batch_generate_optimized(self, image_paths, config):
        """ìµœì í™”ëœ ë°°ì¹˜ ìƒì„±"""
        
        # 1. ì´ë¯¸ì§€ í•´ì‹œ ê³„ì‚° (ìºì‹±ìš©)
        image_hashes = await self.compute_image_hashes(image_paths)
        
        # 2. ìºì‹œì—ì„œ ê¸°ì¡´ ê²°ê³¼ í™•ì¸
        cached_results = {}
        new_images = []
        
        for i, (path, hash_val) in enumerate(zip(image_paths, image_hashes)):
            cache_key = f"{hash_val}_{config['output_format']}"
            if cache_key in self.generation_cache:
                cached_results[path] = self.generation_cache[cache_key]
            else:
                new_images.append((path, hash_val))
        
        print(f"ğŸ’¾ ìºì‹œì—ì„œ {len(cached_results)}ê°œ ê²°ê³¼ ë¡œë“œ")
        print(f"ğŸ”„ ìƒˆë¡œ ìƒì„±í•  ì´ë¯¸ì§€: {len(new_images)}ê°œ")
        
        # 3. ìƒˆ ì´ë¯¸ì§€ë“¤ ë³‘ë ¬ ì²˜ë¦¬
        new_results = {}
        if new_images:
            tasks = []
            semaphore = asyncio.Semaphore(self.max_workers)
            
            for path, hash_val in new_images:
                task = self.generate_with_semaphore(
                    semaphore, path, hash_val, config
                )
                tasks.append(task)
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            for (path, hash_val), result in zip(new_images, results):
                if not isinstance(result, Exception):
                    new_results[path] = result
                    # ìºì‹œì— ì €ì¥
                    cache_key = f"{hash_val}_{config['output_format']}"
                    self.generation_cache[cache_key] = result
        
        # 4. ê²°ê³¼ ë³‘í•©
        all_results = {**cached_results, **new_results}
        
        return all_results
    
    async def generate_with_semaphore(self, semaphore, image_path, image_hash, config):
        """ì„¸ë§ˆí¬ì–´ë¥¼ ì‚¬ìš©í•œ ì œí•œëœ ë™ì‹œ ì‹¤í–‰"""
        
        async with semaphore:
            start_time = time.time()
            
            screencoder = ScreenCoder()
            result = await screencoder.generate_code(
                image_path=image_path,
                **config
            )
            
            generation_time = time.time() - start_time
            
            print(f"âœ… {image_path} ìƒì„± ì™„ë£Œ ({generation_time:.2f}ì´ˆ)")
            
            return {
                'result': result,
                'generation_time': generation_time,
                'image_hash': image_hash
            }
    
    async def compute_image_hashes(self, image_paths):
        """ì´ë¯¸ì§€ í•´ì‹œ ê³„ì‚° (ìºì‹±ìš©)"""
        
        import hashlib
        from PIL import Image
        
        hashes = []
        
        for path in image_paths:
            # ì´ë¯¸ì§€ íŒŒì¼ì˜ í•´ì‹œ ê³„ì‚°
            with open(path, 'rb') as f:
                file_hash = hashlib.md5(f.read()).hexdigest()
            
            hashes.append(file_hash)
        
        return hashes

class GenerationMetrics:
    """ì½”ë“œ ìƒì„± ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
    
    def __init__(self):
        self.metrics = {
            'total_generations': 0,
            'successful_generations': 0,
            'failed_generations': 0,
            'total_time': 0,
            'average_time': 0,
            'cache_hits': 0,
            'models_used': {},
            'output_formats': {},
            'error_types': {}
        }
    
    def record_generation(self, success, time_taken, model, output_format, error=None):
        """ìƒì„± ë©”íŠ¸ë¦­ ê¸°ë¡"""
        
        self.metrics['total_generations'] += 1
        self.metrics['total_time'] += time_taken
        
        if success:
            self.metrics['successful_generations'] += 1
        else:
            self.metrics['failed_generations'] += 1
            if error:
                error_type = type(error).__name__
                self.metrics['error_types'][error_type] = \
                    self.metrics['error_types'].get(error_type, 0) + 1
        
        # ëª¨ë¸ë³„ í†µê³„
        self.metrics['models_used'][model] = \
            self.metrics['models_used'].get(model, 0) + 1
        
        # ì¶œë ¥ í˜•ì‹ë³„ í†µê³„
        self.metrics['output_formats'][output_format] = \
            self.metrics['output_formats'].get(output_format, 0) + 1
        
        # í‰ê·  ì‹œê°„ ì—…ë°ì´íŠ¸
        self.metrics['average_time'] = \
            self.metrics['total_time'] / self.metrics['total_generations']
    
    def record_cache_hit(self):
        """ìºì‹œ íˆíŠ¸ ê¸°ë¡"""
        self.metrics['cache_hits'] += 1
    
    def get_performance_report(self):
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        
        success_rate = (self.metrics['successful_generations'] / 
                       max(self.metrics['total_generations'], 1)) * 100
        
        cache_hit_rate = (self.metrics['cache_hits'] / 
                         max(self.metrics['total_generations'], 1)) * 100
        
        return {
            'summary': {
                'total_generations': self.metrics['total_generations'],
                'success_rate': f"{success_rate:.2f}%",
                'average_time': f"{self.metrics['average_time']:.2f}ì´ˆ",
                'cache_hit_rate': f"{cache_hit_rate:.2f}%"
            },
            'details': self.metrics
        }
```

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ

### 1. ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°

```python
# troubleshooting.py
import asyncio
import logging
from screencoder import ScreenCoder
from screencoder.exceptions import *

class ScreenCoderTroubleshooter:
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.common_issues = {
            'api_key_error': self.fix_api_key_error,
            'image_quality_poor': self.fix_image_quality,
            'generation_timeout': self.fix_timeout_issue,
            'invalid_output': self.fix_invalid_output,
            'memory_error': self.fix_memory_error
        }
    
    async def diagnose_and_fix(self, error, context):
        """ì˜¤ë¥˜ ì§„ë‹¨ ë° ìë™ ìˆ˜ì •"""
        
        issue_type = self.classify_error(error)
        
        if issue_type in self.common_issues:
            fix_function = self.common_issues[issue_type]
            return await fix_function(error, context)
        else:
            return await self.generic_fix_attempt(error, context)
    
    def classify_error(self, error):
        """ì˜¤ë¥˜ ìœ í˜• ë¶„ë¥˜"""
        
        error_message = str(error).lower()
        
        if 'api key' in error_message or 'unauthorized' in error_message:
            return 'api_key_error'
        elif 'timeout' in error_message or 'time out' in error_message:
            return 'generation_timeout'
        elif 'memory' in error_message or 'out of memory' in error_message:
            return 'memory_error'
        elif 'image' in error_message and 'quality' in error_message:
            return 'image_quality_poor'
        elif 'invalid' in error_message or 'malformed' in error_message:
            return 'invalid_output'
        else:
            return 'unknown'
    
    async def fix_api_key_error(self, error, context):
        """API í‚¤ ì˜¤ë¥˜ ìˆ˜ì •"""
        
        fixes = []
        
        # 1. í™˜ê²½ ë³€ìˆ˜ í™•ì¸
        import os
        if not os.getenv('OPENAI_API_KEY'):
            fixes.append("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # 2. API í‚¤ í˜•ì‹ ê²€ì¦
        api_key = os.getenv('OPENAI_API_KEY', '')
        if api_key and not api_key.startswith('sk-'):
            fixes.append("OpenAI API í‚¤ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. 'sk-'ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.")
        
        # 3. API í‚¤ ê¶Œí•œ í™•ì¸
        if api_key:
            try:
                # ê°„ë‹¨í•œ API í˜¸ì¶œë¡œ í‚¤ ìœ íš¨ì„± ê²€ì¦
                from openai import OpenAI
                client = OpenAI(api_key=api_key)
                client.models.list()
                fixes.append("API í‚¤ëŠ” ìœ íš¨í•˜ì§€ë§Œ ë‹¤ë¥¸ ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                fixes.append(f"API í‚¤ ê¶Œí•œ ë¬¸ì œ: {str(e)}")
        
        return {
            'issue': 'API Key Error',
            'fixes': fixes,
            'suggested_actions': [
                "1. .env íŒŒì¼ì— ì˜¬ë°”ë¥¸ OPENAI_API_KEY ì„¤ì •",
                "2. API í‚¤ ê¶Œí•œ ë° ì”ì•¡ í™•ì¸",
                "3. ë°©í™”ë²½ ë˜ëŠ” í”„ë¡ì‹œ ì„¤ì • í™•ì¸"
            ]
        }
    
    async def fix_image_quality(self, error, context):
        """ì´ë¯¸ì§€ í’ˆì§ˆ ë¬¸ì œ ìˆ˜ì •"""
        
        image_path = context.get('image_path')
        
        fixes = []
        
        if image_path:
            from PIL import Image
            
            try:
                img = Image.open(image_path)
                
                # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
                if img.size[0] < 300 or img.size[1] < 300:
                    fixes.append("ì´ë¯¸ì§€ í•´ìƒë„ê°€ ë„ˆë¬´ ë‚®ìŠµë‹ˆë‹¤. ìµœì†Œ 300x300 ê¶Œì¥")
                
                # ì´ë¯¸ì§€ í˜•ì‹ í™•ì¸
                if img.format not in ['PNG', 'JPEG', 'JPG']:
                    fixes.append("ì§€ì›ë˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹ì…ë‹ˆë‹¤. PNG ë˜ëŠ” JPEG ì‚¬ìš© ê¶Œì¥")
                
                # íŒŒì¼ í¬ê¸° í™•ì¸
                import os
                file_size = os.path.getsize(image_path)
                if file_size > 10 * 1024 * 1024:  # 10MB
                    fixes.append("ì´ë¯¸ì§€ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤. 10MB ì´í•˜ ê¶Œì¥")
                
                # ìë™ ì´ë¯¸ì§€ ê°œì„  ì‹œë„
                enhanced_path = await self.enhance_image_automatically(image_path)
                fixes.append(f"ìë™ ê°œì„ ëœ ì´ë¯¸ì§€ ì €ì¥: {enhanced_path}")
                
            except Exception as e:
                fixes.append(f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        
        return {
            'issue': 'Image Quality',
            'fixes': fixes,
            'suggested_actions': [
                "1. ê³ í•´ìƒë„ ì´ë¯¸ì§€ ì‚¬ìš© (ìµœì†Œ 300x300)",
                "2. ëª…í™•í•˜ê³  ì„ ëª…í•œ ë””ìì¸ ì œê³µ",
                "3. PNG í˜•ì‹ ê¶Œì¥ (íˆ¬ëª…ë„ ì§€ì›)",
                "4. ì ì ˆí•œ ëŒ€ë¹„ì™€ ìƒ‰ìƒ ì‚¬ìš©"
            ]
        }
    
    async def enhance_image_automatically(self, image_path):
        """ì´ë¯¸ì§€ ìë™ ê°œì„ """
        
        from PIL import Image, ImageEnhance
        import os
        
        img = Image.open(image_path)
        
        # ëŒ€ë¹„ í–¥ìƒ
        enhancer = ImageEnhance.Contrast(img)
        img = enhancer.enhance(1.2)
        
        # ì„ ëª…ë„ í–¥ìƒ
        enhancer = ImageEnhance.Sharpness(img)
        img = enhancer.enhance(1.1)
        
        # ê°œì„ ëœ ì´ë¯¸ì§€ ì €ì¥
        base_name = os.path.splitext(image_path)[0]
        enhanced_path = f"{base_name}_enhanced.png"
        img.save(enhanced_path, "PNG")
        
        return enhanced_path

# ìë™ ë³µêµ¬ ì‹œìŠ¤í…œ
class AutoRecoverySystem:
    def __init__(self, screencoder):
        self.screencoder = screencoder
        self.troubleshooter = ScreenCoderTroubleshooter()
        self.max_retry_attempts = 3
    
    async def generate_with_auto_recovery(self, **kwargs):
        """ìë™ ë³µêµ¬ ê¸°ëŠ¥ì´ ìˆëŠ” ì½”ë“œ ìƒì„±"""
        
        for attempt in range(self.max_retry_attempts):
            try:
                result = await self.screencoder.generate_code(**kwargs)
                return result
                
            except Exception as e:
                print(f"ğŸ”„ ì‹œë„ {attempt + 1}/{self.max_retry_attempts} ì‹¤íŒ¨: {e}")
                
                if attempt < self.max_retry_attempts - 1:
                    # ìë™ ì§„ë‹¨ ë° ìˆ˜ì •
                    diagnosis = await self.troubleshooter.diagnose_and_fix(e, kwargs)
                    print(f"ğŸ”§ ì§„ë‹¨ ê²°ê³¼: {diagnosis['issue']}")
                    
                    # ìˆ˜ì • ì‚¬í•­ ì ìš©
                    kwargs = await self.apply_fixes(kwargs, diagnosis)
                    
                    # ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„
                    await asyncio.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
                else:
                    # ìµœì¢… ì‹¤íŒ¨
                    print(f"âŒ ëª¨ë“  ë³µêµ¬ ì‹œë„ ì‹¤íŒ¨")
                    raise e
    
    async def apply_fixes(self, kwargs, diagnosis):
        """ì§„ë‹¨ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒŒë¼ë¯¸í„° ìˆ˜ì •"""
        
        # ì—¬ê¸°ì„œ ì§„ë‹¨ ê²°ê³¼ì— ë”°ë¼ kwargsë¥¼ ìˆ˜ì •
        # ì˜ˆ: ì´ë¯¸ì§€ ê²½ë¡œ ë³€ê²½, ëª¨ë¸ ë³€ê²½, íƒ€ì„ì•„ì›ƒ ì¦ê°€ ë“±
        
        if diagnosis['issue'] == 'Image Quality':
            # ê°œì„ ëœ ì´ë¯¸ì§€ ê²½ë¡œë¡œ ë³€ê²½
            for fix in diagnosis['fixes']:
                if 'ìë™ ê°œì„ ëœ ì´ë¯¸ì§€' in fix:
                    enhanced_path = fix.split(': ')[1]
                    kwargs['image_path'] = enhanced_path
                    break
        
        elif diagnosis['issue'] == 'Generation Timeout':
            # íƒ€ì„ì•„ì›ƒ ì¦ê°€
            kwargs['timeout'] = kwargs.get('timeout', 30) * 2
        
        return kwargs
```

## ê²°ë¡ 

**ScreenCoder**ëŠ” ë””ìì¸ê³¼ ê°œë°œ ì‚¬ì´ì˜ ê°„ê·¹ì„ íšê¸°ì ìœ¼ë¡œ ì¤„ì—¬ì£¼ëŠ” í˜ì‹ ì ì¸ ë„êµ¬ì…ë‹ˆë‹¤. AI ë¹„ì „ ëª¨ë¸ì˜ ë°œì „ìœ¼ë¡œ ì´ì œ **ìŠ¤í¬ë¦°ìƒ·ë§Œìœ¼ë¡œë„ í”„ë¡œë•ì…˜ ë ˆë”” ì½”ë“œë¥¼ ìƒì„±**í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.

### ğŸ¯ í•µì‹¬ ê°€ì¹˜

1. **ê°œë°œ ìƒì‚°ì„± ê·¹ëŒ€í™”**: ë””ìì¸ â†’ ì½”ë“œ ë³€í™˜ ì‹œê°„ 95% ë‹¨ì¶•
2. **í”½ì…€ í¼í™íŠ¸ êµ¬í˜„**: AIê°€ ë””ìì¸ì„ ì •í™•íˆ ë¶„ì„í•˜ì—¬ êµ¬í˜„
3. **ë‹¤ì–‘í•œ í”„ë ˆì„ì›Œí¬ ì§€ì›**: React, Vue, Flutter ë“± ì›í•˜ëŠ” í˜•íƒœë¡œ ì¶œë ¥
4. **CI/CD í†µí•©**: ìë™í™”ëœ ê°œë°œ ì›Œí¬í”Œë¡œìš° êµ¬ì¶•

### ğŸš€ ì ìš© ë¶„ì•¼

- **í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œ**: ë¹ ë¥¸ UI ì»´í¬ë„ŒíŠ¸ ìƒì„±
- **í”„ë¡œí† íƒ€ì´í•‘**: ì•„ì´ë””ì–´ë¥¼ ë¹ ë¥´ê²Œ ì½”ë“œë¡œ ë³€í™˜
- **ë””ìì¸ ì‹œìŠ¤í…œ**: ì¼ê´€ëœ ì»´í¬ë„ŒíŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ êµ¬ì¶•
- **êµìœ¡**: ì‹œê°ì  í•™ìŠµì„ í†µí•œ ì½”ë”© êµìœ¡

### ğŸ”® ë¯¸ë˜ ì „ë§

ScreenCoderëŠ” **No-Code/Low-Code í”Œë«í¼ì˜ ë‹¤ìŒ ë‹¨ê³„**ì…ë‹ˆë‹¤. ì•ìœ¼ë¡œëŠ”:

- **ì‹¤ì‹œê°„ ë””ìì¸-ì½”ë“œ ë™ê¸°í™”**
- **ìŒì„± ëª…ë ¹ìœ¼ë¡œ UI ìˆ˜ì •**
- **ìë™ ì ‘ê·¼ì„± ë° ì„±ëŠ¥ ìµœì í™”**
- **ë‹¤êµ­ì–´ UI ìë™ ìƒì„±**

ì´ ëª¨ë“  ê¸°ëŠ¥ì´ í†µí•©ë˜ì–´ **ì§„ì •í•œ AI ê¸°ë°˜ ê°œë°œ í™˜ê²½**ì„ ë§Œë“¤ì–´ê°ˆ ê²ƒì…ë‹ˆë‹¤.

---

**ì°¸ê³  ìë£Œ:**
- [ScreenCoder GitHub](https://github.com/leigest519/ScreenCoder)
- **ì§€ì› AI ëª¨ë¸**: GPT-4V, Claude Vision, LLaVA, Qwen-VL
- **ì¶œë ¥ í˜•ì‹**: HTML/CSS, React, Vue, Flutter, SwiftUI

**ê´€ë ¨ í‚¤ì›Œë“œ:** `#ScreenCoder` `#AIì½”ë”©` `#ë¹„ì£¼ì–¼ì½”ë”©` `#UI-to-Code` `#GPT-4V` `#ì½”ë“œìƒì„±` `#ìë™í™”`