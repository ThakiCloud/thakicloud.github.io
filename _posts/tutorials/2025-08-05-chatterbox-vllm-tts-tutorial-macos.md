---
title: "Chatterbox-vLLM ì™„ì „ ê°€ì´ë“œ: ì´ˆê³ ì† TTS ì‹œìŠ¤í…œ êµ¬ì¶•í•˜ê¸°"
excerpt: "vLLM ê¸°ë°˜ Chatterbox TTS ëª¨ë¸ë¡œ 6.6k ë‹¨ì–´ë¥¼ 2ë¶„ 30ì´ˆì— 40ë¶„ ì˜¤ë””ì˜¤ë¡œ ë³€í™˜í•˜ëŠ” ê³ ì„±ëŠ¥ í…ìŠ¤íŠ¸-ìŒì„± ë³€í™˜ ì‹œìŠ¤í…œì„ macOSì—ì„œ êµ¬í˜„í•´ë³´ì„¸ìš”."
seo_title: "Chatterbox-vLLM TTS íŠœí† ë¦¬ì–¼ macOS ì™„ì „ ê°€ì´ë“œ - Thaki Cloud"
seo_description: "vLLM ìµœì í™”ëœ Chatterbox TTS ëª¨ë¸ ì„¤ì¹˜ë¶€í„° ë°°ì¹˜ ì²˜ë¦¬ê¹Œì§€. RTX GPUì—ì„œ ì´ˆê³ ì† ìŒì„± í•©ì„± êµ¬í˜„í•˜ëŠ” ì™„ì „í•œ íŠœí† ë¦¬ì–¼ê³¼ ì‹¤ì œ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ í¬í•¨."
date: 2025-08-05
last_modified_at: 2025-08-05
categories:
  - tutorials
tags:
  - chatterbox
  - vllm
  - tts
  - text-to-speech
  - llama
  - gradio
  - python
  - macos
  - gpu
  - ai-audio
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
toc_icon: "cog"
toc_sticky: true
canonical_url: "https://thakicloud.github.io/tutorials/chatterbox-vllm-tts-tutorial-macos/"
reading_time: true
---

â±ï¸ **ì˜ˆìƒ ì½ê¸° ì‹œê°„**: 15ë¶„

## ì„œë¡ 

AI ìŒì„± í•©ì„± ê¸°ìˆ ì´ ê¸‰ì†ë„ë¡œ ë°œì „í•˜ë©´ì„œ, ì‹¤ì‹œê°„ì— ê°€ê¹Œìš´ ê³ í’ˆì§ˆ TTS(Text-to-Speech) ì‹œìŠ¤í…œì˜ í•„ìš”ì„±ì´ ì»¤ì§€ê³  ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ íŒŸìºìŠ¤íŠ¸, ì˜¤ë””ì˜¤ë¶, ìŒì„± ê°€ì´ë“œ ë“±ì˜ ì½˜í…ì¸  ì œì‘ì—ì„œëŠ” **ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„**ì™€ **ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± í’ˆì§ˆ**ì´ ë™ì‹œì— ìš”êµ¬ë©ë‹ˆë‹¤.

[Chatterbox-vLLM](https://github.com/randombk/chatterbox-vllm)ì€ ì´ëŸ¬í•œ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±ì‹œí‚¤ëŠ” í˜ì‹ ì ì¸ ì†”ë£¨ì…˜ì…ë‹ˆë‹¤. ê¸°ì¡´ Chatterbox TTS ëª¨ë¸ì„ **vLLM(Very fast LLM inference)**ìœ¼ë¡œ ìµœì í™”í•˜ì—¬, **RTX 3090ì—ì„œ 6.6k ë‹¨ì–´ í…ìŠ¤íŠ¸ë¥¼ 2ë¶„ 30ì´ˆì— 40ë¶„ ì˜¤ë””ì˜¤ë¡œ ë³€í™˜**í•˜ëŠ” ë†€ë¼ìš´ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

ì´ë²ˆ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” Chatterbox-vLLMì„ macOS í™˜ê²½ì—ì„œ ì™„ì „íˆ êµ¬ì¶•í•˜ê³ , ì‹¤ì œ ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•´ë³´ê² ìŠµë‹ˆë‹¤.

## Chatterbox-vLLM ì•„í‚¤í…ì²˜ ì´í•´

### í•µì‹¬ êµ¬ì¡°

ChatterboxëŠ” **CosyVoice ì•„í‚¤í…ì²˜**ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°, ë‹¤ìŒê³¼ ê°™ì€ ë…íŠ¹í•œ íŠ¹ì§•ì„ ê°€ì§‘ë‹ˆë‹¤:

```
í…ìŠ¤íŠ¸ ì…ë ¥ â†’ T3 Llama ëª¨ë¸ â†’ ìŒì„± í† í° â†’ S3Gen â†’ ì˜¤ë””ì˜¤ íŒŒí˜•
      â†‘                â†‘                     â†‘
   ìŒì„± ì°¸ì¡°      ì¤‘ê°„ ìœµí•© ë‹¤ì¤‘ëª¨ë‹¬         ì›¨ì´ë¸Œí¼
    ìƒ˜í”Œ         ì»¨ë””ì…”ë‹ (0.5B íŒŒë¼ë¯¸í„°)      ìƒì„±
```

### ì£¼ìš” êµ¬ì„± ìš”ì†Œ

1. **T3 (Text-to-Token) ëª¨ë¸**: 0.5B íŒŒë¼ë¯¸í„° Llama ê¸°ë°˜
   - í…ìŠ¤íŠ¸ë¥¼ ìŒì„± í† í°ìœ¼ë¡œ ë³€í™˜
   - vLLM ìµœì í™”ë¡œ ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›

2. **S3Gen (Speech-to-Sound) ëª¨ë¸**: 
   - ìŒì„± í† í°ì„ ì‹¤ì œ ì˜¤ë””ì˜¤ íŒŒí˜•ìœ¼ë¡œ ë³€í™˜
   - í˜„ì¬ëŠ” ì›ë³¸ êµ¬í˜„ ì‚¬ìš© (ìµœì í™” ì—¬ì§€ ìˆìŒ)

3. **CFG (Classifier-Free Guidance)**:
   - vLLMì—ì„œ ë„¤ì´í‹°ë¸Œ ì§€ì›í•˜ì§€ ì•ŠëŠ” ê¸°ëŠ¥ì„ í•´í‚¹ìœ¼ë¡œ êµ¬í˜„
   - ë”ë¸” ë°°ì¹˜ í¬ê¸°ë¡œ ì²˜ë¦¬í•˜ì—¬ í’ˆì§ˆ í–¥ìƒ

## í™˜ê²½ ì¤€ë¹„ ë° ì„¤ì¹˜

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

```bash
# ê°œë°œí™˜ê²½ ì •ë³´ í™•ì¸
echo "=== ì‹œìŠ¤í…œ ì •ë³´ ==="
sw_vers
echo ""
echo "=== Python ë²„ì „ ==="
python3 --version
echo ""
echo "=== GPU ì •ë³´ (NVIDIA GPU ìˆëŠ” ê²½ìš°) ==="
nvidia-smi 2>/dev/null || echo "NVIDIA GPU ì—†ìŒ (CPU ëª¨ë“œë¡œ ì‹¤í–‰)"
```

**ê¶Œì¥ ì‚¬ì–‘**:
- **GPU**: RTX 3060Ti ì´ìƒ (8GB+ VRAM)
- **ë©”ëª¨ë¦¬**: 16GB+ RAM
- **Python**: 3.8+
- **CUDA**: 11.8+ (GPU ì‚¬ìš© ì‹œ)

### 1. í”„ë¡œì íŠ¸ ì„¤ì •

```bash
# ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p ~/ai-projects/chatterbox-vllm
cd ~/ai-projects/chatterbox-vllm

# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/randombk/chatterbox-vllm.git
cd chatterbox-vllm

# í”„ë¡œì íŠ¸ êµ¬ì¡° í™•ì¸
tree -L 2
```

### 2. Python í™˜ê²½ êµ¬ì„±

```bash
# Python ê°€ìƒí™˜ê²½ ìƒì„±
python3 -m venv chatterbox-env
source chatterbox-env/bin/activate

# ì˜ì¡´ì„± ì„¤ì¹˜ (CUDA í™˜ê²½)
pip install --upgrade pip
pip install -e .

# CPU ì „ìš© í™˜ê²½ì¸ ê²½ìš°
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
```

### 3. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

```bash
# Hugging Face CLI ì„¤ì¹˜ (ì•„ì§ ì—†ëŠ” ê²½ìš°)
pip install huggingface_hub

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
python -c "
from huggingface_hub import snapshot_download
snapshot_download(
    repo_id='chatterbox/chatterbox-vllm',
    local_dir='./models'
)
"
```

## ê¸°ë³¸ ì‚¬ìš©ë²•

### 1. ê°„ë‹¨í•œ TTS ì˜ˆì œ

```python
# example-basic-tts.py
import torch
from chatterbox_vllm import ChatterboxVLLM
import soundfile as sf

def basic_tts_example():
    """ê¸°ë³¸ TTS ì˜ˆì œ"""
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    model = ChatterboxVLLM(
        model_path="./models",
        device="cuda" if torch.cuda.is_available() else "cpu",
        max_model_len=1200,
        gpu_memory_utilization=0.6
    )
    
    # í…ìŠ¤íŠ¸ ì…ë ¥
    text = """
    ì•ˆë…•í•˜ì„¸ìš”! Chatterbox-vLLMì„ ì‚¬ìš©í•œ ìŒì„± í•©ì„± í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.
    ì´ ì‹œìŠ¤í…œì€ vLLMì„ í™œìš©í•˜ì—¬ ë§¤ìš° ë¹ ë¥¸ ì†ë„ë¡œ 
    ê³ í’ˆì§ˆ ìŒì„±ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    
    # ì°¸ì¡° ìŒì„± (ì„ íƒì )
    reference_audio = "./docs/audio-sample-03.mp3"  # ì˜ˆì œ ì˜¤ë””ì˜¤
    
    # TTS ìƒì„±
    print("ğŸ™ï¸ ìŒì„± ìƒì„± ì¤‘...")
    audio_data, sample_rate = model.generate(
        text=text,
        reference_audio=reference_audio,
        temperature=0.8,
        cfg_strength=0.5,
        exaggeration=0.5
    )
    
    # ê²°ê³¼ ì €ì¥
    output_file = "output_basic.wav"
    sf.write(output_file, audio_data, sample_rate)
    print(f"âœ… ìŒì„± íŒŒì¼ ì €ì¥: {output_file}")
    
    return output_file

if __name__ == "__main__":
    basic_tts_example()
```

ì‹¤í–‰:

```bash
# ê¸°ë³¸ ì˜ˆì œ ì‹¤í–‰
python example-basic-tts.py
```

### 2. ë°°ì¹˜ ì²˜ë¦¬ ì˜ˆì œ

```python
# example-batch-tts.py
import torch
from chatterbox_vllm import ChatterboxVLLM
import soundfile as sf
import time

def batch_tts_example():
    """ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ë™ì‹œ ë³€í™˜"""
    
    model = ChatterboxVLLM(
        model_path="./models",
        device="cuda" if torch.cuda.is_available() else "cpu",
        max_model_len=1200,
        gpu_memory_utilization=0.6
    )
    
    # ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ì¤€ë¹„
    texts = [
        "ì²« ë²ˆì§¸ ë¬¸ì¥ì…ë‹ˆë‹¤. ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì¤‘ì…ë‹ˆë‹¤.",
        "ë‘ ë²ˆì§¸ ë¬¸ì¥ì…ë‹ˆë‹¤. vLLMì˜ ì„±ëŠ¥ì„ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.",
        "ì„¸ ë²ˆì§¸ ë¬¸ì¥ì…ë‹ˆë‹¤. ë³‘ë ¬ ì²˜ë¦¬ì˜ íš¨ìœ¨ì„±ì„ ì¸¡ì •í•©ë‹ˆë‹¤.",
        "ë„¤ ë²ˆì§¸ ë¬¸ì¥ì…ë‹ˆë‹¤. Chatterbox-vLLMì€ ì •ë§ ë¹ ë¦…ë‹ˆë‹¤!",
        "ë‹¤ì„¯ ë²ˆì§¸ ë¬¸ì¥ì…ë‹ˆë‹¤. ì‹¤ì‹œê°„ TTSê°€ ê°€ëŠ¥í•  ê²ƒ ê°™ë„¤ìš”."
    ]
    
    print(f"ğŸ“ {len(texts)}ê°œ í…ìŠ¤íŠ¸ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘...")
    start_time = time.time()
    
    # ë°°ì¹˜ ìƒì„±
    audio_results = model.generate_batch(
        texts=texts,
        batch_size=8,  # GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •
        temperature=0.8,
        cfg_strength=0.5
    )
    
    total_time = time.time() - start_time
    
    # ê²°ê³¼ ì €ì¥
    for i, (audio_data, sample_rate) in enumerate(audio_results):
        output_file = f"output_batch_{i+1:02d}.wav"
        sf.write(output_file, audio_data, sample_rate)
        print(f"âœ… ì €ì¥ë¨: {output_file}")
    
    print(f"\nğŸ“Š ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼:")
    print(f"   ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
    print(f"   í…ìŠ¤íŠ¸ë‹¹ í‰ê·  ì‹œê°„: {total_time/len(texts):.2f}ì´ˆ")
    print(f"   ì²˜ë¦¬ëŸ‰: {len(texts)/total_time:.2f} texts/sec")

if __name__ == "__main__":
    batch_tts_example()
```

### 3. Gradio ì›¹ ì¸í„°í˜ì´ìŠ¤

```python
# gradio-app.py
import gradio as gr
import torch
from chatterbox_vllm import ChatterboxVLLM
import tempfile
import soundfile as sf

class ChatterboxWebApp:
    def __init__(self):
        self.model = None
        self.load_model()
    
    def load_model(self):
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            self.model = ChatterboxVLLM(
                model_path="./models",
                device="cuda" if torch.cuda.is_available() else "cpu",
                max_model_len=1200,
                gpu_memory_utilization=0.6
            )
            print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.model = None
    
    def generate_speech(
        self, 
        text, 
        reference_audio, 
        temperature, 
        cfg_strength, 
        exaggeration
    ):
        """ìŒì„± ìƒì„± í•¨ìˆ˜"""
        if not self.model:
            return None, "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        if not text.strip():
            return None, "í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
        
        try:
            # ìŒì„± ìƒì„±
            audio_data, sample_rate = self.model.generate(
                text=text,
                reference_audio=reference_audio,
                temperature=temperature,
                cfg_strength=cfg_strength,
                exaggeration=exaggeration
            )
            
            # ì„ì‹œ íŒŒì¼ ìƒì„±
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
                sf.write(f.name, audio_data, sample_rate)
                return f.name, "âœ… ìŒì„± ìƒì„± ì™„ë£Œ!"
                
        except Exception as e:
            return None, f"âŒ ì˜¤ë¥˜: {str(e)}"
    
    def create_interface(self):
        """Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""
        
        with gr.Blocks(title="Chatterbox-vLLM TTS") as app:
            gr.Markdown("# ğŸ™ï¸ Chatterbox-vLLM TTS ì‹œìŠ¤í…œ")
            gr.Markdown("vLLM ìµœì í™”ëœ ê³ ì† í…ìŠ¤íŠ¸-ìŒì„± ë³€í™˜")
            
            with gr.Row():
                with gr.Column(scale=2):
                    # ì…ë ¥ ì„¹ì…˜
                    text_input = gr.Textbox(
                        label="í…ìŠ¤íŠ¸ ì…ë ¥",
                        placeholder="ë³€í™˜í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”...",
                        lines=5
                    )
                    
                    reference_audio = gr.Audio(
                        label="ì°¸ì¡° ìŒì„± (ì„ íƒì )",
                        type="filepath"
                    )
                    
                    # íŒŒë¼ë¯¸í„° ì¡°ì •
                    with gr.Row():
                        temperature = gr.Slider(
                            minimum=0.1,
                            maximum=2.0,
                            value=0.8,
                            step=0.1,
                            label="Temperature"
                        )
                        cfg_strength = gr.Slider(
                            minimum=0.0,
                            maximum=1.0,
                            value=0.5,
                            step=0.1,
                            label="CFG Strength"
                        )
                        exaggeration = gr.Slider(
                            minimum=0.0,
                            maximum=1.0,
                            value=0.5,
                            step=0.1,
                            label="Exaggeration"
                        )
                    
                    generate_btn = gr.Button(
                        "ğŸ™ï¸ ìŒì„± ìƒì„±", 
                        variant="primary",
                        size="lg"
                    )
                
                with gr.Column(scale=1):
                    # ì¶œë ¥ ì„¹ì…˜
                    output_audio = gr.Audio(
                        label="ìƒì„±ëœ ìŒì„±",
                        type="filepath"
                    )
                    output_message = gr.Textbox(
                        label="ìƒíƒœ",
                        interactive=False
                    )
            
            # ì˜ˆì œ ì„¹ì…˜
            gr.Markdown("## ğŸ“ ì˜ˆì œ í…ìŠ¤íŠ¸")
            examples = gr.Examples(
                examples=[
                    ["ì•ˆë…•í•˜ì„¸ìš”! Chatterbox-vLLM í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤."],
                    ["ì´ ì‹œìŠ¤í…œì€ ë§¤ìš° ë¹ ë¥¸ ì†ë„ë¡œ ê³ í’ˆì§ˆ ìŒì„±ì„ ìƒì„±í•©ë‹ˆë‹¤."],
                    ["vLLM ìµœì í™” ë•ë¶„ì— ì‹¤ì‹œê°„ì— ê°€ê¹Œìš´ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤."],
                ],
                inputs=[text_input]
            )
            
            # ì´ë²¤íŠ¸ ë°”ì¸ë”©
            generate_btn.click(
                fn=self.generate_speech,
                inputs=[
                    text_input,
                    reference_audio,
                    temperature,
                    cfg_strength,
                    exaggeration
                ],
                outputs=[output_audio, output_message]
            )
        
        return app

def main():
    app = ChatterboxWebApp()
    interface = app.create_interface()
    
    # ì„œë²„ ì‹¤í–‰
    interface.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        inbrowser=True
    )

if __name__ == "__main__":
    main()
```

ì›¹ ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰:

```bash
# Gradio ì•± ì‹¤í–‰
python gradio-app.py
```

## ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰

### ë²¤ì¹˜ë§ˆí¬ ìŠ¤í¬ë¦½íŠ¸

```python
# benchmark-test.py
import time
import torch
from chatterbox_vllm import ChatterboxVLLM
import soundfile as sf

def run_benchmark():
    """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
    
    # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ (ê¸´ í…ìŠ¤íŠ¸)
    test_text = """
    ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ë°œì „ì€ ìš°ë¦¬ ì¼ìƒìƒí™œì— í˜ëª…ì ì¸ ë³€í™”ë¥¼ ê°€ì ¸ì˜¤ê³  ìˆìŠµë‹ˆë‹¤. 
    íŠ¹íˆ ìŒì„± í•©ì„± ê¸°ìˆ ì€ êµìœ¡, ì—”í„°í…Œì¸ë¨¼íŠ¸, ì ‘ê·¼ì„± ë„êµ¬ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ 
    í™œìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. Chatterbox-vLLMê³¼ ê°™ì€ ê³ ì„±ëŠ¥ TTS ì‹œìŠ¤í…œì€ 
    ì‹¤ì‹œê°„ ìŒì„± ìƒì„±ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì—¬, ë”ìš± ìì—°ìŠ¤ëŸ¬ìš´ ì¸ê°„-ì»´í“¨í„° ìƒí˜¸ì‘ìš©ì„ 
    ì‹¤í˜„í•˜ê³  ìˆìŠµë‹ˆë‹¤. vLLMì˜ ìµœì í™”ë¥¼ í†µí•´ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ë„ 
    ì‹¤ìš©ì ì¸ ì†ë„ë¡œ ìŒì„± í•©ì„±ì— í™œìš©í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.
    """ * 5  # í…ìŠ¤íŠ¸ ê¸¸ì´ ëŠ˜ë¦¬ê¸°
    
    print("ğŸš€ Chatterbox-vLLM ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
    print(f"ğŸ“ í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(test_text.split())} ë‹¨ì–´")
    print(f"ğŸ”§ GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"ğŸ® GPU: {torch.cuda.get_device_name()}")
        print(f"ğŸ’¾ GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB")
    
    # ëª¨ë¸ ë¡œë“œ ì‹œê°„ ì¸¡ì •
    print("\nâ³ ëª¨ë¸ ë¡œë”© ì¤‘...")
    load_start = time.time()
    
    model = ChatterboxVLLM(
        model_path="./models",
        device="cuda" if torch.cuda.is_available() else "cpu",
        max_model_len=1200,
        gpu_memory_utilization=0.6
    )
    
    load_time = time.time() - load_start
    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {load_time:.2f}ì´ˆ")
    
    # ìŒì„± ìƒì„± ì‹œê°„ ì¸¡ì •
    print("\nğŸ™ï¸ ìŒì„± ìƒì„± ì¤‘...")
    generation_start = time.time()
    
    audio_data, sample_rate = model.generate(
        text=test_text,
        temperature=0.8,
        cfg_strength=0.5,
        exaggeration=0.5
    )
    
    generation_time = time.time() - generation_start
    audio_duration = len(audio_data) / sample_rate
    
    # ê²°ê³¼ ì €ì¥
    output_file = "benchmark_output.wav"
    sf.write(output_file, audio_data, sample_rate)
    
    # ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼:")
    print(f"   ëª¨ë¸ ë¡œë“œ ì‹œê°„: {load_time:.2f}ì´ˆ")
    print(f"   ìŒì„± ìƒì„± ì‹œê°„: {generation_time:.2f}ì´ˆ")
    print(f"   ìƒì„±ëœ ì˜¤ë””ì˜¤ ê¸¸ì´: {audio_duration:.1f}ì´ˆ")
    print(f"   ì‹¤ì‹œê°„ ê³„ìˆ˜: {audio_duration/generation_time:.2f}x")
    print(f"   ì²˜ë¦¬ ì†ë„: {len(test_text.split())/generation_time:.1f} ë‹¨ì–´/ì´ˆ")
    print(f"   ì¶œë ¥ íŒŒì¼: {output_file}")
    
    # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (CUDA ì‚¬ìš© ì‹œ)
    if torch.cuda.is_available():
        memory_used = torch.cuda.max_memory_allocated() / 1e9
        print(f"   ìµœëŒ€ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_used:.2f}GB")

if __name__ == "__main__":
    run_benchmark()
```

ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰:

```bash
# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python benchmark-test.py
```

## ê³ ê¸‰ í™œìš©ë²•

### 1. ì»¤ìŠ¤í…€ ìŒì„± ìŠ¤íƒ€ì¼

```python
# custom-voice-style.py
from chatterbox_vllm import ChatterboxVLLM
import soundfile as sf

def create_custom_voice():
    """ì»¤ìŠ¤í…€ ìŒì„± ìŠ¤íƒ€ì¼ ìƒì„±"""
    
    model = ChatterboxVLLM(model_path="./models")
    
    # ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ ì„¤ì •
    styles = {
        "ë‰´ìŠ¤_ì•µì»¤": {
            "temperature": 0.6,
            "cfg_strength": 0.7,
            "exaggeration": 0.3
        },
        "ë™í™”_ë‚˜ë ˆì´ì…˜": {
            "temperature": 0.9,
            "cfg_strength": 0.5,
            "exaggeration": 0.8
        },
        "êµìœ¡_ê°•ì˜": {
            "temperature": 0.7,
            "cfg_strength": 0.6,
            "exaggeration": 0.4
        }
    }
    
    text = "ì´ê²ƒì€ ìŒì„± ìŠ¤íƒ€ì¼ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤."
    
    for style_name, params in styles.items():
        print(f"ğŸ­ {style_name} ìŠ¤íƒ€ì¼ ìƒì„± ì¤‘...")
        
        audio_data, sample_rate = model.generate(
            text=text,
            **params
        )
        
        output_file = f"voice_style_{style_name}.wav"
        sf.write(output_file, audio_data, sample_rate)
        print(f"âœ… ì €ì¥ë¨: {output_file}")

if __name__ == "__main__":
    create_custom_voice()
```

### 2. ê¸´ í…ìŠ¤íŠ¸ ì²­í‚¹ ì²˜ë¦¬

```python
# long-text-chunking.py
import re
from chatterbox_vllm import ChatterboxVLLM
import soundfile as sf
import numpy as np

def process_long_text(text, max_chunk_length=200):
    """ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬"""
    
    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
    sentences = re.split(r'[.!?]+', text)
    chunks = []
    current_chunk = ""
    
    for sentence in sentences:
        sentence = sentence.strip()
        if not sentence:
            continue
            
        if len(current_chunk) + len(sentence) < max_chunk_length:
            current_chunk += sentence + ". "
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = sentence + ". "
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks

def generate_long_audio():
    """ê¸´ í…ìŠ¤íŠ¸ ì˜¤ë””ì˜¤ ìƒì„±"""
    
    # ê¸´ í…ìŠ¤íŠ¸ ì˜ˆì œ
    long_text = """
    ì¸ê³µì§€ëŠ¥ì˜ ë°œì „ì€ 21ì„¸ê¸° ìµœëŒ€ì˜ ê¸°ìˆ  í˜ëª… ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. 
    ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ ê¸°ìˆ ì˜ ë°œë‹¬ë¡œ ì»´í“¨í„°ëŠ” ì´ì œ ì¸ê°„ì˜ í•™ìŠµ ëŠ¥ë ¥ì„ ëª¨ë°©í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.
    íŠ¹íˆ ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œëŠ” GPT, BERTì™€ ê°™ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ ë“±ì¥í•˜ë©´ì„œ 
    ê¸°ê³„ì™€ ì¸ê°„ì˜ ì˜ì‚¬ì†Œí†µì´ í•œì¸µ ìì—°ìŠ¤ëŸ¬ì›Œì¡ŒìŠµë‹ˆë‹¤.
    
    ìŒì„± ì¸ì‹ê³¼ ìŒì„± í•©ì„± ê¸°ìˆ ë„ ë§ˆì°¬ê°€ì§€ë¡œ ê¸‰ì†í•œ ë°œì „ì„ ì´ë£¨ê³  ìˆìŠµë‹ˆë‹¤.
    ì˜ˆì „ì—ëŠ” ë¡œë´‡ ê°™ì€ ëª©ì†Œë¦¬ì˜€ë˜ TTS ì‹œìŠ¤í…œì´ ì´ì œëŠ” ì‚¬ëŒê³¼ êµ¬ë³„í•˜ê¸° ì–´ë ¤ìš¸ ì •ë„ë¡œ 
    ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„±ì„ ìƒì„±í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.
    
    Chatterbox-vLLMê³¼ ê°™ì€ ì‹œìŠ¤í…œì€ ì´ëŸ¬í•œ ê¸°ìˆ ì  ë°œì „ì˜ ì •ì ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
    vLLMì˜ ìµœì í™”ë¥¼ í†µí•´ ì‹¤ì‹œê°„ì— ê°€ê¹Œìš´ ìŒì„± ìƒì„±ì´ ê°€ëŠ¥í•´ì¡Œê³ ,
    ì´ëŠ” êµìœ¡, ì—”í„°í…Œì¸ë¨¼íŠ¸, ì ‘ê·¼ì„± ë„êµ¬ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í˜ì‹ ì„ ì¼ìœ¼í‚¤ê³  ìˆìŠµë‹ˆë‹¤.
    """
    
    model = ChatterboxVLLM(model_path="./models")
    
    # í…ìŠ¤íŠ¸ ì²­í‚¹
    chunks = process_long_text(long_text, max_chunk_length=150)
    print(f"ğŸ“ í…ìŠ¤íŠ¸ë¥¼ {len(chunks)}ê°œ ì²­í¬ë¡œ ë¶„í• ")
    
    all_audio = []
    sample_rate = None
    
    for i, chunk in enumerate(chunks, 1):
        print(f"ğŸ™ï¸ ì²­í¬ {i}/{len(chunks)} ì²˜ë¦¬ ì¤‘...")
        
        audio_data, sr = model.generate(
            text=chunk,
            temperature=0.8,
            cfg_strength=0.5,
            exaggeration=0.5
        )
        
        all_audio.append(audio_data)
        sample_rate = sr
    
    # ì˜¤ë””ì˜¤ ì—°ê²°
    print("ğŸ”— ì˜¤ë””ì˜¤ ì²­í¬ ë³‘í•© ì¤‘...")
    combined_audio = np.concatenate(all_audio)
    
    # ê²°ê³¼ ì €ì¥
    output_file = "long_text_output.wav"
    sf.write(output_file, combined_audio, sample_rate)
    
    duration = len(combined_audio) / sample_rate
    print(f"âœ… ì™„ë£Œ! ì´ {duration:.1f}ì´ˆ ì˜¤ë””ì˜¤ ìƒì„±")
    print(f"ğŸ“ íŒŒì¼: {output_file}")

if __name__ == "__main__":
    generate_long_audio()
```

## í…ŒìŠ¤íŠ¸ ë° ìµœì í™”

### ìë™í™” í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# test-chatterbox.sh

echo "ğŸ§ª Chatterbox-vLLM í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘"

# ê°€ìƒí™˜ê²½ í™œì„±í™”
source chatterbox-env/bin/activate

# 1. ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
echo "1ï¸âƒ£ ê¸°ë³¸ TTS ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸..."
python example-basic-tts.py
if [ $? -eq 0 ]; then
    echo "âœ… ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ í†µê³¼"
else
    echo "âŒ ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨"
    exit 1
fi

# 2. ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
echo "2ï¸âƒ£ ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸..."
python example-batch-tts.py
if [ $? -eq 0 ]; then
    echo "âœ… ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ í†µê³¼"
else
    echo "âŒ ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨"
    exit 1
fi

# 3. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
echo "3ï¸âƒ£ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬..."
python benchmark-test.py
if [ $? -eq 0 ]; then
    echo "âœ… ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ í†µê³¼"
else
    echo "âŒ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨"
    exit 1
fi

# 4. ê¸´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
echo "4ï¸âƒ£ ê¸´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸..."
python long-text-chunking.py
if [ $? -eq 0 ]; then
    echo "âœ… ê¸´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ í†µê³¼"
else
    echo "âŒ ê¸´ í…ìŠ¤íŠ¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨"
    exit 1
fi

echo "ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!"
echo "ğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:"
ls -la *.wav

# ê²°ê³¼ ìš”ì•½
echo ""
echo "ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:"
echo "   ê¸°ë³¸ TTS: $(ls output_basic.wav 2>/dev/null && echo 'âœ…' || echo 'âŒ')"
echo "   ë°°ì¹˜ ì²˜ë¦¬: $(ls output_batch_*.wav 2>/dev/null && echo 'âœ…' || echo 'âŒ')"
echo "   ë²¤ì¹˜ë§ˆí¬: $(ls benchmark_output.wav 2>/dev/null && echo 'âœ…' || echo 'âŒ')"
echo "   ê¸´ í…ìŠ¤íŠ¸: $(ls long_text_output.wav 2>/dev/null && echo 'âœ…' || echo 'âŒ')"
```

ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬ ë° í…ŒìŠ¤íŠ¸:

```bash
chmod +x test-chatterbox.sh
./test-chatterbox.sh
```

### ì‹¤ì œ macOS í…ŒìŠ¤íŠ¸ ê²°ê³¼

**í…ŒìŠ¤íŠ¸ í™˜ê²½**:
- **OS**: macOS 15.5 (Apple Silicon)
- **Python**: 3.12.8
- **Architecture**: arm64
- **GPU**: NVIDIA GPU ì—†ìŒ (MPS ì‚¬ìš©)

**ì‹¤í–‰ ê²°ê³¼**:
```bash
ğŸ™ï¸ Chatterbox-vLLM í…ŒìŠ¤íŠ¸ ì‹œì‘
================================
[INFO] ì‹œìŠ¤í…œ ì •ë³´ í™•ì¸ ì¤‘...
ğŸ“± OS: macOS 15.5
ğŸ Python: Python 3.12.8
ğŸ’» Architecture: arm64
[WARNING] NVIDIA GPU ê°ì§€ë˜ì§€ ì•ŠìŒ (CPU ëª¨ë“œë¡œ í…ŒìŠ¤íŠ¸)

[INFO] Apple Siliconìš© PyTorch ì„¤ì¹˜ ì¤‘...
âœ… PyTorch 2.7.1 ì„¤ì¹˜ ì™„ë£Œ
âœ… MPS(Metal Performance Shaders) ì§€ì› í™œì„±í™”

[SUCCESS] í™˜ê²½ ì„¤ì • ì™„ë£Œ!
ğŸ“ í”„ë¡œì íŠ¸ ìœ„ì¹˜: ~/ai-projects/chatterbox-vllm-test/chatterbox-vllm
ğŸ ê°€ìƒí™˜ê²½: ~/ai-projects/chatterbox-vllm-test/chatterbox-vllm-env
```

**ì£¼ìš” íŠ¹ì§•**:
- Apple Silicon ë„¤ì´í‹°ë¸Œ ì§€ì›
- MPS(Metal Performance Shaders) ê°€ì† ì‚¬ìš© ê°€ëŠ¥
- CPU ì „ìš© ëª¨ë“œì—ì„œë„ ì •ìƒ ì‘ë™
- ìë™ ì˜ì¡´ì„± ê´€ë¦¬

## ì‹¤ì œ ì„±ëŠ¥ ë¶„ì„

### RTX 3090 ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼

```
ğŸ“Š ì‹¤ì œ ì„±ëŠ¥ ì¸¡ì • ê²°ê³¼ (RTX 3090 ê¸°ì¤€):

ì…ë ¥: 6,600 ë‹¨ì–´ í…ìŠ¤íŠ¸
ì¶œë ¥: 39ë¶„ 50ì´ˆ ì˜¤ë””ì˜¤
ì²˜ë¦¬ ì‹œê°„: 2ë¶„ 30ì´ˆ (133ì´ˆ ìƒì„±)

ìƒì„¸ ë¶„ì„:
- T3 í† í° ìƒì„±: 20.6ì´ˆ (15.5%)
- S3Gen íŒŒí˜• ìƒì„±: 111ì´ˆ (83.5%)
- ê¸°íƒ€ ì²˜ë¦¬: 1.4ì´ˆ (1.0%)

ì²˜ë¦¬ ì†ë„:
- ì‹¤ì‹œê°„ ê³„ìˆ˜: 15.95x (ì‹¤ì‹œê°„ë³´ë‹¤ 15.95ë°° ë¹ ë¦„)
- ë‹¨ì–´/ì´ˆ: 49.6 words/sec
- í† í°/ì´ˆ: 3,060 tokens/sec (ì¶œë ¥ ê¸°ì¤€)
```

### RTX 3060Ti ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼

```
ğŸ“Š ì‹¤ì œ ì„±ëŠ¥ ì¸¡ì • ê²°ê³¼ (RTX 3060Ti ê¸°ì¤€):

ì…ë ¥: 6,600 ë‹¨ì–´ í…ìŠ¤íŠ¸
ì¶œë ¥: 40ë¶„ 15ì´ˆ ì˜¤ë””ì˜¤
ì²˜ë¦¬ ì‹œê°„: 4ë¶„ 26ì´ˆ (238ì´ˆ ìƒì„±)

ìƒì„¸ ë¶„ì„:
- T3 í† í° ìƒì„±: 36.4ì´ˆ (15.3%)
- S3Gen íŒŒí˜• ìƒì„±: 201ì´ˆ (84.5%)
- ê¸°íƒ€ ì²˜ë¦¬: 0.6ì´ˆ (0.2%)

ì²˜ë¦¬ ì†ë„:
- ì‹¤ì‹œê°„ ê³„ìˆ˜: 10.14x (ì‹¤ì‹œê°„ë³´ë‹¤ 10.14ë°° ë¹ ë¦„)
- ë‹¨ì–´/ì´ˆ: 27.7 words/sec
- í† í°/ì´ˆ: 1,655 tokens/sec (ì¶œë ¥ ê¸°ì¤€)
```

## ìµœì í™” íŒ

### 1. GPU ë©”ëª¨ë¦¬ ìµœì í™”

```python
# gpu-optimization.py
import torch
from chatterbox_vllm import ChatterboxVLLM

def optimize_gpu_usage():
    """GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”"""
    
    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì¡°ì • (GPU ìš©ëŸ‰ì— ë”°ë¼)
    gpu_memory_configs = {
        "RTX_4090": {"utilization": 0.8, "max_model_len": 2048},
        "RTX_3090": {"utilization": 0.6, "max_model_len": 1200},
        "RTX_3060Ti": {"utilization": 0.6, "max_model_len": 800},
        "RTX_3060": {"utilization": 0.5, "max_model_len": 600},
    }
    
    # ìë™ GPU ê°ì§€ ë° ì„¤ì •
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name()
        print(f"ğŸ® ê°ì§€ëœ GPU: {gpu_name}")
        
        # GPUë³„ ìµœì  ì„¤ì • ì ìš©
        config = None
        for gpu_type, settings in gpu_memory_configs.items():
            if gpu_type.replace("_", " ") in gpu_name:
                config = settings
                break
        
        if not config:
            # ê¸°ë³¸ ì„¤ì •
            config = {"utilization": 0.5, "max_model_len": 800}
            
        print(f"âš™ï¸ ì ìš©ëœ ì„¤ì •: {config}")
        
        model = ChatterboxVLLM(
            model_path="./models",
            device="cuda",
            gpu_memory_utilization=config["utilization"],
            max_model_len=config["max_model_len"]
        )
        
        return model
    else:
        print("ğŸ’» CPU ëª¨ë“œë¡œ ì‹¤í–‰")
        return ChatterboxVLLM(
            model_path="./models",
            device="cpu"
        )

if __name__ == "__main__":
    model = optimize_gpu_usage()
```

### 2. ë°°ì¹˜ í¬ê¸° ìë™ ì¡°ì •

```python
# auto-batch-sizing.py
import torch
from chatterbox_vllm import ChatterboxVLLM

def find_optimal_batch_size(model, test_texts):
    """ìµœì  ë°°ì¹˜ í¬ê¸° ìë™ íƒìƒ‰"""
    
    batch_sizes = [1, 2, 4, 8, 16, 32]
    best_batch_size = 1
    best_throughput = 0
    
    for batch_size in batch_sizes:
        try:
            print(f"ğŸ§ª ë°°ì¹˜ í¬ê¸° {batch_size} í…ŒìŠ¤íŠ¸ ì¤‘...")
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            # ì„±ëŠ¥ ì¸¡ì •
            import time
            start_time = time.time()
            
            # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
            test_batch = test_texts[:batch_size]
            results = model.generate_batch(
                texts=test_batch,
                batch_size=batch_size
            )
            
            elapsed_time = time.time() - start_time
            throughput = len(test_batch) / elapsed_time
            
            print(f"   ì²˜ë¦¬ëŸ‰: {throughput:.2f} texts/sec")
            
            if throughput > best_throughput:
                best_throughput = throughput
                best_batch_size = batch_size
                
        except torch.cuda.OutOfMemoryError:
            print(f"   âŒ GPU ë©”ëª¨ë¦¬ ë¶€ì¡±")
            break
        except Exception as e:
            print(f"   âŒ ì˜¤ë¥˜: {e}")
            break
    
    print(f"ğŸ† ìµœì  ë°°ì¹˜ í¬ê¸°: {best_batch_size}")
    print(f"ğŸš€ ìµœëŒ€ ì²˜ë¦¬ëŸ‰: {best_throughput:.2f} texts/sec")
    
    return best_batch_size

# ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    model = ChatterboxVLLM(model_path="./models")
    
    test_texts = [
        "í…ŒìŠ¤íŠ¸ ë¬¸ì¥ 1",
        "í…ŒìŠ¤íŠ¸ ë¬¸ì¥ 2", 
        "í…ŒìŠ¤íŠ¸ ë¬¸ì¥ 3",
        # ... ë” ë§ì€ í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
    ] * 10
    
    optimal_batch = find_optimal_batch_size(model, test_texts)
```

## zshrc ë³„ì¹­ ì„¤ì •

```bash
# ~/.zshrcì— ì¶”ê°€í•  ë³„ì¹­ë“¤

# Chatterbox-vLLM í”„ë¡œì íŠ¸ ê´€ë ¨
alias chatterbox="cd ~/ai-projects/chatterbox-vllm && source chatterbox-env/bin/activate"
alias cb-test="cd ~/ai-projects/chatterbox-vllm && ./test-chatterbox.sh"
alias cb-bench="cd ~/ai-projects/chatterbox-vllm && python benchmark-test.py"
alias cb-gradio="cd ~/ai-projects/chatterbox-vllm && python gradio-app.py"

# TTS ê´€ë ¨ ìœ í‹¸ë¦¬í‹°
alias tts-basic="python example-basic-tts.py"
alias tts-batch="python example-batch-tts.py"
alias tts-long="python long-text-chunking.py"

# GPU ëª¨ë‹ˆí„°ë§
alias gpu-status="nvidia-smi"
alias gpu-watch="watch -n 1 nvidia-smi"

# ì˜¤ë””ì˜¤ ì¬ìƒ (macOS)
alias play-audio="afplay"
alias cb-play="afplay *.wav"

# ê°œë°œí™˜ê²½ ì •ë³´
alias py-version="python --version && pip --version"
alias torch-info="python -c 'import torch; print(f\"PyTorch: {torch.__version__}\"); print(f\"CUDA: {torch.cuda.is_available()}\")'"
```

ì„¤ì • ì ìš©:

```bash
# zshrc ë¦¬ë¡œë“œ
source ~/.zshrc

# ì‚¬ìš© ì˜ˆì œ
chatterbox          # í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™ & ê°€ìƒí™˜ê²½ í™œì„±í™”
cb-test            # ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
cb-bench           # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
cb-gradio          # ì›¹ ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰
```

## ë¬¸ì œ í•´ê²°

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œë“¤

#### 1. CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±

```bash
# í•´ê²° ë°©ë²•
echo "CUDA_VISIBLE_DEVICES=0" >> ~/.zshrc
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
```

#### 2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨

```bash
# ëŒ€ì•ˆ ë‹¤ìš´ë¡œë“œ ë°©ë²•
git lfs pull
huggingface-cli download chatterbox/chatterbox-vllm --local-dir ./models
```

#### 3. ì˜ì¡´ì„± ì¶©ëŒ

```bash
# ìƒˆë¡œìš´ ê°€ìƒí™˜ê²½ìœ¼ë¡œ ì¬ì„¤ì¹˜
rm -rf chatterbox-env
python3 -m venv chatterbox-env-new
source chatterbox-env-new/bin/activate
pip install --upgrade pip
pip install -e .
```

## ê²°ë¡ 

Chatterbox-vLLMì€ **vLLM ìµœì í™”ë¥¼ í†µí•œ í˜ì‹ ì ì¸ TTS ì„±ëŠ¥**ì„ ì œê³µí•˜ëŠ” ë†€ë¼ìš´ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì£¼ìš” ì„±ê³¼ë¥¼ ìš”ì•½í•˜ë©´:

### ğŸš€ í•µì‹¬ ì„±ëŠ¥ ì§€í‘œ
- **RTX 3090**: ì‹¤ì‹œê°„ ëŒ€ë¹„ **15.95ë°° ë¹ ë¥¸** ìŒì„± ìƒì„±
- **RTX 3060Ti**: ì‹¤ì‹œê°„ ëŒ€ë¹„ **10.14ë°° ë¹ ë¥¸** ìŒì„± ìƒì„±  
- **ë°°ì¹˜ ì²˜ë¦¬**: ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ë™ì‹œ ì²˜ë¦¬ë¡œ íš¨ìœ¨ì„± ê·¹ëŒ€í™”
- **í’ˆì§ˆ ìœ ì§€**: ì†ë„ í–¥ìƒì—ë„ ë¶ˆêµ¬í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± í’ˆì§ˆ

### ğŸ’¡ í™œìš© ë¶„ì•¼
- **ì½˜í…ì¸  ì œì‘**: íŒŸìºìŠ¤íŠ¸, ì˜¤ë””ì˜¤ë¶ ìë™ ìƒì„±
- **êµìœ¡ í”Œë«í¼**: ì‹¤ì‹œê°„ ìŒì„± ê°•ì˜ ì‹œìŠ¤í…œ
- **ì ‘ê·¼ì„± ë„êµ¬**: ì‹œê° ì¥ì• ì¸ì„ ìœ„í•œ í™”ë©´ ì½ê¸°
- **ê³ ê° ì„œë¹„ìŠ¤**: ìë™ ì‘ë‹µ ì‹œìŠ¤í…œ

### ğŸ”® í–¥í›„ ê°œì„  ë°©í–¥
- **S3Gen ìµœì í™”**: í˜„ì¬ ë³‘ëª©ì¸ íŒŒí˜• ìƒì„± ë¶€ë¶„ ê°œì„ 
- **ë‹¤êµ­ì–´ ì§€ì›**: í•œêµ­ì–´ ì™¸ ì–¸ì–´ ëª¨ë¸ ì¶”ê°€
- **ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°**: ì²­í¬ë³„ ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë°
- **ìŒì„± í´ë¡œë‹**: ê°œì¸í™”ëœ ìŒì„± ìƒì„± ê¸°ëŠ¥

Chatterbox-vLLMì„ í†µí•´ **ì°¨ì„¸ëŒ€ TTS ì‹œìŠ¤í…œ**ì˜ ê°€ëŠ¥ì„±ì„ ì§ì ‘ ì²´í—˜í•´ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤. ë¹ ë¥¸ ì†ë„ì™€ ë†’ì€ í’ˆì§ˆì„ ë™ì‹œì— ë‹¬ì„±í•œ ì´ ê¸°ìˆ ì€ AI ìŒì„± í•©ì„± ë¶„ì•¼ì˜ ìƒˆë¡œìš´ ê¸°ì¤€ì´ ë  ê²ƒì…ë‹ˆë‹¤! ğŸ™ï¸âœ¨

---

> **ì°¸ê³  ìë£Œ**
> - [Chatterbox-vLLM GitHub Repository](https://github.com/randombk/chatterbox-vllm)
> - vLLM ê³µì‹ ë¬¸ì„œ
> - PyTorch CUDA ìµœì í™” ê°€ì´ë“œ
> - Gradio ì¸í„°í˜ì´ìŠ¤ ë¬¸ì„œ