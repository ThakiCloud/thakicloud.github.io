---
title: "NVIDIA OpenCodeReasoning: ê²½ìŸ í”„ë¡œê·¸ë˜ë°ì„ ìœ„í•œ ìµœëŒ€ ê·œëª¨ ì¶”ë¡  ê¸°ë°˜ ì½”ë”© ë°ì´í„°ì…‹"
excerpt: "735K ìƒ˜í”Œê³¼ 28K ë¬¸ì œë¡œ êµ¬ì„±ëœ OpenCodeReasoning ì™„ì „ ë¶„ì„ - R1 ëª¨ë¸ ê¸°ë°˜ í•©ì„± ë°ì´í„°, 10ê°œ ì£¼ìš” í”Œë«í¼ í†µí•©, SFT ìµœì í™”"
date: 2025-06-18
categories: 
  - datasets
  - llmops
tags: 
  - nvidia
  - opencode-reasoning
  - competitive-programming
  - synthetic-dataset
  - code-generation
  - r1-model
  - supervised-fine-tuning
  - codeforces
  - leetcode
  - cc-by-4.0
author_profile: true
toc: true
toc_label: "OpenCodeReasoning ê°€ì´ë“œ"
---

## ê°œìš”

**NVIDIA OpenCodeReasoning**ì€ ê²½ìŸ í”„ë¡œê·¸ë˜ë°ì„ ìœ„í•œ **í˜„ì¬ê¹Œì§€ ê°€ì¥ í° ì¶”ë¡  ê¸°ë°˜ í•©ì„± ë°ì´í„°ì…‹**ì…ë‹ˆë‹¤. **735,255ê°œ ìƒ˜í”Œ**ê³¼ **28,319ê°œ ê³ ìœ  ë¬¸ì œ**ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, **Python ì–¸ì–´**ì— íŠ¹í™”ë˜ì–´ **ì§€ë„ í•™ìŠµ(SFT)**ìš©ìœ¼ë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

ì´ ë°ì´í„°ì…‹ì€ **R1 ëª¨ë¸**ì— ì˜í•´ ìƒì„±ëœ ê³ í’ˆì§ˆ ì¶”ë¡  ê¸°ë°˜ ì‘ë‹µì„ í¬í•¨í•˜ë©°, **CodeForces, LeetCode, CodeChef** ë“± **10ê°œ ì£¼ìš” ê²½ìŸ í”„ë¡œê·¸ë˜ë° í”Œë«í¼**ì˜ ë¬¸ì œë“¤ì„ í†µí•©í–ˆìŠµë‹ˆë‹¤. **CC BY 4.0 ë¼ì´ì„¼ìŠ¤**ë¡œ ì œê³µë˜ì–´ ìƒì—…ì /ë¹„ìƒì—…ì  ìš©ë„ ëª¨ë‘ì—ì„œ ììœ ë¡­ê²Œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ë°ì´í„°ì…‹ ê·œëª¨ ë° êµ¬ì„±

### ì „ì²´ í†µê³„

| **í•­ëª©** | **ìˆ˜ëŸ‰** | **ì„¤ëª…** |
|---|---|---|
| **ì´ ìƒ˜í”Œ ìˆ˜** | **735,255ê°œ** | R1 ëª¨ë¸ì´ ìƒì„±í•œ ì¶”ë¡  ê¸°ë°˜ ì†”ë£¨ì…˜ |
| **ê³ ìœ  ë¬¸ì œ ìˆ˜** | **28,319ê°œ** | ê²½ìŸ í”„ë¡œê·¸ë˜ë° ë¬¸ì œ |
| **ì§€ì› ì–¸ì–´** | **Python** | ë‹¨ì¼ ì–¸ì–´ë¡œ ì§‘ì¤‘ |
| **ë°ì´í„° ë¶„í• ** | **2ê°œ ìŠ¤í”Œë¦¿** | split_0, split_1 |
| **íŒŒì¼ í¬ê¸°** | **100K-1M** | íš¨ìœ¨ì ì¸ Parquet í˜•ì‹ |

### í”Œë«í¼ë³„ ë°ì´í„° ë¶„í¬

| **ì†ŒìŠ¤** | **ë¬¸ì œ ìˆ˜** | **ìƒ˜í”Œ ìˆ˜** | **ë¹„ìœ¨** |
|---|---|---|---|
| **CodeForces** | **10,069** | **386,948** | **52.6%** |
| **CodeChef** | 3,796 | 72,925 | 9.9% |
| **AIZU** | 2,123 | 62,476 | 8.5% |
| **HackerEarth** | 2,269 | 59,181 | 8.0% |
| **AtCoder** | 2,043 | 47,222 | 6.4% |
| **GeeksForGeeks** | 2,667 | 37,602 | 5.1% |
| **Codewars** | 2,493 | 34,326 | 4.7% |
| **Kattis** | 1,187 | 13,095 | 1.8% |
| **HackerRank** | 895 | 10,955 | 1.5% |
| **LeetCode** | 777 | 10,525 | 1.4% |

### ë°ì´í„° ì†ŒìŠ¤ ìƒì„¸

**ì›ë³¸ ë°ì´í„°ì…‹ ì»¬ë ‰ì…˜**:
- [TACO](https://huggingface.co/datasets/BAAI/TACO)
- [APPS](https://huggingface.co/datasets/codeparrot/apps)
- [CodeContests](https://huggingface.co/datasets/deepmind/code_contests)
- [open-r1/codeforces](https://huggingface.co/datasets/open-r1/codeforces)

**ì œì™¸ì‚¬í•­**:
- CodeContestsì™€ open-r1/codeforcesì˜ í…ŒìŠ¤íŠ¸ ìŠ¤í”Œë¦¿ ì œì™¸
- ë°ì´í„° ì˜¤ì—¼ ë°©ì§€ë¥¼ ìœ„í•œ ì—„ê²©í•œ ë¶„ë¦¬

## ë°ì´í„° í•„ë“œ êµ¬ì¡°

### ì£¼ìš” í•„ë“œ ì„¤ëª…

```json
{
  "id": "ë¬¸ì œë³„ ê³ ìœ  ì‹ë³„ì",
  "input": "ê²½ìŸ í”„ë¡œê·¸ë˜ë° ë¬¸ì œ ì„¤ëª… (split_0ë§Œ í•´ë‹¹)",
  "output": "R1 ëª¨ë¸ì˜ ì™„ì „í•œ ì¶”ë¡  ì‘ë‹µ",
  "solution": "R1 ì‘ë‹µì—ì„œ ì¶”ì¶œí•œ ì½”ë“œ ë¶€ë¶„ë§Œ",
  "dataset": "ì›ë³¸ ë°ì´í„°ì…‹ëª… (ì˜ˆ: apps, taco, code_contests)",
  "license": "ë°ì´í„°ì…‹ ë¼ì´ì„¼ìŠ¤ (ì˜ˆ: mit, apache-2.0, cc-by-4.0)",
  "split": "ì›ë³¸ ë°ì´í„°ì…‹ì˜ ë¶„í• ëª… (ì˜ˆ: train, valid, test)",
  "source": "ê²½ìŸ í”„ë¡œê·¸ë˜ë° í”Œë«í¼ëª… (ì˜ˆ: CodeForces, CodeChef)",
  "difficulty": "ë¬¸ì œ ë‚œì´ë„ ë ˆì´ë¸”",
  "index": "APPS/TACO ë°ì´í„°ì…‹ì—ì„œ ë¬¸ì œ ê²€ìƒ‰ìš© ì¸ë±ìŠ¤ (split_1ë§Œ)"
}
```

### ìŠ¤í”Œë¦¿ êµ¬ì¡°

#### Split_0 (567,850 ìƒ˜í”Œ)
- **ì™„ì „í•œ ë¬¸ì œ ì„¤ëª…** í¬í•¨
- ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ í˜•íƒœ
- ì§ì ‘ì ì¸ SFT í›ˆë ¨ í™œìš©

#### Split_1 (167,405 ìƒ˜í”Œ)
- **ì°¸ì¡° ê¸°ë°˜ êµ¬ì¡°** (input = "-")
- TACO/APPS ë°ì´í„°ì…‹ì—ì„œ ë³„ë„ ë¡œë“œ í•„ìš”
- ì €ì¥ ê³µê°„ íš¨ìœ¨ì„± ìµœì í™”

## ì‚¬ìš© ë°©ë²• ë° ì‹¤ìŠµ

### ê¸°ë³¸ ë°ì´í„° ë¡œë“œ

```python
from datasets import load_dataset
from tqdm import tqdm

# Split_0 ë¡œë“œ (ì™„ì „í•œ ë¬¸ì œ í¬í•¨)
ocr_split_0 = load_dataset("nvidia/OpenCodeReasoning", "split_0")
print(f"Split_0 ìƒ˜í”Œ ìˆ˜: {len(ocr_split_0['split_0'])}")

# Split_1 ë¡œë“œ (ì°¸ì¡° ê¸°ë°˜)
ocr_split_1 = load_dataset("nvidia/OpenCodeReasoning", "split_1")
print(f"Split_1 ìƒ˜í”Œ ìˆ˜: {len(ocr_split_1['split_1'])}")
```

### Split_1 ë¬¸ì œ ë‚´ìš© ë³µì›

```python
# ì°¸ì¡° ë°ì´í„°ì…‹ ë¡œë“œ
reference_datasets = {
    "taco": load_dataset("BAAI/TACO"),
    "apps": load_dataset("codeparrot/apps")
}

# Split_1 ë¬¸ì œ ë‚´ìš© ë³µì›
def restore_split_1_problems(split_1_data):
    restored_data = []
    
    for item in tqdm(split_1_data["split_1"]):
        # ì…ë ¥ì´ "-"ì¸ì§€ í™•ì¸
        assert item["input"] == "-"
        assert item["dataset"] in ["taco", "apps"]
        
        # ì›ë³¸ ë°ì´í„°ì…‹ì—ì„œ ë¬¸ì œ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
        original_dataset = reference_datasets[item["dataset"]]
        question = original_dataset[item["split"]][int(item["index"])]["question"]
        
        # ë¬¸ì œ ë‚´ìš© ë³µì›
        restored_item = item.copy()
        restored_item["input"] = question
        restored_data.append(restored_item)
    
    return restored_data

# ë³µì› ì‹¤í–‰
restored_split_1 = restore_split_1_problems(ocr_split_1)
```

### í”Œë«í¼ë³„ ë°ì´í„° ë¶„ì„

```python
# í”Œë«í¼ë³„ í†µê³„ ë¶„ì„
def analyze_platform_distribution(dataset):
    platform_stats = {}
    
    for item in dataset:
        platform = item['source']
        difficulty = item['difficulty']
        
        if platform not in platform_stats:
            platform_stats[platform] = {
                'total': 0,
                'difficulties': {}
            }
        
        platform_stats[platform]['total'] += 1
        
        if difficulty not in platform_stats[platform]['difficulties']:
            platform_stats[platform]['difficulties'][difficulty] = 0
        platform_stats[platform]['difficulties'][difficulty] += 1
    
    return platform_stats

# ë¶„ì„ ì‹¤í–‰
stats = analyze_platform_distribution(ocr_split_0['split_0'])

# ê²°ê³¼ ì¶œë ¥
for platform, data in stats.items():
    print(f"\n{platform}: {data['total']} ìƒ˜í”Œ")
    for diff, count in data['difficulties'].items():
        print(f"  - {diff}: {count} ê°œ")
```

## R1 ëª¨ë¸ ê¸°ë°˜ ì¶”ë¡  ìƒì„±

### ì¶”ë¡  í’ˆì§ˆ íŠ¹ì§•

**R1 ëª¨ë¸ì˜ ì¶”ë¡  íŠ¹ì„±**:
1. **ë‹¨ê³„ë³„ ì‚¬ê³  ê³¼ì •** ëª…ì‹œ
2. **ë¬¸ì œ ë¶„ì„ê³¼ í•´ê²° ì „ëµ** ì„¤ëª…
3. **ì½”ë“œ êµ¬í˜„ê³¼ ê²€ì¦** ê³¼ì • í¬í•¨
4. **ì—£ì§€ ì¼€ì´ìŠ¤ ê³ ë ¤** ë° ìµœì í™”

### ì¶”ë¡  ì‘ë‹µ êµ¬ì¡° ì˜ˆì‹œ

```python
# R1 ìƒì„± ì‘ë‹µ ì˜ˆì‹œ êµ¬ì¡°
sample_output = """
ë¬¸ì œ ë¶„ì„:
ì´ ë¬¸ì œëŠ” ë°°ì—´ì—ì„œ ìµœëŒ€ ë¶€ë¶„ ë°°ì—´ì˜ í•©ì„ êµ¬í•˜ëŠ” ë¬¸ì œì…ë‹ˆë‹¤.
ì¹´ë°ì¸ ì•Œê³ ë¦¬ì¦˜(Kadane's Algorithm)ì„ ì‚¬ìš©í•˜ì—¬ O(n) ì‹œê°„ì— í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

í•´ê²° ì „ëµ:
1. í˜„ì¬ê¹Œì§€ì˜ ìµœëŒ€ í•©ì„ ì¶”ì 
2. ê° ì›ì†Œì—ì„œ ìƒˆë¡œ ì‹œì‘í• ì§€ ì´ì–´ê°ˆì§€ ê²°ì •
3. ì „ì²´ ìµœëŒ€ê°’ ì—…ë°ì´íŠ¸

ì½”ë“œ êµ¬í˜„:
```python
def max_subarray_sum(arr):
    if not arr:
        return 0
    
    max_sum = current_sum = arr[0]
    
    for i in range(1, len(arr)):
        # ìƒˆë¡œ ì‹œì‘í•˜ê±°ë‚˜ ì´ì–´ì„œ ì§„í–‰
        current_sum = max(arr[i], current_sum + arr[i])
        max_sum = max(max_sum, current_sum)
    
    return max_sum
```

ì‹œê°„ ë³µì¡ë„: O(n)
ê³µê°„ ë³µì¡ë„: O(1)

í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ê²€ì¦:
- ì…ë ¥: [-2, 1, -3, 4, -1, 2, 1, -5, 4]
- ì¶œë ¥: 6 (ë¶€ë¶„ ë°°ì—´ [4, -1, 2, 1])
"""
```

## ë°ì´í„° í’ˆì§ˆ ë° íŠ¹ì„±

### í’ˆì§ˆ ê´€ë¦¬ ê³¼ì •

1. **ì›ë³¸ ë°ì´í„° ê²€ì¦**
   - 10ê°œ ì£¼ìš” í”Œë«í¼ì—ì„œ ê²€ì¦ëœ ë¬¸ì œ
   - ì¤‘ë³µ ë¬¸ì œ ì œê±° ë° ì •ê·œí™”
   - ë‚œì´ë„ë³„ ê· í˜• ìˆëŠ” ë¶„í¬

2. **R1 ëª¨ë¸ ìƒì„± í’ˆì§ˆ**
   - ë…¼ë¦¬ì  ì¼ê´€ì„± ê²€ì¦
   - ì½”ë“œ ì‹¤í–‰ ê°€ëŠ¥ì„± í™•ì¸
   - ì¶”ë¡  ê³¼ì •ì˜ ëª…í™•ì„± í‰ê°€

3. **ë¼ì´ì„¼ìŠ¤ í˜¸í™˜ì„±**
   - ê° í”Œë«í¼ë³„ ë¼ì´ì„¼ìŠ¤ í™•ì¸
   - ìƒì—…ì  ì‚¬ìš© ê°€ëŠ¥ì„± ê²€í† 
   - ì¬ë°°í¬ ì¡°ê±´ ëª…ì‹œ

### ë‚œì´ë„ ë¶„í¬ ë¶„ì„

```python
# ë‚œì´ë„ë³„ ë¶„í¬ ì‹œê°í™”
def analyze_difficulty_distribution(dataset):
    difficulty_counts = {}
    
    for item in dataset:
        difficulty = item['difficulty']
        if difficulty not in difficulty_counts:
            difficulty_counts[difficulty] = 0
        difficulty_counts[difficulty] += 1
    
    # ì •ë ¬ëœ ê²°ê³¼ ë°˜í™˜
    return sorted(difficulty_counts.items(), key=lambda x: x[1], reverse=True)

# ì‹¤í–‰ ë° ì¶œë ¥
diff_stats = analyze_difficulty_distribution(ocr_split_0['split_0'])
print("ë‚œì´ë„ë³„ ë¶„í¬:")
for difficulty, count in diff_stats:
    percentage = (count / len(ocr_split_0['split_0'])) * 100
    print(f"- {difficulty}: {count:,} ê°œ ({percentage:.1f}%)")
```

## í™œìš© ì‚¬ë¡€ ë° ì‘ìš©

### SFT ëª¨ë¸ í›ˆë ¨

```python
# SFT í›ˆë ¨ì„ ìœ„í•œ ë°ì´í„° ì „ì²˜ë¦¬
def prepare_sft_data(dataset):
    sft_samples = []
    
    for item in dataset:
        # í‘œì¤€ í”„ë¡¬í”„íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        prompt = f"ë‹¤ìŒ í”„ë¡œê·¸ë˜ë° ë¬¸ì œë¥¼ í•´ê²°í•˜ì„¸ìš”:\n\n{item['input']}"
        response = item['output']
        
        sft_sample = {
            'prompt': prompt,
            'response': response,
            'metadata': {
                'source': item['source'],
                'difficulty': item['difficulty'],
                'dataset': item['dataset']
            }
        }
        sft_samples.append(sft_sample)
    
    return sft_samples

# SFT ë°ì´í„° ì¤€ë¹„
sft_data = prepare_sft_data(ocr_split_0['split_0'])
print(f"SFT í›ˆë ¨ ìƒ˜í”Œ ì¤€ë¹„ ì™„ë£Œ: {len(sft_data)} ê°œ")
```

### ì½”ë“œ ìƒì„± ëª¨ë¸ í‰ê°€

```python
# ìƒì„±ëœ ì½”ë“œ í’ˆì§ˆ í‰ê°€
def evaluate_code_quality(dataset, sample_size=100):
    import ast
    import random
    
    samples = random.sample(list(dataset), sample_size)
    
    quality_metrics = {
        'syntactically_valid': 0,
        'has_main_function': 0,
        'handles_input': 0,
        'has_comments': 0
    }
    
    for item in samples:
        solution = item['solution']
        
        try:
            # êµ¬ë¬¸ ìœ íš¨ì„± ê²€ì‚¬
            ast.parse(solution)
            quality_metrics['syntactically_valid'] += 1
        except SyntaxError:
            continue
            
        # ì¶”ê°€ í’ˆì§ˆ ì§€í‘œ ê²€ì‚¬
        if 'def ' in solution:
            quality_metrics['has_main_function'] += 1
        if 'input()' in solution or 'sys.stdin' in solution:
            quality_metrics['handles_input'] += 1
        if '#' in solution:
            quality_metrics['has_comments'] += 1
    
    # ë°±ë¶„ìœ¨ë¡œ ë³€í™˜
    for metric in quality_metrics:
        quality_metrics[metric] = (quality_metrics[metric] / sample_size) * 100
    
    return quality_metrics

# í’ˆì§ˆ í‰ê°€ ì‹¤í–‰
quality_report = evaluate_code_quality(ocr_split_0['split_0'])
print("ì½”ë“œ í’ˆì§ˆ í‰ê°€ ê²°ê³¼:")
for metric, percentage in quality_report.items():
    print(f"- {metric}: {percentage:.1f}%")
```

## OpenCodeReasoning ëª¨ë¸ ì‹œë¦¬ì¦ˆ

### ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸

NVIDIAëŠ” ì´ ë°ì´í„°ì…‹ì„ ê¸°ë°˜ìœ¼ë¡œ ì—¬ëŸ¬ ëª¨ë¸ì„ ê³µê°œí–ˆìŠµë‹ˆë‹¤:

| **ëª¨ë¸** | **í¬ê¸°** | **ì£¼ìš” íŠ¹ì§•** |
|---|---|---|
| [OpenCodeReasoning-Nemotron-7B](https://huggingface.co/nvidia/OpenCodeReasoning-Nemotron-7B) | 7B | íš¨ìœ¨ì ì¸ ì¤‘ê¸‰ í¬ê¸° ëª¨ë¸ |
| [OpenCodeReasoning-Nemotron-32B](https://huggingface.co/nvidia/OpenCodeReasoning-Nemotron-32B) | 32B | ìµœê³  ì„±ëŠ¥ ëŒ€í˜• ëª¨ë¸ |

### ì»¤ë®¤ë‹ˆí‹° íŒŒì¸ íŠœë‹ ëª¨ë¸

**218ê°œ ì´ìƒì˜ íŒŒìƒ ëª¨ë¸**ì´ ì´ ë°ì´í„°ì…‹ìœ¼ë¡œ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤:

- **SVECTOR-CORPORATION/Spec-Coder-4b-V1**: 11.3K ë‹¤ìš´ë¡œë“œ
- **Mungert/OpenCodeReasoning-Nemotron-32B-IOI-GGUF**: GGUF ì–‘ìí™” ë²„ì „
- **ertghiu256/qwen3-4b-code-reasoning**: Qwen ê¸°ë°˜ íŒŒì¸íŠœë‹

## ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­

### ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

```python
# ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì˜ˆì‹œ
class OpenCodeReasoningProcessor:
    def __init__(self):
        self.platforms = [
            'CodeForces', 'CodeChef', 'LeetCode', 'AtCoder',
            'HackerRank', 'HackerEarth', 'AIZU', 'Kattis',
            'Codewars', 'GeeksForGeeks'
        ]
    
    def load_raw_problems(self):
        """ì›ë³¸ ë¬¸ì œ ë°ì´í„° ë¡œë“œ"""
        problems = {}
        for platform in self.platforms:
            problems[platform] = self.fetch_platform_problems(platform)
        return problems
    
    def generate_solutions_with_r1(self, problems):
        """R1 ëª¨ë¸ë¡œ ì†”ë£¨ì…˜ ìƒì„±"""
        solutions = []
        for platform, problem_list in problems.items():
            for problem in problem_list:
                solution = self.r1_generate_solution(problem)
                solutions.append({
                    'problem': problem,
                    'solution': solution,
                    'platform': platform
                })
        return solutions
    
    def quality_filter(self, solutions):
        """í’ˆì§ˆ í•„í„°ë§ ì ìš©"""
        filtered = []
        for item in solutions:
            if self.validate_solution(item['solution']):
                filtered.append(item)
        return filtered
    
    def export_to_parquet(self, data, filename):
        """Parquet í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        import pandas as pd
        df = pd.DataFrame(data)
        df.to_parquet(filename, compression='snappy')

# ì‚¬ìš© ì˜ˆì‹œ
processor = OpenCodeReasoningProcessor()
# raw_problems = processor.load_raw_problems()
# solutions = processor.generate_solutions_with_r1(raw_problems)
# filtered_solutions = processor.quality_filter(solutions)
# processor.export_to_parquet(filtered_solutions, 'opencode_reasoning.parquet')
```

### ì €ì¥ í˜•ì‹ ë° ìµœì í™”

- **í˜•ì‹**: Parquet with Snappy ì••ì¶•
- **ìŠ¤í‚¤ë§ˆ**: Apache Arrow í˜¸í™˜
- **ì••ì¶•ë¥ **: ì•½ 60-70% í¬ê¸° ì ˆì•½
- **ì ‘ê·¼ ì„±ëŠ¥**: ì»¬ëŸ¼í˜• ì €ì¥ìœ¼ë¡œ ë¹ ë¥¸ ì¿¼ë¦¬

## ë¼ì´ì„¼ìŠ¤ ë° ì‚¬ìš© ì¡°ê±´

### CC BY 4.0 ë¼ì´ì„¼ìŠ¤

**í—ˆìš©ì‚¬í•­**:
- âœ… **ìƒì—…ì  ì‚¬ìš©**: ììœ ë¡œìš´ ìƒì—…ì  í™œìš©
- âœ… **ìˆ˜ì •**: ë°ì´í„° ë³€ê²½ ë° ê°€ê³µ ê°€ëŠ¥
- âœ… **ë°°í¬**: ì›ë³¸ ë° ìˆ˜ì •ë³¸ ì¬ë°°í¬ í—ˆìš©
- âœ… **ì‚¬ì  ì‚¬ìš©**: ê°œì¸/ì¡°ì§ ë‚´ë¶€ ì‚¬ìš©

**ì˜ë¬´ì‚¬í•­**:
- ğŸ“ **ì €ì‘ì í‘œì‹œ**: NVIDIA ê°œë°œì ëª…ì‹œ í•„ìš”
- ğŸ“ **ë¼ì´ì„¼ìŠ¤ ê³ ì§€**: CC BY 4.0 ë¼ì´ì„¼ìŠ¤ í‘œì‹œ
- ğŸ“ **ë³€ê²½ì‚¬í•­ í‘œì‹œ**: ìˆ˜ì • ì‹œ ë³€ê²½ì‚¬í•­ ëª…ì‹œ

### ê°œë³„ ë°ì´í„°ì…‹ ë¼ì´ì„¼ìŠ¤ ì£¼ì˜ì‚¬í•­

**ì¤‘ìš”**: ê° ì›ë³¸ ë°ì´í„°ì…‹ì˜ ë¼ì´ì„¼ìŠ¤ë„ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤:

```python
# ë¼ì´ì„¼ìŠ¤ í™•ì¸ ì½”ë“œ
def check_dataset_licenses(dataset):
    license_distribution = {}
    
    for item in dataset:
        license_type = item['license']
        dataset_name = item['dataset']
        
        if license_type not in license_distribution:
            license_distribution[license_type] = []
        
        if dataset_name not in license_distribution[license_type]:
            license_distribution[license_type].append(dataset_name)
    
    return license_distribution

# ë¼ì´ì„¼ìŠ¤ ë¶„í¬ í™•ì¸
licenses = check_dataset_licenses(ocr_split_0['split_0'])
print("ë°ì´í„°ì…‹ë³„ ë¼ì´ì„¼ìŠ¤ ë¶„í¬:")
for license_type, datasets in licenses.items():
    print(f"- {license_type}: {', '.join(datasets)}")
```

## ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹

### í‰ê°€ ë©”íŠ¸ë¦­

1. **ì½”ë“œ ì •í™•ì„±**: í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ í†µê³¼ìœ¨
2. **ì¶”ë¡  í’ˆì§ˆ**: ì„¤ëª…ì˜ ë…¼ë¦¬ì  ì¼ê´€ì„±
3. **ì‹¤í–‰ íš¨ìœ¨ì„±**: ì‹œê°„/ê³µê°„ ë³µì¡ë„ ìµœì í™”
4. **ê°€ë…ì„±**: ì½”ë“œ ìŠ¤íƒ€ì¼ ë° ì£¼ì„ í’ˆì§ˆ

### ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì˜ˆì‹œ

```python
# ì„±ëŠ¥ í‰ê°€ í”„ë ˆì„ì›Œí¬
class CodeReasoningEvaluator:
    def __init__(self, dataset):
        self.dataset = dataset
        self.test_cases = self.prepare_test_cases()
    
    def evaluate_correctness(self, model_output, expected_output):
        """ì½”ë“œ ì •í™•ì„± í‰ê°€"""
        try:
            # ì½”ë“œ ì‹¤í–‰ ë° ê²°ê³¼ ë¹„êµ
            result = self.execute_code(model_output)
            return result == expected_output
        except Exception as e:
            return False
    
    def evaluate_reasoning_quality(self, reasoning_text):
        """ì¶”ë¡  í’ˆì§ˆ í‰ê°€"""
        quality_score = 0
        
        # ë‹¨ê³„ë³„ ì„¤ëª… ì¡´ì¬ ì—¬ë¶€
        if "ë‹¨ê³„" in reasoning_text or "Step" in reasoning_text:
            quality_score += 25
        
        # ë³µì¡ë„ ë¶„ì„ í¬í•¨ ì—¬ë¶€
        if "ë³µì¡ë„" in reasoning_text or "complexity" in reasoning_text:
            quality_score += 25
        
        # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì–¸ê¸‰ ì—¬ë¶€
        if "í…ŒìŠ¤íŠ¸" in reasoning_text or "test" in reasoning_text:
            quality_score += 25
        
        # ì—£ì§€ ì¼€ì´ìŠ¤ ê³ ë ¤ ì—¬ë¶€
        if "ì—£ì§€" in reasoning_text or "edge case" in reasoning_text:
            quality_score += 25
        
        return quality_score
    
    def run_evaluation(self, sample_size=1000):
        """ì „ì²´ í‰ê°€ ì‹¤í–‰"""
        import random
        
        samples = random.sample(list(self.dataset), sample_size)
        
        results = {
            'correctness': [],
            'reasoning_quality': [],
            'avg_solution_length': 0
        }
        
        total_length = 0
        
        for item in samples:
            # ì •í™•ì„± í‰ê°€ (ì—¬ê¸°ì„œëŠ” êµ¬ë¬¸ ìœ íš¨ì„±ìœ¼ë¡œ ëŒ€ì²´)
            try:
                compile(item['solution'], '<string>', 'exec')
                results['correctness'].append(1)
            except:
                results['correctness'].append(0)
            
            # ì¶”ë¡  í’ˆì§ˆ í‰ê°€
            quality = self.evaluate_reasoning_quality(item['output'])
            results['reasoning_quality'].append(quality)
            
            # ì†”ë£¨ì…˜ ê¸¸ì´
            total_length += len(item['solution'])
        
        # í‰ê·  ê³„ì‚°
        results['avg_correctness'] = sum(results['correctness']) / len(results['correctness'])
        results['avg_reasoning_quality'] = sum(results['reasoning_quality']) / len(results['reasoning_quality'])
        results['avg_solution_length'] = total_length / len(samples)
        
        return results

# í‰ê°€ ì‹¤í–‰ ì˜ˆì‹œ
# evaluator = CodeReasoningEvaluator(ocr_split_0['split_0'])
# results = evaluator.run_evaluation()
# print(f"í‰ê·  ì •í™•ì„±: {results['avg_correctness']:.2%}")
# print(f"í‰ê·  ì¶”ë¡  í’ˆì§ˆ: {results['avg_reasoning_quality']:.1f}/100")
```

## í–¥í›„ ë°œì „ ë°©í–¥

### ë°ì´í„°ì…‹ í™•ì¥ ê³„íš

1. **ë‹¤êµ­ì–´ ì§€ì›**
   - Python ì™¸ Java, C++, JavaScript ì¶”ê°€
   - ì–¸ì–´ë³„ íŠ¹ì„±ì„ ê³ ë ¤í•œ ì¶”ë¡  ìƒì„±
   - ì–¸ì–´ê°„ ì½”ë“œ ë³€í™˜ ê¸°ëŠ¥

2. **ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸**
   - ìƒˆë¡œìš´ ê²½ìŸ í”„ë¡œê·¸ë˜ë° ë¬¸ì œ ì¶”ê°€
   - íŠ¸ë Œë“œ ë°˜ì˜í•œ ìµœì‹  ì•Œê³ ë¦¬ì¦˜ í¬í•¨
   - ì»¤ë®¤ë‹ˆí‹° ê¸°ì—¬ ì‹œìŠ¤í…œ êµ¬ì¶•

3. **ê³ ê¸‰ ì¶”ë¡  ë°©ë²•ë¡ **
   - ë‹¤ë‹¨ê³„ ì¶”ë¡  ê³¼ì • ê°•í™”
   - ëŒ€ì•ˆì  ì†”ë£¨ì…˜ ì œì‹œ
   - ìµœì í™” ê³¼ì • ìƒì„¸ ì„¤ëª…

### ëª¨ë¸ ì„±ëŠ¥ ê°œì„ 

1. **ë” ê°•ë ¥í•œ ìƒì„± ëª¨ë¸**
   - R1 í›„ì† ëª¨ë¸ ì ìš©
   - íŠ¹í™”ëœ ì½”ë“œ ìƒì„± ëª¨ë¸ í™œìš©
   - ì¸ê°„ í”¼ë“œë°± í•™ìŠµ í†µí•©

2. **í’ˆì§ˆ ë³´ì¦ ì‹œìŠ¤í…œ**
   - ìë™í™”ëœ ì½”ë“œ ê²€ì¦
   - ì¶”ë¡  ì¼ê´€ì„± ê²€ì‚¬
   - ì»¤ë®¤ë‹ˆí‹° ë¦¬ë·° ì‹œìŠ¤í…œ

## ê²°ë¡ 

**NVIDIA OpenCodeReasoning**ì€ ê²½ìŸ í”„ë¡œê·¸ë˜ë° ë¶„ì•¼ì—ì„œ **í˜„ì¬ê¹Œì§€ ê°€ì¥ í° ê·œëª¨ì˜ ì¶”ë¡  ê¸°ë°˜ í•©ì„± ë°ì´í„°ì…‹**ì…ë‹ˆë‹¤. **735,255ê°œ ìƒ˜í”Œ**ê³¼ **28,319ê°œ ê³ ìœ  ë¬¸ì œ**ë¥¼ í†µí•´ **10ê°œ ì£¼ìš” í”Œë«í¼**ì˜ ë‹¤ì–‘í•œ í”„ë¡œê·¸ë˜ë° ë„ì „ì„ í¬ê´„í•©ë‹ˆë‹¤.

**R1 ëª¨ë¸ ê¸°ë°˜ì˜ ê³ í’ˆì§ˆ ì¶”ë¡ **ê³¼ **ì²´ê³„ì ì¸ ë°ì´í„° ìˆ˜ì§‘ ë°©ë²•ë¡ **ì€ ì´ ë°ì´í„°ì…‹ì„ ì½”ë“œ ìƒì„± AI ê°œë°œì˜ ìƒˆë¡œìš´ ê¸°ì¤€ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤. **CC BY 4.0 ë¼ì´ì„¼ìŠ¤**ë¡œ ì œê³µë˜ì–´ êµìœ¡, ì—°êµ¬, ìƒì—…ì  í™œìš© ëª¨ë“  ë¶„ì•¼ì—ì„œ ììœ ë¡­ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**218ê°œ ì´ìƒì˜ íŒŒìƒ ëª¨ë¸**ê³¼ **í™œë°œí•œ ì»¤ë®¤ë‹ˆí‹° í™œìš©**ì€ ì´ ë°ì´í„°ì…‹ì˜ ì‹¤ìš©ì„±ê³¼ í’ˆì§ˆì„ ì…ì¦í•©ë‹ˆë‹¤. í–¥í›„ ë‹¤êµ­ì–´ ì§€ì›ê³¼ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ë¥¼ í†µí•´ ë”ìš± ë°œì „ëœ ì½”ë“œ ì¶”ë¡  AI ê°œë°œì˜ ê¸°ë°˜ì´ ë  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.

## ì¸ìš© ì •ë³´

```bibtex
@article{ahmad2025opencodereasoning,
      title={OpenCodeReasoning: Advancing Data Distillation for Competitive Coding}, 
      author={Wasi Uddin Ahmad, Sean Narenthiran, Somshubra Majumdar, Aleksander Ficek, Siddhartha Jain, Jocelyn Huang, Vahid Noroozi, Boris Ginsburg},
      year={2025},
      eprint={2504.01943},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2504.01943}, 
}
```

## ì°¸ê³  ìë£Œ

- [NVIDIA OpenCodeReasoning Hugging Face](https://huggingface.co/datasets/nvidia/OpenCodeReasoning)
- [ArXiv ê¸°ìˆ  ë³´ê³ ì„œ](https://arxiv.org/abs/2504.01943)
- [GitHub ì „ì²´ íŒŒì´í”„ë¼ì¸](https://github.com/nvidia/OpenCodeReasoning)
- [OpenCodeReasoning-Nemotron ëª¨ë¸ ì‹œë¦¬ì¦ˆ](https://huggingface.co/collections/nvidia/opencodereasoning-65f42e4f2e4ca0f7b69a4c6c)
- [Creative Commons BY 4.0 License](https://creativecommons.org/licenses/by/4.0/legalcode)
- [NVIDIA AI ìœ¤ë¦¬ ì •ì±…](https://www.nvidia.com/en-us/ai-data-science/ai-governance/) 