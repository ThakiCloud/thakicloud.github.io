---
title: "Essential-Web v1.0: 24ì¡° í† í° ê·œëª¨ì˜ ê³ í’ˆì§ˆ ì›¹ ë°ì´í„°ì…‹ - EAI ë¶„ë¥˜ ì²´ê³„ì™€ í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ"
excerpt: "Essential AIì˜ 24T í† í° ì›¹ ë°ì´í„°ì…‹ ì™„ì „ ë¶„ì„ - EAI ë¶„ë¥˜í•™, Red Pajama v2 í’ˆì§ˆ ì§€í‘œ, FastText ë¶„ë¥˜, ODC-By ë¼ì´ì„¼ìŠ¤ ê°€ì´ë“œ"
date: 2025-06-20
categories: 
  - datasets
  - llmops
tags: 
  - essential-ai
  - essential-web
  - web-dataset
  - 24t-tokens
  - eai-taxonomy
  - quality-signals
  - odc-by-license
  - red-pajama-v2
  - fasttext-classification
  - large-scale-dataset
author_profile: true
toc: true
toc_label: "Essential-Web v1.0 ê°€ì´ë“œ"
---

## ê°œìš”

**Essential-Web v1.0**ì€ Essential AIì—ì„œ ì œê³µí•˜ëŠ” **24ì¡° í† í° ê·œëª¨ì˜ ëŒ€ê·œëª¨ ì›¹ ë°ì´í„°ì…‹**ì…ë‹ˆë‹¤. ì´ ë°ì´í„°ì…‹ì€ **ì²´ê³„ì ì¸ í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ**ê³¼ **EAI ë¶„ë¥˜í•™(EAI Taxonomy)**ì„ í†µí•´ ë¶„ë¥˜ëœ ê³ í’ˆì§ˆ ì›¹ ì½˜í…ì¸ ë¥¼ ì œê³µí•˜ë©°, **ODC-By ë¼ì´ì„¼ìŠ¤**ë¡œ ìƒì—…ì  í™œìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

ì›¹ ì•„ì¹´ì´ë¸Œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ **WARC(Web ARChive) ë©”íƒ€ë°ì´í„°**ë¥¼ í¬í•¨í•˜ê³  ìˆìœ¼ë©°, **Red Pajama v2 í’ˆì§ˆ ì§€í‘œ**ì™€ **FastText ë¶„ë¥˜ ìŠ¤ì½”ì–´**ë¥¼ í†µí•´ ë°ì´í„° í’ˆì§ˆì„ ë‹¤ê°ë„ë¡œ í‰ê°€í•©ë‹ˆë‹¤. **ëŒ€ê·œëª¨ ì–¸ì–´ëª¨ë¸ ì‚¬ì „í•™ìŠµ**ê³¼ **ê³ í’ˆì§ˆ ì›¹ ë°ì´í„° ì—°êµ¬**ì— ìµœì í™”ëœ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.

## ë°ì´í„°ì…‹ í•µì‹¬ íŠ¹ì§•

### ê·œëª¨ ë° êµ¬ì„±

| **í•­ëª©** | **ê·œëª¨** | **ì„¤ëª…** |
|---|---|---|
| **ì´ í† í° ìˆ˜** | **24ì¡° í† í°** | ëŒ€ê·œëª¨ ì–¸ì–´ëª¨ë¸ ì‚¬ì „í•™ìŠµ ìµœì í™” |
| **ë°ì´í„° í¬ê¸°** | **10B-100B** | íš¨ìœ¨ì ì¸ ë¶„ì‚° ì²˜ë¦¬ ì§€ì› |
| **í’ˆì§ˆ ì§€í‘œ** | **ë‹¤ì¤‘ í‰ê°€ ì‹œìŠ¤í…œ** | EAI Taxonomy + Red Pajama v2 + FastText |
| **ë©”íƒ€ë°ì´í„°** | **WARC í‘œì¤€** | ì›¹ ì•„ì¹´ì´ë¸Œ í˜¸í™˜ ë©”íƒ€ë°ì´í„° |
| **ë¼ì´ì„¼ìŠ¤** | **ODC-By** | ìƒì—…ì  í™œìš© í—ˆìš© |

### ë°ì´í„° êµ¬ì¡° ìš”ì•½

```python
# ë°ì´í„°ì…‹ ê¸°ë³¸ êµ¬ì¡°
{
    "id": int64,                    # ê³ ìœ  ì‹ë³„ì
    "text": string,                 # ì›¹ í˜ì´ì§€ í…ìŠ¤íŠ¸ ì½˜í…ì¸ 
    "metadata": dict,               # WARC ë©”íƒ€ë°ì´í„° (URL, ë„ë©”ì¸, íƒ€ì„ìŠ¤íƒ¬í”„ ë“±)
    "line_start_n_end_idx": dict,   # í…ìŠ¤íŠ¸ ë¼ì¸ ìœ„ì¹˜ ì •ë³´
    "quality_signals": dict,        # í’ˆì§ˆ í‰ê°€ ì§€í‘œ (Red Pajama v2 + FastText)
    "eai_taxonomy": dict,           # EAI ë¶„ë¥˜í•™ (ë„ë©”ì¸, ê¸°ìˆ  ì •í™•ì„±, êµìœ¡ ìˆ˜ì¤€)
    "pid": string                   # í”„ë¡œì„¸ìŠ¤ ì‹ë³„ì
}
```

## EAI ë¶„ë¥˜í•™ (EAI Taxonomy) ì‹œìŠ¤í…œ

Essential-Web v1.0ì˜ í•µì‹¬ í˜ì‹  ì¤‘ í•˜ë‚˜ëŠ” **EAI Taxonomy**ë¼ëŠ” ì²´ê³„ì ì¸ ë¶„ë¥˜ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### ë„ë©”ì¸ ë¶„ë¥˜ (Domain Classification)

ì›¹ ì½˜í…ì¸ ë¥¼ **ì£¼ì œë³„**ë¡œ ì²´ê³„ì ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤:

```python
# ë„ë©”ì¸ ë¶„ë¥˜ êµ¬ì¡°
eai_taxonomy.domain.primary.code     # ì£¼ìš” ë„ë©”ì¸ ì½”ë“œ
eai_taxonomy.domain.primary.label    # ì£¼ìš” ë„ë©”ì¸ ë ˆì´ë¸”
eai_taxonomy.domain.secondary.code   # ë³´ì¡° ë„ë©”ì¸ ì½”ë“œ  
eai_taxonomy.domain.secondary.label  # ë³´ì¡° ë„ë©”ì¸ ë ˆì´ë¸”
```

| **ì½”ë“œ** | **ë ˆì´ë¸”** | **ì„¤ëª…** |
|---------|----------|---------|
| **-1** | **Abstain** | ë„ë©”ì¸ íŒë³„ ë¶ˆê°€ |
| **1** | **Arts & Humanities** | ì˜ˆìˆ , ì¸ë¬¸í•™, ë¬¸í™” |
| **2** | **Business & Economics** | ë¹„ì¦ˆë‹ˆìŠ¤, ê²½ì œ, ê¸ˆìœµ |
| **3** | **Computers & Internet** | IT, ê¸°ìˆ , ì¸í„°ë„· |
| **4** | **Games & Recreation** | ê²Œì„, ì˜¤ë½, ì·¨ë¯¸ |
| **5** | **Health & Medicine** | ê±´ê°•, ì˜í•™, í—¬ìŠ¤ì¼€ì–´ |
| **6** | **News & Politics** | ë‰´ìŠ¤, ì •ì¹˜, ì‹œì‚¬ |
| **7** | **Reference & Education** | êµìœ¡, ì°¸ê³ ìë£Œ, í•™ìˆ  |
| **8** | **Science & Technology** | ê³¼í•™, ê¸°ìˆ , ì—°êµ¬ |
| **9** | **Society & Culture** | ì‚¬íšŒ, ë¬¸í™”, ìƒí™œ |
| **10** | **Sports** | ìŠ¤í¬ì¸ , ìš´ë™ |

### ê¸°ìˆ  ì •í™•ì„± í‰ê°€ (Technical Correctness)

ì½˜í…ì¸ ì˜ **ê¸°ìˆ ì  ì •í™•ì„±**ì„ 6ë‹¨ê³„ë¡œ í‰ê°€í•©ë‹ˆë‹¤:

```python
# ê¸°ìˆ  ì •í™•ì„± í‰ê°€ êµ¬ì¡°
eai_taxonomy.technical_correctness.primary.code     # ì£¼ìš” ì •í™•ì„± ì½”ë“œ
eai_taxonomy.technical_correctness.primary.label    # ì£¼ìš” ì •í™•ì„± ë ˆì´ë¸”
eai_taxonomy.technical_correctness.secondary.code   # ë³´ì¡° ì •í™•ì„± ì½”ë“œ
eai_taxonomy.technical_correctness.secondary.label  # ë³´ì¡° ì •í™•ì„± ë ˆì´ë¸”
```

| **ì½”ë“œ** | **ë ˆì´ë¸”** | **ì„¤ëª…** |
|---------|----------|---------|
| **-1** | **Abstain** | íŒë³„ ë¶ˆê°€ |
| **1** | **Technically Flawed** | ì‹¬ê°í•œ ì˜¤ë¥˜ë¡œ ì¸í•œ ë‚´ìš© ì‹ ë¢°ì„± ì €í•˜ |
| **2** | **Partially Correct** | ì¼ë¶€ ì •í™•í•˜ì§€ë§Œ ê²°í•¨, ëˆ„ë½, ì˜¤ë¥˜ í¬í•¨ |
| **3** | **Mostly Correct** | ê¸°ìˆ ì ìœ¼ë¡œ ì •í™•í•˜ë‚˜ ì•½ê°„ì˜ ê²°í•¨ ë˜ëŠ” ë¶ˆì™„ì „í•œ ì„¤ëª… |
| **4** | **Highly Correct** | ë†’ì€ ê¸°ìˆ ì  ì •í™•ì„±ê³¼ ëª…í™•í•œ ì„¤ëª… |
| **5** | **Exceptionally Correct** | ë›°ì–´ë‚œ ê¸°ìˆ ì  ì •í™•ì„±ê³¼ ì™„ë²½í•œ ë‚´ìš© |
| **6** | **Not Applicable** | ê¸°ìˆ ì  ë‚´ìš© ì—†ìŒ ë˜ëŠ” ë¬¸ë§¥ ë¶€ì¡± |

### êµìœ¡ ìˆ˜ì¤€ í‰ê°€ (Education Level)

ì½˜í…ì¸  ì´í•´ì— í•„ìš”í•œ **êµìœ¡ ë°°ê²½**ì„ í‰ê°€í•©ë‹ˆë‹¤:

```python
# êµìœ¡ ìˆ˜ì¤€ í‰ê°€ êµ¬ì¡°
eai_taxonomy.education_level.primary.code     # ì£¼ìš” êµìœ¡ ìˆ˜ì¤€ ì½”ë“œ
eai_taxonomy.education_level.primary.label    # ì£¼ìš” êµìœ¡ ìˆ˜ì¤€ ë ˆì´ë¸”
eai_taxonomy.education_level.secondary.code   # ë³´ì¡° êµìœ¡ ìˆ˜ì¤€ ì½”ë“œ
eai_taxonomy.education_level.secondary.label  # ë³´ì¡° êµìœ¡ ìˆ˜ì¤€ ë ˆì´ë¸”
```

| **ì½”ë“œ** | **ë ˆì´ë¸”** | **ì„¤ëª…** |
|---------|----------|---------|
| **-1** | **Abstain** | íŒë³„ ë¶ˆê°€ |
| **1** | **General Audience** | ê¸°ë³¸ ë¬¸í•´ë ¥ìœ¼ë¡œ ì ‘ê·¼ ê°€ëŠ¥, ì‰¬ìš´ ìš©ì–´ |
| **2** | **High School Level** | ê³ ë“±í•™êµ êµìœ¡ í•„ìš”, ì „ë¬¸ ìš©ì–´ ì„¤ëª… í¬í•¨ |
| **3** | **Undergraduate Level** | ëŒ€í•™ êµìœ¡ í•„ìš”, ì „ë¬¸ ìš©ì–´ì™€ ë°°ê²½ì§€ì‹ ê°€ì • |
| **4** | **Graduate/Expert Level** | ëŒ€í•™ì› ë˜ëŠ” ì „ë¬¸ê°€ ìˆ˜ì¤€, ê¹Šì€ ë°°ê²½ì§€ì‹ í•„ìš” |
| **5** | **Indeterminate** | êµìœ¡ ìˆ˜ì¤€ íŒë³„ì„ ìœ„í•œ ì½˜í…ì¸  ë¶€ì¡± |

## í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ

### Red Pajama v2 í’ˆì§ˆ ì§€í‘œ

ì›¹ í…ìŠ¤íŠ¸ì˜ **ì¢…í•©ì ì¸ í’ˆì§ˆ**ì„ í‰ê°€í•˜ëŠ” ì§€í‘œë“¤ì…ë‹ˆë‹¤:

#### ì½˜í…ì¸  êµ¬ì¡° ì§€í‘œ

```python
# ê¸°ë³¸ êµ¬ì¡° ë¶„ì„
quality_signals.red_pajama_v2.ccnet_original_length      # ì›ë³¸ ë¬¸ì„œ ê¸¸ì´
quality_signals.red_pajama_v2.ccnet_original_nlines      # ì›ë³¸ ë¬¸ì„œ ë¼ì¸ ìˆ˜
quality_signals.red_pajama_v2.rps_doc_num_sentences      # ì´ ë¬¸ì¥ ìˆ˜
quality_signals.red_pajama_v2.rps_doc_word_count         # ì´ ë‹¨ì–´ ìˆ˜
quality_signals.red_pajama_v2.rps_doc_mean_word_length   # í‰ê·  ë‹¨ì–´ ê¸¸ì´
```

#### ì–¸ì–´ í’ˆì§ˆ ì§€í‘œ

```python
# ì–¸ì–´ í’ˆì§ˆ ë¶„ì„
quality_signals.red_pajama_v2.rps_doc_stop_word_fraction    # ë¶ˆìš©ì–´ ë¹„ìœ¨
quality_signals.red_pajama_v2.rps_doc_frac_unique_words     # ê³ ìœ  ë‹¨ì–´ ë¹„ìœ¨
quality_signals.red_pajama_v2.rps_doc_frac_all_caps_words   # ëŒ€ë¬¸ì ë‹¨ì–´ ë¹„ìœ¨
quality_signals.red_pajama_v2.rps_doc_frac_no_alph_words    # ë¹„ì•ŒíŒŒë²³ ë‹¨ì–´ ë¹„ìœ¨
quality_signals.red_pajama_v2.rps_doc_unigram_entropy       # ìœ ë‹ˆê·¸ë¨ ì—”íŠ¸ë¡œí”¼
```

#### ì¤‘ë³µ íƒì§€ ì§€í‘œ

```python
# N-gram ì¤‘ë³µ ë¶„ì„ (5-gramë¶€í„° 10-gramê¹Œì§€)
quality_signals.red_pajama_v2.rps_doc_frac_chars_dupe_5grams   # 5-gram ì¤‘ë³µë¥ 
quality_signals.red_pajama_v2.rps_doc_frac_chars_dupe_6grams   # 6-gram ì¤‘ë³µë¥ 
quality_signals.red_pajama_v2.rps_doc_frac_chars_dupe_7grams   # 7-gram ì¤‘ë³µë¥ 
quality_signals.red_pajama_v2.rps_doc_frac_chars_dupe_8grams   # 8-gram ì¤‘ë³µë¥ 
quality_signals.red_pajama_v2.rps_doc_frac_chars_dupe_9grams   # 9-gram ì¤‘ë³µë¥ 
quality_signals.red_pajama_v2.rps_doc_frac_chars_dupe_10grams  # 10-gram ì¤‘ë³µë¥ 

# ìƒìœ„ N-gram ì»¤ë²„ë¦¬ì§€
quality_signals.red_pajama_v2.rps_doc_frac_chars_top_2gram     # ìƒìœ„ 2-gram ì»¤ë²„ë¦¬ì§€
quality_signals.red_pajama_v2.rps_doc_frac_chars_top_3gram     # ìƒìœ„ 3-gram ì»¤ë²„ë¦¬ì§€
quality_signals.red_pajama_v2.rps_doc_frac_chars_top_4gram     # ìƒìœ„ 4-gram ì»¤ë²„ë¦¬ì§€
```

#### ë„ë©”ì¸ ì¤‘ìš”ë„ ì ìˆ˜

```python
# ê³ í’ˆì§ˆ ë°ì´í„°ì…‹ ìœ ì‚¬ë„ ì ìˆ˜
quality_signals.red_pajama_v2.rps_doc_books_importance                           # ë„ì„œ ì½˜í…ì¸  ìœ ì‚¬ë„
quality_signals.red_pajama_v2.rps_doc_books_importance_length_correction         # ê¸¸ì´ ë³´ì • ë„ì„œ ìœ ì‚¬ë„
quality_signals.red_pajama_v2.rps_doc_openwebtext_importance                     # OpenWebText ìœ ì‚¬ë„
quality_signals.red_pajama_v2.rps_doc_openwebtext_importance_length_correction   # ê¸¸ì´ ë³´ì • OpenWebText ìœ ì‚¬ë„
quality_signals.red_pajama_v2.rps_doc_wikipedia_importance                       # Wikipedia ìœ ì‚¬ë„
quality_signals.red_pajama_v2.rps_doc_wikipedia_importance_length_correction     # ê¸¸ì´ ë³´ì • Wikipedia ìœ ì‚¬ë„
```

### FastText ë¶„ë¥˜ ìŠ¤ì½”ì–´

**ì½˜í…ì¸  ìœ í˜•ë³„ ë¶„ë¥˜ í™•ë¥ **ì„ ì œê³µí•©ë‹ˆë‹¤:

```python
# FastText ë¶„ë¥˜ ìŠ¤ì½”ì–´
quality_signals.fasttext.dclm                  # DataComp-LM ë¶„ë¥˜ê¸° ì ìˆ˜
quality_signals.fasttext.english               # ì˜ì–´ ì‹ ë¢°ë„
quality_signals.fasttext.fineweb_edu_approx    # êµìœ¡ ì½˜í…ì¸  ê·¼ì‚¬ê°’
quality_signals.fasttext.eai_general_math      # ì¼ë°˜ ìˆ˜í•™ ì½˜í…ì¸ 
quality_signals.fasttext.eai_open_web_math     # ì›¹ ìˆ˜í•™ ì½˜í…ì¸ 
quality_signals.fasttext.eai_web_code          # ì½”ë“œ ì½˜í…ì¸  íƒì§€
```

## ë©”íƒ€ë°ì´í„° êµ¬ì¡°

### WARC ë©”íƒ€ë°ì´í„°

ì›¹ ì•„ì¹´ì´ë¸Œ í‘œì¤€ì„ ë”°ë¥´ëŠ” **ìƒì„¸í•œ ë©”íƒ€ë°ì´í„°**ë¥¼ ì œê³µí•©ë‹ˆë‹¤:

```python
# URL ì •ë³´
metadata.url                      # ì›ë³¸ URL
metadata.source_domain           # ì†ŒìŠ¤ ë„ë©”ì¸
metadata.snapshot_id             # ì›¹ ì•„ì¹´ì´ë¸Œ ìŠ¤ëƒ…ìƒ· ID

# WARC í‘œì¤€ ë©”íƒ€ë°ì´í„°
metadata.warc_metadata.Content-Length                    # ì½˜í…ì¸  í¬ê¸°
metadata.warc_metadata.Content-Type                      # MIME íƒ€ì…
metadata.warc_metadata.WARC-Block-Digest                 # ë¸”ë¡ ì²´í¬ì„¬
metadata.warc_metadata.WARC-Date                         # í¬ë¡¤ë§ íƒ€ì„ìŠ¤íƒ¬í”„
metadata.warc_metadata.WARC-IP-Address                   # ì„œë²„ IP ì£¼ì†Œ
metadata.warc_metadata.WARC-Identified-Payload-Type      # ì‹ë³„ëœ ì½˜í…ì¸  íƒ€ì…
metadata.warc_metadata.WARC-Payload-Digest               # í˜ì´ë¡œë“œ ì²´í¬ì„¬
metadata.warc_metadata.WARC-Record-ID                    # ê³ ìœ  WARC ë ˆì½”ë“œ ID
metadata.warc_metadata.WARC-Target-URI                   # ëŒ€ìƒ URL
metadata.warc_metadata.WARC-Type                         # WARC ë ˆì½”ë“œ íƒ€ì…
```

## ë°ì´í„°ì…‹ í™œìš© ë°©ë²•

### ê¸°ë³¸ ë¡œë“œ ë° íƒìƒ‰

#### Hugging Face Datasets ì‚¬ìš©

```python
from datasets import load_dataset

# ì „ì²´ ë°ì´í„°ì…‹ ë¡œë“œ
dataset = load_dataset("EssentialAI/essential-web-v1.0")

# ë°ì´í„°ì…‹ êµ¬ì¡° í™•ì¸
print(f"ë°ì´í„°ì…‹ í¬ê¸°: {len(dataset['train'])}")
print(f"ì»¬ëŸ¼: {dataset['train'].column_names}")

# ìƒ˜í”Œ ë°ì´í„° í™•ì¸
sample = dataset['train'][0]
print("ìƒ˜í”Œ êµ¬ì¡°:")
for key in sample.keys():
    print(f"- {key}: {type(sample[key])}")
```

#### ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ì‚¬ìš©

```python
# ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ì„ ìœ„í•œ ìŠ¤íŠ¸ë¦¬ë° ë¡œë“œ
dataset_stream = load_dataset("EssentialAI/essential-web-v1.0", streaming=True)
data_iter = dataset_stream["train"]

# ì²« 5ê°œ ìƒ˜í”Œ í™•ì¸
for i, example in enumerate(data_iter):
    if i >= 5:
        break
    print(f"ID: {example['id']}")
    print(f"Text length: {len(example['text'])}")
    print(f"Domain: {example['eai_taxonomy']['domain']['primary']['label']}")
    print("---")
```

### í’ˆì§ˆ ê¸°ë°˜ í•„í„°ë§

#### EAI Taxonomy ê¸°ë°˜ í•„í„°ë§

```python
def filter_by_quality(dataset, min_correctness=3, target_domains=None):
    """
    EAI Taxonomy ê¸°ë°˜ ê³ í’ˆì§ˆ ë°ì´í„° í•„í„°ë§
    
    Args:
        dataset: ì…ë ¥ ë°ì´í„°ì…‹
        min_correctness: ìµœì†Œ ê¸°ìˆ  ì •í™•ì„± ì ìˆ˜ (1-5)
        target_domains: ëŒ€ìƒ ë„ë©”ì¸ ë¦¬ìŠ¤íŠ¸
    """
    filtered_data = []
    
    for sample in dataset:
        # ê¸°ìˆ  ì •í™•ì„± í•„í„°ë§
        correctness = sample['eai_taxonomy']['technical_correctness']['primary']['code']
        if correctness < min_correctness:
            continue
            
        # ë„ë©”ì¸ í•„í„°ë§
        if target_domains:
            domain_label = sample['eai_taxonomy']['domain']['primary']['label']
            if domain_label not in target_domains:
                continue
                
        filtered_data.append(sample)
    
    return filtered_data

# ê³ í’ˆì§ˆ ê¸°ìˆ /ê³¼í•™ ì½˜í…ì¸  í•„í„°ë§
high_quality_tech = filter_by_quality(
    dataset['train'],
    min_correctness=4,
    target_domains=['Science & Technology', 'Computers & Internet']
)

print(f"í•„í„°ë§ëœ ìƒ˜í”Œ ìˆ˜: {len(high_quality_tech)}")
```

#### Red Pajama v2 ì§€í‘œ ê¸°ë°˜ í•„í„°ë§

```python
def filter_by_redpajama_metrics(dataset, 
                               min_word_count=100,
                               max_duplicate_ratio=0.1,
                               min_stop_word_fraction=0.05):
    """
    Red Pajama v2 í’ˆì§ˆ ì§€í‘œ ê¸°ë°˜ í•„í„°ë§
    
    Args:
        dataset: ì…ë ¥ ë°ì´í„°ì…‹
        min_word_count: ìµœì†Œ ë‹¨ì–´ ìˆ˜
        max_duplicate_ratio: ìµœëŒ€ ì¤‘ë³µ ë¹„ìœ¨
        min_stop_word_fraction: ìµœì†Œ ë¶ˆìš©ì–´ ë¹„ìœ¨
    """
    filtered_data = []
    
    for sample in dataset:
        quality = sample['quality_signals']['red_pajama_v2']
        
        # ë‹¨ì–´ ìˆ˜ í•„í„°
        if quality['rps_doc_word_count'] < min_word_count:
            continue
            
        # ì¤‘ë³µ ë¹„ìœ¨ í•„í„° (5-gram ê¸°ì¤€)
        if quality['rps_doc_frac_chars_dupe_5grams'] > max_duplicate_ratio:
            continue
            
        # ë¶ˆìš©ì–´ ë¹„ìœ¨ í•„í„°
        if quality['rps_doc_stop_word_fraction'] < min_stop_word_fraction:
            continue
            
        filtered_data.append(sample)
    
    return filtered_data

# ê³ í’ˆì§ˆ í…ìŠ¤íŠ¸ í•„í„°ë§
high_quality_text = filter_by_redpajama_metrics(dataset['train'])
print(f"Red Pajama í•„í„°ë§ í›„ ìƒ˜í”Œ ìˆ˜: {len(high_quality_text)}")
```

### ë„ë©”ì¸ë³„ ë¶„ì„ ë° í™œìš©

```python
import matplotlib.pyplot as plt
from collections import Counter

def analyze_domain_distribution(dataset):
    """ë„ë©”ì¸ë³„ ë¶„í¬ ë¶„ì„"""
    domains = []
    correctness_scores = []
    
    for sample in dataset:
        domain = sample['eai_taxonomy']['domain']['primary']['label']
        correctness = sample['eai_taxonomy']['technical_correctness']['primary']['code']
        
        domains.append(domain)
        correctness_scores.append(correctness)
    
    # ë„ë©”ì¸ë³„ ë¶„í¬
    domain_counts = Counter(domains)
    
    # ë„ë©”ì¸ë³„ í‰ê·  ê¸°ìˆ  ì •í™•ì„±
    domain_correctness = {}
    for domain, correctness in zip(domains, correctness_scores):
        if domain not in domain_correctness:
            domain_correctness[domain] = []
        if correctness != -1:  # Abstain ì œì™¸
            domain_correctness[domain].append(correctness)
    
    domain_avg_correctness = {
        domain: sum(scores) / len(scores) 
        for domain, scores in domain_correctness.items() 
        if scores
    }
    
    return domain_counts, domain_avg_correctness

# ë¶„ì„ ì‹¤í–‰
domain_dist, domain_quality = analyze_domain_distribution(dataset['train'])

print("ë„ë©”ì¸ë³„ ë¶„í¬:")
for domain, count in domain_dist.most_common():
    avg_quality = domain_quality.get(domain, 0)
    print(f"{domain}: {count:,}ê°œ (í‰ê·  ê¸°ìˆ ì •í™•ì„±: {avg_quality:.2f})")
```

### PySpark í™œìš© (ëŒ€ê·œëª¨ ì²˜ë¦¬)

```python
# PySparkë¡œ ëŒ€ê·œëª¨ ë°ì´í„° ì²˜ë¦¬
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, when, avg

# Spark ì„¸ì…˜ ì´ˆê¸°í™”
spark = SparkSession.builder.appName("EssentialWeb-Analysis").getOrCreate()

# ë°ì´í„°ì…‹ ë¡œë“œ
df = spark.read.format("huggingface").load("EssentialAI/essential-web-v1.0")

# ë„ë©”ì¸ë³„ í†µê³„ ë¶„ì„
domain_stats = df.groupBy("eai_taxonomy.domain.primary.label") \
                .agg(
                    avg("quality_signals.red_pajama_v2.rps_doc_word_count").alias("avg_word_count"),
                    avg("eai_taxonomy.technical_correctness.primary.code").alias("avg_correctness")
                ) \
                .orderBy(col("avg_correctness").desc())

domain_stats.show()

# ê³ í’ˆì§ˆ ë°ì´í„° í•„í„°ë§ ë° ì €ì¥
high_quality_df = df.filter(
    (col("eai_taxonomy.technical_correctness.primary.code") >= 4) &
    (col("quality_signals.red_pajama_v2.rps_doc_word_count") >= 200)
)

high_quality_df.write.mode("overwrite").parquet("essential_web_high_quality.parquet")
```

## ë¼ì´ì„¼ìŠ¤ ë° í™œìš© ê°€ì´ë“œ

### ODC-By ë¼ì´ì„¼ìŠ¤ ìƒì„¸

**Open Data Commons Attribution License (ODC-By)**ëŠ” Essential-Web v1.0ì— ì ìš©ë˜ëŠ” ë¼ì´ì„¼ìŠ¤ì…ë‹ˆë‹¤.

#### í—ˆìš© ì‚¬í•­

âœ… **ìƒì—…ì  í™œìš© í—ˆìš©**: ë¹„ì¦ˆë‹ˆìŠ¤ ëª©ì ìœ¼ë¡œ ììœ ë¡­ê²Œ ì‚¬ìš© ê°€ëŠ¥  
âœ… **ìˆ˜ì • ë° ì¬ë°°í¬**: ë°ì´í„° ë³€ê²½, ê°€ê³µ, ì¬ë°°í¬ ê°€ëŠ¥  
âœ… **íŒŒìƒ ì‘í’ˆ ìƒì„±**: ë°ì´í„° ê¸°ë°˜ ìƒˆë¡œìš´ ì½˜í…ì¸  ì œì‘ ê°€ëŠ¥  
âœ… **AI ëª¨ë¸ í•™ìŠµ**: ëŒ€ê·œëª¨ ì–¸ì–´ëª¨ë¸ ì‚¬ì „í•™ìŠµ ë° íŒŒì¸íŠœë‹ í™œìš©  

#### ì˜ë¬´ ì‚¬í•­

ğŸ“‹ **ì¶œì²˜ í‘œì‹œ í•„ìˆ˜**: ë°ì´í„° ì‚¬ìš© ì‹œ Essential AI í¬ë ˆë”§ ëª…ì‹œ  
ğŸ“‹ **ë¼ì´ì„¼ìŠ¤ ê³ ì§€**: ODC-By ë¼ì´ì„¼ìŠ¤ì„ì„ ëª…ì‹œ  
ğŸ“‹ **ë³€ê²½ì‚¬í•­ ê¸°ë¡**: ë°ì´í„° ìˆ˜ì • ì‹œ ë³€ê²½ ë‚´ì—­ ë¬¸ì„œí™”  

#### ì˜¬ë°”ë¥¸ ì¸ìš© ë°©ë²•

```bibtex
@misc{ai2025essentialwebv1024ttokens,
      title={Essential-Web v1.0: 24T tokens of organized web data}, 
      author={Essential AI and Andrew Hojel and Michael Pust and Tim Romanski and Yash Vanjani and Ritvik Kapila and Mohit Parmar and Adarsh Chaluvaraju and Alok Tripathy and Anil Thomas and Ashish Tanwer and Darsh J Shah and Ishaan Shah and Karl Stratos and Khoi Nguyen and Kurt Smith and Michael Callahan and Peter Rushton and Philip Monk and Platon Mazarakis and Saad Jamal and Saurabh Srivastava and Somanshu Singla and Ashish Vaswani},
      year={2025},
      eprint={2506.14111},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2506.14111}, 
}
```

### ìƒì—…ì  í™œìš© ì‹œë‚˜ë¦¬ì˜¤

#### AI ëª¨ë¸ ê°œë°œ íšŒì‚¬

```python
# ìƒì—…ì  LLM ì‚¬ì „í•™ìŠµ ì˜ˆì œ
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset

# Essential-Web ë°ì´í„° ë¡œë“œ
dataset = load_dataset("EssentialAI/essential-web-v1.0", streaming=True)

# ê³ í’ˆì§ˆ ë°ì´í„°ë§Œ í•„í„°ë§
filtered_stream = dataset['train'].filter(
    lambda x: x['eai_taxonomy']['technical_correctness']['primary']['code'] >= 4
)

# ìƒì—…ì  ëª¨ë¸ ì‚¬ì „í•™ìŠµ
tokenizer = AutoTokenizer.from_pretrained("your-base-model")
model = AutoModelForCausalLM.from_pretrained("your-base-model")

# í•™ìŠµ ì½”ë“œ...
# ê²°ê³¼ ëª¨ë¸ì„ ìƒì—…ì ìœ¼ë¡œ ë°°í¬ ê°€ëŠ¥
```

#### ë°ì´í„° ì• ë„ë¦¬í‹±ìŠ¤ ì„œë¹„ìŠ¤

```python
# ì›¹ ì½˜í…ì¸  í’ˆì§ˆ ë¶„ì„ ì„œë¹„ìŠ¤ ê°œë°œ
class WebContentQualityAnalyzer:
    def __init__(self):
        self.dataset = load_dataset("EssentialAI/essential-web-v1.0")
        
    def analyze_domain_quality(self, domain):
        """íŠ¹ì • ë„ë©”ì¸ì˜ ì½˜í…ì¸  í’ˆì§ˆ ë¶„ì„"""
        domain_data = self.dataset['train'].filter(
            lambda x: x['eai_taxonomy']['domain']['primary']['label'] == domain
        )
        
        # í’ˆì§ˆ ì§€í‘œ ê³„ì‚°
        quality_metrics = self.calculate_quality_metrics(domain_data)
        
        # ìƒì—…ì  ë¦¬í¬íŠ¸ ìƒì„±
        return self.generate_commercial_report(quality_metrics)
    
    # ì´ ì„œë¹„ìŠ¤ë¥¼ ìœ ë£Œë¡œ ì œê³µ ê°€ëŠ¥
```

### ì£¼ì˜ì‚¬í•­ ë° ì œí•œì‚¬í•­

âš ï¸ **ì›¹ í¬ë¡¤ë§ ë°ì´í„° íŠ¹ì„±**: ì›ë³¸ ì›¹ì‚¬ì´íŠ¸ì˜ ì €ì‘ê¶Œì€ ë³„ë„ í™•ì¸ í•„ìš”  
âš ï¸ **ë°ì´í„° ê²€ì¦ ê¶Œì¥**: íŠ¹ì • ìš©ë„ì— ë§ëŠ” ì¶”ê°€ í’ˆì§ˆ ê²€ì¦ ê¶Œì¥  
âš ï¸ **ê°œì¸ì •ë³´ ì£¼ì˜**: ì›¹ ë°ì´í„° íŠ¹ì„±ìƒ ê°œì¸ì •ë³´ í¬í•¨ ê°€ëŠ¥ì„± ê²€í†  í•„ìš”  

## ê´€ë ¨ ì—°êµ¬ ë° ì°¸ê³ ìë£Œ

### ë…¼ë¬¸ ì •ë³´

- **ë…¼ë¬¸ ì œëª©**: Essential-Web v1.0: 24T tokens of organized web data
- **ì €ì**: Essential AI íŒ€ (Andrew Hojel, Michael Pust ì™¸ 20ëª…)
- **ë°œí–‰ì¼**: 2025ë…„
- **arXiv ID**: 2506.14111
- **ë¶„ì•¼**: cs.CL (Computational Linguistics)

### ê´€ë ¨ ë°ì´í„°ì…‹ ë¹„êµ

| **ë°ì´í„°ì…‹** | **ê·œëª¨** | **ë¼ì´ì„¼ìŠ¤** | **í’ˆì§ˆ ì§€í‘œ** | **í™œìš© ë¶„ì•¼** |
|-------------|---------|-------------|-------------|-------------|
| **Essential-Web v1.0** | **24T í† í°** | **ODC-By** | **EAI Taxonomy + Red Pajama v2** | **ìƒì—…ì  LLM ê°œë°œ** |
| Common Crawl | ìˆ˜ë°±TB | ì œí•œì  | ê¸°ë³¸ì  | ì—°êµ¬ìš© |
| C4 | 750GB | Apache 2.0 | ê¸°ë³¸ì  | í•™ìˆ  ì—°êµ¬ |
| RefinedWeb | 600B í† í° | ODC-By | ê³ ê¸‰ | LLM ì‚¬ì „í•™ìŠµ |

### ì¶”ê°€ í•™ìŠµ ìë£Œ

- [Hugging Face ë°ì´í„°ì…‹ í˜ì´ì§€](https://huggingface.co/datasets/EssentialAI/essential-web-v1.0)
- [arXiv ë…¼ë¬¸](https://arxiv.org/abs/2506.14111)
- [ODC-By ë¼ì´ì„¼ìŠ¤ ì „ë¬¸](https://opendatacommons.org/licenses/by/)
- [Red Pajama v2 í’ˆì§ˆ ì§€í‘œ ë¬¸ì„œ](https://github.com/togethercomputer/RedPajama-Data)

## ê²°ë¡ 

Essential-Web v1.0ì€ **24ì¡° í† í° ê·œëª¨ì˜ ê³ í’ˆì§ˆ ì›¹ ë°ì´í„°ì…‹**ìœ¼ë¡œ, **ì²´ê³„ì ì¸ EAI ë¶„ë¥˜í•™**ê³¼ **ë‹¤ì¸µì  í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ**ì„ í†µí•´ ëŒ€ê·œëª¨ ì–¸ì–´ëª¨ë¸ ê°œë°œì— ìµœì í™”ëœ ë°ì´í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤. **ODC-By ë¼ì´ì„¼ìŠ¤**ë¡œ ìƒì—…ì  í™œìš©ì´ ê°€ëŠ¥í•˜ë©°, **ë‹¤ì–‘í•œ ë„ë©”ì¸**ê³¼ **êµìœ¡ ìˆ˜ì¤€**ì„ ì•„ìš°ë¥´ëŠ” í¬ê´„ì ì¸ ì›¹ ì½˜í…ì¸ ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.

íŠ¹íˆ **EAI Taxonomyì˜ ë„ë©”ì¸ ë¶„ë¥˜**, **ê¸°ìˆ  ì •í™•ì„± í‰ê°€**, **êµìœ¡ ìˆ˜ì¤€ ë¶„ì„** ê¸°ëŠ¥ì€ ìš©ë„ë³„ ë§ì¶¤í˜• ë°ì´í„° ì„ ë³„ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ë©°, **Red Pajama v2 í’ˆì§ˆ ì§€í‘œ**ì™€ **FastText ë¶„ë¥˜ ìŠ¤ì½”ì–´**ëŠ” ë°ì´í„° í’ˆì§ˆì„ ë‹¤ê°ë„ë¡œ ê²€ì¦í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

ëŒ€ê·œëª¨ ì–¸ì–´ëª¨ë¸ ì‚¬ì „í•™ìŠµ, ë„ë©”ì¸ íŠ¹í™” AI ê°œë°œ, ì›¹ ì½˜í…ì¸  í’ˆì§ˆ ì—°êµ¬ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” **ì°¨ì„¸ëŒ€ ì›¹ ë°ì´í„°ì…‹**ì…ë‹ˆë‹¤.
