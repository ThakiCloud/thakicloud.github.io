---
title: "مستقبل البنية التحتية للذكاء الاصطناعي والحوسبة مع جيف دين"
excerpt: "كبير علماء Alphabet جيف دين يناقش تطور نماذج الذكاء الاصطناعي واسعة النطاق، أجهزة الاستنتاج، العوامل متعددة الوسائط، أنظمة Pathways، وجدوى الذكاء الاصطناعي بمستوى المهندس المبتدئ—ملخص شامل لحاضر ومستقبل البنية التحتية للذكاء الاصطناعي"
date: 2025-06-05
lang: ar
permalink: /ar/news/jeff-dean-bill-coughran-talk/
canonical_url: "https://thakicloud.github.io/ar/news/jeff-dean-bill-coughran-talk/"
categories:
  - news
tags:
  - البنية التحتية للذكاء الاصطناعي
  - النماذج الكبيرة
  - جيف دين
  - Google AI
  - Pathways
  - TPU
  - مستقبل الحوسبة
author_profile: true
toc: true
toc_label: "المحتويات"
---

<figure class="video-container">
 <iframe width="560" height="315"
          src="https://www.youtube.com/embed/dq8MhTFCs80?si=0qg8c0zG5YE1aail"
          title="جيف دين من Google حول التحولات القادمة في الذكاء الاصطناعي"
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
          referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>
        </iframe>
    <figcaption>※ يمكنك مشاهدة الفيديو الكامل (≈ 30 دقيقة) والاطلاع على المحاضرة مباشرة.</figcaption>
</figure>

# ملخص محاضرة جيف دين التقنية: البنية التحتية للذكاء الاصطناعي والنماذج واسعة النطاق ومستقبل الحوسبة

**المتحدث:** جيف دين (كبير العلماء، Alphabet)
**المضيف:** بيل كوغران (شريك Sequoia، نائب رئيس الهندسة السابق في Google)
**الموضوع:** توسيع الذكاء الاصطناعي، النماذج الأساسية، أجهزة الاستنتاج، البنية التحتية للحوسبة من الجيل التالي

---

## 👤 جيف دين

**المنصب:** كبير العلماء، Google DeepMind & Google Research (Alphabet Inc.)

**التعريف:**
جيف دين هو **كبير العلماء** الذي يقود DeepMind و Google Research تحت Alphabet.
انضم إلى Google كمهندس مبكر وكان له تأثير عميق على الحوسبة الحديثة وتطوير تقنية الذكاء الاصطناعي من خلال **البنية التحتية لبحث Google، MapReduce، BigTable، TensorFlow، BERT**، والمزيد.

**الإنجازات الرئيسية:**

- شارك في تأسيس Google Brain
- قاد مشروع TensorFlow مفتوح المصدر
- قيادة في الأوراق الأساسية مثل Transformer و BERT
- قاد برنامج أجهزة TPU (وحدة معالجة Tensor)
- يقود مؤخراً استراتيجية **نموذج Gemini الكبير** في Google

---

## 👤 بيل كوغران

**المنصب:** شريك، Sequoia Capital
**المنصب السابق:** نائب الرئيس الأول للهندسة، Google

**التعريف:**
بيل كوغران حالياً **شريك في شركة رأس المال الاستثماري العالمية Sequoia Capital** وهو **نائب رئيس أول للهندسة** سابق قاد الهندسة في Google لأكثر من 8 سنوات.
قاد منظمة هندسية من آلاف الأشخاص تغطي فرق تطوير البحث والبنية التحتية وأنظمة الإعلانات و Chrome و Android في Google.

**الإنجازات الرئيسية:**

- ساهم في التوسع العمودي لمنظمة الهندسة في Google
- قاد تحسينات الأداء في أنظمة Chrome والإعلانات والبحث
- ساهم في تشكيل فريق القيادة المبكر في Google
- استثمر في الشركات الناشئة التقنية مثل Snowflake و Databricks في Sequoia

## 🔧 تطور الذكاء الاصطناعي ونموذج التوسيع

- بدأ التعلم العميق الحديث بجدية حوالي **2012-2013**.
- استخدمت Google **16,000 نواة CPU** لتدريب أكبر شبكة عصبية في ذلك الوقت، مثبتة إمكانات الحجم.
- قاعدة الإبهام الأساسية:
  > **وسع النماذج، زد البيانات، والأداء يتحسن**

---

## 🧠 النماذج متعددة الوسائط وعوامل الذكاء الاصطناعي

### الأنظمة متعددة الوسائط

- **الذكاء الاصطناعي متعدد الوسائط** الذي يعالج مدخلات/مخرجات متنوعة مثل النص والصور والصوت والفيديو والكود يظهر كمفتاح.
- تسريع التطبيقات في مجالات متنوعة (مثل التعليم والروبوتات وواجهات المستخدم).

### عوامل الذكاء الاصطناعي

- حالياً قادرة على وظائف محدودة فقط، لكن يمكن أن تصبح أكثر تطوراً من خلال **التعلم المعزز (RL)** و**التدريب اللاحق**.
- الروبوتات متوقعة أيضاً لأداء أكثر من 20 مهمة مفيدة في الأماكن المغلقة **خلال 1-2 سنة**.

---

## 🧱 نظام النماذج الأساسية

- تدريب LLMs المتطورة يتطلب موارد وبنية تحتية ضخمة → **عدد قليل من الشركات الرائدة** فقط يمكنها القيادة.
- ومع ذلك، **تقطير المعرفة** يمكن أن ينشئ نماذج مشتقة خفيفة متنوعة.
- المستقبل متوقع أن يكون له هذا الهيكل:
  - عدد قليل من النماذج الكبيرة للأغراض العامة
  - العديد من النماذج الخفيفة/المتخصصة

---

## ⚙️ الأجهزة المخصصة للذكاء الاصطناعي وبرمجيات النظام

### العناصر الأساسية لأجهزة ML

- **مسرعات الجبر الخطي منخفضة الدقة**
- **شبكات ربط فائقة السرعة**

### تاريخ تطوير TPU

- **TPUv1**: للاستنتاج
- **TPUv2~الحاضر**: تكامل التدريب + الاستنتاج
- الجيل الأحدث: **Trillium → Ironwood**

### الاستنتاج التناظري مقابل الرقمي

- **الاستنتاج التناظري** واعد لكفاءة الطاقة، لكن **الأنظمة الرقمية** لا تزال لها مزايا في مرونة التطوير.
- الهدف هو ابتكار الأجهزة القادرة على **تحسينات كفاءة 10~50,000x**.

---

## 🧪 تأثير الذكاء الاصطناعي على المجالات العلمية

- مطبق على مشاكل قائمة على المحاكيات عالية التكلفة مثل التنبؤ بالطقس وديناميكا الموائع والكيمياء الكمية.
- يمكن إنشاء **نماذج استنتاج أسرع بعشرات الآلاف من المرات** بتعلم بيانات المحاكي.
- مثال: محاكاة ملايين الهياكل الجزيئية في يوم → تسريع سرعة الاكتشاف العلمي.

---

## 🧵 تجربة المطور: تجريد Pathways

- نظام Google الداخلي **Pathways** يمكن أن يتحكم في آلاف الأجهزة بعملية Python واحدة.
- متوافق مع JAX و PyTorch.
- أُطلق مؤخراً إلى GCP → مستخدمو السحابة يمكنهم **استخدام TPUs واسعة النطاق بعملية واحدة**.

```python
# مثال Pathways: التحكم في 10,000 جهاز بكود Python واحد
model = YourModel()
output = model(input)  # ضمان القابلية للتوسع بسكريبت واحد
```

## 🛠️ اتجاه البنية التحتية للحوسبة من الجيل التالي

- تحليل التعقيد الخوارزمي التقليدي كان محوره **عدد العمليات (op count)**.
- ومع ذلك، في عصر الذكاء الاصطناعي، **عرض نطاق الذاكرة** و**حركة البيانات** ظهرت كعقد أداء رئيسية.
- خاصة في أنظمة الذكاء الاصطناعي:
  - **التدريب** و**الاستنتاج** لهما خصائص أحمال عمل مختلفة،
  - الأجهزة وتصميم النظام المحسن لكل منهما مطلوب.
- في الخلاصة، **التصميم المشترك للأجهزة-برمجيات النظام-الخوارزمية** يحدد الأداء.

---

## 🤖 جدوى مهندسي الذكاء الاصطناعي المبتدئين

- **خلال سنة**، هناك إمكانية لتنفيذ ذكاء اصطناعي بمستوى **مهندسي البرمجيات المبتدئين**.
- توليد الكود البسيط وحده غير كافٍ؛ القدرات التالية مطلوبة:
  - تنفيذ الاختبارات (مثل اختبار الوحدة/التكامل)
  - تصحيح الأداء (مثل تحليل الكمون، تحليل عقد الزجاجة)
  - تعلم الوثائق واستخدام الأدوات العملية (مثل git، CI/CD، تفسير السجلات)

---

## 🧩 معمارية النموذج المستقبلية: متناثرة ومعيارية

- جيف دين يركز على معمارية **متناثرة** قائمة على **خليط الخبراء (MoE)**.
- المفاهيم الأساسية:
  - **تفعيل المسارات الضرورية فقط** أثناء التنفيذ → استخدام فعال للموارد الحاسوبية
  - تصميم مرن ممكن بتركيبات **خبراء خفيفين** و**خبراء مكلفين**
- الخصائص المستقبلية:
  - **اختيار المسار الديناميكي**: يسمح بفروق حاسوبية من عشرات إلى آلاف المرات حسب الحالة
  - **توسع/ضغط المعاملات المعياري**:
    - توسع عند الحاجة، تنظيف الأجزاء غير الضرورية بالتقطير أو جمع القمامة
    - يمكن التعلم المستمر وتحسين الذاكرة

---

## 📌 رؤى الختام

> "**كل من الابتكار الخوارزمي وابتكار البنية التحتية مهمان. لا يمكن لأي منهما وحده الحفاظ على التنافسية.**"

- معادلة **مجرد امتلاك مجموعات كبيرة = ميزة** لم تعد صالحة.
- التنافسية الحقيقية تأتي من مجموع هذه العوامل:
  - ✅ **تصميم خوارزمي فعال**
  - ✅ **معمارية أجهزة عالية الأداء**
  - ✅ **أدوات وأطر عمل صديقة للمطور**
  - ✅ **تجربة مستخدم (UX) قائمة على العوامل بديهية وموثوقة**

---
