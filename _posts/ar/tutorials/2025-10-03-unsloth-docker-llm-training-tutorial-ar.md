---
title: "ุฏููู ุดุงูู ูุถุจุท ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุจุงุณุชุฎุฏุงู Unsloth Docker: ูู ุงูุชุซุจูุช ุฅูู ุงูุฅูุชุงุฌ"
excerpt: "ุชุนูู ููููุฉ ุถุจุท ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุจููุงุกุฉ ุจุงุณุชุฎุฏุงู ุญุงููุฉ Unsloth Docker. ูุฐุง ุงูุฏููู ุงูุดุงูู ูุบุทู ุงูุชุซุจูุช ูุงูุชูููู ูุงูุฃูุซูุฉ ุงูุนูููุฉ ููุชุฏุฑูุจ ุงููุญูู ูููุงุฐุฌ ุงููุบุฉ."
seo_title: "ุฏููู Unsloth Docker ูุถุจุท ููุงุฐุฌ ุงููุบุฉ - ุงูุฏููู ุงููุงูู 2025"
seo_description: "ุฃุชูู ุถุจุท ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุจุงุณุชุฎุฏุงู Unsloth Docker. ุฏููู ุฎุทูุฉ ุจุฎุทูุฉ ูุบุทู ุงูุชุซุจูุช ูุฅุนุฏุงุฏ GPU ูุงููุตูู ุฅูู Jupyter Lab ูุฃูุซูุฉ ุงูุชุฏุฑูุจ ุงูุนูููุฉ ูุชุฎุตูุต ุงูููุงุฐุฌ ุจููุงุกุฉ."
date: 2025-10-03
categories:
  - tutorials
tags:
  - unsloth
  - docker
  - llm
  - fine-tuning
  - machine-learning
  - gpu
  - jupyter
  - nvidia
author_profile: true
toc: true
toc_label: "ุฌุฏูู ุงููุญุชููุงุช"
lang: ar
permalink: /ar/tutorials/unsloth-docker-llm-training-tutorial/
canonical_url: "https://thakicloud.github.io/ar/tutorials/unsloth-docker-llm-training-tutorial/"
---

โฑ๏ธ **ููุช ุงููุฑุงุกุฉ ุงููุชููุน**: 12 ุฏูููุฉ

## ููุฏูุฉ

ุฃุตุจุญ ุถุจุท ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ (LLMs) ุฃูุฑุงู ูููุงู ุจุดูู ูุชุฒุงูุฏ ูุฅูุดุงุก ุชุทุจููุงุช ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุงููุชุฎุตุตุฉ. ููุน ุฐููุ ูููู ุฃู ูููู ุฅุนุฏุงุฏ ุงูุจูุฆุฉ ุงูููุงุณุจุฉ ูุชุฏุฑูุจ ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุฃูุฑุงู ุตุนุจุงู ุจุณุจุจ ุงูุชุจุนูุงุช ุงููุนูุฏุฉ ูุงูุชุนุงุฑุถุงุช ุงููุญุชููุฉ. ูุญู ุญู Unsloth Docker ูุฐู ุงููุดุงูู ูู ุฎูุงู ุชูููุฑ ุจูุฆุฉ ูุณุชูุฑุฉ ูููุนุฏุฉ ูุณุจูุงู ูุถุจุท ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุจููุงุกุฉ.

ูู ูุฐุง ุงูุฏููู ุงูุดุงููุ ุณูุณุชูุดู ููููุฉ ุงุณุชุฎุฏุงู ุตูุฑุฉ Unsloth Docker ูุถุจุท ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ูุญููุงูุ ูุบุทูู ูู ุดูุก ูู ุงูุฅุนุฏุงุฏ ุงูุฃููู ุฅูู ุฃูุซูุฉ ุงูุชุฏุฑูุจ ุงูุนูููุฉ.

## ูุง ูู Unslothุ

Unsloth ูู ุฅุทุงุฑ ุนูู ููู ูุตูู ูุชุณุฑูุน ุถุจุท ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ูุน ุชูููู ุงุณุชุฎุฏุงู ุงูุฐุงูุฑุฉ. ูููุฑ ุชุญุณููุงุช ูุจูุฑุฉ ูู ุงูุฃุฏุงุก ููุงุฑูุฉ ุจุทุฑู ุงูุถุจุท ุงูุชูููุฏูุฉุ ููุง ูุฌุนู ูู ุงููููู ุชุฏุฑูุจ ููุงุฐุฌ ุฃูุจุฑ ุนูู ุฃุฌูุฒุฉ ุงููุณุชููููู.

### ุงูููุงุฆุฏ ุงูุฑุฆูุณูุฉ ูู Unsloth Docker

- **ุฅุฏุงุฑุฉ ุงูุชุจุนูุงุช**: ููุบู "ุฌุญูู ุงูุชุจุนูุงุช" ุจุจูุฆุฉ ูุญุชูุงุฉ ุจุงููุงูู
- **ุฃูุงู ุงููุธุงู**: ูุนูู ุจุฏูู ุตูุงุญูุงุช ุงูุฌุฐุฑุ ููุง ูุญุงูุธ ุนูู ูุธุงูุฉ ุงููุธุงู
- **ูุงุจููุฉ ุงูููู**: ูุนูู ุจุซุจุงุช ุนุจุฑ ููุตุงุช ูุฅุนุฏุงุฏุงุช ูุฎุชููุฉ
- **ุจูุฆุฉ ููุนุฏุฉ ูุณุจูุงู**: ุชุชุถูู ุฌููุน ุงูุฃุฏูุงุช ูุงูููุชุจุงุช ุงูุถุฑูุฑูุฉ
- **ุชุญุฏูุซุงุช ููุชุธูุฉ**: ูุชู ุชุญุฏูุซูุง ุจุงูุชุธุงู ุจุฃุญุฏุซ ุงูุชุญุณููุงุช

## ุงููุชุทูุจุงุช ุงููุณุจูุฉ

ูุจู ุงูุจุฏุกุ ุชุฃูุฏ ูู ุชููุฑ:

- **NVIDIA GPU**: ูุทููุจ ููุชุฏุฑูุจ ุงููุนุงู (ูููุตุญ ุจู RTX 3060 ุฃู ุฃูุถู)
- **Docker**: ูุซุจุช ููุนูู ุนูู ูุธุงูู
- **NVIDIA Container Toolkit**: ูููุตูู ุฅูู GPU ุฏุงุฎู ุงูุญุงููุงุช
- **ูุณุงุญุฉ ุชุฎุฒูู ูุงููุฉ**: ุนูู ุงูุฃูู 50 ุฌูุฌุงุจุงูุช ูุณุงุญุฉ ูุงุฑุบุฉ ููููุงุฐุฌ ูุงูุจูุงูุงุช
- **ุฐุงูุฑุฉ ุงููุตูู ุงูุนุดูุงุฆู**: ูููุตุญ ุจู 16 ุฌูุฌุงุจุงูุช ุฃู ุฃูุซุฑ

## ุงูุฎุทูุฉ 1: ุชุซุจูุช Docker ู NVIDIA Container Toolkit

### ุชุซุจูุช Docker

ูุฃูุธูุฉ Linux:
```bash
# ุชุญุฏูุซ ููุฑุณ ุงูุญุฒู
sudo apt-get update

# ุชุซุจูุช Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# ุฅุถุงูุฉ ุงููุณุชุฎุฏู ุฅูู ูุฌููุนุฉ docker
sudo usermod -aG docker $USER
newgrp docker
```

ููุฃูุธูุฉ ุงูุฃุฎุฑูุ ูู ุจุฒูุงุฑุฉ [ุฏููู ุชุซุจูุช Docker ุงูุฑุณูู](https://docs.docker.com/get-docker/).

### ุชุซุจูุช NVIDIA Container Toolkit

ุชููู NVIDIA Container Toolkit ุงููุตูู ุฅูู GPU ุฏุงุฎู ุญุงููุงุช Docker:

```bash
# ุชุนููู ุงูุฅุตุฏุงุฑ (ุงุณุชุฎุฏู ุฃุญุฏุซ ุฅุตุฏุงุฑ ูุณุชูุฑ)
export NVIDIA_CONTAINER_TOOLKIT_VERSION=1.17.8-1

# ุชุซุจูุช NVIDIA Container Toolkit
sudo apt-get update && sudo apt-get install -y \
  nvidia-container-toolkit=${NVIDIA_CONTAINER_TOOLKIT_VERSION} \
  nvidia-container-toolkit-base=${NVIDIA_CONTAINER_TOOLKIT_VERSION} \
  libnvidia-container-tools=${NVIDIA_CONTAINER_TOOLKIT_VERSION} \
  libnvidia-container1=${NVIDIA_CONTAINER_TOOLKIT_VERSION}

# ุฅุนุงุฏุฉ ุชุดุบูู ุฎุฏูุฉ Docker
sudo systemctl restart docker
```

### ุงูุชุญูู ูู ุงูุชุซุจูุช

ุงุฎุชุจุฑ ุงููุตูู ุฅูู GPU:
```bash
# ุงุฎุชุจุงุฑ ุชูุงูู NVIDIA Docker
docker run --rm --gpus all nvidia/cuda:11.8-base-ubuntu20.04 nvidia-smi
```

## ุงูุฎุทูุฉ 2: ุชุดุบูู ุญุงููุฉ Unsloth Docker

### ุฅุนุฏุงุฏ ุงูุญุงููุฉ ุงูุฃุณุงุณู

ุฃูุดุฆ ุฏููู ุนูู ูุดุบู ุงูุญุงููุฉ:

```bash
# ุฅูุดุงุก ุฏููู ุงูุนูู
mkdir -p ~/unsloth-workspace
cd ~/unsloth-workspace

# ุชุดุบูู ุญุงููุฉ Unsloth ุจุงูุชูููู ุงูุฃุณุงุณู
docker run -d \
  --name unsloth-training \
  -e JUPYTER_PASSWORD="mypassword" \
  -p 8888:8888 \
  -p 2222:22 \
  -v $(pwd)/work:/workspace/work \
  --gpus all \
  unsloth/unsloth
```

### ุงูุชูููู ุงููุชูุฏู

ููุงุณุชุฎุฏุงู ูู ุงูุฅูุชุงุฌุ ููุฑ ูู ูุฐุง ุงูุฅุนุฏุงุฏ ุงููุญุณู:

```bash
# ุฅูุดุงุก ููุชุงุญ SSH ูููุตูู ุงูุขูู
ssh-keygen -t rsa -b 4096 -f ~/.ssh/unsloth_key

# ุชุดุบูู ุงูุญุงููุฉ ุจุงูุฅุนุฏุงุฏุงุช ุงููุชูุฏูุฉ
docker run -d \
  --name unsloth-production \
  -e JUPYTER_PORT=8000 \
  -e JUPYTER_PASSWORD="secure_password_2024" \
  -e "SSH_KEY=$(cat ~/.ssh/unsloth_key.pub)" \
  -e USER_PASSWORD="unsloth2024" \
  -p 8000:8000 \
  -p 2222:22 \
  -v $(pwd)/work:/workspace/work \
  -v $(pwd)/models:/workspace/models \
  -v $(pwd)/datasets:/workspace/datasets \
  --gpus all \
  --restart unless-stopped \
  unsloth/unsloth
```

## ุงูุฎุทูุฉ 3: ุงููุตูู ุฅูู Jupyter Lab

### ุงููุตูู ุนุจุฑ ูุงุฌูุฉ ุงูููุจ

1. ุงูุชุญ ูุชุตูุญู ูุงูุชูู ุฅูู `http://localhost:8888`
2. ุฃุฏุฎู ูููุฉ ุงููุฑูุฑ ุงูุชู ุญุฏุฏุชูุง (ุงูุชุฑุงุถู: "unsloth")
3. ุณุชุดุงูุฏ ูุงุฌูุฉ Jupyter Lab ูุน ุฏูุงุชุฑ ูุญููุฉ ูุณุจูุงู

### ุงููุตูู ุนุจุฑ SSH (ุงุฎุชูุงุฑู)

ูููุตูู ุนุจุฑ ุณุทุฑ ุงูุฃูุงูุฑ:
```bash
# ุงูุงุชุตุงู ุนุจุฑ SSH
ssh -i ~/.ssh/unsloth_key -p 2222 unsloth@localhost
```

## ุงูุฎุทูุฉ 4: ููู ูููู ุงูุญุงููุฉ

ุญุงููุฉ Unsloth ููุธูุฉ ููุง ููู:

```
/workspace/
โโโ work/                    # ุฏููู ุงูุนูู ุงูููุฑูุจ
โโโ unsloth-notebooks/       # ุฏูุงุชุฑ ุฃูุซูุฉ ุงูุถุจุท
โโโ models/                  # ุชุฎุฒูู ุงูููุงุฐุฌ (ุฅุฐุง ูุงู ููุฑูุจุงู)
โโโ datasets/               # ุชุฎุฒูู ูุฌููุนุงุช ุงูุจูุงูุงุช (ุฅุฐุง ูุงู ููุฑูุจุงู)

/home/unsloth/              # ุฏููู ุงููุณุชุฎุฏู ุงูุฑุฆูุณู
```

## ุงูุฎุทูุฉ 5: ูุซุงู ุงูุถุจุท ุงูุฃูู

ุฏุนูุง ููุดุฆ ูุซุงูุงู ุจุณูุทุงู ููุถุจุท ุจุงุณุชุฎุฏุงู Llama-3.

### ุฅูุดุงุก ุฏูุชุฑ ุฌุฏูุฏ

1. ูู Jupyter Labุ ุฃูุดุฆ ุฏูุชุฑุงู ุฌุฏูุฏุงู
2. ุฃุถู ุฎูุงูุง ุงูููุฏ ุงูุชุงููุฉ:

```python
# ุงูุฎููุฉ 1: ุชุซุจูุช ูุงุณุชูุฑุงุฏ ุงูุชุจุนูุงุช
from unsloth import FastLanguageModel
import torch

# ุงูุฎููุฉ 2: ุชุญููู ุงููููุฐุฌ
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name="unsloth/llama-3-8b-bnb-4bit",
    max_seq_length=2048,
    dtype=None,
    load_in_4bit=True,
)

# ุงูุฎููุฉ 3: ุชูููู LoRA
model = FastLanguageModel.get_peft_model(
    model,
    r=16,
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj",
                    "gate_proj", "up_proj", "down_proj"],
    lora_alpha=16,
    lora_dropout=0,
    bias="none",
    use_gradient_checkpointing="unsloth",
    random_state=3407,
    use_rslora=False,
    loftq_config=None,
)

# ุงูุฎููุฉ 4: ุฅุนุฏุงุฏ ูุฌููุนุฉ ุงูุจูุงูุงุช
alpaca_prompt = """Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.

### Instruction:
{}

### Input:
{}

### Response:
{}"""

def formatting_prompts_func(examples):
    instructions = examples["instruction"]
    inputs       = examples["input"]
    outputs      = examples["output"]
    texts = []
    for instruction, input, output in zip(instructions, inputs, outputs):
        text = alpaca_prompt.format(instruction, input, output) + tokenizer.eos_token
        texts.append(text)
    return { "text" : texts, }

# ุชุญููู ูุฌููุนุฉ ุงูุจูุงูุงุช
from datasets import load_dataset
dataset = load_dataset("yahma/alpaca-cleaned", split="train")
dataset = dataset.map(formatting_prompts_func, batched=True)

# ุงูุฎููุฉ 5: ุชูููู ุงูุชุฏุฑูุจ
from trl import SFTTrainer
from transformers import TrainingArguments

trainer = SFTTrainer(
    model=model,
    tokenizer=tokenizer,
    train_dataset=dataset,
    dataset_text_field="text",
    max_seq_length=2048,
    dataset_num_proc=2,
    packing=False,
    args=TrainingArguments(
        per_device_train_batch_size=2,
        gradient_accumulation_steps=4,
        warmup_steps=5,
        max_steps=60,
        learning_rate=2e-4,
        fp16=not torch.cuda.is_bf16_supported(),
        bf16=torch.cuda.is_bf16_supported(),
        logging_steps=1,
        optim="adamw_8bit",
        weight_decay=0.01,
        lr_scheduler_type="linear",
        seed=3407,
        output_dir="outputs",
    ),
)

# ุงูุฎููุฉ 6: ุจุฏุก ุงูุชุฏุฑูุจ
trainer_stats = trainer.train()
```

### ูุฑุงูุจุฉ ุชูุฏู ุงูุชุฏุฑูุจ

ุณุชุนุฑุถ ุนูููุฉ ุงูุชุฏุฑูุจ ุฃุดุฑุทุฉ ุงูุชูุฏู ูููุงููุณ ุงูุฎุณุงุฑุฉ. ุฑุงูุจ ูุฐู ูุถูุงู ุฃู ุงูุชุฏุฑูุจ ูุณูุฑ ุจุดูู ุตุญูุญ.

## ุงูุฎุทูุฉ 6: ุญูุธ ูุงุณุชุฎุฏุงู ุงููููุฐุฌ ุงููุถุจูุท

### ุงูุญูุธ ุจุชูุณููุงุช ูุฎุชููุฉ

```python
# ุงูุญูุธ ุจุชูุณูู Hugging Face
model.save_pretrained("my_finetuned_model")
tokenizer.save_pretrained("my_finetuned_model")

# ุงูุญูุธ ุจุชูุณูู GGUF ูู Ollama
model.save_pretrained_gguf("my_model", tokenizer, quantization_method="q4_k_m")

# ุงูุญูุธ ูู VLLM
model.save_pretrained_merged("my_model_vllm", tokenizer, save_method="merged_16bit")
```

### ุงุฎุชุจุงุฑ ุงููููุฐุฌ

```python
# ุงุฎุชุจุงุฑ ุงูุงุณุชูุชุงุฌ
FastLanguageModel.for_inference(model)

inputs = tokenizer(
    [alpaca_prompt.format(
        "ูุง ูู ุนุงุตูุฉ ูุฑูุณุงุ",
        "",
        ""
    )], return_tensors="pt").to("cuda")

outputs = model.generate(**inputs, max_new_tokens=64, use_cache=True)
print(tokenizer.batch_decode(outputs))
```

## ุฎูุงุฑุงุช ุงูุชูููู ุงููุชูุฏูุฉ

### ูุชุบูุฑุงุช ุงูุจูุฆุฉ

| ุงููุชุบูุฑ | ุงููุตู | ุงููููุฉ ุงูุงูุชุฑุงุถูุฉ |
|---------|--------|------------------|
| `JUPYTER_PASSWORD` | ูููุฉ ูุฑูุฑ Jupyter Lab | `unsloth` |
| `JUPYTER_PORT` | ูููุฐ Jupyter Lab | `8888` |
| `SSH_KEY` | ุงูููุชุงุญ ุงูุนุงู ูู SSH | `None` |
| `USER_PASSWORD` | ูููุฉ ูุฑูุฑ ุงููุณุชุฎุฏู ูู sudo | `unsloth` |

### ุชุญุณูู ุฐุงูุฑุฉ GPU

ููุฃูุธูุฉ ุฐุงุช ุฐุงูุฑุฉ GPU ุงููุญุฏูุฏุฉ:

```python
# ุงุณุชุฎุฏุงู ุฃุญุฌุงู ุฏูุนุงุช ุฃุตุบุฑ
per_device_train_batch_size=1
gradient_accumulation_steps=8

# ุชูุนูู ููุงุท ุชูุชูุด ุงูุชุฏุฑุฌ
use_gradient_checkpointing="unsloth"

# ุงุณุชุฎุฏุงู ุงูุชูููู 4-ุจุช
load_in_4bit=True
```

### ุงูุชุฏุฑูุจ ูุชุนุฏุฏ GPU

ููุฃูุธูุฉ ุฐุงุช GPUs ูุชุนุฏุฏุฉ:

```bash
# ุชุดุบูู ุงูุญุงููุฉ ูุน ุฌููุน GPUs
docker run -d \
  --gpus all \
  # ... ูุนุงููุงุช ุฃุฎุฑู
  unsloth/unsloth

# ูู ุณูุฑูุจุช ุงูุชุฏุฑูุจุ ุงุณุชุฎุฏู DataParallel
model = torch.nn.DataParallel(model)
```

## ุญู ุงููุดุงูู ุงูุดุงุฆุนุฉ

### ุนุฏู ุงูุชุดุงู GPU

```bash
# ูุญุต ุชููุฑ GPU
nvidia-smi

# ุงูุชุญูู ูู ูุตูู Docker ุฅูู GPU
docker run --rm --gpus all nvidia/cuda:11.8-base-ubuntu20.04 nvidia-smi
```

### ูุดุงูู ุงูุฐุงูุฑุฉ

- ุชูููู ุญุฌู ุงูุฏูุนุฉ
- ุชูุนูู ููุงุท ุชูุชูุด ุงูุชุฏุฑุฌ
- ุงุณุชุฎุฏุงู ุงูุชูููู 4-ุจุช
- ูุณุญ ุฐุงูุฑุฉ GPU: `torch.cuda.empty_cache()`

### ูุดุงูู ุงููุตูู ุฅูู ุงูุญุงููุฉ

```bash
# ูุญุต ุญุงูุฉ ุงูุญุงููุฉ
docker ps -a

# ุนุฑุถ ุณุฌูุงุช ุงูุญุงููุฉ
docker logs unsloth-training

# ุฅุนุงุฏุฉ ุชุดุบูู ุงูุญุงููุฉ
docker restart unsloth-training
```

## ุฃูุถู ุงูููุงุฑุณุงุช

### 1. ุฅุฏุงุฑุฉ ุงูุจูุงูุงุช

- ุงุณุชุฎุฏุงู ุชุฑููุจ ุงูุฃุญุฌุงู ููุชุฎุฒูู ุงูุฏุงุฆู
- ุชูุธูู ูุฌููุนุงุช ุงูุจูุงูุงุช ูู ุฃุฏูุฉ ูุฎุตุตุฉ
- ูุณุฎ ุงุญุชูุงุทู ููุชุธู ููููุงุฐุฌ ุงููููุฉ

### 2. ูุฑุงูุจุฉ ุงูููุงุฑุฏ

```python
# ูุฑุงูุจุฉ ุงุณุชุฎุฏุงู GPU
import GPUtil
GPUtil.showUtilization()

# ูุฑุงูุจุฉ ููุงุฑุฏ ุงููุธุงู
import psutil
print(f"CPU: {psutil.cpu_percent()}%")
print(f"RAM: {psutil.virtual_memory().percent}%")
```

### 3. ุงุนุชุจุงุฑุงุช ุงูุฃูุงู

- ุงุณุชุฎุฏุงู ูููุงุช ูุฑูุฑ ูููุฉ ูููุตูู ุฅูู Jupyter
- ุชูููุฐ ูุตุงุฏูุฉ ููุชุงุญ SSH
- ุชุดุบูู ุงูุญุงููุงุช ููุณุชุฎุฏููู ุบูุฑ ุฌุฐุฑ
- ุชุญุฏูุซ ุตูุฑุฉ Unsloth ุจุงูุชุธุงู

### 4. ุชุญุณูู ุงูุฃุฏุงุก

- ุงุณุชุฎุฏุงู ุฃุญุฌุงู ุฏูุนุงุช ููุงุณุจุฉ ูู GPU ุงูุฎุงุต ุจู
- ุชูุนูู ุชุฏุฑูุจ ุงูุฏูุฉ ุงููุฎุชูุทุฉ
- ุงุณุชุฎุฏุงู ุชุฑุงูู ุงูุชุฏุฑุฌ ูุฃุญุฌุงู ุฏูุนุงุช ุฃูุจุฑ ูุนุงูุฉ
- ูุฑุงูุจุฉ ููุงููุณ ุงูุชุฏุฑูุจ ูููุน ุงูุฅูุฑุงุท ูู ุงูุชุฏุฑูุจ

## ุงููุดุฑ ูู ุงูุฅูุชุงุฌ

### ุฅุนุฏุงุฏ Docker Compose

ุฅูุดุงุก `docker-compose.yml` ูุฅุฏุงุฑุฉ ุฃุณูู:

```yaml
version: '3.8'
services:
  unsloth:
    image: unsloth/unsloth
    container_name: unsloth-production
    environment:
      - JUPYTER_PASSWORD=secure_password
      - JUPYTER_PORT=8888
      - USER_PASSWORD=unsloth2024
    ports:
      - "8888:8888"
      - "2222:22"
    volumes:
      - ./work:/workspace/work
      - ./models:/workspace/models
      - ./datasets:/workspace/datasets
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped
```

### ุฎุท ุฃูุงุจูุจ ุงูุชุฏุฑูุจ ุงูุขูู

ุฅูุดุงุก ุณูุฑูุจุช ุชุฏุฑูุจ ูุณูุฑ ุงูุนูู ุงูุขูู:

```python
#!/usr/bin/env python3
"""
ุฎุท ุฃูุงุจูุจ ุชุฏุฑูุจ Unsloth ุงูุขูู
"""
import argparse
import json
from pathlib import Path
from unsloth import FastLanguageModel
from transformers import TrainingArguments
from trl import SFTTrainer

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", required=True, help="ููู JSON ูุชูููู ุงูุชุฏุฑูุจ")
    args = parser.parse_args()
    
    # ุชุญููู ุงูุชูููู
    with open(args.config) as f:
        config = json.load(f)
    
    # ุชููุฆุฉ ุงููููุฐุฌ
    model, tokenizer = FastLanguageModel.from_pretrained(
        model_name=config["model_name"],
        max_seq_length=config["max_seq_length"],
        load_in_4bit=config.get("load_in_4bit", True)
    )
    
    # ุชูููู LoRA
    model = FastLanguageModel.get_peft_model(
        model,
        r=config["lora_r"],
        target_modules=config["target_modules"],
        lora_alpha=config["lora_alpha"],
        lora_dropout=config["lora_dropout"],
        bias="none",
        use_gradient_checkpointing="unsloth"
    )
    
    # ููุทู ุงูุชุฏุฑูุจ...
    print("ุชู ุฅููุงู ุงูุชุฏุฑูุจ ุจูุฌุงุญ!")

if __name__ == "__main__":
    main()
```

## ุงูุฎูุงุตุฉ

ูููุฑ Unsloth Docker ุญูุงู ููุชุงุฒุงู ูุถุจุท ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉุ ููุง ููุบู ุชุนููุฏ ุงูุฅุนุฏุงุฏ ูุน ุงูุญูุงุธ ุนูู ุงูุฃุฏุงุก ูุงููุฑููุฉ. ุจุงุชุจุงุน ูุฐุง ุงูุฏูููุ ูุฏูู ุงูุขู:

- ุจูุฆุฉ Unsloth ููููุฉ ุจุงููุงูู
- ููู ูุฎูุงุฑุงุช ุงูุชูููู ุงูุฃุณุงุณูุฉ ูุงููุชูุฏูุฉ
- ุฎุจุฑุฉ ุนูููุฉ ูุน ุณูุฑ ุนูู ุงูุถุจุท
- ูุนุฑูุฉ ุจุฃูุถู ุงูููุงุฑุณุงุช ูุชูููุงุช ุญู ุงููุดุงูู

ูุถูู ุงูููุฌ ุงููุญุชูู ูุชุงุฆุฌ ูุงุจูุฉ ููุชูุฑุงุฑ ููุฌุนู ูู ุงูุณูู ุชูุณูุน ุนูููุงุช ุงูุถุจุท ุนุจุฑ ุจูุฆุงุช ูุฎุชููุฉ.

### ุงูุฎุทูุงุช ุงูุชุงููุฉ

1. **ุชุฌุฑูุจ ููุงุฐุฌ ูุฎุชููุฉ**: ุฌุฑุจ ุถุจุท ูุนูุงุฑูุงุช ููุงุฐุฌ ูุชููุนุฉ
2. **ุงุณุชูุดุงู ุงูุชูููุงุช ุงููุชูุฏูุฉ**: ุงุจุญุซ ูู ุงูุชุนูู ุงููุนุฒุฒ ูุชุฏุฑูุจ DPO
3. **ุงูุชุญุณูู ููุฅูุชุงุฌ**: ุชูููุฐ ุฎุทูุท ุฃูุงุจูุจ ุงูุชุฏุฑูุจ ุงูุขููุฉ
4. **ูุฑุงูุจุฉ ุงูุฃุฏุงุก**: ุฅุนุฏุงุฏ ุชุณุฌูู ููุฑุงูุจุฉ ุดุงูููู

### ููุงุฑุฏ ุฅุถุงููุฉ

- [ูุซุงุฆู Unsloth ุงูุฑุณููุฉ](https://docs.unsloth.ai/)
- [ูุณุชูุฏุน Unsloth ุนูู GitHub](https://github.com/unslothai/unsloth)
- [ุฃูุถู ููุงุฑุณุงุช Docker](https://docs.docker.com/develop/best-practices/)
- [ูุซุงุฆู NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/)

ุชุฏุฑูุจ ุณุนูุฏ! ๐
