---
title: "دليل Ollama App الشامل: أفضل عميل لنماذج الذكاء الاصطناعي المحلية"
excerpt: "تعلم كيفية استخدام Ollama App للتفاعل مع نماذج الذكاء الاصطناعي المحلية خطوة بخطوة. من التثبيت إلى الميزات المتقدمة، نغطي كل ما تحتاج لمعرفته."
seo_title: "دليل Ollama App الشامل - تعليم استخدام عميل نماذج الذكاء الاصطناعي المحلية"
seo_description: "أتقن استخدام Ollama App للدردشة مع نماذج الذكاء الاصطناعي المحلية. دليل شامل للتثبيت والإعداد والاستخدام مع الميزات المتقدمة وحل المشاكل."
date: 2025-10-01
categories:
  - tutorials
tags:
  - ollama
  - ai
  - local-ai
  - flutter
  - mobile-app
author_profile: true
toc: true
toc_label: "جدول المحتويات"
canonical_url: "https://thakicloud.github.io/ar/tutorials/ollama-app-complete-guide/"
lang: ar
permalink: /ar/tutorials/ollama-app-complete-guide/
---

⏱️ **الوقت المقدر للقراءة**: 12 دقيقة

## مقدمة

Ollama App هو عميل حديث وسهل الاستخدام للتفاعل مع نماذج الذكاء الاصطناعي المحلية. يتيح لك هذا التطبيق الاستفادة من قوة نماذج الذكاء الاصطناعي مع الحفاظ على خصوصية وأمان بياناتك. يغطي هذا الدليل الشامل كل شيء من التثبيت إلى الميزات المتقدمة.

## ما هو Ollama App؟

Ollama App هو تطبيق متعدد المنصات مبني باستخدام Flutter، تم تطويره بواسطة [JHubi1/ollama-app](https://github.com/JHubi1/ollama-app). يعمل كعميل يتصل بخادم Ollama، مما يتيح لك الدردشة مع نماذج الذكاء الاصطناعي المحلية.

### الميزات الرئيسية

- **حماية الخصوصية**: جميع البيانات تتم معالجتها داخل شبكتك المحلية
- **متعدد المنصات**: يدعم Android و Windows و Linux و macOS
- **واجهة بديهية**: واجهة حديثة وسهلة الاستخدام
- **دعم نماذج متعددة**: يعمل مع Llama و Mistral و CodeLlama والمزيد
- **وضع الصوت**: ميزة محادثة صوتية تجريبية

## متطلبات النظام

### منصات سطح المكتب
- **Windows**: Windows 10 أو أعلى
- **Linux**: مكتبات GTK3 مطلوبة
- **macOS**: macOS 10.14 أو أعلى

### منصات الهاتف المحمول
- **Android**: Android 5.0 (API 21) أو أعلى

## الخطوة 1: تثبيت خادم Ollama

قبل استخدام Ollama App، تحتاج إلى تثبيت خادم Ollama أولاً.

### تثبيت Windows
```bash
# تشغيل في PowerShell
winget install Ollama.Ollama
```

### تثبيت macOS
```bash
# استخدام Homebrew
brew install ollama

# أو استخدام سكريبت التثبيت الرسمي
curl -fsSL https://ollama.com/install.sh | sh
```

### تثبيت Linux
```bash
# Ubuntu/Debian
curl -fsSL https://ollama.com/install.sh | sh

# أو استخدام مدير الحزم
sudo apt install ollama
```

## الخطوة 2: بدء تشغيل خادم Ollama

بعد التثبيت، ابدأ تشغيل خادم Ollama.

```bash
# بدء الخادم
ollama serve

# تشغيل في الخلفية (Linux/macOS)
ollama serve &
```

بمجرد بدء الخادم بنجاح، ستكون API متاحة على `http://localhost:11434`.

## الخطوة 3: تحميل نماذج الذكاء الاصطناعي

مع تشغيل خادم Ollama، يمكنك تحميل نماذج الذكاء الاصطناعي المطلوبة.

```bash
# تحميل نموذج Llama 2
ollama pull llama2

# تحميل نموذج Mistral
ollama pull mistral

# تحميل نموذج CodeLlama
ollama pull codellama

# فحص النماذج المتاحة
ollama list
```

## الخطوة 4: تثبيت Ollama App

### تثبيت Android
1. تحميل من [Google Play Store](https://play.google.com/store/apps/details?id=com.jhubi.ollama_app)
2. أو تحميل APK من [GitHub Releases](https://github.com/JHubi1/ollama-app/releases)

### تثبيت Windows
1. تحميل مثبت Windows من [GitHub Releases](https://github.com/JHubi1/ollama-app/releases)
2. تشغيل المثبت (قد تحتاج إلى تجاهل تحذيرات Windows Defender)
3. تشغيل التطبيق بعد التثبيت

### تثبيت Linux
```bash
# تحميل ملف Linux القابل للتنفيذ من صفحة الإصدارات
wget https://github.com/JHubi1/ollama-app/releases/latest/download/ollama-linux.tar.gz

# استخراج
tar -xzf ollama-linux.tar.gz

# تشغيل
./ollama
```

### تثبيت macOS
```bash
# استخدام Homebrew (إذا كان cask متاحاً)
brew install --cask ollama-app

# أو تحميل مباشرة من GitHub
```

## الخطوة 5: تكوين Ollama App

### الإعداد الأولي

1. **تشغيل التطبيق**: ابدأ تشغيل Ollama App
2. **تكوين المضيف**: أدخل عنوان خادم Ollama
   - الخادم المحلي: `http://localhost:11434`
   - الخادم البعيد: `http://[serverIP]:11434`
3. **اختبار الاتصال**: بمجرد الاتصال، ستظهر قائمة النماذج المتاحة

### الإعدادات المتقدمة

#### تكوين الشبكة
- **إعدادات البروكسي**: الاتصال عبر البروكسي في الشبكات المؤسسية
- **شهادات SSL**: تكوين الشهادات للاتصالات HTTPS
- **إعدادات المهلة**: ضبط مدة مهلة الاتصال

#### إعدادات النموذج
- **النموذج الافتراضي**: تعيين النموذج ليتم اختياره تلقائياً عند بدء التطبيق
- **معاملات النموذج**: ضبط درجة الحرارة والرموز المميزة القصوى ومعاملات النموذج الأخرى
- **طول السياق**: تعيين طول سياق المحادثة

## الخطوة 6: الاستخدام الأساسي

### بدء محادثة

1. **اختيار النموذج**: اختر نموذج الذكاء الاصطناعي الذي تريد استخدامه
2. **إدخال الرسالة**: اكتب رسالتك في حقل إدخال النص في الأسفل
3. **إرسال**: اضغط على زر الإرسال أو اضغط Enter
4. **عرض الرد**: تحقق من رد نموذج الذكاء الاصطناعي

### إدارة المحادثات

#### تاريخ المحادثات
- **قائمة المحادثات**: عرض المحادثات السابقة في قائمة
- **البحث في المحادثات**: البحث عن محادثات محددة باستخدام الكلمات المفتاحية
- **حذف المحادثات**: إزالة المحادثات غير الضرورية

#### تصدير المحادثات
- **تصدير النص**: تصدير المحادثات كملفات نصية
- **تصدير PDF**: تصدير المحادثات كملفات PDF
- **المشاركة**: مشاركة المحادثات مع التطبيقات الأخرى

## الخطوة 7: الميزات المتقدمة

### وضع الصوت (ميزة تجريبية)

وضع الصوت في Ollama App هو ميزة تجريبية تتيح لك إجراء محادثات صوتية مع الذكاء الاصطناعي.

#### تفعيل وضع الصوت
1. تفعيل خيار "وضع الصوت" في الإعدادات
2. منح أذونات الميكروفون
3. استخدام زر الإدخال الصوتي

#### استخدام وضع الصوت
- **الإدخال الصوتي**: اضغط مع الاستمرار على زر الميكروفون أثناء التحدث
- **الإرسال التلقائي**: يتم إرسال الرسائل تلقائياً بعد التعرف على الصوت
- **الإخراج الصوتي**: الاستماع إلى ردود الذكاء الاصطناعي مع الإخراج الصوتي

### إدارة النماذج

#### معلومات النموذج
- **حجم النموذج**: فحص استخدام القرص لكل نموذج
- **أداء النموذج**: عرض معلومات سرعة الاستدلال والدقة
- **تحديثات النموذج**: فحص وتحديث إصدارات النماذج الجديدة

#### تحسين النموذج
- **تسريع GPU**: استخدام تسريع CUDA إذا كان GPU NVIDIA متاحاً
- **إدارة الذاكرة**: تحسين استخدام الذاكرة لتحميل النماذج
- **المعالجة المجمعة**: معالجة طلبات متعددة في مجموعات لأداء أفضل

## الخطوة 8: حل المشاكل

### المشاكل الشائعة

#### مشاكل الاتصال
```bash
# فحص حالة خادم Ollama
ollama ps

# إعادة تشغيل الخادم
ollama serve
```

#### مشاكل تحميل النماذج
```bash
# إعادة تحميل النموذج
ollama pull [model-name]

# حذف وإعادة تثبيت النموذج
ollama rm [model-name]
ollama pull [model-name]
```

#### مشاكل الأداء
- **نقص الذاكرة**: استخدام نماذج أصغر أو زيادة ذاكرة النظام
- **رد بطيء**: تفعيل تسريع GPU أو استخدام أجهزة أسرع
- **تأخير الشبكة**: استخدام خادم محلي أو تحسين الشبكة

### فحص السجلات

#### سجلات خادم Ollama
```bash
# فحص سجلات الخادم
ollama logs

# سجلات مفصلة
ollama serve --verbose
```

#### فحص سجلات التطبيق
- **Android**: استخدام Logcat في Android Studio
- **Windows**: فحص سجلات التطبيق في Event Viewer
- **Linux**: عرض السجلات مباشرة في الطرفية

## الخطوة 9: اعتبارات الأمان

### حماية الخصوصية
- **المعالجة المحلية**: جميع البيانات تتم معالجتها محلياً ولا يتم إرسالها خارجياً أبداً
- **تشفير البيانات**: تشفير محلي لبيانات المحادثة
- **التحكم في الوصول**: إعدادات المصادقة للوصول إلى التطبيق

### أمان الشبكة
- **استخدام HTTPS**: استخدام اتصالات HTTPS عند الإمكان
- **إعدادات الجدار الناري**: فتح المنافذ الضرورية فقط
- **استخدام VPN**: استخدام اتصال VPN عند استخدام الخوادم البعيدة

## الخطوة 10: نصائح التحسين

### تحسين الأداء

#### تحسين الأجهزة
- **استخدام SSD**: استخدام SSD لتحميل أسرع للنماذج
- **ذاكرة كافية**: ضمان وجود ذاكرة بحجم ضعف حجم النموذج على الأقل
- **استخدام GPU**: استخدام تسريع CUDA إذا كان GPU NVIDIA متاحاً

#### تحسين البرمجيات
- **اختيار النموذج**: اختيار نماذج بحجم مناسب لاستخدامك
- **إدارة السياق**: تنظيف تاريخ المحادثات غير الضروري
- **استخدام التخزين المؤقت**: استخدام التخزين المؤقت للنماذج المستخدمة بكثرة

### تحسين سهولة الاستخدام

#### اختصارات لوحة المفاتيح
- **Enter**: إرسال الرسالة
- **Ctrl+Enter**: فاصل السطر
- **Ctrl+A**: تحديد الكل
- **Ctrl+C/V**: نسخ/لصق

#### تحسين الإعدادات
- **الحفظ التلقائي**: تفعيل حفظ المحادثات التلقائي
- **إعدادات الإشعارات**: تكوين إشعارات الرسائل الجديدة
- **إعدادات المظهر**: تعيين وضع الظلام/الضوء

## الخلاصة

Ollama App هو أحد أفضل العملاء للتفاعل مع نماذج الذكاء الاصطناعي المحلية. يغطي هذا الدليل كل شيء من التثبيت إلى الميزات المتقدمة. يمكنك الآن الاستفادة من نماذج الذكاء الاصطناعي القوية مع الحفاظ على خصوصية وأمان بياناتك.

### الخطوات التالية
- تحقق من [الوثائق الرسمية لـ Ollama](https://ollama.com/docs) لمزيد من المعلومات
- زر [مستودع GitHub](https://github.com/JHubi1/ollama-app) للحصول على أحدث التحديثات
- شارك التجارب مع المستخدمين الآخرين في المجتمع

### روابط مفيدة
- [الموقع الرسمي لـ Ollama](https://ollama.com)
- [مستودع Ollama App على GitHub](https://github.com/JHubi1/ollama-app)
- [مكتبة نماذج Ollama](https://ollama.com/library)
- [وثائق تطوير Flutter](https://flutter.dev/docs)

---

**💡 نصيحة**: إذا واجهت مشاكل أثناء استخدام Ollama App، أبلغ عنها في GitHub Issues أو اطلب المساعدة في المجتمع. مجتمع نشط دائماً مستعد للمساعدة!
