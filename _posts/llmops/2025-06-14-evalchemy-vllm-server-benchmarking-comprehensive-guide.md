---
title: "vLLM ì„œë²„ë¡œ ê³ ì„±ëŠ¥ ëª¨ë¸ ë²¤ì¹˜ë§ˆí‚¹í•˜ê¸°: Evalchemy ì™„ë²½ ì‹¤ì „ ê°€ì´ë“œ"
excerpt: "vLLM ì„œë²„ì™€ Evalchemyë¥¼ ì—°ë™í•˜ì—¬ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ íš¨ìœ¨ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ë°©ë²•ê³¼ 50+ ë²¤ì¹˜ë§ˆí¬ íƒœìŠ¤í¬ ì´ì •ë¦¬"
date: 2025-06-14
categories: 
  - llmops
  - dev
tags: 
  - vllm
  - evalchemy
  - benchmarking
  - model-evaluation
  - gpu-inference
  - performance-optimization
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
---

## ì†Œê°œ

GPU ì„œë²„ì—ì„œ vLLMìœ¼ë¡œ ëª¨ë¸ì„ ê³ ì† ì‹¤í–‰í•˜ë©´ì„œ ì²´ê³„ì ì¸ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì›í•˜ì…¨ë‚˜ìš”? **vLLM + Evalchemy** ì¡°í•©ì´ë©´ OpenAI APIì™€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤ë¡œ 50+ ì¢…ë¥˜ì˜ í‰ê°€ íƒœìŠ¤í¬ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

ì´ ê°€ì´ë“œì—ì„œëŠ” vLLM ì„œë²„ ì„¤ì •ë¶€í„° Evalchemy ì—°ë™, ê·¸ë¦¬ê³  ìˆ˜í•™ ì¶”ë¡ (MATH500), ì½”ë”©(HumanEval), ê³¼í•™ ì§€ì‹(MMLU), ìƒì‹ ì¶”ë¡ (HellaSwag) ë“± ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ íƒœìŠ¤í¬ë¥¼ ì‹¤í–‰í•˜ëŠ” ì „ ê³¼ì •ì„ ë‹¤ë£¹ë‹ˆë‹¤. Evalchemyì˜ `Curator` ëª¨ë¸ ì–´ëŒ‘í„°ì™€ `LM-Eval-Harness`ë¥¼ í†µí•´ REST APIë¡œ ëª¨ë¸ì„ í˜¸ì¶œí•˜ê³  í‰ê°€í•˜ëŠ” ì „ ê³¼ì •ì„ ì •ë¦¬í•©ë‹ˆë‹¤. CLI í”Œë˜ê·¸ì—ì„œ `--model curator` ë˜ëŠ” `--model openai`ë§Œ ë°”ê¿”ì£¼ë©´ GPT-4o, Claude 3, GeminiëŠ” ë¬¼ë¡ , ìì²´ vLLM ì„œë²„ë‚˜ 100ì¢… ì´ìƒì˜ API ëª¨ë¸ì„ ì„¤ì¹˜ ì—†ì´ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ í‰ê°€í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤.

### í•µì‹¬ ì¥ì 

- **20ë°° ë¹ ë¥¸ ì¶”ë¡  ì†ë„**: CPU ê¸°ë°˜ ëŒ€ë¹„ GPU vLLMì˜ ì••ë„ì  ì„±ëŠ¥
- **í™•ì¥ ê°€ëŠ¥í•œ ë°°ì¹˜ ì²˜ë¦¬**: ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ë¡œ ì²˜ë¦¬ëŸ‰ ê·¹ëŒ€í™”
- **í‘œì¤€í™”ëœ í‰ê°€**: LM-Eval-Harness ê¸°ë°˜ ì¼ê´€ëœ í‰ê°€ í™˜ê²½
- **50+ ë²¤ì¹˜ë§ˆí¬ ì§€ì›**: ë‹¤ì–‘í•œ ë„ë©”ì¸ì˜ ì¢…í•©ì  ëª¨ë¸ í‰ê°€

## vLLM ì„œë²„ ì„¤ì • ë° ì‹¤í–‰

### í™˜ê²½ ì¤€ë¹„

```bash
# vLLM ì„¤ì¹˜ (CUDA í™˜ê²½ í•„ìš”)
pip install vllm

# í•„ìš”í•œ ì˜ì¡´ì„± ì„¤ì¹˜
pip install transformers torch accelerate
```

### vLLM ì„œë²„ ì‹¤í–‰

#### í‘œì¤€ ì„¤ì •ìœ¼ë¡œ ì„œë²„ ì‹œì‘

```bash
# ê¸°ë³¸ vLLM ì„œë²„ ì‹¤í–‰
vllm serve microsoft/DialoGPT-medium \
  --host 0.0.0.0 \
  --port 8000 \
  --api-key your-secret-key
```

#### ê³ ì„±ëŠ¥ ìµœì í™” ì„¤ì •

```bash
# ì„±ëŠ¥ ìµœì í™”ëœ vLLM ì„œë²„ ì‹¤í–‰
vllm serve deepseek-ai/deepseek-r1-0528-qwen3-8b \
  --host 0.0.0.0 \
  --port 8000 \
  --api-key your-secret-key \
  --tensor-parallel-size 2 \
  --max-model-len 8192 \
  --max-num-batched-tokens 8192 \
  --enable-chunked-prefill \
  --gpu-memory-utilization 0.9 \
  --disable-log-requests
```

#### ì£¼ìš” íŒŒë¼ë¯¸í„° ì„¤ëª…

| íŒŒë¼ë¯¸í„° | ì„¤ëª… | ê¶Œì¥ê°’ |
|:---------|:-----|:-------|
| `--tensor-parallel-size` | GPU ë³‘ë ¬ ì²˜ë¦¬ ê°œìˆ˜ | GPU ê°œìˆ˜ì— ë§ì¶° ì„¤ì • |
| `--max-model-len` | ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ | 8192 ë˜ëŠ” 4096 |
| `--max-num-batched-tokens` | ë°°ì¹˜ ì²˜ë¦¬ ìµœëŒ€ í† í° | 8192-16384 |
| `--enable-chunked-prefill` | ì²­í¬ ë‹¨ìœ„ prefill í™œì„±í™” | ì²˜ë¦¬ëŸ‰ í–¥ìƒ |
| `--gpu-memory-utilization` | GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  | 0.85-0.95 |

### ì„œë²„ ìƒíƒœ í™•ì¸

```bash
# ëª¨ë¸ ëª©ë¡ í™•ì¸
curl http://localhost:8000/v1/models

# ê°„ë‹¨í•œ ì±„íŒ… í…ŒìŠ¤íŠ¸
curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-secret-key" \
  -d '{
    "model": "deepseek-ai/deepseek-r1-0528-qwen3-8b",
    "messages": [{"role": "user", "content": "Hello"}],
    "max_tokens": 100
  }'
```

## Evalchemy + vLLM ì—°ë™ ì„¤ì •

### í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
# 1. LiteLLM ìµœì‹  ë²„ì „ ì„¤ì¹˜
pip install -U "litellm>=1.72"

# 2. vLLM ì„œë²„ ì •ë³´ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export OPENAI_API_BASE="http://localhost:8000/v1"
export OPENAI_API_KEY="your-secret-key"

# 3. Evalchemy ì„¤ì¹˜
pip install evalchemy
```

### ê¸°ë³¸ ì‹¤í–‰ ëª…ë ¹ì–´

```bash
# ë°©ë²• 1: OpenAI í˜¸í™˜ API ì–´ëŒ‘í„° ì‚¬ìš©
python -m eval.eval \
  --model openai \
  --tasks MMLU,HellaSwag,ARC-c \
  --model_name "deepseek-ai/deepseek-r1-0528-qwen3-8b" \
  --apply_chat_template True \
  --batch_size 8 \
  --output_path logs/vllm_benchmark_results.json

# ë°©ë²• 2: Curator ì–´ëŒ‘í„° ì‚¬ìš© (LiteLLM í†µí•©)
python -m eval.eval \
  --model curator \
  --tasks MMLU,HellaSwag,ARC-c \
  --model_name "openai/deepseek-ai/deepseek-r1-0528-qwen3-8b" \
  --model_args "api_base=http://localhost:8000/v1,api_key=your-secret-key" \
  --apply_chat_template True \
  --batch_size 8 \
  --output_path logs/vllm_curator_results.json
```

## í‰ê°€ ê°€ëŠ¥í•œ íƒœìŠ¤í¬ ì¢…í•© ê°€ì´ë“œ

### ìˆ˜í•™ ë° ì¶”ë¡  íƒœìŠ¤í¬

| íƒœìŠ¤í¬ëª… | ì„¤ëª… | ë¬¸ì œ ìˆ˜ | í‰ê°€ ì§€í‘œ | ë‚œì´ë„ |
|:---------|:-----|:--------|:----------|:-------|
| **AIME24** | ë¯¸êµ­ ìˆ˜í•™ ê²½ì‹œëŒ€íšŒ ë¬¸ì œ | 30 | ì •í™•ë„ | ë§¤ìš° ì–´ë ¤ì›€ |
| **MATH500** | ê³ ë“±í•™êµ/ëŒ€í•™ ìˆ˜í•™ ë¬¸ì œ | 500 | ì •í™•ë„ | ì–´ë ¤ì›€ |
| **GSM8K** | ì´ˆë“±í•™êµ ìˆ˜í•™ ë‹¨ì–´ ë¬¸ì œ | 1,319 | ì •í™•ë„ | ë³´í†µ |
| **MATH** | ê²½ìŸ ìˆ˜í•™ ë¬¸ì œ (ì „ì²´) | 12,500 | ì •í™•ë„ | ì–´ë ¤ì›€ |
| **MathQA** | ë‹¤ì¤‘ ì„ íƒ ìˆ˜í•™ ë¬¸ì œ | 37,000 | ì •í™•ë„ | ë³´í†µ |

### ì½”ë”© ë° í”„ë¡œê·¸ë˜ë° íƒœìŠ¤í¬

| íƒœìŠ¤í¬ëª… | ì„¤ëª… | ë¬¸ì œ ìˆ˜ | í‰ê°€ ì§€í‘œ | ì–¸ì–´ |
|:---------|:-----|:--------|:----------|:-----|
| **HumanEval** | Python ì½”ë”© ë¬¸ì œ | 164 | pass@k | Python |
| **MBPP** | Python í”„ë¡œê·¸ë˜ë° ê¸°ì´ˆ | 974 | ì •í™•ë„ | Python |
| **CodeContests** | í”„ë¡œê·¸ë˜ë° ëŒ€íšŒ ë¬¸ì œ | 13,328 | ì •í™•ë„ | ë‹¤ì–‘ |
| **DS-1000** | ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ì½”ë”© | 1,000 | ì‹¤í–‰ ì„±ê³µë¥  | Python |

### ì¼ë°˜ ì§€ì‹ ë° ì¶”ë¡  íƒœìŠ¤í¬

| íƒœìŠ¤í¬ëª… | ì„¤ëª… | ë¬¸ì œ ìˆ˜ | í‰ê°€ ì§€í‘œ | ë„ë©”ì¸ |
|:---------|:-----|:--------|:----------|:-------|
| **MMLU** | ëŒ€í•™ ìˆ˜ì¤€ ë‹¤ë¶„ì•¼ ì§€ì‹ | 15,908 | ì •í™•ë„ | ì¢…í•© |
| **HellaSwag** | ìƒì‹ ì¶”ë¡  (ë¬¸ì¥ ì™„ì„±) | 10,042 | ì •í™•ë„ | ìƒì‹ |
| **ARC-Challenge** | ê³¼í•™ ì¶”ë¡  (ì–´ë ¤ìš´ ë²„ì „) | 1,172 | ì •í™•ë„ | ê³¼í•™ |
| **ARC-Easy** | ê³¼í•™ ì¶”ë¡  (ì‰¬ìš´ ë²„ì „) | 2,376 | ì •í™•ë„ | ê³¼í•™ |
| **TruthfulQA** | ì§„ì‹¤ì„± í‰ê°€ | 817 | ì •í™•ë„ | ì‚¬ì‹¤ í™•ì¸ |
| **Winogrande** | ìƒì‹ ì¶”ë¡  | 1,267 | ì •í™•ë„ | ìƒì‹ |

### ì–¸ì–´ ì´í•´ ë° ìƒì„± íƒœìŠ¤í¬

| íƒœìŠ¤í¬ëª… | ì„¤ëª… | ë¬¸ì œ ìˆ˜ | í‰ê°€ ì§€í‘œ | ìœ í˜• |
|:---------|:-----|:--------|:----------|:-----|
| **SQUAD** | ë…í•´ ë° ì§ˆë¬¸ ì‘ë‹µ | 10,570 | F1/EM | ë…í•´ |
| **BoolQ** | ì˜ˆ/ì•„ë‹ˆì˜¤ ì§ˆë¬¸ | 3,270 | ì •í™•ë„ | ì´í•´ |
| **COPA** | ì¸ê³¼ ê´€ê³„ ì¶”ë¡  | 1,000 | ì •í™•ë„ | ì¶”ë¡  |
| **RTE** | í…ìŠ¤íŠ¸ í•¨ì˜ ì¸ì‹ | 3,000 | ì •í™•ë„ | ë…¼ë¦¬ |
| **WSC** | Winograd Schema Challenge | 273 | ì •í™•ë„ | ìƒì‹ |

### ì „ë¬¸ ë„ë©”ì¸ íƒœìŠ¤í¬

| íƒœìŠ¤í¬ëª… | ì„¤ëª… | ë¬¸ì œ ìˆ˜ | í‰ê°€ ì§€í‘œ | ì „ë¬¸ ë¶„ì•¼ |
|:---------|:-----|:--------|:----------|:----------|
| **MedQA** | ì˜í•™ ì§ˆë¬¸ ë‹µë³€ | 1,273 | ì •í™•ë„ | ì˜í•™ |
| **LegalBench** | ë²•í•™ ì¶”ë¡  ë¬¸ì œ | 20,000+ | ì •í™•ë„ | ë²•í•™ |
| **FinanceQA** | ê¸ˆìœµ ì§€ì‹ í‰ê°€ | 1,486 | ì •í™•ë„ | ê¸ˆìœµ |
| **SciQ** | ê³¼í•™ ì§€ì‹ ë¬¸ì œ | 13,679 | ì •í™•ë„ | ê³¼í•™ |

### ë©€í‹°ëª¨ë‹¬ ë° íŠ¹ìˆ˜ íƒœìŠ¤í¬

| íƒœìŠ¤í¬ëª… | ì„¤ëª… | ë¬¸ì œ ìˆ˜ | í‰ê°€ ì§€í‘œ | íŠ¹ì§• |
|:---------|:-----|:--------|:----------|:-----|
| **LAMBADA** | ì¥ë¬¸ ë§¥ë½ ì´í•´ | 5,153 | ì •í™•ë„ | ê¸´ ë§¥ë½ |
| **DROP** | ìˆ˜ì¹˜ ì¶”ë¡  ë° ë…í•´ | 9,536 | F1 | ë³µí•© ì¶”ë¡  |
| **QuAC** | ëŒ€í™”í˜• ì§ˆë¬¸ ë‹µë³€ | 98,407 | F1 | ëŒ€í™” |
| **CoQA** | ëŒ€í™”í˜• ì§ˆë¬¸ ë‹µë³€ | 127,000+ | F1 | ëŒ€í™” |

## ì‹¤í–‰ ì˜ˆì‹œ ë° ìµœì í™”

### ë‹¨ì¼ íƒœìŠ¤í¬ í‰ê°€

```bash
# ìˆ˜í•™ ì¶”ë¡  í‰ê°€ - OpenAI ì–´ëŒ‘í„°
python -m eval.eval \
  --model openai \
  --tasks AIME24 \
  --model_name "deepseek-ai/deepseek-r1-0528-qwen3-8b" \
  --apply_chat_template True \
  --batch_size 4 \
  --output_path logs/aime24_results.json

# ìˆ˜í•™ ì¶”ë¡  í‰ê°€ - Curator ì–´ëŒ‘í„°
python -m eval.eval \
  --model curator \
  --tasks AIME24 \
  --model_name "openai/deepseek-ai/deepseek-r1-0528-qwen3-8b" \
  --model_args "api_base=http://localhost:8000/v1" \
  --apply_chat_template True \
  --batch_size 4 \
  --output_path logs/aime24_curator_results.json
```

### ë‹¤ì¤‘ íƒœìŠ¤í¬ ì¢…í•© í‰ê°€

```bash
# ì¢…í•© ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ (ìˆ˜í•™, ì½”ë”©, ì¶”ë¡ ) - OpenAI ì–´ëŒ‘í„°
python -m eval.eval \
  --model openai \
  --tasks MATH500,HumanEval,MMLU,HellaSwag,ARC-c \
  --model_name "deepseek-ai/deepseek-r1-0528-qwen3-8b" \
  --apply_chat_template True \
  --batch_size 8 \
  --output_path logs/comprehensive_benchmark.json

# ì¢…í•© ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ (ìˆ˜í•™, ì½”ë”©, ì¶”ë¡ ) - Curator ì–´ëŒ‘í„°
python -m eval.eval \
  --model curator \
  --tasks MATH500,HumanEval,MMLU,HellaSwag,ARC-c \
  --model_name "openai/deepseek-ai/deepseek-r1-0528-qwen3-8b" \
  --model_args "api_base=http://localhost:8000/v1" \
  --apply_chat_template True \
  --batch_size 8 \
  --output_path logs/comprehensive_curator_benchmark.json
```

### ë„ë©”ì¸ë³„ íŠ¹í™” í‰ê°€

```bash
# ì˜ë£Œ ë„ë©”ì¸ í‰ê°€
python -m eval.eval \
  --model openai \
  --tasks MedQA,MedMCQA,PubMedQA \
  --model_name "microsoft/BioGPT-Large" \
  --apply_chat_template True \
  --batch_size 6 \
  --output_path logs/medical_benchmark.json

# ì½”ë”© ëŠ¥ë ¥ ì§‘ì¤‘ í‰ê°€
python -m eval.eval \
  --model openai \
  --tasks HumanEval,MBPP,CodeContests,DS-1000 \
  --model_name "codellama/CodeLlama-13b-Instruct-hf" \
  --apply_chat_template True \
  --batch_size 4 \
  --output_path logs/coding_benchmark.json
```

## ì„±ëŠ¥ ìµœì í™” ì „ëµ

### vLLM ì„œë²„ ìµœì í™”

```bash
# ê³ ì„±ëŠ¥ ì„¤ì • ì˜ˆì‹œ
vllm serve deepseek-ai/deepseek-r1-0528-qwen3-8b \
  --host 0.0.0.0 \
  --port 8000 \
  --api-key your-secret-key \
  --tensor-parallel-size 4 \
  --pipeline-parallel-size 1 \
  --max-model-len 4096 \
  --max-num-batched-tokens 16384 \
  --max-num-seqs 256 \
  --enable-chunked-prefill \
  --gpu-memory-utilization 0.9 \
  --swap-space 4 \
  --disable-log-requests \
  --quantization awq
```

### Evalchemy ìµœì í™” ì„¤ì •

| íŒŒë¼ë¯¸í„° | ì„¤ëª… | ê¶Œì¥ê°’ | íš¨ê³¼ |
|:---------|:-----|:-------|:-----|
| `--batch_size` | ë°°ì¹˜ í¬ê¸° | 8-16 | API í˜¸ì¶œ íšŸìˆ˜ ê°ì†Œ |
| `--limit` | íƒœìŠ¤í¬ë‹¹ ìƒ˜í”Œ ìˆ˜ ì œí•œ | 100-1000 | ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ |
| `--num_fewshot` | Few-shot ì˜ˆì‹œ ê°œìˆ˜ | 0-5 | ì„±ëŠ¥ vs ì†ë„ íŠ¸ë ˆì´ë“œì˜¤í”„ |
| `--max_batch_size` | ìµœëŒ€ ë°°ì¹˜ í¬ê¸° | 32 | ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± |

## ê²°ê³¼ ë¶„ì„ ë° í•´ì„

### í‘œì¤€ ì¶œë ¥ ì˜ˆì‹œ

```text
python -m eval.eval --model curator --tasks MMLU,HellaSwag,ARC-c \
  --model_name "openai/deepseek-ai/deepseek-r1-0528-qwen3-8b" \
  --model_args "api_base=http://localhost:8000/v1" \
  --batch_size 8 --output_path logs/multi_task_results.json

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% â€¢ Time Elapsed 0:15:32 â€¢ Time Remaining 0:00:00
Requests: Total: 1,247 â€¢ Cached: 0âœ“ â€¢ Success: 1,247âœ“ â€¢ Failed: 0âœ— â€¢ Req/min: 4.8 â€¢ Res/min: 4.8

                            Final Benchmark Results
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Task                    â”‚ Score                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ MMLU                    â”‚ 0.7234 (72.34%)                                 â”‚
â”‚ HellaSwag               â”‚ 0.8456 (84.56%)                                 â”‚
â”‚ ARC-Challenge           â”‚ 0.6789 (67.89%)                                 â”‚
â”‚ Average                 â”‚ 0.7493 (74.93%)                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Total Time              â”‚ 932.1s                                           â”‚
â”‚ Requests per Minute     â”‚ 4.8                                              â”‚
â”‚ Tokens per Second       â”‚ 156.7                                            â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

### ì„±ëŠ¥ ì§€í‘œ í•´ì„

| ì§€í‘œ | ì˜ë¯¸ | ì¢‹ì€ ìˆ˜ì¹˜ |
|:-----|:-----|:----------|
| **Requests per Minute** | ë¶„ë‹¹ ì²˜ë¦¬ ìš”ì²­ ìˆ˜ | 5+ (vLLM), 0.5-1 (CPU) |
| **Tokens per Second** | ì´ˆë‹¹ í† í° ìƒì„± ì†ë„ | 100+ (GPU), 10-20 (CPU) |
| **Success Rate** | ì„±ê³µë¥  | 99%+ |
| **Average Score** | í‰ê·  ì ìˆ˜ | íƒœìŠ¤í¬ë³„ ìƒëŒ€ í‰ê°€ |

### íƒœìŠ¤í¬ë³„ ì„±ëŠ¥ ê¸°ì¤€

| ë‚œì´ë„ | íƒœìŠ¤í¬ ì˜ˆì‹œ | ì¢‹ì€ ì„±ëŠ¥ | ìš°ìˆ˜í•œ ì„±ëŠ¥ |
|:-------|:------------|:----------|:------------|
| **ì‰¬ì›€** | GSM8K, ARC-Easy | 70%+ | 85%+ |
| **ë³´í†µ** | MMLU, HellaSwag | 60%+ | 75%+ |
| **ì–´ë ¤ì›€** | MATH, HumanEval | 40%+ | 60%+ |
| **ë§¤ìš° ì–´ë ¤ì›€** | AIME24, CodeContests | 20%+ | 40%+ |

## ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ)

### ì„œë²„ ê´€ë ¨ ë¬¸ì œ

| ë¬¸ì œ | ì›ì¸ | í•´ê²°ì±… |
|:-----|:-----|:-------|
| **CUDA OOM Error** | GPU ë©”ëª¨ë¦¬ ë¶€ì¡± | `--gpu-memory-utilization` ë‚®ì¶”ê¸° (0.8-0.85) |
| **Connection Refused** | ì„œë²„ ë¯¸ì‹¤í–‰ ë˜ëŠ” í¬íŠ¸ ì¶©ëŒ | ì„œë²„ ìƒíƒœ í™•ì¸, í¬íŠ¸ ë³€ê²½ |
| **Model Loading Failed** | ëª¨ë¸ ê²½ë¡œ ì˜¤ë¥˜ ë˜ëŠ” ê¶Œí•œ ë¬¸ì œ | ëª¨ë¸ëª… í™•ì¸, HuggingFace ë¡œê·¸ì¸ |
| **Too Many Requests** | ë°°ì¹˜ í¬ê¸° ì´ˆê³¼ | `--batch_size` ì¤„ì´ê¸° |

### ì„±ëŠ¥ ìµœì í™” íŒ

| ì˜ì—­ | ìµœì í™” ë°©ë²• | ì„±ëŠ¥ í–¥ìƒ |
|:-----|:------------|:----------|
| **GPU í™œìš©** | `--tensor-parallel-size` ì¦ê°€ | 2-4ë°° ì†ë„ í–¥ìƒ |
| **ë©”ëª¨ë¦¬ ê´€ë¦¬** | `--enable-chunked-prefill` í™œì„±í™” | ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ì¦ëŒ€ |
| **ë°°ì¹˜ ì²˜ë¦¬** | `--max-num-batched-tokens` ìµœì í™” | ì²˜ë¦¬ëŸ‰ 50% ì¦ê°€ |
| **ì–‘ìí™”** | `--quantization awq/gptq` ì‚¬ìš© | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 50% ê°ì†Œ |

## ê³ ê¸‰ ì‚¬ìš©ë²•

### ì»¤ìŠ¤í…€ íƒœìŠ¤í¬ ì¶”ê°€

```python
# custom_task.yaml ì˜ˆì‹œ
task: custom_math_reasoning
dataset_path: ./data/custom_math.json
metric: exact_match
num_fewshot: 3
description: "ì»¤ìŠ¤í…€ ìˆ˜í•™ ì¶”ë¡  íƒœìŠ¤í¬"
```

### ê²°ê³¼ í›„ì²˜ë¦¬ ë° ë¶„ì„

```python
import json
import pandas as pd

# ê²°ê³¼ íŒŒì¼ ë¡œë“œ
with open('logs/benchmark_results.json', 'r') as f:
    results = json.load(f)

# íƒœìŠ¤í¬ë³„ ì„±ëŠ¥ ë¶„ì„
df = pd.DataFrame(results['results'])
print(df.groupby('task')['score'].mean())

# ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„
df['difficulty'] = df['task'].map({
    'GSM8K': 'Easy',
    'MMLU': 'Medium', 
    'MATH': 'Hard',
    'AIME24': 'Very Hard'
})
print(df.groupby('difficulty')['score'].mean())
```

## ê²°ë¡ 

vLLMê³¼ Evalchemyì˜ ì¡°í•©ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì˜ ì¢…í•©ì  ì„±ëŠ¥ í‰ê°€ë¥¼ ìœ„í•œ ê°•ë ¥í•œ ë„êµ¬ì…ë‹ˆë‹¤. GPU ê°€ì†ì„ í†µí•œ ë¹ ë¥¸ ì¶”ë¡  ì†ë„ì™€ 50+ ì¢…ë¥˜ì˜ ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ íƒœìŠ¤í¬ë¡œ ëª¨ë¸ì˜ ê°•ì ê³¼ ì•½ì ì„ ì •í™•íˆ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì£¼ìš” ì„±ê³¼

- **ì†ë„**: CPU ëŒ€ë¹„ 20-50ë°° ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„
- **í™•ì¥ì„±**: ë‹¤ì¤‘ GPU í™˜ê²½ì—ì„œ ì„ í˜•ì  ì„±ëŠ¥ í–¥ìƒ
- **ì •í™•ì„±**: í‘œì¤€í™”ëœ í‰ê°€ í”„ë¡œí† ì½œë¡œ ì¼ê´€ëœ ê²°ê³¼
- **íš¨ìœ¨ì„±**: ë°°ì¹˜ ì²˜ë¦¬ë¥¼ í†µí•œ ìì› í™œìš©ë„ ê·¹ëŒ€í™”

### ë‹¤ìŒ ë‹¨ê³„

1. **ëª¨ë¸ ìµœì í™”**: ì–‘ìí™”, í”„ë£¨ë‹ì„ í†µí•œ íš¨ìœ¨ì„± ê°œì„ 
2. **ì»¤ìŠ¤í…€ íƒœìŠ¤í¬**: ë„ë©”ì¸ íŠ¹í™” ë²¤ì¹˜ë§ˆí¬ ê°œë°œ
3. **ìë™í™”**: CI/CD íŒŒì´í”„ë¼ì¸ì— ë²¤ì¹˜ë§ˆí¬ í†µí•©
4. **ëª¨ë‹ˆí„°ë§**: ì§€ì†ì ì¸ ì„±ëŠ¥ ì¶”ì  ë° ë¶„ì„

ì´ ê°€ì´ë“œë¥¼ í†µí•´ ì—¬ëŸ¬ë¶„ì˜ ëª¨ë¸ì´ ì‹¤ì œ í™˜ê²½ì—ì„œ ì–´ë–¤ ì„±ëŠ¥ì„ ë³´ì¼ì§€ ì •í™•íˆ ì˜ˆì¸¡í•˜ê³ , ê°œì„  ë°©í–¥ì„ ì„¤ì •í•˜ì‹¤ ìˆ˜ ìˆê¸°ë¥¼ ë°”ëë‹ˆë‹¤! ğŸš€

---

**ì°¸ê³  ìë£Œ:**
- [vLLM ê³µì‹ ë¬¸ì„œ](https://docs.vllm.ai/)
- [Evalchemy API ë ˆí¼ëŸ°ìŠ¤](https://docs.bespokelabs.ai/)
- [LM Evaluation Harness](https://github.com/EleutherAI/lm-evaluation-harness)
- [HuggingFace Transformers](https://huggingface.co/docs/transformers) 