---
title: "vLLM + Evalchemy ë²¤ì¹˜ë§ˆí‚¹ ì™„ë²½ ìµœì í™” ê°€ì´ë“œ: ë™ì  ë°°ì¹­ë¶€í„° ì‹¤ì „ íŠœë‹ê¹Œì§€"
excerpt: "ë™ì  ë°°ì¹­ê³¼ ìš”ì²­ íë¥¼ ì´í•´í•˜ì—¬ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” LLM ì„±ëŠ¥ ì¸¡ì •ì„ ìœ„í•œ ì„œë²„-í´ë¼ì´ì–¸íŠ¸ í†µí•© ìµœì í™” ì „ëµ"
date: 2025-06-14
categories: 
  - llmops
  - dev
tags: 
  - vllm
  - evalchemy
  - benchmarking
  - dynamic-batching
  - performance-optimization
  - llm-evaluation
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
---

## ì†Œê°œ

"ê·¸ëƒ¥ ëŒë ¤ë„" ê²°ê³¼ëŠ” ë‚˜ì˜µë‹ˆë‹¤. í•˜ì§€ë§Œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì˜ ì„±ëŠ¥ì„ ì •í™•í•˜ê²Œ ì¸¡ì •í•˜ê³ , ì‹¤ì œ ì„œë¹„ìŠ¤ í™˜ê²½ê³¼ ìœ ì‚¬í•œ ë¶€í•˜ ìƒí™©ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ë ¤ë©´ ëª‡ ê°€ì§€ í•µì‹¬ ìš”ì†Œë¥¼ ë°˜ë“œì‹œ ì´í•´í•´ì•¼ í•©ë‹ˆë‹¤. ë¶€ì •í™•í•œ ë²¤ì¹˜ë§ˆí¬ëŠ” ì˜ëª»ëœ ëª¨ë¸ ì„ íƒìœ¼ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

ì´ ê°€ì´ë“œì—ì„œëŠ” **vLLMì˜ ë™ì  ë°°ì¹­(Dynamic Batching)**ê³¼ **ìš”ì²­ í(Request Queue)** ì‹œìŠ¤í…œì„ ì´í•´í•˜ê³ , Evalchemyì™€ ê°™ì€ í‰ê°€ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ë•Œ ì„œë²„ì™€ í´ë¼ì´ì–¸íŠ¸ ì–‘ìª½ì—ì„œ ì •í™•ë„, ì†ë„, ì•ˆì •ì„±ì„ ê·¹ëŒ€í™”í•˜ëŠ” í†µí•© ìµœì í™” ì „ëµì„ ì œê³µí•©ë‹ˆë‹¤.

### ì™œ íŠœë‹ì´ í•„ìš”í•œê°€?

LLM ì„œë²„ëŠ” í•œ ë²ˆì— í•˜ë‚˜ì˜ ìš”ì²­ë§Œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. vLLMê³¼ ê°™ì€ ê³ ì„±ëŠ¥ ì„œë¹™ ì—”ì§„ì€ ë‹¤ìŒê³¼ ê°™ì€ ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤:

- **ë¹„ë™ê¸° ìš”ì²­ í**: ìš”ì²­ì„ ì¦‰ì‹œ íì— ì €ì¥í•˜ê³  ì—°ê²° ìœ ì§€
- **ë™ì  ë°°ì¹­**: ì„œë¡œ ë‹¤ë¥¸ ê¸¸ì´ì˜ ìš”ì²­ë“¤ì„ íš¨ìœ¨ì ìœ¼ë¡œ ë¬¶ì–´ ì²˜ë¦¬
- **Prefill-First ì •ì±…**: ìƒˆ ìš”ì²­ì˜ ì²« í† í° ìƒì„± ì‹œê°„(TTFT) ìµœì†Œí™”

ë”°ë¼ì„œ ì„œë²„ì˜ ë°°ì¹˜Â·í íŒŒë¼ë¯¸í„°ì™€ í´ë¼ì´ì–¸íŠ¸ì˜ ìš”ì²­ëŸ‰, ë°°ì¹˜ í¬ê¸°ë¥¼ ì¡°ìœ¨í•˜ì§€ ì•Šìœ¼ë©´ ë‹¤ìŒ ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤:

| ë¬¸ì œ | ê²°ê³¼ |
|:-----|:-----|
| **ë¶€ì •í™•í•œ ì†ë„ ì¸¡ì •** | ëŒ€ê¸° í ì§€ì—°ì„ ê³ ë ¤í•˜ì§€ ëª»í•´ ëª¨ë¸ ìˆœìˆ˜ ì¶”ë¡  ì†ë„ ì˜¤í•´ |
| **ê²°ê³¼ ë¹„ì¼ê´€ì„±** | ì„œë²„ ìƒíƒœì— ë”°ë¼ ê²°ê³¼ê°€ ë‹¬ë¼ì ¸ ê³µì •í•œ ë¹„êµ ë¶ˆê°€ |
| **ë¶ˆì•ˆì •í•œ í™˜ê²½** | 429 ì˜¤ë¥˜ë‚˜ ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨ |

## vLLM í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜ ì´í•´

### ë™ì  ë°°ì¹­ê³¼ ìš”ì²­ í ì‹œìŠ¤í…œ

vLLMì˜ í•µì‹¬ ì°¨ë³„í™” ìš”ì†ŒëŠ” **continuous batching**ê³¼ **ë¹„ë™ê¸° ìš”ì²­ í**ì…ë‹ˆë‹¤.

**ë¹„ë™ê¸° ìš”ì²­ ì²˜ë¦¬ íë¦„:**
1. HTTP ìš”ì²­ ìˆ˜ì‹  â†’ ì¦‰ì‹œ `asyncio.Queue`ì— ì €ì¥
2. ìš”ì²­ ìƒíƒœ: **waiting**(ëŒ€ê¸°) â†” **running**(GPU ì²˜ë¦¬ ì¤‘)
3. ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ë§¤ í† í° ìƒì„±ë§ˆë‹¤ ìƒíƒœ ë™ì  ê´€ë¦¬

**ê³¼ë¶€í•˜ ìƒí™© ëŒ€ì‘:**
- GPU í† í° ë²„ì§“ ì´ˆê³¼ â†’ ë‹¤ìŒ ìŠ¤í…ì—ì„œ ì¬ì‹œë„
- í ê¸¸ì´ í•œê³„ ì´ˆê³¼ â†’ HTTP 429/503 ì‘ë‹µ
- ê¸´ ìš”ì²­ â†’ Partial Prefillë¡œ ì ì§„ì  ì²˜ë¦¬

### ë™ì  ë°°ì¹­ì˜ ì¥ì 

ê¸°ì¡´ ì •ì  ë°°ì¹­ê³¼ ë‹¬ë¦¬, vLLMì€ ì„œë¡œ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸/ìƒì„± ê¸¸ì´ë¥¼ ê°™ì€ GPU ì»¤ë„ì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬:

- **ì²˜ë¦¬ëŸ‰(TPS) ê·¹ëŒ€í™”**: GPU í™œìš©ë¥  í–¥ìƒ
- **TTFT ìµœì†Œí™”**: ìƒˆ ìš”ì²­ ìš°ì„  ì²˜ë¦¬
- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: KV Cache ë™ì  í• ë‹¹

## ì„œë²„ ì¸¡ ìµœì í™” ì „ëµ

### vLLM í•„ìˆ˜ íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | ì„¤ëª… | ê¶Œì¥ê°’ | íš¨ê³¼ |
|:---------|:-----|:-------|:-----|
| `--max-num-batched-tokens` | ë°°ì¹˜ë‹¹ ìµœëŒ€ í† í° ìˆ˜ | 8,000-16,000 | TPSâ†‘, TTFTâ†‘ íŠ¸ë ˆì´ë“œì˜¤í”„ |
| `--enable-chunked-prefill` | ì²­í¬ ë‹¨ìœ„ prefill í™œì„±í™” | í™œì„±í™” ê¶Œì¥ | ëŒ€ê¸° íâ†“, ë©”ëª¨ë¦¬ íš¨ìœ¨â†‘ |
| `--scheduling-policy priority` | ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ìŠ¤ì¼€ì¤„ë§ | priority | ì„œë¹„ìŠ¤ ë ˆë²¨ ì°¨ë³„í™” |
| `--concurrency-limit` | ìµœëŒ€ ë™ì‹œ ìš”ì²­ ìˆ˜ | 32-128 | 429 ì˜¤ë¥˜ ë°©ì§€ |
| `--gpu-memory-utilization` | GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  | 0.85-0.95 | OOM ë°©ì§€ |

### ê³ ì„±ëŠ¥ vLLM ì„œë²„ ì‹¤í–‰ ì˜ˆì‹œ

```bash
# ìµœì í™”ëœ vLLM ì„œë²„ ì„¤ì •
vllm serve deepseek-ai/deepseek-r1-0528-qwen3-8b \
  --host 0.0.0.0 \
  --port 8000 \
  --api-key your-secret-key \
  --tensor-parallel-size 4 \
  --max-model-len 4096 \
  --max-num-batched-tokens 16384 \
  --max-num-seqs 256 \
  --enable-chunked-prefill \
  --scheduling-policy priority \
  --gpu-memory-utilization 0.9 \
  --swap-space 4 \
  --disable-log-requests \
  --quantization awq
```

### LM Studio ì‚¬ìš© ì‹œ ì£¼ì˜ì‚¬í•­

LM StudioëŠ” vLLMê³¼ ë‹¬ë¦¬ ìì²´ íë‚˜ ë™ì  ë°°ì¹­ì´ ì—†ìœ¼ë¯€ë¡œ:

- **ì—”ë“œí¬ì¸íŠ¸**: `/v1` í¬í•¨ í•„ìˆ˜
- **ëª¨ë¸ ID**: ë°‘ì¤„ í˜•ì‹ í™•ì¸ (ì˜ˆ: `deepseek-ai_deepseek-r1-...`)
- **API í‚¤**: ë”ë¯¸ í‚¤ ì„¤ì • (`LM_STUDIO_API_KEY=dummy`)
- **ë™ì‹œ ìš”ì²­**: ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ì—ì„œ ì œí•œ í•„ìš”

```bash
# LM Studio ì—°ë™ ì„¤ì •
export LM_STUDIO_API_BASE="http://127.0.0.1:1234/v1"
export LM_STUDIO_API_KEY="dummy"
```

## í´ë¼ì´ì–¸íŠ¸ ì¸¡ ìµœì í™” ì „ëµ

### ë¹ ë¥¸ ì‚¬ì „ í™•ì¸

ë³¸ê²©ì ì¸ ë²¤ì¹˜ë§ˆí¬ ì „ ì—°ê²° í…ŒìŠ¤íŠ¸:

```bash
# Sanity Check - ì—°ê²°/í¬ë§· ì˜¤ë¥˜ ì¦‰ì‹œ ê²€ì¶œ
python -m eval.eval \
  --model curator \
  --tasks hellaswag \
  --limit 1 \
  --model_name "openai/deepseek-ai/deepseek-r1-0528-qwen3-8b" \
  --model_args "api_base=http://localhost:8000/v1"
```

### ì‹œë‚˜ë¦¬ì˜¤ë³„ ìš”ì²­ ì „ëµ

| ì‹œë‚˜ë¦¬ì˜¤ | ê¶Œì¥ ì„¤ì • | ì´ìœ  |
|:---------|:----------|:-----|
| **ëŒ€ê·œëª¨ ë²¤ì¹˜ë§ˆí¬ (>1,000ìƒ˜í”Œ)** | `--batch_size auto:8` ë˜ëŠ” ìˆ˜ë™ `4-8` | ì„œë²„-í´ë¼ì´ì–¸íŠ¸ ë°°ì¹˜ ì¤‘ë³µ ë°©ì§€, ì•ˆì •ì„± í™•ë³´ |
| **ì‹¤ì„œë¹„ìŠ¤ ë¶€í•˜ ì‹œë®¬ë ˆì´ì…˜** | `--batch_size 1` + ë©€í‹°í”„ë¡œì„¸ìŠ¤ | ì§„ì •í•œ ë™ì‹œ ìš”ì²­ìœ¼ë¡œ í/ìŠ¤ì¼€ì¤„ëŸ¬ ë™ì‘ ê´€ì°° |
| **ë¹ ë¥¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸** | `--batch_size auto:16` + ìºì‹œ í™œìš© | ì²˜ë¦¬ëŸ‰ ê·¹ëŒ€í™”, ë°˜ë³µ í…ŒìŠ¤íŠ¸ íš¨ìœ¨ì„± |

### ìºì‹œì™€ ì¬í˜„ì„± ê´€ë¦¬

**ë¶€í•˜ ì¸¡ì • vs ì •ë°€ ë¹„êµ:**

```bash
# ì‹¤ì œ ì„œë²„ ë¶€í•˜ ì¸¡ì • (ìºì‹œ ì—†ìŒ)
python -m eval.eval \
  --model curator \
  --tasks MMLU,HellaSwag \
  --model_name "openai/deepseek-ai/deepseek-r1-0528-qwen3-8b" \
  --seed 42 \
  --output_path logs/load_test.json

# ì •ë°€ ì„±ëŠ¥ ë¹„êµ (ìºì‹œ í™œìš©)
python -m eval.eval \
  --model curator \
  --tasks MMLU,HellaSwag \
  --model_name "openai/deepseek-ai/deepseek-r1-0528-qwen3-8b" \
  --use_cache ./cache \
  --seed 42 \
  --output_path logs/performance_test.json
```

## ëª¨ë‹ˆí„°ë§ê³¼ ì„±ëŠ¥ ì§„ë‹¨

### í•µì‹¬ ëª¨ë‹ˆí„°ë§ ì§€í‘œ

vLLMì€ Prometheus í˜•ì‹ ë©”íŠ¸ë¦­ì„ `/metrics` ì—”ë“œí¬ì¸íŠ¸ë¡œ ì œê³µ:

| ì§€í‘œ | ì˜ë¯¸ | ì„ê³„ê°’ | ëŒ€ì‘ ë°©ì•ˆ |
|:-----|:-----|:-------|:----------|
| `vllm:num_requests_waiting` | ëŒ€ê¸° í ê¸¸ì´ | <10 | `max-num-batched-tokens` ì¦ê°€ |
| `time_to_first_token_seconds` | ì²« í† í° ì§€ì—° | <2ì´ˆ | í ê¸¸ì´ ëª¨ë‹ˆí„°ë§, ìŠ¤ì¼€ì¤„ë§ ì •ì±… ì¡°ì • |
| `vllm:gpu_cache_usage_perc` | KV Cache ì‚¬ìš©ë¥  | <90% | ëª¨ë¸ ê¸¸ì´ ì œí•œ, ë©”ëª¨ë¦¬ ìµœì í™” |
| `vllm:avg_generation_throughput_toks_per_s` | ì´ˆë‹¹ í† í° ìƒì„± | ëª¨ë¸ë³„ ìƒëŒ€í‰ê°€ | ë°°ì¹˜ í¬ê¸° ì¡°ì • |

### Grafana ëŒ€ì‹œë³´ë“œ ì„¤ì •

```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'vllm'
    static_configs:
      - targets: ['localhost:8000']
    metrics_path: '/metrics'
    scrape_interval: 5s
```

## ê¶Œì¥ ì›Œí¬í”Œë¡œìš°: 5ë‹¨ê³„ ìµœì í™”

### 1ë‹¨ê³„: ì‹œìŠ¤í…œ ì›Œë°ì—…

```bash
# JIT ì»´íŒŒì¼ê³¼ CUDA ê·¸ë˜í”„ ìºì‹±
for i in {1..5}; do
  curl -X POST http://localhost:8000/v1/chat/completions \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer your-secret-key" \
    -d '{"model":"deepseek-ai/deepseek-r1-0528-qwen3-8b","messages":[{"role":"user","content":"Hello"}],"max_tokens":10}'
done
```

### 2ë‹¨ê³„: ì—°ê²° í…ŒìŠ¤íŠ¸

```bash
# ë¹ ë¥¸ ì—°ê²°/í¬ë§· í™•ì¸
python -m eval.eval --model curator --tasks hellaswag --limit 1 \
  --model_name "openai/deepseek-ai/deepseek-r1-0528-qwen3-8b" \
  --model_args "api_base=http://localhost:8000/v1"
```

### 3ë‹¨ê³„: ê·œëª¨ë³„ 2ë‹¨ê³„ í…ŒìŠ¤íŠ¸

```bash
# ì†Œê·œëª¨ í…ŒìŠ¤íŠ¸ (100ê°œ ìƒ˜í”Œ)
python -m eval.eval --model curator --tasks MMLU --limit 100 \
  --model_name "openai/deepseek-ai/deepseek-r1-0528-qwen3-8b" \
  --batch_size 8 --output_path logs/small_scale.json

# ì „ì²´ í…ŒìŠ¤íŠ¸
python -m eval.eval --model curator --tasks MMLU \
  --model_name "openai/deepseek-ai/deepseek-r1-0528-qwen3-8b" \
  --batch_size 8 --output_path logs/full_scale.json
```

### 4ë‹¨ê³„: ì‹¤ì‹œê°„ ìµœì í™”

Prometheus ë©”íŠ¸ë¦­ì„ ëª¨ë‹ˆí„°ë§í•˜ë©° íŒŒë¼ë¯¸í„° ì¡°ì •:

| ê´€ì°°ëœ ë¬¸ì œ | ì¡°ì • ë°©í–¥ |
|:------------|:----------|
| ëŒ€ê¸° í ê¸¸ì´ ì¦ê°€ | `--max-num-batched-tokens` ì¦ê°€ |
| TTFT ê³¼ë„í•œ ì¦ê°€ | `--enable-chunked-prefill` í™œì„±í™” |
| GPU í™œìš©ë¥  ì €ì¡° | í´ë¼ì´ì–¸íŠ¸ `--batch_size` ì¦ê°€ |
| ë©”ëª¨ë¦¬ ë¶€ì¡± | `--gpu-memory-utilization` ê°ì†Œ |

### 5ë‹¨ê³„: ì¼ê´€ì„± ê²€ì¦

ë™ì¼í•œ ì¡°ê±´ì—ì„œ ì—¬ëŸ¬ ëª¨ë¸ ë¹„êµ:

```bash
# ê³µì •í•œ ë¹„êµë¥¼ ìœ„í•œ ì„¤ì • ê³ ì •
export EVAL_SEED=42
export EVAL_CACHE_DIR="./eval_cache"
export EVAL_BATCH_SIZE=8

# ëª¨ë¸ë³„ ìˆœì°¨ í‰ê°€
for model in "deepseek-ai/deepseek-r1-0528-qwen3-8b" "Qwen/Qwen2.5-7B-Instruct"; do
  python -m eval.eval --model curator --tasks MMLU,HellaSwag \
    --model_name "openai/$model" \
    --seed $EVAL_SEED \
    --use_cache $EVAL_CACHE_DIR \
    --batch_size $EVAL_BATCH_SIZE \
    --output_path "logs/${model//\//_}_results.json"
done
```

## ì‹¤ì „ íŠœë‹ íŒ

### TTFT vs TPS íŠ¸ë ˆì´ë“œì˜¤í”„ ìµœì í™”

**ë°°ì¹˜ í¬ê¸°ë³„ ì„±ëŠ¥ íŠ¹ì„±:**

| ë°°ì¹˜ ì„¤ì • | TPS | TTFT | ì‚¬ìš© ì¼€ì´ìŠ¤ |
|:----------|:----|:-----|:------------|
| ì‘ì€ ë°°ì¹˜ (1-4) | ë‚®ìŒ | ë¹ ë¦„ | ì¸í„°ë™í‹°ë¸Œ ì„œë¹„ìŠ¤ |
| ì¤‘ê°„ ë°°ì¹˜ (8-16) | ë³´í†µ | ë³´í†µ | ì¼ë°˜ì  ë²¤ì¹˜ë§ˆí¬ |
| í° ë°°ì¹˜ (32+) | ë†’ìŒ | ëŠë¦¼ | ëŒ€ëŸ‰ ë°°ì¹˜ ì²˜ë¦¬ |

### ì„œë¹„ìŠ¤ ë ˆë²¨ë³„ ìš°ì„ ìˆœìœ„ ì„¤ì •

```json
{
  "model": "deepseek-ai/deepseek-r1-0528-qwen3-8b",
  "messages": [{"role": "user", "content": "Urgent question"}],
  "priority": 1,  // ë‚®ì„ìˆ˜ë¡ ë†’ì€ ìš°ì„ ìˆœìœ„
  "max_tokens": 100
}
```

### ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ ìµœì í™”

```bash
# í™˜ê²½ ë³€ìˆ˜ ìµœì í™”
export HF_HUB_CACHE=/nvme/cache          # ê³ ì† SSD í™œìš©
export HF_TOKEN=<your_token>             # Private ëª¨ë¸ ì ‘ê·¼
export CUDA_VISIBLE_DEVICES=0,1,2,3     # GPU ì„ íƒ
export VLLM_ATTENTION_BACKEND=FLASHINFER # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ
```

## ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ í•´ì„

### í‘œì¤€ ì¶œë ¥ ë¶„ì„

```text
python -m eval.eval --model curator --tasks MMLU,HellaSwag \
  --model_name "openai/deepseek-ai/deepseek-r1-0528-qwen3-8b" \
  --batch_size 8 --output_path logs/results.json

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% â€¢ Time Elapsed 0:15:32
Requests: Total: 1,247 â€¢ Success: 1,247âœ“ â€¢ Failed: 0âœ— â€¢ Req/min: 4.8

                            Final Benchmark Results
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Task                    â”‚ Score                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ MMLU                    â”‚ 0.7234 (72.34%)                                 â”‚
â”‚ HellaSwag               â”‚ 0.8456 (84.56%)                                 â”‚
â”‚ Average                 â”‚ 0.7845 (78.45%)                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Requests per Minute     â”‚ 4.8                                              â”‚
â”‚ Tokens per Second       â”‚ 156.7                                            â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

### ì„±ëŠ¥ ì§€í‘œ ê¸°ì¤€

| ì§€í‘œ | vLLM (ì¢‹ìŒ) | CPU (ì¼ë°˜) | í•´ì„ |
|:-----|:------------|:-----------|:-----|
| **Requests per Minute** | 5+ | 0.5-1 | API ì²˜ë¦¬ íš¨ìœ¨ì„± |
| **Tokens per Second** | 100+ | 10-20 | ìƒì„± ì†ë„ |
| **Success Rate** | 99%+ | 99%+ | ì•ˆì •ì„± |
| **Average TTFT** | <2ì´ˆ | <10ì´ˆ | ì‘ë‹µì„± |

## ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ì™€ í•´ê²°ì±…

| ì˜¤ë¥˜ | ì›ì¸ | í•´ê²°ì±… |
|:-----|:-----|:-------|
| **CUDA OOM Error** | GPU ë©”ëª¨ë¦¬ ë¶€ì¡± | `--gpu-memory-utilization 0.8`, `--max-model-len` ê°ì†Œ |
| **Connection Refused** | ì„œë²„ ë¯¸ì‹¤í–‰/í¬íŠ¸ ì¶©ëŒ | ì„œë²„ ìƒíƒœ í™•ì¸, í¬íŠ¸ ë³€ê²½ |
| **429 Too Many Requests** | ë™ì‹œ ìš”ì²­ ì´ˆê³¼ | `--concurrency-limit` ì¦ê°€, í´ë¼ì´ì–¸íŠ¸ `--batch_size` ê°ì†Œ |
| **Model Loading Failed** | ëª¨ë¸ ê²½ë¡œ/ê¶Œí•œ ì˜¤ë¥˜ | HuggingFace í† í° í™•ì¸, ëª¨ë¸ëª… ê²€ì¦ |

### ì„±ëŠ¥ ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] vLLM ì„œë²„ ì›Œë°ì—… ì™„ë£Œ
- [ ] `--max-num-batched-tokens` ìµœì í™” (8K-16K)
- [ ] `--enable-chunked-prefill` í™œì„±í™”
- [ ] í´ë¼ì´ì–¸íŠ¸ ë°°ì¹˜ í¬ê¸° ì¡°ì • (4-8)
- [ ] Prometheus ëª¨ë‹ˆí„°ë§ ì„¤ì •
- [ ] ìºì‹œ ë° ì‹œë“œ ê´€ë¦¬ ì •ì±… ìˆ˜ë¦½
- [ ] ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ í™˜ê²½ í†µì¼

## ê²°ë¡ 

vLLMê³¼ Evalchemyë¥¼ í™œìš©í•œ LLM ë²¤ì¹˜ë§ˆí‚¹ì€ ë‹¨ìˆœíˆ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ëŠ” ê²ƒì—ì„œ ëë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤. **ë™ì  ë°°ì¹­ê³¼ ìš”ì²­ í ì‹œìŠ¤í…œ**ì„ ì´í•´í•˜ê³ , **ì„œë²„-í´ë¼ì´ì–¸íŠ¸ í†µí•© ìµœì í™”**ë¥¼ í†µí•´ ë‹¤ìŒ ì„¸ ê°€ì§€ ì¶•ì˜ ê· í˜•ì„ ë§ì¶°ì•¼ í•©ë‹ˆë‹¤:

1. **ì„œë²„ ì¸¡ ë°°ì¹˜ í† í°ê³¼ ìŠ¤ì¼€ì¤„ëŸ¬** â†’ ì²˜ë¦¬ëŸ‰ ìµœì í™”
2. **í´ë¼ì´ì–¸íŠ¸ ë°°ì¹˜ í¬ê¸°ì™€ ìš”ì²­ íŒ¨í„´** â†’ ì‹¤ì œ ì‚¬ìš© í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜
3. **ìºì‹œì™€ ì‹œë“œ ê´€ë¦¬** â†’ ì¬í˜„ ê°€ëŠ¥í•œ ë²¤ì¹˜ë§ˆí¬ í™˜ê²½

### í•µì‹¬ ì„±ê³¼

- **ì •í™•ì„±**: ì‹¤ì œ ì„œë¹„ìŠ¤ ë¶€í•˜ì™€ ìœ ì‚¬í•œ ì¡°ê±´ì—ì„œ ì¸¡ì •
- **íš¨ìœ¨ì„±**: GPU í™œìš©ë¥  ê·¹ëŒ€í™”ë¡œ 20-50ë°° ì†ë„ í–¥ìƒ
- **ì•ˆì •ì„±**: ì²´ê³„ì ì¸ ëª¨ë‹ˆí„°ë§ìœ¼ë¡œ ì¼ê´€ëœ ê²°ê³¼ ë³´ì¥
- **ì¬í˜„ì„±**: í‘œì¤€í™”ëœ ì„¤ì •ìœ¼ë¡œ ê³µì •í•œ ëª¨ë¸ ë¹„êµ

ì´ ê°€ì´ë“œë¥¼ ë”°ë¼ ì„¤ì •í•˜ë©´, ì‹¤ì œ ì„œë¹„ìŠ¤ ë¶€í•˜ì— ê·¼ì ‘í•œ ì¡°ê±´ì—ì„œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì„±ëŠ¥ ì¸¡ì • ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Prometheus ë©”íŠ¸ë¦­ì„ í†µí•œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ìœ¼ë¡œ ì§€ì—° ì›ì¸ì„ ì¦‰ì‹œ íŒŒì•…í•˜ê³  ëŒ€ì‘í•˜ì—¬, ë²¤ì¹˜ë§ˆí¬ì˜ ì •í™•ë„ì™€ íš¨ìœ¨ì„±ì„ ë™ì‹œì— í™•ë³´í•˜ì„¸ìš”! ğŸš€

---

**ì°¸ê³  ìë£Œ:**
- [vLLM ê³µì‹ ë¬¸ì„œ](https://docs.vllm.ai/)
- [Evalchemy API ê°€ì´ë“œ](https://docs.bespokelabs.ai/)
- [Prometheus ëª¨ë‹ˆí„°ë§ ì„¤ì •](https://prometheus.io/docs/)
- [LM Evaluation Harness](https://github.com/EleutherAI/lm-evaluation-harness) 