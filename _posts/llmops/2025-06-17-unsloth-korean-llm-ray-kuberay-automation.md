---
title: "Unsloth+TRL ν•κµ­μ–΄ LLM ν•™μµ μλ™ν™” - 4νΈ: Rayμ™€ KubeRayλ¥Ό ν™μ©ν• λ€κ·λ¨ λ¶„μ‚° ν•™μµ"
excerpt: "Ray Train/Tune/Serveμ™€ KubeRayλ¥Ό ν™μ©ν• μ—”ν„°ν”„λΌμ΄μ¦κΈ‰ λ¶„μ‚° ν•κµ­μ–΄ LLM ν•™μµ λ° μ¤ν† μ¤μΌ€μΌλ§ μ‹μ¤ν… κµ¬μ¶•"
date: 2025-06-17
categories:
  - llmops
tags:
  - Ray
  - KubeRay
  - Ray Train
  - Ray Tune
  - Ray Serve
  - Korean LLM
  - Distributed Training
  - Auto Scaling
  - MLOps
  - Unsloth
author_profile: true
toc: true
toc_label: "λ©μ°¨"
---

## κ°μ”

λ³Έ κ°€μ΄λ“λ” [Unsloth+TRL ν•κµ­μ–΄ LLM ν•™μµ μ‹λ¦¬μ¦](#)μ 4νΈμΌλ΅, Rayμ™€ KubeRayλ¥Ό ν™μ©ν•μ—¬ λ€κ·λ¨ λ¶„μ‚° ν•κµ­μ–΄ LLM ν•™μµμ„ μλ™ν™”ν•κ³  μ¤ν† μ¤μΌ€μΌλ§ν•λ” μ—”ν„°ν”„λΌμ΄μ¦κΈ‰ μ‹μ¤ν…μ„ κµ¬μ¶•ν•λ” λ°©λ²•μ„ λ‹¤λ£Ήλ‹λ‹¤.

**ν•™μµ λ©ν‘**:

- π€ **Ray Train**: λ¶„μ‚° ν•™μµ μ›ν¬λ΅λ“ μλ™ν™”
- π― **Ray Tune**: ν•μ΄νΌνλΌλ―Έν„° νλ‹ μµμ ν™”
- β΅ **Ray Serve**: κ³ μ„±λ¥ λ¨λΈ μ„λΉ™ μΈν”„λΌ
- π”„ **KubeRay**: μΏ λ²„λ„¤ν‹°μ¤ κΈ°λ° μ¤ν† μ¤μΌ€μΌλ§

---

## 1. Ray λ° KubeRay μ„¤μΉ

### 1.1 KubeRay Operator μ„¤μΉ

```bash
# KubeRay Operator μ„¤μΉ
helm repo add kuberay https://ray-project.github.io/kuberay-helm/
helm repo update

# λ„¤μ„μ¤νμ΄μ¤ μƒμ„±
kubectl create namespace ray-system

# KubeRay Operator μ„¤μΉ
helm install kuberay-operator kuberay/kuberay-operator \
  --namespace ray-system \
  --version 1.0.0

# μ„¤μΉ ν™•μΈ
kubectl get pods -n ray-system
```

### 1.2 Ray Cluster μ •μ

```yaml
# ray-cluster.yaml
apiVersion: ray.io/v1alpha1
kind: RayCluster
metadata:
  name: korean-llm-cluster
  namespace: ray-system
spec:
  rayVersion: '2.8.0'
  enableInTreeAutoscaling: true
  autoscalerOptions:
    upscalingMode: Default
    idleTimeoutSeconds: 60
    resources:
      limits:
        cpu: "1000m"
        memory: "2Gi"
      requests:
        cpu: "500m"
        memory: "1Gi"
  
  headGroupSpec:
    rayStartParams:
      dashboard-host: '0.0.0.0'
      num-cpus: '0'
    template:
      spec:
        containers:
        - name: ray-head
          image: rayproject/ray:2.8.0-py310-gpu
          ports:
          - containerPort: 6379
            name: gcs-server
          - containerPort: 8265
            name: dashboard
          - containerPort: 10001
            name: client
          resources:
            limits:
              cpu: "4"
              memory: "16Gi"
            requests:
              cpu: "2"
              memory: "8Gi"
          volumeMounts:
          - name: data-volume
            mountPath: /data
        volumes:
        - name: data-volume
          persistentVolumeClaim:
            claimName: ray-data-pvc
  
  workerGroupSpecs:
  - replicas: 2
    minReplicas: 1
    maxReplicas: 10
    groupName: gpu-workers
    rayStartParams:
      num-cpus: '8'
      num-gpus: '4'
    template:
      spec:
        containers:
        - name: ray-worker
          image: rayproject/ray:2.8.0-py310-gpu
          resources:
            limits:
              cpu: "16"
              memory: "64Gi"
              nvidia.com/gpu: "4"
            requests:
              cpu: "8"
              memory: "32Gi"
              nvidia.com/gpu: "4"
          volumeMounts:
          - name: data-volume
            mountPath: /data
        volumes:
        - name: data-volume
          persistentVolumeClaim:
            claimName: ray-data-pvc
        tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
```

---

## 2. Ray Trainμ„ ν™μ©ν• λ¶„μ‚° ν•™μµ

### 2.1 λ¶„μ‚° ν•™μµ μ¤ν¬λ¦½νΈ

```python
# ray_distributed_training.py
import ray
from ray import train
from ray.train import ScalingConfig
from ray.train.torch import TorchTrainer
from ray.train.huggingface import HuggingfaceTrainer
import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModelForCausalLM
from unsloth import FastLanguageModel
from datasets import load_dataset
import mlflow
import os

@ray.remote
class KoreanLLMDistributedTrainer:
    def __init__(self, config):
        self.config = config
        self.model = None
        self.tokenizer = None
        
    def setup_model(self):
        """λ¨λΈ λ° ν† ν¬λ‚μ΄μ € μ„¤μ •"""
        model_name = self.config.get("model_name", "unsloth/Qwen2.5-7B-bnb-4bit")
        
        self.model, self.tokenizer = FastLanguageModel.from_pretrained(
            model_name=model_name,
            max_seq_length=4096,
            dtype=None,
            load_in_4bit=True,
        )
        
        # LoRA μ„¤μ •
        self.model = FastLanguageModel.get_peft_model(
            self.model,
            r=64,
            target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],
            lora_alpha=16,
            lora_dropout=0.1,
            bias="none",
            use_gradient_checkpointing="unsloth",
            use_rslora=True,
            loftq_config=None,
        )
    
    def prepare_dataset(self):
        """λ°μ΄ν„°μ…‹ μ¤€λΉ„"""
        dataset_path = self.config.get("dataset_path", "/data/korean_corpus.jsonl")
        dataset = load_dataset("json", data_files=dataset_path, split="train")
        
        def tokenize_function(examples):
            return self.tokenizer(
                examples["text"],
                truncation=True,
                padding="max_length",
                max_length=2048,
                return_tensors="pt"
            )
        
        tokenized_dataset = dataset.map(tokenize_function, batched=True)
        return tokenized_dataset
    
    def train_function(self, config):
        """λ¶„μ‚° ν•™μµ ν•¨μ"""
        # Ray Train μ»¨ν…μ¤νΈμ—μ„ μ‹¤ν–‰
        import torch.distributed as dist
        from torch.nn.parallel import DistributedDataParallel as DDP
        
        # λ¶„μ‚° μ„¤μ •
        rank = train.get_context().get_world_rank()
        local_rank = train.get_context().get_local_rank()
        world_size = train.get_context().get_world_size()
        
        # λ””λ°”μ΄μ¤ μ„¤μ •
        device = torch.device(f"cuda:{local_rank}")
        torch.cuda.set_device(device)
        
        # λ¨λΈ μ¤€λΉ„
        self.setup_model()
        self.model = self.model.to(device)
        
        # DDP λν•‘
        if world_size > 1:
            self.model = DDP(self.model, device_ids=[local_rank])
        
        # λ°μ΄ν„°μ…‹ μ¤€λΉ„
        dataset = self.prepare_dataset()
        
        # μµν‹°λ§μ΄μ € μ„¤μ •
        optimizer = torch.optim.AdamW(
            self.model.parameters(),
            lr=config["learning_rate"],
            weight_decay=config["weight_decay"]
        )
        
        # ν•™μµ λ£¨ν”„
        self.model.train()
        for epoch in range(config["num_epochs"]):
            total_loss = 0
            num_batches = 0
            
            # λ°μ΄ν„°λ΅λ” μ„¤μ • (λ¶„μ‚° ν™κ²½ κ³ λ ¤)
            sampler = torch.utils.data.distributed.DistributedSampler(
                dataset, num_replicas=world_size, rank=rank
            ) if world_size > 1 else None
            
            dataloader = torch.utils.data.DataLoader(
                dataset,
                batch_size=config["batch_size"],
                sampler=sampler,
                shuffle=(sampler is None)
            )
            
            for batch_idx, batch in enumerate(dataloader):
                # μ…λ ¥ λ°μ΄ν„° μ¤€λΉ„
                input_ids = batch["input_ids"].to(device)
                attention_mask = batch["attention_mask"].to(device)
                labels = input_ids.clone()
                
                # Forward pass
                outputs = self.model(
                    input_ids=input_ids,
                    attention_mask=attention_mask,
                    labels=labels
                )
                loss = outputs.loss
                
                # Backward pass
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                
                total_loss += loss.item()
                num_batches += 1
                
                # μ£ΌκΈ°μ  λ΅κΉ…
                if batch_idx % 100 == 0 and rank == 0:
                    print(f"Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}")
            
            # μ—ν¬ν¬λ³„ ν‰κ·  μ†μ‹¤
            avg_loss = total_loss / num_batches
            
            # Ray Train λ©”νΈλ¦­ λ¦¬ν¬ν…
            train.report({
                "epoch": epoch,
                "loss": avg_loss,
                "learning_rate": config["learning_rate"]
            })
            
            # MLflow λ΅κΉ… (rank 0μ—μ„λ§)
            if rank == 0:
                mlflow.log_metrics({
                    "train_loss": avg_loss,
                    "epoch": epoch
                }, step=epoch)

def run_distributed_training():
    """λ¶„μ‚° ν•™μµ μ‹¤ν–‰"""
    # Ray μ΄κΈ°ν™”
    ray.init(address="ray://korean-llm-cluster-head:10001")
    
    # MLflow μ„¤μ •
    mlflow.set_tracking_uri("http://mlflow-server:5000")
    
    with mlflow.start_run(run_name="ray-distributed-training"):
        # ν•™μµ μ„¤μ •
        config = {
            "model_name": "unsloth/Qwen2.5-7B-bnb-4bit",
            "dataset_path": "/data/korean_corpus.jsonl",
            "learning_rate": 1e-5,
            "weight_decay": 0.01,
            "batch_size": 4,
            "num_epochs": 3
        }
        
        # MLflow νλΌλ―Έν„° λ΅κΉ…
        mlflow.log_params(config)
        
        # TorchTrainer μ„¤μ •
        trainer = TorchTrainer(
            train_loop_per_worker=KoreanLLMDistributedTrainer(config).train_function,
            train_loop_config=config,
            scaling_config=ScalingConfig(
                num_workers=4,  # μ›μ»¤ μ
                use_gpu=True,
                resources_per_worker={"CPU": 4, "GPU": 1}
            ),
            run_config=train.RunConfig(
                name="korean-llm-distributed-training",
                storage_path="/data/ray_results"
            )
        )
        
        # ν•™μµ μ‹¤ν–‰
        result = trainer.fit()
        
        # κ²°κ³Ό λ΅κΉ…
        mlflow.log_metrics({
            "final_loss": result.metrics["loss"],
            "total_epochs": result.metrics["epoch"]
        })
        
        print("λ¶„μ‚° ν•™μµ μ™„λ£!")
        print(f"μµμΆ… μ†μ‹¤: {result.metrics['loss']:.4f}")

if __name__ == "__main__":
    run_distributed_training()
```

---

## 3. Ray Tuneμ„ ν™μ©ν• ν•μ΄νΌνλΌλ―Έν„° νλ‹

### 3.1 ν•μ΄νΌνλΌλ―Έν„° μµμ ν™”

```python
# ray_hyperparameter_tuning.py
import ray
from ray import tune
from ray.tune import CLIReporter
from ray.tune.schedulers import ASHAScheduler
from ray.tune.search.optuna import OptunaSearch
import torch
from transformers import TrainingArguments
from trl import SFTTrainer
from unsloth import FastLanguageModel
from datasets import load_dataset
import mlflow
import tempfile
import os

class KoreanLLMTuner:
    def __init__(self, base_config):
        self.base_config = base_config
        
    def objective_function(self, config):
        """νλ‹ λ©μ  ν•¨μ"""
        # MLflow μλ™ λ΅κΉ… μ„¤μ •
        mlflow.set_tracking_uri("http://mlflow-server:5000")
        
        with mlflow.start_run(nested=True):
            # νλΌλ―Έν„° λ΅κΉ…
            mlflow.log_params(config)
            
            # λ¨λΈ λ΅λ”©
            model, tokenizer = FastLanguageModel.from_pretrained(
                model_name=self.base_config["model_name"],
                max_seq_length=2048,
                dtype=None,
                load_in_4bit=True,
            )
            
            # LoRA μ„¤μ • (νλ‹ νλΌλ―Έν„° μ μ©)
            model = FastLanguageModel.get_peft_model(
                model,
                r=int(config["lora_r"]),
                target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],
                lora_alpha=int(config["lora_alpha"]),
                lora_dropout=config["lora_dropout"],
                bias="none",
                use_gradient_checkpointing="unsloth",
            )
            
            # λ°μ΄ν„°μ…‹ λ΅λ”©
            dataset = load_dataset(
                "json", 
                data_files=self.base_config["dataset_path"], 
                split="train"
            )
            
            # μ„μ‹ μ¶λ ¥ λ””λ ‰ν† λ¦¬
            with tempfile.TemporaryDirectory() as temp_dir:
                # ν•™μµ μΈμ μ„¤μ •
                training_args = TrainingArguments(
                    output_dir=temp_dir,
                    num_train_epochs=2,  # νλ‹ μ‹μ—λ” μ§§κ²
                    per_device_train_batch_size=int(config["batch_size"]),
                    learning_rate=config["learning_rate"],
                    weight_decay=config["weight_decay"],
                    warmup_steps=int(config["warmup_steps"]),
                    logging_steps=50,
                    save_steps=1000,
                    fp16=True,
                    dataloader_num_workers=4,
                    remove_unused_columns=False,
                )
                
                # νΈλ μ΄λ„ μ„¤μ •
                trainer = SFTTrainer(
                    model=model,
                    tokenizer=tokenizer,
                    args=training_args,
                    train_dataset=dataset,
                    dataset_text_field="text",
                    max_seq_length=2048,
                )
                
                # ν•™μµ μ‹¤ν–‰
                trainer.train()
                
                # μµμΆ… μ†μ‹¤κ°’ κ°€μ Έμ¤κΈ°
                final_loss = trainer.state.log_history[-1]["train_loss"]
                
                # λ©”νΈλ¦­ λ¦¬ν¬ν…
                tune.report(loss=final_loss, accuracy=1.0/final_loss)
                mlflow.log_metric("final_loss", final_loss)
                
                return final_loss

def run_hyperparameter_tuning():
    """ν•μ΄νΌνλΌλ―Έν„° νλ‹ μ‹¤ν–‰"""
    # Ray μ΄κΈ°ν™”
    ray.init(address="ray://korean-llm-cluster-head:10001")
    
    # λ² μ΄μ¤ μ„¤μ •
    base_config = {
        "model_name": "unsloth/Qwen2.5-7B-bnb-4bit",
        "dataset_path": "/data/instruction_dataset.jsonl"
    }
    
    # νλ‹ κ³µκ°„ μ •μ
    search_space = {
        "learning_rate": tune.loguniform(1e-6, 1e-3),
        "batch_size": tune.choice([2, 4, 8]),
        "weight_decay": tune.uniform(0.0, 0.1),
        "warmup_steps": tune.randint(50, 500),
        "lora_r": tune.choice([16, 32, 64, 128]),
        "lora_alpha": tune.choice([16, 32, 64]),
        "lora_dropout": tune.uniform(0.05, 0.3),
    }
    
    # μ¤μΌ€μ¤„λ¬ μ„¤μ • (μ΅°κΈ° μΆ…λ£)
    scheduler = ASHAScheduler(
        time_attr="training_iteration",
        metric="loss",
        mode="min",
        max_t=10,
        grace_period=2,
        reduction_factor=2
    )
    
    # κ²€μƒ‰ μ•κ³ λ¦¬μ¦ μ„¤μ •
    search_alg = OptunaSearch(
        metric="loss",
        mode="min",
        n_startup_trials=5
    )
    
    # λ¦¬ν¬ν„° μ„¤μ •
    reporter = CLIReporter(
        metric_columns=["loss", "accuracy", "training_iteration"]
    )
    
    # νλ‹ μ‹¤ν–‰
    tuner = tune.Tuner(
        KoreanLLMTuner(base_config).objective_function,
        param_space=search_space,
        tune_config=tune.TuneConfig(
            scheduler=scheduler,
            search_alg=search_alg,
            num_samples=20,  # μ‹¤ν–‰ν•  μ‹¤ν— μ
            max_concurrent_trials=4,
        ),
        run_config=train.RunConfig(
            name="korean-llm-hyperparameter-tuning",
            progress_reporter=reporter,
            storage_path="/data/ray_results"
        )
    )
    
    results = tuner.fit()
    
    # μµμ  κ²°κ³Ό
    best_result = results.get_best_result("loss", "min")
    
    print("=== μµμ  ν•μ΄νΌνλΌλ―Έν„° ===")
    print(f"μµμ  μ†μ‹¤: {best_result.metrics['loss']:.4f}")
    print(f"μµμ  νλΌλ―Έν„°: {best_result.config}")
    
    # MLflowμ— μµμ  νλΌλ―Έν„° λ΅κΉ…
    with mlflow.start_run(run_name="best-hyperparameters"):
        mlflow.log_params(best_result.config)
        mlflow.log_metrics(best_result.metrics)
    
    return best_result

if __name__ == "__main__":
    best_result = run_hyperparameter_tuning()
```

---

## 4. Ray Serveλ¥Ό ν™μ©ν• λ¨λΈ μ„λΉ™

### 4.1 λ¶„μ‚° λ¨λΈ μ„λΉ™ μ„¤μ •

```python
# ray_model_serving.py
import ray
from ray import serve
from ray.serve import deployment
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from unsloth import FastLanguageModel
import asyncio
from typing import Dict, List
import time
import logging

# λ΅κΉ… μ„¤μ •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@serve.deployment(
    num_replicas=3,
    ray_actor_options={
        "num_cpus": 4,
        "num_gpus": 1,
        "memory": 16 * 1024 * 1024 * 1024,  # 16GB
    },
    autoscaling_config={
        "min_replicas": 1,
        "max_replicas": 10,
        "target_num_ongoing_requests_per_replica": 2,
        "metrics_interval_s": 10,
        "look_back_period_s": 30,
        "smoothing_factor": 1.0,
        "downscale_delay_s": 600,  # 10λ¶„ ν›„ λ‹¤μ΄μ¤μΌ€μΌ
        "upscale_delay_s": 30,     # 30μ΄ ν›„ μ—…μ¤μΌ€μΌ
    },
    max_concurrent_queries=5,
    health_check_period_s=10,
    health_check_timeout_s=30,
)
class KoreanLLMService:
    def __init__(self, model_path: str = "unsloth/Qwen2.5-7B-bnb-4bit"):
        self.model_path = model_path
        self.model = None
        self.tokenizer = None
        self.device = None
        
    async def __call__(self, request: Dict) -> Dict:
        """μ¶”λ΅  μ—”λ“ν¬μΈνΈ"""
        try:
            # λ¨λΈ λ΅λ”© (μ§€μ—° λ΅λ”©)
            if self.model is None:
                await self._load_model()
            
            # μ…λ ¥ κ²€μ¦
            if "prompt" not in request:
                return {"error": "Missing 'prompt' in request"}
            
            prompt = request["prompt"]
            max_length = request.get("max_length", 256)
            temperature = request.get("temperature", 0.7)
            top_p = request.get("top_p", 0.9)
            
            # μ¶”λ΅  μ‹¤ν–‰
            start_time = time.time()
            response = await self._generate_text(
                prompt, max_length, temperature, top_p
            )
            inference_time = time.time() - start_time
            
            return {
                "generated_text": response,
                "inference_time": inference_time,
                "model_path": self.model_path,
                "device": str(self.device)
            }
            
        except Exception as e:
            logger.error(f"μ¶”λ΅  μ¤‘ μ¤λ¥ λ°μƒ: {str(e)}")
            return {"error": str(e)}
    
    async def _load_model(self):
        """λ¨λΈ λ΅λ”©"""
        logger.info(f"λ¨λΈ λ΅λ”© μ‹μ‘: {self.model_path}")
        
        # GPU λ””λ°”μ΄μ¤ μ„¤μ •
        if torch.cuda.is_available():
            self.device = torch.device("cuda")
        else:
            self.device = torch.device("cpu")
        
        # Unsloth λ¨λΈ λ΅λ”©
        self.model, self.tokenizer = FastLanguageModel.from_pretrained(
            model_name=self.model_path,
            max_seq_length=2048,
            dtype=None,
            load_in_4bit=True,
        )
        
        # μ¶”λ΅  λ¨λ“λ΅ μ„¤μ •
        FastLanguageModel.for_inference(self.model)
        self.model = self.model.to(self.device)
        
        logger.info(f"λ¨λΈ λ΅λ”© μ™„λ£. λ””λ°”μ΄μ¤: {self.device}")
    
    async def _generate_text(
        self, 
        prompt: str, 
        max_length: int, 
        temperature: float, 
        top_p: float
    ) -> str:
        """ν…μ¤νΈ μƒμ„±"""
        # μ…λ ¥ ν† ν¬λ‚μ΄μ§•
        inputs = self.tokenizer(
            prompt, 
            return_tensors="pt", 
            truncation=True, 
            max_length=1024
        ).to(self.device)
        
        # ν…μ¤νΈ μƒμ„±
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=max_length,
                temperature=temperature,
                top_p=top_p,
                do_sample=True,
                pad_token_id=self.tokenizer.eos_token_id,
                eos_token_id=self.tokenizer.eos_token_id,
            )
        
        # λ””μ½”λ”©
        generated_text = self.tokenizer.decode(
            outputs[0], 
            skip_special_tokens=True
        )
        
        # ν”„λ΅¬ν”„νΈ μ κ±°
        response = generated_text[len(prompt):].strip()
        return response

@serve.deployment(
    num_replicas=1,
    ray_actor_options={"num_cpus": 2, "memory": 4 * 1024 * 1024 * 1024}
)
class LoadBalancer:
    """λ΅λ“ λ°Έλ°μ„ λ° λ¨λ‹ν„°λ§"""
    
    def __init__(self):
        self.request_count = 0
        self.total_inference_time = 0.0
    
    async def __call__(self, request: Dict) -> Dict:
        """μ”μ²­ λΌμ°ν… λ° λ¨λ‹ν„°λ§"""
        self.request_count += 1
        
        # KoreanLLMServiceλ΅ μ”μ²­ μ „λ‹¬
        korean_llm_handle = serve.get_deployment("KoreanLLMService").get_handle()
        
        start_time = time.time()
        response = await korean_llm_handle.remote(request)
        end_time = time.time()
        
        # λ¨λ‹ν„°λ§ λ©”νΈλ¦­ μ—…λ°μ΄νΈ
        inference_time = end_time - start_time
        self.total_inference_time += inference_time
        
        # μ‘λ‹µμ— λ©”νƒ€λ°μ΄ν„° μ¶”κ°€
        if isinstance(response, dict) and "error" not in response:
            response["request_id"] = self.request_count
            response["queue_time"] = inference_time - response.get("inference_time", 0)
        
        return response
    
    async def get_metrics(self) -> Dict:
        """λ©”νΈλ¦­ μ΅°ν"""
        avg_inference_time = (
            self.total_inference_time / self.request_count 
            if self.request_count > 0 else 0
        )
        
        return {
            "total_requests": self.request_count,
            "average_inference_time": avg_inference_time,
            "total_inference_time": self.total_inference_time
        }

def deploy_korean_llm_service():
    """Ray Serve λ°°ν¬"""
    # Ray μ΄κΈ°ν™”
    ray.init(address="ray://korean-llm-cluster-head:10001")
    
    # Serve μ‹μ‘
    serve.start(detached=True, http_options={"host": "0.0.0.0", "port": 8000})
    
    # λ¨λΈ μ„λΉ„μ¤ λ°°ν¬
    KoreanLLMService.deploy(name="KoreanLLMService")
    
    # λ΅λ“ λ°Έλ°μ„ λ°°ν¬
    LoadBalancer.deploy(name="LoadBalancer")
    
    # λΌμ°ν… μ„¤μ •
    serve.run(LoadBalancer.bind(), name="korean-llm-api", route_prefix="/")
    
    logger.info("Ray Serve λ°°ν¬ μ™„λ£")
    logger.info("API μ—”λ“ν¬μΈνΈ: http://0.0.0.0:8000")
    
    return "λ°°ν¬ μ™„λ£"

# ν΄λΌμ΄μ–ΈνΈ ν…μ¤νΈ μ½”λ“
async def test_api():
    """API ν…μ¤νΈ"""
    import aiohttp
    
    test_requests = [
        {
            "prompt": "ν•κµ­μ μ „ν†µ μμ‹μ— λ€ν•΄ μ„¤λ…ν•΄μ£Όμ„Έμ”.",
            "max_length": 200,
            "temperature": 0.7
        },
        {
            "prompt": "μΈκ³µμ§€λ¥μ λ―Έλλ” μ–΄λ–¨κΉμ”?",
            "max_length": 150,
            "temperature": 0.8
        }
    ]
    
    async with aiohttp.ClientSession() as session:
        for i, request in enumerate(test_requests):
            start_time = time.time()
            
            async with session.post(
                "http://localhost:8000", 
                json=request
            ) as response:
                result = await response.json()
                end_time = time.time()
                
                print(f"\n=== ν…μ¤νΈ {i+1} ===")
                print(f"μ”μ²­: {request['prompt']}")
                print(f"μ‘λ‹µ: {result.get('generated_text', 'Error')}")
                print(f"μ΄ μ‹κ°„: {end_time - start_time:.2f}μ΄")
                print(f"μ¶”λ΅  μ‹κ°„: {result.get('inference_time', 0):.2f}μ΄")

if __name__ == "__main__":
    # μ„λΉ„μ¤ λ°°ν¬
    deploy_korean_llm_service()
    
    # ν…μ¤νΈ μ‹¤ν–‰
    import asyncio
    asyncio.run(test_api())
```

---

## 5. λ¨λ‹ν„°λ§ λ° μ¤ν† μ¤μΌ€μΌλ§

### 5.1 Ray Dashboard ν™μ©

```python
# ray_monitoring.py
import ray
from ray.util.metrics import Counter, Histogram, Gauge
import time
import asyncio

class RayMetricsCollector:
    def __init__(self):
        # λ©”νΈλ¦­ μ •μ
        self.request_counter = Counter(
            "korean_llm_requests_total",
            description="Total number of inference requests",
            tag_keys=("model_type", "status")
        )
        
        self.inference_duration = Histogram(
            "korean_llm_inference_duration_seconds",
            description="Inference duration in seconds",
            boundaries=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0],
            tag_keys=("model_type",)
        )
        
        self.active_connections = Gauge(
            "korean_llm_active_connections",
            description="Number of active connections",
            tag_keys=("model_type",)
        )
        
        self.gpu_utilization = Gauge(
            "korean_llm_gpu_utilization",
            description="GPU utilization percentage",
            tag_keys=("gpu_id",)
        )
    
    def record_request(self, model_type: str, status: str):
        """μ”μ²­ μΉ΄μ΄ν„° μ¦κ°€"""
        self.request_counter.inc(tags={"model_type": model_type, "status": status})
    
    def record_inference_time(self, model_type: str, duration: float):
        """μ¶”λ΅  μ‹κ°„ κΈ°λ΅"""
        self.inference_duration.observe(duration, tags={"model_type": model_type})
    
    def update_active_connections(self, model_type: str, count: int):
        """ν™μ„± μ—°κ²° μ μ—…λ°μ΄νΈ"""
        self.active_connections.set(count, tags={"model_type": model_type})
    
    def update_gpu_utilization(self, gpu_id: str, utilization: float):
        """GPU μ‚¬μ©λ¥  μ—…λ°μ΄νΈ"""
        self.gpu_utilization.set(utilization, tags={"gpu_id": gpu_id})

# Prometheus λ©”νΈλ¦­ μµμ¤ν¬νΈ
@ray.remote
class MetricsExporter:
    def __init__(self):
        self.metrics_collector = RayMetricsCollector()
    
    async def start_metrics_server(self, port=8080):
        """Prometheus λ©”νΈλ¦­ μ„λ²„ μ‹μ‘"""
        from prometheus_client import start_http_server
        start_http_server(port)
        print(f"Prometheus λ©”νΈλ¦­ μ„λ²„ μ‹μ‘: http://0.0.0.0:{port}/metrics")
    
    async def collect_system_metrics(self):
        """μ‹μ¤ν… λ©”νΈλ¦­ μμ§‘"""
        while True:
            try:
                # Ray ν΄λ¬μ¤ν„° μƒνƒ
                cluster_resources = ray.cluster_resources()
                cluster_usage = ray.available_resources()
                
                # GPU μ‚¬μ©λ¥  μμ§‘ (μμ‹)
                import torch
                if torch.cuda.is_available():
                    for i in range(torch.cuda.device_count()):
                        utilization = torch.cuda.utilization(i)
                        self.metrics_collector.update_gpu_utilization(
                            f"gpu_{i}", utilization
                        )
                
                await asyncio.sleep(10)  # 10μ΄λ§λ‹¤ μμ§‘
                
            except Exception as e:
                print(f"λ©”νΈλ¦­ μμ§‘ μ¤‘ μ¤λ¥: {e}")
                await asyncio.sleep(30)
```

### 5.2 μ¤ν† μ¤μΌ€μΌλ§ μ •μ±…

```yaml
# ray-autoscaling-policy.yaml
apiVersion: ray.io/v1alpha1
kind: RayCluster
metadata:
  name: korean-llm-cluster
  namespace: ray-system
spec:
  rayVersion: '2.8.0'
  enableInTreeAutoscaling: true
  autoscalerOptions:
    upscalingMode: Conservative  # λ³΄μμ  μ—…μ¤μΌ€μΌλ§
    idleTimeoutSeconds: 300      # 5λ¶„ μ ν΄ ν›„ λ‹¤μ΄μ¤μΌ€μΌ
    resources:
      limits:
        cpu: "2000m"
        memory: "4Gi"
      requests:
        cpu: "1000m"
        memory: "2Gi"
  
  headGroupSpec:
    # Head λ…Έλ“λ” κ³ μ •
    rayStartParams:
      dashboard-host: '0.0.0.0'
      num-cpus: '0'
    template:
      spec:
        containers:
        - name: ray-head
          image: rayproject/ray:2.8.0-py310-gpu
          resources:
            limits:
              cpu: "8"
              memory: "32Gi"
            requests:
              cpu: "4"
              memory: "16Gi"
  
  workerGroupSpecs:
  # GPU μ›μ»¤ κ·Έλ£Ή - ν•™μµμ©
  - replicas: 2
    minReplicas: 1
    maxReplicas: 20
    groupName: training-workers
    rayStartParams:
      num-cpus: '16'
      num-gpus: '4'
      resources: '{"training": 1}'
    template:
      spec:
        containers:
        - name: ray-worker
          image: rayproject/ray:2.8.0-py310-gpu
          resources:
            limits:
              cpu: "32"
              memory: "128Gi"
              nvidia.com/gpu: "4"
            requests:
              cpu: "16"
              memory: "64Gi"
              nvidia.com/gpu: "4"
        nodeSelector:
          node-type: gpu-training
        tolerations:
        - key: "gpu-training"
          operator: "Equal"
          value: "true"
          effect: "NoSchedule"
  
  # CPU μ›μ»¤ κ·Έλ£Ή - μ „μ²λ¦¬μ©
  - replicas: 1
    minReplicas: 0
    maxReplicas: 10
    groupName: cpu-workers
    rayStartParams:
      num-cpus: '8'
      resources: '{"preprocessing": 1}'
    template:
      spec:
        containers:
        - name: ray-worker
          image: rayproject/ray:2.8.0-py310
          resources:
            limits:
              cpu: "16"
              memory: "64Gi"
            requests:
              cpu: "8"
              memory: "32Gi"
        nodeSelector:
          node-type: cpu-preprocessing
  
  # μ¶”λ΅  μ „μ© μ›μ»¤ κ·Έλ£Ή
  - replicas: 3
    minReplicas: 2
    maxReplicas: 50
    groupName: inference-workers
    rayStartParams:
      num-cpus: '8'
      num-gpus: '1'
      resources: '{"inference": 1}'
    template:
      spec:
        containers:
        - name: ray-worker
          image: rayproject/ray:2.8.0-py310-gpu
          resources:
            limits:
              cpu: "16"
              memory: "32Gi"
              nvidia.com/gpu: "1"
            requests:
              cpu: "8"
              memory: "16Gi"
              nvidia.com/gpu: "1"
        nodeSelector:
          node-type: gpu-inference
```

---

## 6. μ‹¤μ  μ΄μ μ‹λ‚λ¦¬μ¤

### 6.1 μ—”λ“ν¬μ—”λ“ νμ΄ν”„λΌμΈ

```python
# end_to_end_pipeline.py
import ray
from ray import train, tune, serve
from ray.train.torch import TorchTrainer
import asyncio
import mlflow
from datetime import datetime

class KoreanLLMPipeline:
    def __init__(self):
        self.ray_address = "ray://korean-llm-cluster-head:10001"
        self.mlflow_uri = "http://mlflow-server:5000"
        
    async def run_complete_pipeline(self, config):
        """μ™„μ „ν• MLOps νμ΄ν”„λΌμΈ μ‹¤ν–‰"""
        # Ray μ΄κΈ°ν™”
        ray.init(address=self.ray_address)
        mlflow.set_tracking_uri(self.mlflow_uri)
        
        pipeline_run_id = f"pipeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        with mlflow.start_run(run_name=pipeline_run_id):
            try:
                # 1λ‹¨κ³„: ν•μ΄νΌνλΌλ―Έν„° νλ‹
                print("π― 1λ‹¨κ³„: ν•μ΄νΌνλΌλ―Έν„° νλ‹ μ‹μ‘...")
                best_params = await self.hyperparameter_tuning(config)
                mlflow.log_params(best_params)
                
                # 2λ‹¨κ³„: μµμ  νλΌλ―Έν„°λ΅ μ „μ²΄ ν•™μµ
                print("π€ 2λ‹¨κ³„: μµμ  νλΌλ―Έν„°λ΅ λ¶„μ‚° ν•™μµ μ‹μ‘...")
                model_path = await self.distributed_training(best_params)
                mlflow.log_artifact(model_path)
                
                # 3λ‹¨κ³„: λ¨λΈ ν‰κ°€
                print("π“ 3λ‹¨κ³„: λ¨λΈ ν‰κ°€ μ‹μ‘...")
                eval_metrics = await self.model_evaluation(model_path)
                mlflow.log_metrics(eval_metrics)
                
                # 4λ‹¨κ³„: μ΅°κ±΄λ¶€ λ°°ν¬
                if eval_metrics["accuracy"] > config.get("deployment_threshold", 0.8):
                    print("β΅ 4λ‹¨κ³„: ν”„λ΅λ•μ… λ°°ν¬ μ‹μ‘...")
                    service_url = await self.deploy_model(model_path)
                    mlflow.log_param("service_url", service_url)
                    
                    # 5λ‹¨κ³„: A/B ν…μ¤νΈ
                    print("π”„ 5λ‹¨κ³„: A/B ν…μ¤νΈ μ‹μ‘...")
                    ab_results = await self.ab_testing(service_url)
                    mlflow.log_metrics(ab_results)
                else:
                    print("β λ¨λΈ μ„±λ¥μ΄ κΈ°μ¤€μ— λ―Έλ‹¬ν•μ—¬ λ°°ν¬ν•μ§€ μ•μµλ‹λ‹¤.")
                
                return {
                    "status": "success",
                    "model_path": model_path,
                    "eval_metrics": eval_metrics
                }
                
            except Exception as e:
                print(f"β νμ΄ν”„λΌμΈ μ‹¤ν–‰ μ¤‘ μ¤λ¥: {e}")
                mlflow.log_param("error", str(e))
                return {"status": "failed", "error": str(e)}
    
    async def hyperparameter_tuning(self, config):
        """ν•μ΄νΌνλΌλ―Έν„° νλ‹"""
        # Ray Tune μ‹¤ν–‰ (μ΄μ „ μ„Ήμ…μ μ½”λ“ ν™μ©)
        search_space = {
            "learning_rate": tune.loguniform(1e-6, 1e-3),
            "batch_size": tune.choice([2, 4, 8]),
            "lora_r": tune.choice([16, 32, 64]),
        }
        
        # νλ‹ μ‹¤ν–‰ (κ°„μ†ν™”λ λ²„μ „)
        tuner = tune.Tuner(
            self.training_objective,
            param_space=search_space,
            tune_config=tune.TuneConfig(num_samples=5)
        )
        
        results = tuner.fit()
        best_result = results.get_best_result("loss", "min")
        return best_result.config
    
    async def distributed_training(self, params):
        """λ¶„μ‚° ν•™μµ μ‹¤ν–‰"""
        trainer = TorchTrainer(
            train_loop_per_worker=self.train_function,
            train_loop_config=params,
            scaling_config=train.ScalingConfig(
                num_workers=4,
                use_gpu=True,
                resources_per_worker={"CPU": 4, "GPU": 1}
            )
        )
        
        result = trainer.fit()
        return result.checkpoint.path
    
    async def model_evaluation(self, model_path):
        """λ¨λΈ ν‰κ°€"""
        # ν‰κ°€ λ΅μ§ κµ¬ν„
        return {
            "accuracy": 0.85,
            "perplexity": 12.3,
            "bleu_score": 0.42
        }
    
    async def deploy_model(self, model_path):
        """λ¨λΈ λ°°ν¬"""
        # Ray Serveλ¥Ό μ‚¬μ©ν• λ°°ν¬
        serve.start(detached=True)
        
        @serve.deployment(num_replicas=3)
        class ModelService:
            def __init__(self, model_path):
                self.model_path = model_path
                # λ¨λΈ λ΅λ”© λ΅μ§
        
        ModelService.deploy(model_path)
        return "http://korean-llm-service:8000"
    
    async def ab_testing(self, service_url):
        """A/B ν…μ¤νΈ"""
        # A/B ν…μ¤νΈ λ΅μ§
        return {
            "conversion_rate": 0.12,
            "response_time": 1.2,
            "user_satisfaction": 4.2
        }

# μ‹¤ν–‰ μ¤ν¬λ¦½νΈ
async def main():
    pipeline = KoreanLLMPipeline()
    
    config = {
        "model_name": "unsloth/Qwen2.5-7B-bnb-4bit",
        "dataset_path": "/data/korean_corpus.jsonl",
        "deployment_threshold": 0.8
    }
    
    result = await pipeline.run_complete_pipeline(config)
    print(f"νμ΄ν”„λΌμΈ μ™„λ£: {result}")

if __name__ == "__main__":
    asyncio.run(main())
```

### 6.2 μ¥μ•  λ³µκµ¬ λ° λ°±μ—…

```python
# disaster_recovery.py
import ray
import boto3
import kubernetes
from datetime import datetime
import json

class DisasterRecoveryManager:
    def __init__(self):
        self.s3_client = boto3.client('s3')
        self.k8s_client = kubernetes.client.ApiClient()
        
    def backup_ray_cluster_state(self, cluster_name, backup_bucket):
        """Ray ν΄λ¬μ¤ν„° μƒνƒ λ°±μ—…"""
        try:
            # ν΄λ¬μ¤ν„° μƒνƒ μμ§‘
            cluster_state = {
                "timestamp": datetime.now().isoformat(),
                "cluster_resources": ray.cluster_resources(),
                "running_jobs": self.get_running_jobs(),
                "deployed_services": self.get_deployed_services()
            }
            
            # S3μ— λ°±μ—…
            backup_key = f"ray-backups/{cluster_name}/{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            self.s3_client.put_object(
                Bucket=backup_bucket,
                Key=backup_key,
                Body=json.dumps(cluster_state, indent=2)
            )
            
            print(f"ν΄λ¬μ¤ν„° μƒνƒ λ°±μ—… μ™„λ£: s3://{backup_bucket}/{backup_key}")
            return backup_key
            
        except Exception as e:
            print(f"λ°±μ—… μ‹¤ν¨: {e}")
            return None
    
    def restore_ray_cluster(self, backup_key, backup_bucket):
        """Ray ν΄λ¬μ¤ν„° λ³µμ›"""
        try:
            # λ°±μ—… λ°μ΄ν„° λ‹¤μ΄λ΅λ“
            response = self.s3_client.get_object(
                Bucket=backup_bucket,
                Key=backup_key
            )
            backup_data = json.loads(response['Body'].read())
            
            # ν΄λ¬μ¤ν„° λ³µμ› λ΅μ§
            print("ν΄λ¬μ¤ν„° λ³µμ› μ‹μ‘...")
            
            # 1. Ray ν΄λ¬μ¤ν„° μ¬μ‹μ‘
            self.restart_ray_cluster()
            
            # 2. μ„λΉ„μ¤ λ³µμ›
            for service in backup_data.get("deployed_services", []):
                self.restore_service(service)
            
            # 3. μ‘μ—… λ³µμ›
            for job in backup_data.get("running_jobs", []):
                self.restore_job(job)
            
            print("ν΄λ¬μ¤ν„° λ³µμ› μ™„λ£")
            return True
            
        except Exception as e:
            print(f"λ³µμ› μ‹¤ν¨: {e}")
            return False
    
    def health_check_and_auto_recovery(self):
        """ν—¬μ¤ μ²΄ν¬ λ° μλ™ λ³µκµ¬"""
        try:
            # Ray ν΄λ¬μ¤ν„° μƒνƒ ν™•μΈ
            if not self.is_ray_cluster_healthy():
                print("β οΈ Ray ν΄λ¬μ¤ν„° λΉ„μ •μƒ μƒνƒ κ°μ§€")
                
                # μλ™ λ³µκµ¬ μ‹λ„
                if self.auto_recovery():
                    print("β… μλ™ λ³µκµ¬ μ„±κ³µ")
                else:
                    print("β μλ™ λ³µκµ¬ μ‹¤ν¨ - μλ™ κ°μ… ν•„μ”")
                    self.send_alert("Ray cluster auto-recovery failed")
            
            # μ„λΉ„μ¤ μƒνƒ ν™•μΈ
            unhealthy_services = self.check_service_health()
            if unhealthy_services:
                print(f"β οΈ λΉ„μ •μƒ μ„λΉ„μ¤ κ°μ§€: {unhealthy_services}")
                for service in unhealthy_services:
                    self.restart_service(service)
                    
        except Exception as e:
            print(f"ν—¬μ¤ μ²΄ν¬ μ¤‘ μ¤λ¥: {e}")
    
    def is_ray_cluster_healthy(self):
        """Ray ν΄λ¬μ¤ν„° μƒνƒ ν™•μΈ"""
        try:
            resources = ray.cluster_resources()
            return len(resources) > 0
        except:
            return False
    
    def auto_recovery(self):
        """μλ™ λ³µκµ¬ μ‹¤ν–‰"""
        try:
            # μµμ‹  λ°±μ—… μ°ΎκΈ°
            latest_backup = self.find_latest_backup()
            if latest_backup:
                return self.restore_ray_cluster(latest_backup, "ray-backups")
            return False
        except:
            return False

# μ •κΈ°μ  λ°±μ—… μ¤μΌ€μ¤„λ¬
@ray.remote
class BackupScheduler:
    def __init__(self):
        self.recovery_manager = DisasterRecoveryManager()
    
    async def run_periodic_backup(self):
        """μ •κΈ° λ°±μ—… μ‹¤ν–‰"""
        while True:
            try:
                # λ§¤ μ‹κ°„λ§λ‹¤ λ°±μ—…
                self.recovery_manager.backup_ray_cluster_state(
                    "korean-llm-cluster",
                    "korean-llm-backups"
                )
                
                # ν—¬μ¤ μ²΄ν¬
                self.recovery_manager.health_check_and_auto_recovery()
                
                await asyncio.sleep(3600)  # 1μ‹κ°„ λ€κΈ°
                
            except Exception as e:
                print(f"λ°±μ—… μ¤μΌ€μ¤„λ¬ μ¤λ¥: {e}")
                await asyncio.sleep(300)  # 5λ¶„ ν›„ μ¬μ‹λ„
```

---

## κ²°λ΅ 

λ³Έ κ°€μ΄λ“λ¥Ό ν†µν•΄ Rayμ™€ KubeRayλ¥Ό ν™μ©ν• μ—”ν„°ν”„λΌμ΄μ¦κΈ‰ λ€κ·λ¨ λ¶„μ‚° ν•κµ­μ–΄ LLM ν•™μµ μ‹μ¤ν…μ„ κµ¬μ¶•ν–μµλ‹λ‹¤.

**μ£Όμ” μ„±κ³Ό**:

- π€ **ν™•μ¥μ„±**: Rayμ λ¶„μ‚° μ»΄ν“¨ν…μ„ ν†µν• λ¬΄μ ν• ν™•μ¥
- π― **ν¨μ¨μ„±**: Ray Tuneμ„ ν†µν• μλ™ ν•μ΄νΌνλΌλ―Έν„° μµμ ν™”
- β΅ **κ³ μ„±λ¥**: Ray Serveλ¥Ό ν†µν• μ§€μ—°μ‹κ°„ μµμ†ν™” μ„λΉ™
- π”„ **μ¤ν† μ¤μΌ€μΌλ§**: KubeRayμ μΏ λ²„λ„¤ν‹°μ¤ λ„¤μ΄ν‹°λΈ μλ™ ν™•μ¥

**μ—”ν„°ν”„λΌμ΄μ¦ κ°€μΉ**:

- **λΉ„μ© ν¨μ¨μ„±**: ν•„μ”μ‹μ—λ§ λ¦¬μ†μ¤ ν™•μ¥μΌλ΅ 30-50% λΉ„μ© μ κ°
- **μ΄μ μ•μ •μ„±**: μλ™ μ¥μ•  λ³µκµ¬ λ° λ°±μ—…μΌλ΅ 99.9% κ°€μ©μ„± λ‹¬μ„±
- **κ°λ° μƒμ‚°μ„±**: ν†µν•© MLOps νμ΄ν”„λΌμΈμΌλ΅ κ°λ° μ£ΌκΈ° 50% λ‹¨μ¶•
- **μ„±λ¥ μµμ ν™”**: GPU ν΄λ¬μ¤ν„° ν™μ©μΌλ΅ ν•™μµ μ‹κ°„ 80% λ‹¨μ¶•

**μ‹¤λ¬΄ μ μ© μ‹λ‚λ¦¬μ¤**:

- **λ€ν™”ν• AI μ„λΉ„μ¤**: μ‹¤μ‹κ°„ μ±„ν…λ΄‡ λ° κ°€μƒ μ–΄μ‹μ¤ν„΄νΈ
- **μ½ν…μΈ  μƒμ„±**: μλ™ κΈ°μ‚¬ μ‘μ„± λ° μ°½μ‘ μ§€μ›
- **κ³ κ° μ„λΉ„μ¤**: μ§€λ¥ν• FAQ λ° λ¬Έμ μ‘λ‹µ μ‹μ¤ν…
- **κµμ΅ ν”λ«νΌ**: κ°μΈν™” ν•™μµ μ½ν…μΈ  μƒμ„±

μ΄ μ‹λ¦¬μ¦μ λ‹¤λ¥Έ κΈ€ λ³΄κΈ°:

- [1νΈ: Unslothλ¥Ό ν™μ©ν• ν•κµ­μ–΄ νΉν™” LLM ν•™μµ μ™„μ „ κ°€μ΄λ“](#)
- [2νΈ: μΏ λ²„λ„¤ν‹°μ¤ νμ΄ν”„λΌμΈ κµ¬μ¶•](#)
- [3νΈ: Kubeflow λ° MLOps ν”„λ μ„μ›ν¬ ν™μ©](#)
- 4νΈ: Rayμ™€ KubeRayλ¥Ό ν™μ©ν• λ€κ·λ¨ λ¶„μ‚° ν•™μµ (ν„μ¬ κΈ€)

Rayμ™€ KubeRayμ κ°•λ ¥ν• λ¶„μ‚° μ»΄ν“¨ν… λ¥λ ¥μ„ ν†µν•΄ ν•κµ­μ–΄ νΉν™” LLM κ°λ°μ μƒλ΅μ΄ μ°¨μ›μ„ κ²½ν—ν•΄λ³΄μ„Έμ”. π€
