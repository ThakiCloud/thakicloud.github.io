---
title: "Unsloth+TRL í•œêµ­ì–´ LLM í•™ìŠµ ìë™í™” - 4í¸: Rayì™€ KubeRayë¥¼ í™œìš©í•œ ëŒ€ê·œëª¨ ë¶„ì‚° í•™ìŠµ"
excerpt: "Ray Train/Tune/Serveì™€ KubeRayë¥¼ í™œìš©í•œ ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ë¶„ì‚° í•œêµ­ì–´ LLM í•™ìŠµ ë° ì˜¤í† ìŠ¤ì¼€ì¼ë§ ì‹œìŠ¤í…œ êµ¬ì¶•"
date: 2025-06-17
categories:
  - llmops
tags:
  - Ray
  - KubeRay
  - Ray Train
  - Ray Tune
  - Ray Serve
  - Korean LLM
  - Distributed Training
  - Auto Scaling
  - MLOps
  - Unsloth
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
---

## ê°œìš”

ë³¸ ê°€ì´ë“œëŠ” [Unsloth+TRL í•œêµ­ì–´ LLM í•™ìŠµ ì‹œë¦¬ì¦ˆ]({% post_url 2025-06-17-unsloth-korean-llm-training-guide %})ì˜ 4í¸ìœ¼ë¡œ, Rayì™€ KubeRayë¥¼ í™œìš©í•˜ì—¬ ëŒ€ê·œëª¨ ë¶„ì‚° í•œêµ­ì–´ LLM í•™ìŠµì„ ìë™í™”í•˜ê³  ì˜¤í† ìŠ¤ì¼€ì¼ë§í•˜ëŠ” ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.

**í•™ìŠµ ëª©í‘œ**:

- ğŸš€ **Ray Train**: ë¶„ì‚° í•™ìŠµ ì›Œí¬ë¡œë“œ ìë™í™”
- ğŸ¯ **Ray Tune**: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ìµœì í™”
- âš¡ **Ray Serve**: ê³ ì„±ëŠ¥ ëª¨ë¸ ì„œë¹™ ì¸í”„ë¼
- ğŸ”„ **KubeRay**: ì¿ ë²„ë„¤í‹°ìŠ¤ ê¸°ë°˜ ì˜¤í† ìŠ¤ì¼€ì¼ë§

---

## 1. Ray ë° KubeRay ì„¤ì¹˜

### 1.1 KubeRay Operator ì„¤ì¹˜

```bash
# KubeRay Operator ì„¤ì¹˜
helm repo add kuberay https://ray-project.github.io/kuberay-helm/
helm repo update

# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±
kubectl create namespace ray-system

# KubeRay Operator ì„¤ì¹˜
helm install kuberay-operator kuberay/kuberay-operator \
  --namespace ray-system \
  --version 1.0.0

# ì„¤ì¹˜ í™•ì¸
kubectl get pods -n ray-system
```

### 1.2 Ray Cluster ì •ì˜

```yaml
# ray-cluster.yaml
apiVersion: ray.io/v1alpha1
kind: RayCluster
metadata:
  name: korean-llm-cluster
  namespace: ray-system
spec:
  rayVersion: '2.8.0'
  enableInTreeAutoscaling: true
  autoscalerOptions:
    upscalingMode: Default
    idleTimeoutSeconds: 60
    resources:
      limits:
        cpu: "1000m"
        memory: "2Gi"
      requests:
        cpu: "500m"
        memory: "1Gi"
  
  headGroupSpec:
    rayStartParams:
      dashboard-host: '0.0.0.0'
      num-cpus: '0'
    template:
      spec:
        containers:
        - name: ray-head
          image: rayproject/ray:2.8.0-py310-gpu
          ports:
          - containerPort: 6379
            name: gcs-server
          - containerPort: 8265
            name: dashboard
          - containerPort: 10001
            name: client
          resources:
            limits:
              cpu: "4"
              memory: "16Gi"
            requests:
              cpu: "2"
              memory: "8Gi"
          volumeMounts:
          - name: data-volume
            mountPath: /data
        volumes:
        - name: data-volume
          persistentVolumeClaim:
            claimName: ray-data-pvc
  
  workerGroupSpecs:
  - replicas: 2
    minReplicas: 1
    maxReplicas: 10
    groupName: gpu-workers
    rayStartParams:
      num-cpus: '8'
      num-gpus: '4'
    template:
      spec:
        containers:
        - name: ray-worker
          image: rayproject/ray:2.8.0-py310-gpu
          resources:
            limits:
              cpu: "16"
              memory: "64Gi"
              nvidia.com/gpu: "4"
            requests:
              cpu: "8"
              memory: "32Gi"
              nvidia.com/gpu: "4"
          volumeMounts:
          - name: data-volume
            mountPath: /data
        volumes:
        - name: data-volume
          persistentVolumeClaim:
            claimName: ray-data-pvc
        tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
```

---

## 2. Ray Trainì„ í™œìš©í•œ ë¶„ì‚° í•™ìŠµ

### 2.1 ë¶„ì‚° í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

```python
# ray_distributed_training.py
import ray
from ray import train
from ray.train import ScalingConfig
from ray.train.torch import TorchTrainer
from ray.train.huggingface import HuggingfaceTrainer
import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModelForCausalLM
from unsloth import FastLanguageModel
from datasets import load_dataset
import mlflow
import os

@ray.remote
class KoreanLLMDistributedTrainer:
    def __init__(self, config):
        self.config = config
        self.model = None
        self.tokenizer = None
        
    def setup_model(self):
        """ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì„¤ì •"""
        model_name = self.config.get("model_name", "unsloth/Qwen2.5-7B-bnb-4bit")
        
        self.model, self.tokenizer = FastLanguageModel.from_pretrained(
            model_name=model_name,
            max_seq_length=4096,
            dtype=None,
            load_in_4bit=True,
        )
        
        # LoRA ì„¤ì •
        self.model = FastLanguageModel.get_peft_model(
            self.model,
            r=64,
            target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],
            lora_alpha=16,
            lora_dropout=0.1,
            bias="none",
            use_gradient_checkpointing="unsloth",
            use_rslora=True,
            loftq_config=None,
        )
    
    def prepare_dataset(self):
        """ë°ì´í„°ì…‹ ì¤€ë¹„"""
        dataset_path = self.config.get("dataset_path", "/data/korean_corpus.jsonl")
        dataset = load_dataset("json", data_files=dataset_path, split="train")
        
        def tokenize_function(examples):
            return self.tokenizer(
                examples["text"],
                truncation=True,
                padding="max_length",
                max_length=2048,
                return_tensors="pt"
            )
        
        tokenized_dataset = dataset.map(tokenize_function, batched=True)
        return tokenized_dataset
    
    def train_function(self, config):
        """ë¶„ì‚° í•™ìŠµ í•¨ìˆ˜"""
        # Ray Train ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì‹¤í–‰
        import torch.distributed as dist
        from torch.nn.parallel import DistributedDataParallel as DDP
        
        # ë¶„ì‚° ì„¤ì •
        rank = train.get_context().get_world_rank()
        local_rank = train.get_context().get_local_rank()
        world_size = train.get_context().get_world_size()
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        device = torch.device(f"cuda:{local_rank}")
        torch.cuda.set_device(device)
        
        # ëª¨ë¸ ì¤€ë¹„
        self.setup_model()
        self.model = self.model.to(device)
        
        # DDP ë˜í•‘
        if world_size > 1:
            self.model = DDP(self.model, device_ids=[local_rank])
        
        # ë°ì´í„°ì…‹ ì¤€ë¹„
        dataset = self.prepare_dataset()
        
        # ì˜µí‹°ë§ˆì´ì € ì„¤ì •
        optimizer = torch.optim.AdamW(
            self.model.parameters(),
            lr=config["learning_rate"],
            weight_decay=config["weight_decay"]
        )
        
        # í•™ìŠµ ë£¨í”„
        self.model.train()
        for epoch in range(config["num_epochs"]):
            total_loss = 0
            num_batches = 0
            
            # ë°ì´í„°ë¡œë” ì„¤ì • (ë¶„ì‚° í™˜ê²½ ê³ ë ¤)
            sampler = torch.utils.data.distributed.DistributedSampler(
                dataset, num_replicas=world_size, rank=rank
            ) if world_size > 1 else None
            
            dataloader = torch.utils.data.DataLoader(
                dataset,
                batch_size=config["batch_size"],
                sampler=sampler,
                shuffle=(sampler is None)
            )
            
            for batch_idx, batch in enumerate(dataloader):
                # ì…ë ¥ ë°ì´í„° ì¤€ë¹„
                input_ids = batch["input_ids"].to(device)
                attention_mask = batch["attention_mask"].to(device)
                labels = input_ids.clone()
                
                # Forward pass
                outputs = self.model(
                    input_ids=input_ids,
                    attention_mask=attention_mask,
                    labels=labels
                )
                loss = outputs.loss
                
                # Backward pass
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                
                total_loss += loss.item()
                num_batches += 1
                
                # ì£¼ê¸°ì  ë¡œê¹…
                if batch_idx % 100 == 0 and rank == 0:
                    print(f"Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}")
            
            # ì—í¬í¬ë³„ í‰ê·  ì†ì‹¤
            avg_loss = total_loss / num_batches
            
            # Ray Train ë©”íŠ¸ë¦­ ë¦¬í¬íŒ…
            train.report({
                "epoch": epoch,
                "loss": avg_loss,
                "learning_rate": config["learning_rate"]
            })
            
            # MLflow ë¡œê¹… (rank 0ì—ì„œë§Œ)
            if rank == 0:
                mlflow.log_metrics({
                    "train_loss": avg_loss,
                    "epoch": epoch
                }, step=epoch)

def run_distributed_training():
    """ë¶„ì‚° í•™ìŠµ ì‹¤í–‰"""
    # Ray ì´ˆê¸°í™”
    ray.init(address="ray://korean-llm-cluster-head:10001")
    
    # MLflow ì„¤ì •
    mlflow.set_tracking_uri("http://mlflow-server:5000")
    
    with mlflow.start_run(run_name="ray-distributed-training"):
        # í•™ìŠµ ì„¤ì •
        config = {
            "model_name": "unsloth/Qwen2.5-7B-bnb-4bit",
            "dataset_path": "/data/korean_corpus.jsonl",
            "learning_rate": 1e-5,
            "weight_decay": 0.01,
            "batch_size": 4,
            "num_epochs": 3
        }
        
        # MLflow íŒŒë¼ë¯¸í„° ë¡œê¹…
        mlflow.log_params(config)
        
        # TorchTrainer ì„¤ì •
        trainer = TorchTrainer(
            train_loop_per_worker=KoreanLLMDistributedTrainer(config).train_function,
            train_loop_config=config,
            scaling_config=ScalingConfig(
                num_workers=4,  # ì›Œì»¤ ìˆ˜
                use_gpu=True,
                resources_per_worker={"CPU": 4, "GPU": 1}
            ),
            run_config=train.RunConfig(
                name="korean-llm-distributed-training",
                storage_path="/data/ray_results"
            )
        )
        
        # í•™ìŠµ ì‹¤í–‰
        result = trainer.fit()
        
        # ê²°ê³¼ ë¡œê¹…
        mlflow.log_metrics({
            "final_loss": result.metrics["loss"],
            "total_epochs": result.metrics["epoch"]
        })
        
        print("ë¶„ì‚° í•™ìŠµ ì™„ë£Œ!")
        print(f"ìµœì¢… ì†ì‹¤: {result.metrics['loss']:.4f}")

if __name__ == "__main__":
    run_distributed_training()
```

---

## 3. Ray Tuneì„ í™œìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹

### 3.1 í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”

```python
# ray_hyperparameter_tuning.py
import ray
from ray import tune
from ray.tune import CLIReporter
from ray.tune.schedulers import ASHAScheduler
from ray.tune.search.optuna import OptunaSearch
import torch
from transformers import TrainingArguments
from trl import SFTTrainer
from unsloth import FastLanguageModel
from datasets import load_dataset
import mlflow
import tempfile
import os

class KoreanLLMTuner:
    def __init__(self, base_config):
        self.base_config = base_config
        
    def objective_function(self, config):
        """íŠœë‹ ëª©ì  í•¨ìˆ˜"""
        # MLflow ìë™ ë¡œê¹… ì„¤ì •
        mlflow.set_tracking_uri("http://mlflow-server:5000")
        
        with mlflow.start_run(nested=True):
            # íŒŒë¼ë¯¸í„° ë¡œê¹…
            mlflow.log_params(config)
            
            # ëª¨ë¸ ë¡œë”©
            model, tokenizer = FastLanguageModel.from_pretrained(
                model_name=self.base_config["model_name"],
                max_seq_length=2048,
                dtype=None,
                load_in_4bit=True,
            )
            
            # LoRA ì„¤ì • (íŠœë‹ íŒŒë¼ë¯¸í„° ì ìš©)
            model = FastLanguageModel.get_peft_model(
                model,
                r=int(config["lora_r"]),
                target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],
                lora_alpha=int(config["lora_alpha"]),
                lora_dropout=config["lora_dropout"],
                bias="none",
                use_gradient_checkpointing="unsloth",
            )
            
            # ë°ì´í„°ì…‹ ë¡œë”©
            dataset = load_dataset(
                "json", 
                data_files=self.base_config["dataset_path"], 
                split="train"
            )
            
            # ì„ì‹œ ì¶œë ¥ ë””ë ‰í† ë¦¬
            with tempfile.TemporaryDirectory() as temp_dir:
                # í•™ìŠµ ì¸ì ì„¤ì •
                training_args = TrainingArguments(
                    output_dir=temp_dir,
                    num_train_epochs=2,  # íŠœë‹ ì‹œì—ëŠ” ì§§ê²Œ
                    per_device_train_batch_size=int(config["batch_size"]),
                    learning_rate=config["learning_rate"],
                    weight_decay=config["weight_decay"],
                    warmup_steps=int(config["warmup_steps"]),
                    logging_steps=50,
                    save_steps=1000,
                    fp16=True,
                    dataloader_num_workers=4,
                    remove_unused_columns=False,
                )
                
                # íŠ¸ë ˆì´ë„ˆ ì„¤ì •
                trainer = SFTTrainer(
                    model=model,
                    tokenizer=tokenizer,
                    args=training_args,
                    train_dataset=dataset,
                    dataset_text_field="text",
                    max_seq_length=2048,
                )
                
                # í•™ìŠµ ì‹¤í–‰
                trainer.train()
                
                # ìµœì¢… ì†ì‹¤ê°’ ê°€ì ¸ì˜¤ê¸°
                final_loss = trainer.state.log_history[-1]["train_loss"]
                
                # ë©”íŠ¸ë¦­ ë¦¬í¬íŒ…
                tune.report(loss=final_loss, accuracy=1.0/final_loss)
                mlflow.log_metric("final_loss", final_loss)
                
                return final_loss

def run_hyperparameter_tuning():
    """í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹¤í–‰"""
    # Ray ì´ˆê¸°í™”
    ray.init(address="ray://korean-llm-cluster-head:10001")
    
    # ë² ì´ìŠ¤ ì„¤ì •
    base_config = {
        "model_name": "unsloth/Qwen2.5-7B-bnb-4bit",
        "dataset_path": "/data/instruction_dataset.jsonl"
    }
    
    # íŠœë‹ ê³µê°„ ì •ì˜
    search_space = {
        "learning_rate": tune.loguniform(1e-6, 1e-3),
        "batch_size": tune.choice([2, 4, 8]),
        "weight_decay": tune.uniform(0.0, 0.1),
        "warmup_steps": tune.randint(50, 500),
        "lora_r": tune.choice([16, 32, 64, 128]),
        "lora_alpha": tune.choice([16, 32, 64]),
        "lora_dropout": tune.uniform(0.05, 0.3),
    }
    
    # ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • (ì¡°ê¸° ì¢…ë£Œ)
    scheduler = ASHAScheduler(
        time_attr="training_iteration",
        metric="loss",
        mode="min",
        max_t=10,
        grace_period=2,
        reduction_factor=2
    )
    
    # ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ ì„¤ì •
    search_alg = OptunaSearch(
        metric="loss",
        mode="min",
        n_startup_trials=5
    )
    
    # ë¦¬í¬í„° ì„¤ì •
    reporter = CLIReporter(
        metric_columns=["loss", "accuracy", "training_iteration"]
    )
    
    # íŠœë‹ ì‹¤í–‰
    tuner = tune.Tuner(
        KoreanLLMTuner(base_config).objective_function,
        param_space=search_space,
        tune_config=tune.TuneConfig(
            scheduler=scheduler,
            search_alg=search_alg,
            num_samples=20,  # ì‹¤í–‰í•  ì‹¤í—˜ ìˆ˜
            max_concurrent_trials=4,
        ),
        run_config=train.RunConfig(
            name="korean-llm-hyperparameter-tuning",
            progress_reporter=reporter,
            storage_path="/data/ray_results"
        )
    )
    
    results = tuner.fit()
    
    # ìµœì  ê²°ê³¼
    best_result = results.get_best_result("loss", "min")
    
    print("=== ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ===")
    print(f"ìµœì  ì†ì‹¤: {best_result.metrics['loss']:.4f}")
    print(f"ìµœì  íŒŒë¼ë¯¸í„°: {best_result.config}")
    
    # MLflowì— ìµœì  íŒŒë¼ë¯¸í„° ë¡œê¹…
    with mlflow.start_run(run_name="best-hyperparameters"):
        mlflow.log_params(best_result.config)
        mlflow.log_metrics(best_result.metrics)
    
    return best_result

if __name__ == "__main__":
    best_result = run_hyperparameter_tuning()
```

---

## 4. Ray Serveë¥¼ í™œìš©í•œ ëª¨ë¸ ì„œë¹™

### 4.1 ë¶„ì‚° ëª¨ë¸ ì„œë¹™ ì„¤ì •

```python
# ray_model_serving.py
import ray
from ray import serve
from ray.serve import deployment
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from unsloth import FastLanguageModel
import asyncio
from typing import Dict, List
import time
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@serve.deployment(
    num_replicas=3,
    ray_actor_options={
        "num_cpus": 4,
        "num_gpus": 1,
        "memory": 16 * 1024 * 1024 * 1024,  # 16GB
    },
    autoscaling_config={
        "min_replicas": 1,
        "max_replicas": 10,
        "target_num_ongoing_requests_per_replica": 2,
        "metrics_interval_s": 10,
        "look_back_period_s": 30,
        "smoothing_factor": 1.0,
        "downscale_delay_s": 600,  # 10ë¶„ í›„ ë‹¤ìš´ìŠ¤ì¼€ì¼
        "upscale_delay_s": 30,     # 30ì´ˆ í›„ ì—…ìŠ¤ì¼€ì¼
    },
    max_concurrent_queries=5,
    health_check_period_s=10,
    health_check_timeout_s=30,
)
class KoreanLLMService:
    def __init__(self, model_path: str = "unsloth/Qwen2.5-7B-bnb-4bit"):
        self.model_path = model_path
        self.model = None
        self.tokenizer = None
        self.device = None
        
    async def __call__(self, request: Dict) -> Dict:
        """ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸"""
        try:
            # ëª¨ë¸ ë¡œë”© (ì§€ì—° ë¡œë”©)
            if self.model is None:
                await self._load_model()
            
            # ì…ë ¥ ê²€ì¦
            if "prompt" not in request:
                return {"error": "Missing 'prompt' in request"}
            
            prompt = request["prompt"]
            max_length = request.get("max_length", 256)
            temperature = request.get("temperature", 0.7)
            top_p = request.get("top_p", 0.9)
            
            # ì¶”ë¡  ì‹¤í–‰
            start_time = time.time()
            response = await self._generate_text(
                prompt, max_length, temperature, top_p
            )
            inference_time = time.time() - start_time
            
            return {
                "generated_text": response,
                "inference_time": inference_time,
                "model_path": self.model_path,
                "device": str(self.device)
            }
            
        except Exception as e:
            logger.error(f"ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return {"error": str(e)}
    
    async def _load_model(self):
        """ëª¨ë¸ ë¡œë”©"""
        logger.info(f"ëª¨ë¸ ë¡œë”© ì‹œì‘: {self.model_path}")
        
        # GPU ë””ë°”ì´ìŠ¤ ì„¤ì •
        if torch.cuda.is_available():
            self.device = torch.device("cuda")
        else:
            self.device = torch.device("cpu")
        
        # Unsloth ëª¨ë¸ ë¡œë”©
        self.model, self.tokenizer = FastLanguageModel.from_pretrained(
            model_name=self.model_path,
            max_seq_length=2048,
            dtype=None,
            load_in_4bit=True,
        )
        
        # ì¶”ë¡  ëª¨ë“œë¡œ ì„¤ì •
        FastLanguageModel.for_inference(self.model)
        self.model = self.model.to(self.device)
        
        logger.info(f"ëª¨ë¸ ë¡œë”© ì™„ë£Œ. ë””ë°”ì´ìŠ¤: {self.device}")
    
    async def _generate_text(
        self, 
        prompt: str, 
        max_length: int, 
        temperature: float, 
        top_p: float
    ) -> str:
        """í…ìŠ¤íŠ¸ ìƒì„±"""
        # ì…ë ¥ í† í¬ë‚˜ì´ì§•
        inputs = self.tokenizer(
            prompt, 
            return_tensors="pt", 
            truncation=True, 
            max_length=1024
        ).to(self.device)
        
        # í…ìŠ¤íŠ¸ ìƒì„±
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=max_length,
                temperature=temperature,
                top_p=top_p,
                do_sample=True,
                pad_token_id=self.tokenizer.eos_token_id,
                eos_token_id=self.tokenizer.eos_token_id,
            )
        
        # ë””ì½”ë”©
        generated_text = self.tokenizer.decode(
            outputs[0], 
            skip_special_tokens=True
        )
        
        # í”„ë¡¬í”„íŠ¸ ì œê±°
        response = generated_text[len(prompt):].strip()
        return response

@serve.deployment(
    num_replicas=1,
    ray_actor_options={"num_cpus": 2, "memory": 4 * 1024 * 1024 * 1024}
)
class LoadBalancer:
    """ë¡œë“œ ë°¸ëŸ°ì„œ ë° ëª¨ë‹ˆí„°ë§"""
    
    def __init__(self):
        self.request_count = 0
        self.total_inference_time = 0.0
    
    async def __call__(self, request: Dict) -> Dict:
        """ìš”ì²­ ë¼ìš°íŒ… ë° ëª¨ë‹ˆí„°ë§"""
        self.request_count += 1
        
        # KoreanLLMServiceë¡œ ìš”ì²­ ì „ë‹¬
        korean_llm_handle = serve.get_deployment("KoreanLLMService").get_handle()
        
        start_time = time.time()
        response = await korean_llm_handle.remote(request)
        end_time = time.time()
        
        # ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        inference_time = end_time - start_time
        self.total_inference_time += inference_time
        
        # ì‘ë‹µì— ë©”íƒ€ë°ì´í„° ì¶”ê°€
        if isinstance(response, dict) and "error" not in response:
            response["request_id"] = self.request_count
            response["queue_time"] = inference_time - response.get("inference_time", 0)
        
        return response
    
    async def get_metrics(self) -> Dict:
        """ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        avg_inference_time = (
            self.total_inference_time / self.request_count 
            if self.request_count > 0 else 0
        )
        
        return {
            "total_requests": self.request_count,
            "average_inference_time": avg_inference_time,
            "total_inference_time": self.total_inference_time
        }

def deploy_korean_llm_service():
    """Ray Serve ë°°í¬"""
    # Ray ì´ˆê¸°í™”
    ray.init(address="ray://korean-llm-cluster-head:10001")
    
    # Serve ì‹œì‘
    serve.start(detached=True, http_options={"host": "0.0.0.0", "port": 8000})
    
    # ëª¨ë¸ ì„œë¹„ìŠ¤ ë°°í¬
    KoreanLLMService.deploy(name="KoreanLLMService")
    
    # ë¡œë“œ ë°¸ëŸ°ì„œ ë°°í¬
    LoadBalancer.deploy(name="LoadBalancer")
    
    # ë¼ìš°íŒ… ì„¤ì •
    serve.run(LoadBalancer.bind(), name="korean-llm-api", route_prefix="/")
    
    logger.info("Ray Serve ë°°í¬ ì™„ë£Œ")
    logger.info("API ì—”ë“œí¬ì¸íŠ¸: http://0.0.0.0:8000")
    
    return "ë°°í¬ ì™„ë£Œ"

# í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸ ì½”ë“œ
async def test_api():
    """API í…ŒìŠ¤íŠ¸"""
    import aiohttp
    
    test_requests = [
        {
            "prompt": "í•œêµ­ì˜ ì „í†µ ìŒì‹ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "max_length": 200,
            "temperature": 0.7
        },
        {
            "prompt": "ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ëŠ” ì–´ë–¨ê¹Œìš”?",
            "max_length": 150,
            "temperature": 0.8
        }
    ]
    
    async with aiohttp.ClientSession() as session:
        for i, request in enumerate(test_requests):
            start_time = time.time()
            
            async with session.post(
                "http://localhost:8000", 
                json=request
            ) as response:
                result = await response.json()
                end_time = time.time()
                
                print(f"\n=== í…ŒìŠ¤íŠ¸ {i+1} ===")
                print(f"ìš”ì²­: {request['prompt']}")
                print(f"ì‘ë‹µ: {result.get('generated_text', 'Error')}")
                print(f"ì´ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
                print(f"ì¶”ë¡  ì‹œê°„: {result.get('inference_time', 0):.2f}ì´ˆ")

if __name__ == "__main__":
    # ì„œë¹„ìŠ¤ ë°°í¬
    deploy_korean_llm_service()
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    import asyncio
    asyncio.run(test_api())
```

---

## 5. ëª¨ë‹ˆí„°ë§ ë° ì˜¤í† ìŠ¤ì¼€ì¼ë§

### 5.1 Ray Dashboard í™œìš©

```python
# ray_monitoring.py
import ray
from ray.util.metrics import Counter, Histogram, Gauge
import time
import asyncio

class RayMetricsCollector:
    def __init__(self):
        # ë©”íŠ¸ë¦­ ì •ì˜
        self.request_counter = Counter(
            "korean_llm_requests_total",
            description="Total number of inference requests",
            tag_keys=("model_type", "status")
        )
        
        self.inference_duration = Histogram(
            "korean_llm_inference_duration_seconds",
            description="Inference duration in seconds",
            boundaries=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0],
            tag_keys=("model_type",)
        )
        
        self.active_connections = Gauge(
            "korean_llm_active_connections",
            description="Number of active connections",
            tag_keys=("model_type",)
        )
        
        self.gpu_utilization = Gauge(
            "korean_llm_gpu_utilization",
            description="GPU utilization percentage",
            tag_keys=("gpu_id",)
        )
    
    def record_request(self, model_type: str, status: str):
        """ìš”ì²­ ì¹´ìš´í„° ì¦ê°€"""
        self.request_counter.inc(tags={"model_type": model_type, "status": status})
    
    def record_inference_time(self, model_type: str, duration: float):
        """ì¶”ë¡  ì‹œê°„ ê¸°ë¡"""
        self.inference_duration.observe(duration, tags={"model_type": model_type})
    
    def update_active_connections(self, model_type: str, count: int):
        """í™œì„± ì—°ê²° ìˆ˜ ì—…ë°ì´íŠ¸"""
        self.active_connections.set(count, tags={"model_type": model_type})
    
    def update_gpu_utilization(self, gpu_id: str, utilization: float):
        """GPU ì‚¬ìš©ë¥  ì—…ë°ì´íŠ¸"""
        self.gpu_utilization.set(utilization, tags={"gpu_id": gpu_id})

# Prometheus ë©”íŠ¸ë¦­ ìµìŠ¤í¬íŠ¸
@ray.remote
class MetricsExporter:
    def __init__(self):
        self.metrics_collector = RayMetricsCollector()
    
    async def start_metrics_server(self, port=8080):
        """Prometheus ë©”íŠ¸ë¦­ ì„œë²„ ì‹œì‘"""
        from prometheus_client import start_http_server
        start_http_server(port)
        print(f"Prometheus ë©”íŠ¸ë¦­ ì„œë²„ ì‹œì‘: http://0.0.0.0:{port}/metrics")
    
    async def collect_system_metrics(self):
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        while True:
            try:
                # Ray í´ëŸ¬ìŠ¤í„° ìƒíƒœ
                cluster_resources = ray.cluster_resources()
                cluster_usage = ray.available_resources()
                
                # GPU ì‚¬ìš©ë¥  ìˆ˜ì§‘ (ì˜ˆì‹œ)
                import torch
                if torch.cuda.is_available():
                    for i in range(torch.cuda.device_count()):
                        utilization = torch.cuda.utilization(i)
                        self.metrics_collector.update_gpu_utilization(
                            f"gpu_{i}", utilization
                        )
                
                await asyncio.sleep(10)  # 10ì´ˆë§ˆë‹¤ ìˆ˜ì§‘
                
            except Exception as e:
                print(f"ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(30)
```

### 5.2 ì˜¤í† ìŠ¤ì¼€ì¼ë§ ì •ì±…

```yaml
# ray-autoscaling-policy.yaml
apiVersion: ray.io/v1alpha1
kind: RayCluster
metadata:
  name: korean-llm-cluster
  namespace: ray-system
spec:
  rayVersion: '2.8.0'
  enableInTreeAutoscaling: true
  autoscalerOptions:
    upscalingMode: Conservative  # ë³´ìˆ˜ì  ì—…ìŠ¤ì¼€ì¼ë§
    idleTimeoutSeconds: 300      # 5ë¶„ ìœ íœ´ í›„ ë‹¤ìš´ìŠ¤ì¼€ì¼
    resources:
      limits:
        cpu: "2000m"
        memory: "4Gi"
      requests:
        cpu: "1000m"
        memory: "2Gi"
  
  headGroupSpec:
    # Head ë…¸ë“œëŠ” ê³ ì •
    rayStartParams:
      dashboard-host: '0.0.0.0'
      num-cpus: '0'
    template:
      spec:
        containers:
        - name: ray-head
          image: rayproject/ray:2.8.0-py310-gpu
          resources:
            limits:
              cpu: "8"
              memory: "32Gi"
            requests:
              cpu: "4"
              memory: "16Gi"
  
  workerGroupSpecs:
  # GPU ì›Œì»¤ ê·¸ë£¹ - í•™ìŠµìš©
  - replicas: 2
    minReplicas: 1
    maxReplicas: 20
    groupName: training-workers
    rayStartParams:
      num-cpus: '16'
      num-gpus: '4'
      resources: '{"training": 1}'
    template:
      spec:
        containers:
        - name: ray-worker
          image: rayproject/ray:2.8.0-py310-gpu
          resources:
            limits:
              cpu: "32"
              memory: "128Gi"
              nvidia.com/gpu: "4"
            requests:
              cpu: "16"
              memory: "64Gi"
              nvidia.com/gpu: "4"
        nodeSelector:
          node-type: gpu-training
        tolerations:
        - key: "gpu-training"
          operator: "Equal"
          value: "true"
          effect: "NoSchedule"
  
  # CPU ì›Œì»¤ ê·¸ë£¹ - ì „ì²˜ë¦¬ìš©
  - replicas: 1
    minReplicas: 0
    maxReplicas: 10
    groupName: cpu-workers
    rayStartParams:
      num-cpus: '8'
      resources: '{"preprocessing": 1}'
    template:
      spec:
        containers:
        - name: ray-worker
          image: rayproject/ray:2.8.0-py310
          resources:
            limits:
              cpu: "16"
              memory: "64Gi"
            requests:
              cpu: "8"
              memory: "32Gi"
        nodeSelector:
          node-type: cpu-preprocessing
  
  # ì¶”ë¡  ì „ìš© ì›Œì»¤ ê·¸ë£¹
  - replicas: 3
    minReplicas: 2
    maxReplicas: 50
    groupName: inference-workers
    rayStartParams:
      num-cpus: '8'
      num-gpus: '1'
      resources: '{"inference": 1}'
    template:
      spec:
        containers:
        - name: ray-worker
          image: rayproject/ray:2.8.0-py310-gpu
          resources:
            limits:
              cpu: "16"
              memory: "32Gi"
              nvidia.com/gpu: "1"
            requests:
              cpu: "8"
              memory: "16Gi"
              nvidia.com/gpu: "1"
        nodeSelector:
          node-type: gpu-inference
```

---

## 6. ì‹¤ì œ ìš´ì˜ ì‹œë‚˜ë¦¬ì˜¤

### 6.1 ì—”ë“œíˆ¬ì—”ë“œ íŒŒì´í”„ë¼ì¸

```python
# end_to_end_pipeline.py
import ray
from ray import train, tune, serve
from ray.train.torch import TorchTrainer
import asyncio
import mlflow
from datetime import datetime

class KoreanLLMPipeline:
    def __init__(self):
        self.ray_address = "ray://korean-llm-cluster-head:10001"
        self.mlflow_uri = "http://mlflow-server:5000"
        
    async def run_complete_pipeline(self, config):
        """ì™„ì „í•œ MLOps íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        # Ray ì´ˆê¸°í™”
        ray.init(address=self.ray_address)
        mlflow.set_tracking_uri(self.mlflow_uri)
        
        pipeline_run_id = f"pipeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        with mlflow.start_run(run_name=pipeline_run_id):
            try:
                # 1ë‹¨ê³„: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
                print("ğŸ¯ 1ë‹¨ê³„: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘...")
                best_params = await self.hyperparameter_tuning(config)
                mlflow.log_params(best_params)
                
                # 2ë‹¨ê³„: ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ì „ì²´ í•™ìŠµ
                print("ğŸš€ 2ë‹¨ê³„: ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ë¶„ì‚° í•™ìŠµ ì‹œì‘...")
                model_path = await self.distributed_training(best_params)
                mlflow.log_artifact(model_path)
                
                # 3ë‹¨ê³„: ëª¨ë¸ í‰ê°€
                print("ğŸ“Š 3ë‹¨ê³„: ëª¨ë¸ í‰ê°€ ì‹œì‘...")
                eval_metrics = await self.model_evaluation(model_path)
                mlflow.log_metrics(eval_metrics)
                
                # 4ë‹¨ê³„: ì¡°ê±´ë¶€ ë°°í¬
                if eval_metrics["accuracy"] > config.get("deployment_threshold", 0.8):
                    print("âš¡ 4ë‹¨ê³„: í”„ë¡œë•ì…˜ ë°°í¬ ì‹œì‘...")
                    service_url = await self.deploy_model(model_path)
                    mlflow.log_param("service_url", service_url)
                    
                    # 5ë‹¨ê³„: A/B í…ŒìŠ¤íŠ¸
                    print("ğŸ”„ 5ë‹¨ê³„: A/B í…ŒìŠ¤íŠ¸ ì‹œì‘...")
                    ab_results = await self.ab_testing(service_url)
                    mlflow.log_metrics(ab_results)
                else:
                    print("âŒ ëª¨ë¸ ì„±ëŠ¥ì´ ê¸°ì¤€ì— ë¯¸ë‹¬í•˜ì—¬ ë°°í¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                
                return {
                    "status": "success",
                    "model_path": model_path,
                    "eval_metrics": eval_metrics
                }
                
            except Exception as e:
                print(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
                mlflow.log_param("error", str(e))
                return {"status": "failed", "error": str(e)}
    
    async def hyperparameter_tuning(self, config):
        """í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹"""
        # Ray Tune ì‹¤í–‰ (ì´ì „ ì„¹ì…˜ì˜ ì½”ë“œ í™œìš©)
        search_space = {
            "learning_rate": tune.loguniform(1e-6, 1e-3),
            "batch_size": tune.choice([2, 4, 8]),
            "lora_r": tune.choice([16, 32, 64]),
        }
        
        # íŠœë‹ ì‹¤í–‰ (ê°„ì†Œí™”ëœ ë²„ì „)
        tuner = tune.Tuner(
            self.training_objective,
            param_space=search_space,
            tune_config=tune.TuneConfig(num_samples=5)
        )
        
        results = tuner.fit()
        best_result = results.get_best_result("loss", "min")
        return best_result.config
    
    async def distributed_training(self, params):
        """ë¶„ì‚° í•™ìŠµ ì‹¤í–‰"""
        trainer = TorchTrainer(
            train_loop_per_worker=self.train_function,
            train_loop_config=params,
            scaling_config=train.ScalingConfig(
                num_workers=4,
                use_gpu=True,
                resources_per_worker={"CPU": 4, "GPU": 1}
            )
        )
        
        result = trainer.fit()
        return result.checkpoint.path
    
    async def model_evaluation(self, model_path):
        """ëª¨ë¸ í‰ê°€"""
        # í‰ê°€ ë¡œì§ êµ¬í˜„
        return {
            "accuracy": 0.85,
            "perplexity": 12.3,
            "bleu_score": 0.42
        }
    
    async def deploy_model(self, model_path):
        """ëª¨ë¸ ë°°í¬"""
        # Ray Serveë¥¼ ì‚¬ìš©í•œ ë°°í¬
        serve.start(detached=True)
        
        @serve.deployment(num_replicas=3)
        class ModelService:
            def __init__(self, model_path):
                self.model_path = model_path
                # ëª¨ë¸ ë¡œë”© ë¡œì§
        
        ModelService.deploy(model_path)
        return "http://korean-llm-service:8000"
    
    async def ab_testing(self, service_url):
        """A/B í…ŒìŠ¤íŠ¸"""
        # A/B í…ŒìŠ¤íŠ¸ ë¡œì§
        return {
            "conversion_rate": 0.12,
            "response_time": 1.2,
            "user_satisfaction": 4.2
        }

# ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
async def main():
    pipeline = KoreanLLMPipeline()
    
    config = {
        "model_name": "unsloth/Qwen2.5-7B-bnb-4bit",
        "dataset_path": "/data/korean_corpus.jsonl",
        "deployment_threshold": 0.8
    }
    
    result = await pipeline.run_complete_pipeline(config)
    print(f"íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {result}")

if __name__ == "__main__":
    asyncio.run(main())
```

### 6.2 ì¥ì•  ë³µêµ¬ ë° ë°±ì—…

```python
# disaster_recovery.py
import ray
import boto3
import kubernetes
from datetime import datetime
import json

class DisasterRecoveryManager:
    def __init__(self):
        self.s3_client = boto3.client('s3')
        self.k8s_client = kubernetes.client.ApiClient()
        
    def backup_ray_cluster_state(self, cluster_name, backup_bucket):
        """Ray í´ëŸ¬ìŠ¤í„° ìƒíƒœ ë°±ì—…"""
        try:
            # í´ëŸ¬ìŠ¤í„° ìƒíƒœ ìˆ˜ì§‘
            cluster_state = {
                "timestamp": datetime.now().isoformat(),
                "cluster_resources": ray.cluster_resources(),
                "running_jobs": self.get_running_jobs(),
                "deployed_services": self.get_deployed_services()
            }
            
            # S3ì— ë°±ì—…
            backup_key = f"ray-backups/{cluster_name}/{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            self.s3_client.put_object(
                Bucket=backup_bucket,
                Key=backup_key,
                Body=json.dumps(cluster_state, indent=2)
            )
            
            print(f"í´ëŸ¬ìŠ¤í„° ìƒíƒœ ë°±ì—… ì™„ë£Œ: s3://{backup_bucket}/{backup_key}")
            return backup_key
            
        except Exception as e:
            print(f"ë°±ì—… ì‹¤íŒ¨: {e}")
            return None
    
    def restore_ray_cluster(self, backup_key, backup_bucket):
        """Ray í´ëŸ¬ìŠ¤í„° ë³µì›"""
        try:
            # ë°±ì—… ë°ì´í„° ë‹¤ìš´ë¡œë“œ
            response = self.s3_client.get_object(
                Bucket=backup_bucket,
                Key=backup_key
            )
            backup_data = json.loads(response['Body'].read())
            
            # í´ëŸ¬ìŠ¤í„° ë³µì› ë¡œì§
            print("í´ëŸ¬ìŠ¤í„° ë³µì› ì‹œì‘...")
            
            # 1. Ray í´ëŸ¬ìŠ¤í„° ì¬ì‹œì‘
            self.restart_ray_cluster()
            
            # 2. ì„œë¹„ìŠ¤ ë³µì›
            for service in backup_data.get("deployed_services", []):
                self.restore_service(service)
            
            # 3. ì‘ì—… ë³µì›
            for job in backup_data.get("running_jobs", []):
                self.restore_job(job)
            
            print("í´ëŸ¬ìŠ¤í„° ë³µì› ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"ë³µì› ì‹¤íŒ¨: {e}")
            return False
    
    def health_check_and_auto_recovery(self):
        """í—¬ìŠ¤ ì²´í¬ ë° ìë™ ë³µêµ¬"""
        try:
            # Ray í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸
            if not self.is_ray_cluster_healthy():
                print("âš ï¸ Ray í´ëŸ¬ìŠ¤í„° ë¹„ì •ìƒ ìƒíƒœ ê°ì§€")
                
                # ìë™ ë³µêµ¬ ì‹œë„
                if self.auto_recovery():
                    print("âœ… ìë™ ë³µêµ¬ ì„±ê³µ")
                else:
                    print("âŒ ìë™ ë³µêµ¬ ì‹¤íŒ¨ - ìˆ˜ë™ ê°œì… í•„ìš”")
                    self.send_alert("Ray cluster auto-recovery failed")
            
            # ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
            unhealthy_services = self.check_service_health()
            if unhealthy_services:
                print(f"âš ï¸ ë¹„ì •ìƒ ì„œë¹„ìŠ¤ ê°ì§€: {unhealthy_services}")
                for service in unhealthy_services:
                    self.restart_service(service)
                    
        except Exception as e:
            print(f"í—¬ìŠ¤ ì²´í¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def is_ray_cluster_healthy(self):
        """Ray í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸"""
        try:
            resources = ray.cluster_resources()
            return len(resources) > 0
        except:
            return False
    
    def auto_recovery(self):
        """ìë™ ë³µêµ¬ ì‹¤í–‰"""
        try:
            # ìµœì‹  ë°±ì—… ì°¾ê¸°
            latest_backup = self.find_latest_backup()
            if latest_backup:
                return self.restore_ray_cluster(latest_backup, "ray-backups")
            return False
        except:
            return False

# ì •ê¸°ì  ë°±ì—… ìŠ¤ì¼€ì¤„ëŸ¬
@ray.remote
class BackupScheduler:
    def __init__(self):
        self.recovery_manager = DisasterRecoveryManager()
    
    async def run_periodic_backup(self):
        """ì •ê¸° ë°±ì—… ì‹¤í–‰"""
        while True:
            try:
                # ë§¤ ì‹œê°„ë§ˆë‹¤ ë°±ì—…
                self.recovery_manager.backup_ray_cluster_state(
                    "korean-llm-cluster",
                    "korean-llm-backups"
                )
                
                # í—¬ìŠ¤ ì²´í¬
                self.recovery_manager.health_check_and_auto_recovery()
                
                await asyncio.sleep(3600)  # 1ì‹œê°„ ëŒ€ê¸°
                
            except Exception as e:
                print(f"ë°±ì—… ìŠ¤ì¼€ì¤„ëŸ¬ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(300)  # 5ë¶„ í›„ ì¬ì‹œë„
```

---

## ê²°ë¡ 

ë³¸ ê°€ì´ë“œë¥¼ í†µí•´ Rayì™€ KubeRayë¥¼ í™œìš©í•œ ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ëŒ€ê·œëª¨ ë¶„ì‚° í•œêµ­ì–´ LLM í•™ìŠµ ì‹œìŠ¤í…œì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤.

**ì£¼ìš” ì„±ê³¼**:

- ğŸš€ **í™•ì¥ì„±**: Rayì˜ ë¶„ì‚° ì»´í“¨íŒ…ì„ í†µí•œ ë¬´ì œí•œ í™•ì¥
- ğŸ¯ **íš¨ìœ¨ì„±**: Ray Tuneì„ í†µí•œ ìë™ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
- âš¡ **ê³ ì„±ëŠ¥**: Ray Serveë¥¼ í†µí•œ ì§€ì—°ì‹œê°„ ìµœì†Œí™” ì„œë¹™
- ğŸ”„ **ì˜¤í† ìŠ¤ì¼€ì¼ë§**: KubeRayì˜ ì¿ ë²„ë„¤í‹°ìŠ¤ ë„¤ì´í‹°ë¸Œ ìë™ í™•ì¥

**ì—”í„°í”„ë¼ì´ì¦ˆ ê°€ì¹˜**:

- **ë¹„ìš© íš¨ìœ¨ì„±**: í•„ìš”ì‹œì—ë§Œ ë¦¬ì†ŒìŠ¤ í™•ì¥ìœ¼ë¡œ 30-50% ë¹„ìš© ì ˆê°
- **ìš´ì˜ ì•ˆì •ì„±**: ìë™ ì¥ì•  ë³µêµ¬ ë° ë°±ì—…ìœ¼ë¡œ 99.9% ê°€ìš©ì„± ë‹¬ì„±
- **ê°œë°œ ìƒì‚°ì„±**: í†µí•© MLOps íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ê°œë°œ ì£¼ê¸° 50% ë‹¨ì¶•
- **ì„±ëŠ¥ ìµœì í™”**: GPU í´ëŸ¬ìŠ¤í„° í™œìš©ìœ¼ë¡œ í•™ìŠµ ì‹œê°„ 80% ë‹¨ì¶•

**ì‹¤ë¬´ ì ìš© ì‹œë‚˜ë¦¬ì˜¤**:

- **ëŒ€í™”í˜• AI ì„œë¹„ìŠ¤**: ì‹¤ì‹œê°„ ì±„íŒ…ë´‡ ë° ê°€ìƒ ì–´ì‹œìŠ¤í„´íŠ¸
- **ì½˜í…ì¸  ìƒì„±**: ìë™ ê¸°ì‚¬ ì‘ì„± ë° ì°½ì‘ ì§€ì›
- **ê³ ê° ì„œë¹„ìŠ¤**: ì§€ëŠ¥í˜• FAQ ë° ë¬¸ì˜ ì‘ë‹µ ì‹œìŠ¤í…œ
- **êµìœ¡ í”Œë«í¼**: ê°œì¸í™” í•™ìŠµ ì½˜í…ì¸  ìƒì„±

ì´ ì‹œë¦¬ì¦ˆì˜ ë‹¤ë¥¸ ê¸€ ë³´ê¸°:

- [1í¸: Unslothë¥¼ í™œìš©í•œ í•œêµ­ì–´ íŠ¹í™” LLM í•™ìŠµ ì™„ì „ ê°€ì´ë“œ]({% post_url 2025-06-17-unsloth-korean-llm-training-guide %})
- [2í¸: ì¿ ë²„ë„¤í‹°ìŠ¤ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•]({% post_url 2025-06-17-unsloth-korean-llm-kubernetes-automation %})
- [3í¸: Kubeflow ë° MLOps í”„ë ˆì„ì›Œí¬ í™œìš©]({% post_url 2025-06-17-unsloth-korean-llm-kubeflow-automation %})
- 4í¸: Rayì™€ KubeRayë¥¼ í™œìš©í•œ ëŒ€ê·œëª¨ ë¶„ì‚° í•™ìŠµ (í˜„ì¬ ê¸€)

Rayì™€ KubeRayì˜ ê°•ë ¥í•œ ë¶„ì‚° ì»´í“¨íŒ… ëŠ¥ë ¥ì„ í†µí•´ í•œêµ­ì–´ íŠ¹í™” LLM ê°œë°œì˜ ìƒˆë¡œìš´ ì°¨ì›ì„ ê²½í—˜í•´ë³´ì„¸ìš”. ğŸš€
