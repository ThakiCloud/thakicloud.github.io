---
title: "Anthropic의 멀티 에이전트 연구 시스템: AI 에이전트의 새로운 패러다임"
excerpt: "Claude Research가 보여준 멀티 에이전트 시스템의 혁신적 접근법과 단일 에이전트 대비 90% 성능 향상의 비밀"
date: 2025-06-15
categories: 
  - research
  - llmops
tags: 
  - anthropic
  - claude
  - multi-agent
  - ai-research
  - llm
  - prompt-engineering
  - ai-agents
author_profile: true
toc: true
toc_label: 멀티 에이전트 시스템
---

Simon Willison이 최근 [자신의 블로그](https://simonwillison.net/2025/Jun/14/multi-agent-research-system/)에서 소개한 **Anthropic의 멀티 에이전트 연구 시스템**은 AI 에이전트 분야에 새로운 전환점을 제시하고 있습니다. 기존의 단일 프롬프트 접근법에 회의적이었던 전문가들조차 인정할 만큼 혁신적인 성과를 보여주고 있습니다.

## 멀티 에이전트 시스템이란?

Anthropic은 자신들의 "에이전트" 정의를 명확히 제시합니다:

> **멀티 에이전트 시스템**은 여러 에이전트(루프 내에서 자율적으로 도구를 사용하는 LLM)가 함께 작업하는 시스템입니다. 우리의 Research 기능은 사용자 쿼리를 기반으로 연구 프로세스를 계획하는 에이전트와, 동시에 정보를 검색하는 병렬 에이전트를 생성하는 도구를 사용합니다.

이는 **"Tools in a Loop"** 방식의 에이전트 아키텍처로, 각 에이전트가 독립적으로 도구를 사용하며 루프를 통해 작업을 수행합니다.

## 왜 멀티 에이전트인가? - 압축과 병렬성의 핵심

### 정보 압축의 새로운 접근

> 검색의 본질은 압축입니다: 방대한 말뭉치에서 통찰을 증류하는 것이죠. 서브 에이전트들은 각자의 컨텍스트 윈도우로 병렬 작업하며 질문의 다양한 측면을 동시에 탐색한 후, 가장 중요한 토큰들을 주요 연구 에이전트에게 압축해서 전달함으로써 압축을 촉진합니다.

### 놀라운 성능 향상

Anthropic의 내부 평가에서 멀티 에이전트 시스템의 성과는 압도적이었습니다:

- **Claude Opus 4 리드 에이전트 + Claude Sonnet 4 서브 에이전트** 구성
- **단일 에이전트 Claude Opus 4 대비 90.2% 성능 향상**
- **광범위한 탐색이 필요한 쿼리에서 특히 탁월한 성능**

**실전 예시**: "S&P 500 정보기술 기업들의 이사회 멤버를 모두 찾으시오"
- **멀티 에이전트 시스템**: 작업을 서브 에이전트들에게 분해하여 정확한 답변 도출
- **단일 에이전트 시스템**: 느리고 순차적인 검색으로 실패

## 비용의 현실: 토큰 사용량 급증

멀티 에이전트 시스템의 가장 큰 단점은 **토큰 소모량**입니다:

- **단일 에이전트**: 일반 채팅 대비 약 **4배** 토큰 사용
- **멀티 에이전트**: 일반 채팅 대비 약 **15배** 토큰 사용

> 경제적 타당성을 위해서는 작업의 가치가 증가된 성능을 위한 비용을 지불할 만큼 충분히 높아야 합니다.

### 멀티 에이전트가 적합한 작업들

1. **대규모 병렬화가 필요한 고가치 작업**
2. **단일 컨텍스트 윈도우를 초과하는 정보 처리**
3. **다수의 복잡한 도구와의 인터페이스**

## 200K 토큰 제한의 우아한 해결책

멀티 에이전트 시스템의 핵심 이점은 **컨텍스트 윈도우 관리**입니다:

- 각 서브 태스크가 **독립적인 컨텍스트**를 가짐
- **훨씬 더 큰 볼륨의 콘텐츠** 처리 가능
- 200,000 토큰 제한을 효과적으로 우회

### 메모리 메커니즘의 중요성

> LeadResearcher는 접근 방법을 생각한 후 계획을 Memory에 저장하여 컨텍스트를 유지합니다. 컨텍스트 윈도우가 200,000 토큰을 초과하면 잘릴 수 있기 때문에 계획을 유지하는 것이 중요합니다.

## 프롬프트 엔지니어링: 멀티 에이전트의 핵심

### 초기 문제들과 해결책

초기 에이전트들의 전형적인 실수들:
- 간단한 쿼리에 대해 **50개의 서브 에이전트 생성**
- 존재하지 않는 소스를 **끝없이 웹에서 탐색**
- 과도한 업데이트로 **서로 방해**

> 각 에이전트가 프롬프트에 의해 조정되기 때문에, 프롬프트 엔지니어링이 이러한 행동을 개선하는 주요 수단이었습니다.

### 효과적인 서브 에이전트 구성 요소

각 서브 에이전트에게 필요한 요소들:
1. **명확한 목표 (Objective)**
2. **출력 형식 (Output Format)**
3. **도구 및 소스 사용 가이드**
4. **명확한 작업 경계**

### 도구 최적화 전용 에이전트

혁신적인 접근: **도구 테스팅 에이전트** 개발
- 결함이 있는 MCP 도구를 받아서 **사용 시도 후 도구 설명 재작성**
- 수십 번의 테스트를 통해 **핵심 뉘앙스와 버그 발견**
- 결과: **작업 완료 시간 40% 단축**

## 병렬화를 통한 성능 혁신

### 이중 병렬화 전략

1. **리드 에이전트 레벨**: 3-5개 서브 에이전트를 순차가 아닌 **병렬로** 생성
2. **서브 에이전트 레벨**: 3개 이상의 도구를 **병렬로** 사용

**성과**: 복잡한 쿼리의 연구 시간을 **최대 90% 단축**, 시간 단위 작업을 분 단위로 압축하면서 다른 시스템보다 더 많은 정보를 커버

### 병렬 도구 호출 프롬프트 예시

```text
<use_parallel_tool_calls> 
최대 효율성을 위해 여러 독립적인 작업을 수행해야 할 때는 
순차적이 아닌 모든 관련 도구를 동시에 호출하세요. 
서브 에이전트들을 동시에 실행하기 위해 도구를 병렬로 호출하세요. 
간단한 쿼리가 아닌 이상, 연구 시작 시 여러 서브 에이전트를 
생성할 때 병렬 도구 호출을 반드시 사용해야 합니다.
</use_parallel_tool_calls>
```

## OODA 연구 루프: 체계적 접근법

서브 에이전트들이 사용하는 **OODA(Observe, Orient, Decide, Act) 루프**:

1. **관찰 (Observe)**: 지금까지 수집된 정보, 여전히 필요한 정보, 사용 가능한 도구 파악
2. **방향 설정 (Orient)**: 필요한 정보 수집을 위한 최적의 도구와 쿼리 결정
3. **결정 (Decide)**: 특정 도구를 특정 방식으로 사용하는 정보에 기반한 합리적 결정
4. **행동 (Act)**: 도구 사용 실행

이 루프를 효율적으로 반복하여 **연구를 잘 수행하고 새로운 결과를 바탕으로 학습**합니다.

## 평가 방법론: LLM Judge + 인간 평가

### LLM-as-a-Judge의 효과

Anthropic은 **LLM-as-a-judge** 방식이 잘 작동함을 발견했지만, **인간 평가가 필수**라고 강조합니다.

### 조기 소규모 평가의 중요성

> AI 개발팀들이 수백 개의 테스트 케이스가 있는 대규모 평가만이 유용하다고 믿어서 평가 생성을 미루는 경우를 자주 봅니다. 하지만 더 철저한 평가를 구축할 때까지 미루지 말고, 몇 가지 예시로 즉시 소규모 테스트를 시작하는 것이 최선입니다.

### 인간 평가의 핵심 발견

**문제**: 초기 에이전트들이 권위 있는 소스(학술 PDF, 개인 블로그) 대신 **SEO 최적화된 콘텐츠 팜을 일관되게 선택**

**해결책**: 프롬프트에 **소스 품질 휴리스틱** 추가

## 실무 적용을 위한 핵심 통찰

### 1. 점진적 접근법
- 소규모 테스트부터 시작
- 실제 사용 사례에서 발견되는 문제들을 해결
- 지속적인 프롬프트 개선

### 2. 비용 효율성 고려
- 15배 토큰 사용량에 대한 경제적 정당성 확보
- 고가치 작업에만 멀티 에이전트 시스템 적용

### 3. 도구 최적화
- 전용 도구 테스팅 에이전트 활용
- 도구 설명의 지속적인 개선

## 미래 전망: 멀티 에이전트 시대의 시작

Anthropic의 Claude Research 시스템은 **멀티 에이전트 LLM 시스템의 실용적 가능성**을 명확히 보여줍니다. 이는 단순한 기술적 호기심을 넘어서, **AI 시스템의 근본적 패러다임 전환**을 의미합니다.

### 핵심 교훈

1. **병렬성이 성능의 핵심** - 순차적 처리에서 병렬 처리로
2. **컨텍스트 제한 극복** - 분산된 컨텍스트 윈도우 활용
3. **프롬프트 엔지니어링의 중요성** - 각 에이전트의 역할과 경계 명확화
4. **비용 대비 효과 계산** - 15배 토큰 사용에 대한 정당성 확보
5. **지속적 개선** - 작은 평가부터 시작하여 점진적 향상

Simon Willison의 표현처럼, 이제 **"멀티 에이전트 LLM 시스템에 확신을 갖게 되었다"**고 말할 수 있는 시점이 도래했습니다. Anthropic의 사례는 이 분야에서 **가장 실용적이고 실행 가능한 가이드**를 제공하고 있습니다.

---

*참고자료: [Simon Willison's Weblog - Anthropic: How we built our multi-agent research system](https://simonwillison.net/2025/Jun/14/multi-agent-research-system/)* 