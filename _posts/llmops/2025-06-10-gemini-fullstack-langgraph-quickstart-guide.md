---
title: "Google Gemini 2.5 + LangGraphë¡œ êµ¬ì¶•í•˜ëŠ” AI ì—°êµ¬ ì—ì´ì „íŠ¸ - í’€ìŠ¤íƒ ê°€ì´ë“œ"
date: 2025-06-10
categories: 
  - llmops
  - AI Engineering
tags: 
  - Google Gemini
  - LangGraph
  - Fullstack
  - Research Agent
  - React
  - FastAPI
  - Web Search
  - RAG
author_profile: true
toc: true
toc_label: ëª©ì°¨
---

Googleì—ì„œ ê³µì‹ ë°œí‘œí•œ [Gemini Fullstack LangGraph Quickstart](https://github.com/google-gemini/gemini-fullstack-langgraph-quickstart) í”„ë¡œì íŠ¸ëŠ” Gemini 2.5 ëª¨ë¸ê³¼ LangGraphë¥¼ í™œìš©í•˜ì—¬ ê³ ë„í™”ëœ AI ì—°êµ¬ ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•˜ëŠ” ì™„ì „í•œ í’€ìŠ¤íƒ ì†”ë£¨ì…˜ì…ë‹ˆë‹¤. 11.6k ìŠ¤íƒ€ë¥¼ ë°›ìœ¼ë©° í° ê´€ì‹¬ì„ ë°›ê³  ìˆëŠ” ì´ í”„ë¡œì íŠ¸ëŠ” ë‹¨ìˆœí•œ ì§ˆì˜ì‘ë‹µì„ ë„˜ì–´ ë°˜ë³µì  ê²€ìƒ‰ê³¼ ì§€ì‹ ê²©ì°¨ ë¶„ì„ì„ í†µí•´ ì¢…í•©ì ì¸ ì—°êµ¬ ê²°ê³¼ë¥¼ ì œê³µí•˜ëŠ” í˜ì‹ ì ì¸ ì ‘ê·¼ë²•ì„ ì œì‹œí•©ë‹ˆë‹¤.

## í”„ë¡œì íŠ¸ ê°œìš”

### í•µì‹¬ ëª©ì 

ì´ í”„ë¡œì íŠ¸ì˜ **í•µì‹¬ ëª©ì **ì€ ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆë¬¸ì„ ì…ë ¥ë°›ì•„, Gemini ëª¨ë¸ì´ ìŠ¤ìŠ¤ë¡œ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ê³  Google Search APIë¡œ ìë£Œë¥¼ ìˆ˜ì§‘Â·ê²€ì¦Â·ì •ë¦¬í•˜ì—¬ ì¸ìš©ì´ ë¶™ì€ ìµœì¢… ë‹µë³€ì„ ë°˜í™˜í•˜ëŠ” "í’€ìŠ¤íƒ ì—°êµ¬ ì—ì´ì „íŠ¸" ì˜ˆì‹œë¥¼ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

### ì£¼ìš” íŠ¹ì§•

- ğŸ’¬ **React(Vite) + Tailwind + shadcn/ui**ë¡œ ì‘ì„±ëœ SPA í”„ë¡ íŠ¸ì—”ë“œ
- ğŸ§  **LangGraph ìƒíƒœ ë¨¸ì‹ í˜• ì—ì´ì „íŠ¸** - ê° ë…¸ë“œê°€ ì§ˆë¬¸ ìƒì„±, ì›¹ ê²€ìƒ‰, ì§€ì‹ ê°­ ë¶„ì„, ë°˜ë³µ ì—¬ë¶€ ê²°ì •, ì‘ë‹µ í•©ì„± ê¸°ëŠ¥ì„ ë‹´ë‹¹
- ğŸ” **Google Gemini 2.5 ëª¨ë¸**ì„ í™œìš©í•œ ë™ì  ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
- ğŸŒ **Google Search API** í†µí•©ì„ í†µí•œ ì‹¤ì‹œê°„ ì›¹ ì—°êµ¬
- ğŸ¤” **ë°˜ì‚¬ì  ì¶”ë¡ (Reflective Reasoning)**ìœ¼ë¡œ ì§€ì‹ ê²©ì°¨ ì‹ë³„ ë° ê²€ìƒ‰ ê°œì„ 
- ğŸ“„ **ì¸ìš© í¬í•¨ ë‹µë³€ ìƒì„±**ìœ¼ë¡œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ ì œê³µ
- ğŸ”„ **ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°** - ì„œë²„-ì„¼íŠ¸ ì´ë²¤íŠ¸(SSE) ë° ì‹¤ì‹œê°„ UI ì—…ë°ì´íŠ¸ ì§€ì›
- ğŸ³ **Docker + docker-compose**ë¡œ ì†ì‰¬ìš´ ë°°í¬, Redis(pub-sub)Â·PostgreSQL(ìƒíƒœÂ·ë©”ëª¨ë¦¬ ì˜ì†) ì˜ì¡´

### ì•„í‚¤í…ì²˜ êµ¬ì„±

```text
Frontend (React + Vite)
    â†“ HTTP API
Backend (LangGraph + FastAPI)
    â†“ LLM Calls
Google Gemini 2.5
    â†“ Web Search
Google Search API
    â†“ Data Storage
Redis + PostgreSQL
```

## í”„ë¡œì íŠ¸ êµ¬ì¡° ë° ë¹Œë“œ í”Œë¡œ

### í´ë” êµ¬ì¡° ê°œìš”

| ë””ë ‰í„°ë¦¬ | ì£¼ìš” ë‚´ìš© | ë¹„ê³  |
|---------|----------|------|
| **frontend/** | `src/App.tsx`ì— API ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •, shadcn UI ì»´í¬ë„ŒíŠ¸ë¡œ ì±„íŒ… ì°½ êµ¬ì„± | Vite dev ì„œë²„(`npm run dev`) |
| **backend/** | `src/agent/graph.py` : LangGraph ì›Œí¬í”Œë¡œ ì •ì˜<br>`src/api/main.py` : FastAPI(or LangGraph dev ì„œë²„) ì—”ë“œí¬ì¸íŠ¸ | `langgraph dev` ì‹¤í–‰ ì‹œ ì‹œê°ì  ìŠ¤íŠœë””ì˜¤ ìë™ ì˜¤í”ˆ |
| ë£¨íŠ¸ | Dockerfile, docker-compose.yml, Makefile(`make dev`ë¡œ í”„ëŸ°íŠ¸Â·ë°± ë™ì‹œ ê¸°ë™) | ENV: `GEMINI_API_KEY`, `LANGSMITH_API_KEY` |

### ë¡œì»¬ ì‹¤í–‰ ì ˆì°¨

```bash
# 1. ì‚¬ì „ ìš”êµ¬ì‚¬í•­: Python 3.8+, Node.js ì„¤ì¹˜
python --version  # 3.8+
node --version    # v18+

# 2. API í‚¤ ì„¤ì •
cd backend
cp .env.example .env
# .env íŒŒì¼ì— GEMINI_API_KEY="your_actual_gemini_api_key" ì¶”ê°€

# 3. ê°œë°œ ì„œë²„ ì‹¤í–‰
cd ..
make dev

# 4. ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:5173/app ì ‘ì†í•˜ì—¬ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° í™•ì¸
```

## ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° ì‹¬í™” ë¶„ì„

í”„ë¡œì íŠ¸ì˜ í•µì‹¬ì€ `backend/src/agent/graph.py`ì— ì •ì˜ëœ LangGraph ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ì´ ì—ì´ì „íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì •êµí•œ ì—°êµ¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤:

### LangGraph ì›Œí¬í”Œë¡œ ë‹¤ì´ì–´ê·¸ë¨

```text
â”Œâ”€> GenerateQueries â”€â”
â”‚                    â”‚ (ë°˜ë³µ ìµœëŒ€ NíšŒ)
â”‚   WebSearch        â”‚
â”‚        â”‚           â”‚
â”‚   Reflect & Gap? â”€â”€â”˜â€” ì˜ˆ/ì•„ë‹ˆì˜¤ ë¶„ê¸°
â”‚
â””â”€> SynthesizeAnswer (citations)
```

> **LangGraph ì„ íƒ ì´ìœ **: ì—ì´ì „íŠ¸ì˜ ê° ë‹¨ê³„ë¥¼ *ê·¸ë˜í”„ ë…¸ë“œ*ë¡œ ëª…ì‹œí•´ íë¦„Â·ìƒíƒœÂ·ë°˜ë³µ ì¡°ê±´ì„ íˆ¬ëª…í•˜ê²Œ ê´€ë¦¬í•  ìˆ˜ ìˆê³ , LangSmith + LangGraph Studioë¡œ ë””ë²„ê¹…Â·ëª¨ë‹ˆí„°ë§ì´ ìš©ì´í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

### 1. ì´ˆê¸° ì¿¼ë¦¬ ìƒì„± (Generate Initial Queries)

```python
# ì˜ì‚¬ ì½”ë“œ ì˜ˆì‹œ
def generate_initial_queries(user_input: str) -> List[str]:
    """
    ì‚¬ìš©ì ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ê°ì  ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
    """
    prompt = f"""
    ì‚¬ìš©ì ì§ˆë¬¸: {user_input}
    
    ì´ ì§ˆë¬¸ì— ëŒ€í•œ í¬ê´„ì ì¸ ë‹µë³€ì„ ìœ„í•´ í•„ìš”í•œ 
    ë‹¤ì–‘í•œ ê´€ì ì˜ ê²€ìƒ‰ ì¿¼ë¦¬ 3-5ê°œë¥¼ ìƒì„±í•˜ì„¸ìš”.
    """
    
    response = gemini_model.generate(prompt)
    return parse_queries(response)
```

### 2. ì›¹ ì—°êµ¬ ë‹¨ê³„ (Web Research)

ê° ìƒì„±ëœ ì¿¼ë¦¬ì— ëŒ€í•´ Google Search APIë¥¼ í†µí•œ ì‹¤ì‹œê°„ ì •ë³´ ìˆ˜ì§‘:

```python
def web_research(queries: List[str]) -> Dict[str, List[SearchResult]]:
    """
    ê° ì¿¼ë¦¬ë³„ë¡œ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ ë° ê²°ê³¼ ìˆ˜ì§‘
    """
    results = {}
    
    for query in queries:
        search_results = google_search_api.search(
            query=query,
            num_results=10,
            include_snippets=True
        )
        
        results[query] = search_results
    
    return results
```

### 3. ë°˜ì‚¬ì  ë¶„ì„ (Reflection & Knowledge Gap Analysis)

ìˆ˜ì§‘ëœ ì •ë³´ì˜ ì¶©ë¶„ì„±ì„ í‰ê°€í•˜ê³  ì§€ì‹ ê²©ì°¨ë¥¼ ì‹ë³„:

```python
def analyze_knowledge_gaps(
    original_question: str, 
    search_results: Dict
) -> KnowledgeAnalysis:
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì§€ì‹ ê²©ì°¨ ì‹ë³„
    """
    
    analysis_prompt = f"""
    ì›ë³¸ ì§ˆë¬¸: {original_question}
    ìˆ˜ì§‘ëœ ì •ë³´: {format_search_results(search_results)}
    
    ë‹¤ìŒì„ ë¶„ì„í•˜ì„¸ìš”:
    1. ì§ˆë¬¸ì— ëŒ€í•œ ì™„ì „í•œ ë‹µë³€ì´ ê°€ëŠ¥í•œê°€?
    2. ë¶€ì¡±í•œ ì •ë³´ë‚˜ ì§€ì‹ ê²©ì°¨ëŠ” ë¬´ì—‡ì¸ê°€?
    3. ì¶”ê°€ ê²€ìƒ‰ì´ í•„ìš”í•œ íŠ¹ì • ì˜ì—­ì€?
    """
    
    return gemini_model.analyze(analysis_prompt)
```

### 4. ë°˜ë³µì  ê°œì„  (Iterative Refinement)

ì§€ì‹ ê²©ì°¨ê°€ ë°œê²¬ë˜ë©´ ì¶”ê°€ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì—¬ ì—°êµ¬ë¥¼ ì‹¬í™”í•©ë‹ˆë‹¤. **ë¶€ì¡± ì‹œ ìƒˆ ê²€ìƒ‰ì–´ ìƒì„± í›„ ë£¨í”„ë¥¼ ë°˜ë³µí•˜ë©°, ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜(default 3) ì´ˆê³¼ ì‹œ ê°•ì œ ì¢…ë£Œ**ë©ë‹ˆë‹¤:

```python
def iterative_research_loop(max_iterations: int = 3):
    """
    ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ê¹Œì§€ ì—°êµ¬ë¥¼ ì§€ì†ì ìœ¼ë¡œ ê°œì„ 
    """
    
    for iteration in range(max_iterations):
        gaps = analyze_knowledge_gaps(question, current_results)
        
        if gaps.is_sufficient:
            break
            
        followup_queries = generate_followup_queries(gaps)
        additional_results = web_research(followup_queries)
        current_results.update(additional_results)
    
    return current_results
```

### 5. ìµœì¢… ë‹µë³€ í•©ì„± (Finalize Answer)

ëª¨ë“  ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì¸ìš©ê³¼ í•¨ê»˜ ì¼ê´€ëœ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. **ìµœì¢… ê·¼ê±°ê°€ ë˜ëŠ” ë¬¸ë‹¨ì„ ì¸ìš© í˜•íƒœë¡œ ë¬¶ì–´ ë‹µë³€ ë³¸ë¬¸ì„ ìƒì„±**í•©ë‹ˆë‹¤:

```python
def synthesize_final_answer(
    question: str, 
    all_results: Dict
) -> StructuredAnswer:
    """
    ì—°êµ¬ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ì¸ìš© í¬í•¨ ìµœì¢… ë‹µë³€ ìƒì„±
    """
    
    synthesis_prompt = f"""
    ì§ˆë¬¸: {question}
    ì—°êµ¬ ìë£Œ: {format_all_results(all_results)}
    
    ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¢…í•©ì ì¸ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”:
    1. í•µì‹¬ ë‹µë³€ (2-3 ë¬¸ë‹¨)
    2. ìƒì„¸ ì„¤ëª…
    3. ì¸ìš© ì¶œì²˜ ëª©ë¡ (URLê³¼ ê´€ë ¨ ë¬¸ë‹¨)
    4. ì¶”ê°€ ê³ ë ¤ì‚¬í•­
    
    ê° ì£¼ì¥ì— ëŒ€í•´ [1], [2] í˜•ì‹ìœ¼ë¡œ ì¸ìš© ë²ˆí˜¸ë¥¼ í‘œì‹œí•˜ì„¸ìš”.
    """
    
    return gemini_model.synthesize(synthesis_prompt)
```

## ì¸í”„ë¼ ë° ë°°í¬ ì „ëµ

### ê°œë°œ í™˜ê²½ vs í”„ë¡œë•ì…˜ í™˜ê²½

| í™˜ê²½ | êµ¬ì„± | íŠ¹ì§• |
|-----|------|------|
| **ê°œë°œìš©** | LangGraph dev ì„œë²„(í¬íŠ¸ 2024) + Vite dev ì„œë²„(5173) | FastAPI + SSE ì œê³µ, í•«ë¦¬ë¡œë“œ ì§€ì› |
| **í”„ë¡œë•ì…˜** | Dockerfileì—ì„œ í”„ë¡ íŠ¸ì—”ë“œ ë¹Œë“œ í›„ ë°±ì—”ë“œì—ì„œ ì •ì  íŒŒì¼ ì„œë¹™ | docker-composeë¡œ RedisÂ·Postgres í•¨ê»˜ ê¸°ë™ |

### ê°œë°œ í™˜ê²½ êµ¬ì„±

**1. ì‚¬ì „ ìš”êµ¬ì‚¬í•­**

```bash
# Node.js ë° Python í™˜ê²½ í™•ì¸
node --version  # v18+
python --version  # 3.8+
```

**2. API í‚¤ ì„¤ì •**

```bash
# backend/.env íŒŒì¼ ìƒì„±
cd backend
cp .env.example .env

# .env íŒŒì¼ì— ë‹¤ìŒ ì¶”ê°€
GEMINI_API_KEY="your_actual_gemini_api_key"
GOOGLE_SEARCH_API_KEY="your_google_search_api_key"  # ì„ íƒì‚¬í•­
```

**3. ì˜ì¡´ì„± ì„¤ì¹˜ ë° ì‹¤í–‰**

```bash
# ë°±ì—”ë“œ ì„¤ì •
cd backend
pip install .

# í”„ë¡ íŠ¸ì—”ë“œ ì„¤ì •  
cd ../frontend
npm install

# ê°œë°œ ì„œë²„ ì‹¤í–‰ (ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ)
make dev
```

### í”„ë¡œë•ì…˜ ë°°í¬

í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” Redisì™€ PostgreSQLì´ í•„ìš”í•©ë‹ˆë‹¤:

```yaml
# docker-compose.yml ì˜ˆì‹œ
version: '3.8'
services:
  app:
    build: .
    ports:
      - "8123:8000"
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - LANGSMITH_API_KEY=${LANGSMITH_API_KEY}
    depends_on:
      - redis
      - postgres
      
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
      
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=langgraph
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
    ports:
      - "5432:5432"
```

```bash
# Docker ë¹Œë“œ ë° ì‹¤í–‰
docker build -t gemini-fullstack-langgraph -f Dockerfile .

GEMINI_API_KEY=<your_key> LANGSMITH_API_KEY=<your_key> docker-compose up
```

### í™•ì¥ì„± ê³ ë ¤ì‚¬í•­

- **ìˆ˜í‰ í™•ì¥**: LangGraph ìì²´ëŠ” ìˆ˜í‰ í™•ì¥ ê°€ëŠ¥í•˜ì§€ë§Œ Redis pub-sub ì±„ë„ ëª… ì¶©ëŒì— ì£¼ì˜
- **ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”**: Postgres ì»¤ë„¥ì…˜ í’€ì„ `pool_size=20` ìˆ˜ì¤€ìœ¼ë¡œ ì¡°ì •(ëŒ€ëŸ‰ ë™ì‹œ ì‚¬ìš©ì ëŒ€ë¹„)
- **ìºì‹± ì „ëµ**: Google Search API í˜¸ì¶œ ë¹„ìš© ì ˆê°ì„ ìœ„í•œ Redis TTL ìºì‹œ êµ¬í˜„ ê¶Œì¥

## ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ì´ë“œ

### ì£¼ìš” ì»¤ìŠ¤í„°ë§ˆì´ì§• í¬ì¸íŠ¸

| ìš”êµ¬ì‚¬í•­ | ì ìš© ìœ„ì¹˜ | ì°¸ê³  |
|---------|----------|------|
| ë‹¤ë¥¸ LLM ì‚¬ìš©(OpenAI, Claude ë“±) | `graph.py`ì—ì„œ `GeminiChat` â†’ `ChatOpenAI` êµì²´ | ê¸°ì¡´ ë©€í‹°-í”„ë¡œë°”ì´ë” í¬í¬ ì˜ˆì‹œ (nodew fork) |
| ê²€ìƒ‰ API êµì²´(Bing, Brave) | `tools/web_search.py` ëª¨ë“ˆ ì¶”ê°€ | SerpAPI, ScrapingBee ë“± ëŒ€ì•ˆ |
| ì¥ê¸° ë©”ëª¨ë¦¬(ë²¡í„°ì €ì¥ì†Œ) | LangGraph `memory` node ë˜ëŠ” Postgres + pgvector | Chroma, Pinecone í†µí•© |
| ì¸ì¦/ì‚¬ìš©ì ê´€ë¦¬ | FastAPI ë¼ìš°í„° í™•ì¥ í›„ JWT ì ìš© | NextAuth.js, Auth0 ì—°ë™ |

### LLM êµì²´ ì˜ˆì‹œ

```python
# Geminiì—ì„œ OpenAIë¡œ êµì²´
from langchain_openai import ChatOpenAI

# ê¸°ì¡´ ì½”ë“œ
# llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash")

# ìƒˆë¡œìš´ ì½”ë“œ
llm = ChatOpenAI(
    model="gpt-4o", 
    api_key=os.getenv("OPENAI_API_KEY"),
    temperature=0.1
)
```

### ê²€ìƒ‰ API í™•ì¥

```python
# tools/web_search.pyì— ì¶”ê°€
class MultiSearchTool:
    def __init__(self):
        self.google_search = GoogleSearchAPIWrapper()
        self.bing_search = BingSearchAPIWrapper()
        self.brave_search = BraveSearchWrapper()
    
    async def search_all(self, query: str) -> Dict[str, List[SearchResult]]:
        """ì—¬ëŸ¬ ê²€ìƒ‰ ì—”ì§„ ê²°ê³¼ë¥¼ ë³‘ë ¬ë¡œ ìˆ˜ì§‘"""
        tasks = [
            self.google_search.run(query),
            self.bing_search.run(query),
            self.brave_search.run(query)
        ]
        
        results = await asyncio.gather(*tasks)
        return {
            "google": results[0],
            "bing": results[1], 
            "brave": results[2]
        }
```

## í•œê³„ ë° ê°œì„  ë°©í–¥

### í˜„ì¬ í•œê³„ì 

- **ë¹„ìš© ìµœì í™”**: Google Search API í˜¸ì¶œì´ ë£¨í”„ë§ˆë‹¤ ë°œìƒí•˜ì—¬ ë¹„ìš© ì¦ê°€
- **ë°˜ë³µ ì œí•œ**: ìµœëŒ€ 3íšŒ ë°˜ë³µìœ¼ë¡œ ë³µì¡í•œ ë¶„ì„ ë¬¸ì œì—ëŠ” ë¶€ì¡±í•  ìˆ˜ ìˆìŒ
- **ì¸ìš© ì •í™•ë„**: í˜„ì¬ëŠ” URL ë ˆë²¨ ë©”íƒ€ë°ì´í„°ë§Œ í‘œì‹œ
- **ë‹¨ì¼ ëª¨ë‹¬**: í…ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ìƒ‰ì— êµ­í•œ

### ê°œì„  ì•„ì´ë””ì–´

#### 1. ë¹„ìš© ìµœì í™”

```python
# Redis ìºì‹± ì „ëµ
@cache_search_results(expiry_hours=24)
async def cached_web_search(query: str):
    """ê²€ìƒ‰ ê²°ê³¼ ìºì‹±ìœ¼ë¡œ API í˜¸ì¶œ ìµœì í™”"""
    return await google_search_api.search(query)

# SerpAPI free tier í™œìš©
class HybridSearchStrategy:
    def __init__(self):
        self.free_quota = 100  # ì¼ì¼ ë¬´ë£Œ í• ë‹¹ëŸ‰
        self.paid_api = GoogleSearchAPI()
        self.free_api = SerpAPI()
    
    async def search(self, query: str):
        if self.free_quota > 0:
            self.free_quota -= 1
            return await self.free_api.search(query)
        else:
            return await self.paid_api.search(query)
```

#### 2. ì¸ìš© ì •í™•ë„ ê°œì„ 

```python
# HTML íŒŒì‹± í›„ ë¬¸ì¥ ë‹¨ìœ„ í•˜ì´ë¼ì´íŠ¸
class EnhancedCitationTool:
    def extract_relevant_passages(self, url: str, query: str) -> List[str]:
        """ì›¹í˜ì´ì§€ì—ì„œ ê´€ë ¨ ë¬¸ë‹¨ ì¶”ì¶œ"""
        html_content = self.fetch_html(url)
        passages = self.parse_paragraphs(html_content)
        
        # ì˜ë¯¸ì  ìœ ì‚¬ë„ ê¸°ë°˜ ë¬¸ë‹¨ ì„ ë³„
        relevant_passages = self.semantic_filter(passages, query)
        return relevant_passages
    
    def generate_precise_citation(self, passage: str, url: str) -> str:
        """ì •í™•í•œ ì¸ìš© í˜•ì‹ ìƒì„±"""
        return f'"{passage}" - {url}'
```

#### 3. ë©€í‹°ëª¨ë‹¬ í™•ì¥

```python
# Gemini 2.5 Vision í™œìš©
class MultimodalResearchAgent(BaseAgent):
    def analyze_visual_content(self, image_urls: List[str]) -> Dict:
        """Gemini Visionì„ í™œìš©í•œ ì´ë¯¸ì§€ ë¶„ì„"""
        visual_insights = {}
        
        for url in image_urls:
            analysis = self.vision_model.analyze_image(
                image_url=url,
                prompt="ì´ ì´ë¯¸ì§€ì—ì„œ ì—°êµ¬ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”."
            )
            visual_insights[url] = analysis
            
        return visual_insights
```

## ê²½ìŸ í”„ë¡œì íŠ¸ ë¹„êµ

### ì£¼ìš” ëŒ€ì•ˆ ì†”ë£¨ì…˜ ë¹„êµ

| í•­ëª© | Gemini Fullstack LG | LangGraph Agent Toolkit | LangChain ê¸°ë³¸ AgentExecutor |
|------|-------------------|----------------------|---------------------------|
| LLM | Gemini 2.5 (ê¸°ë³¸) | ë‹¤ì¤‘(ì˜µì…˜) | ë‹¤ì¤‘ |
| íë¦„ ì •ì˜ | ê·¸ë˜í”„í˜•(LangGraph) | ê·¸ë˜í”„í˜• | ìŠ¤íƒí˜•(step loop) |
| í”„ë¡ íŠ¸ì—”ë“œ | React(Vite) í¬í•¨ | ì—†ìŒ(ë°±ì—”ë“œ ì¤‘ì‹¬) | ì—†ìŒ |
| ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼ | Redis pub-sub â†’ SSE | WebSocket/Redis | ì—†ìŒ ê¸°ë³¸ |
| ë°°í¬ ì˜ˆì‹œ | Docker-compose, Redis, PG | FastAPI/Streamlit ì˜ˆì‹œ | ë³„ë„ ì œê³µ X |
| ì‹œê°ì  ë””ë²„ê¹… | LangGraph Studio | LangGraph Studio | ì—†ìŒ |
| í•™ìŠµ ê³¡ì„  | ì¤‘ê°„ | ë†’ìŒ | ë‚®ìŒ |

### ì„ íƒ ê¸°ì¤€

- **í’€ìŠ¤íƒ ê°œë°œ**: Gemini Fullstack LG ì„ íƒ
- **ìµœëŒ€ ìœ ì—°ì„±**: LangGraph Agent Toolkit ì„ íƒ  
- **ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘**: LangChain ê¸°ë³¸ AgentExecutor ì„ íƒ

## ê³ ê¸‰ í™œìš© ì‚¬ë¡€

### 1. ë„ë©”ì¸ íŠ¹í™” ì—°êµ¬ ì—ì´ì „íŠ¸

```python
class DomainSpecificAgent(BaseAgent):
    """
    íŠ¹ì • ë„ë©”ì¸(ì˜ë£Œ, ë²•ë¥ , ê¸°ìˆ  ë“±)ì— íŠ¹í™”ëœ ì—°êµ¬ ì—ì´ì „íŠ¸
    """
    
    def __init__(self, domain: str):
        self.domain = domain
        self.specialized_sources = get_domain_sources(domain)
        super().__init__()
    
    def generate_domain_queries(self, question: str) -> List[str]:
        """ë„ë©”ì¸ íŠ¹í™” ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
        domain_context = f"In the context of {self.domain}:"
        return super().generate_queries(domain_context + question)
    
    def validate_sources(self, sources: List[str]) -> List[str]:
        """ë„ë©”ì¸ ê´€ë ¨ì„± ê¸°ì¤€ìœ¼ë¡œ ì†ŒìŠ¤ í•„í„°ë§"""
        return [s for s in sources if self.is_domain_relevant(s)]
```

### 2. ë©€í‹°ëª¨ë‹¬ ì—°êµ¬ í™•ì¥

```python
class MultimodalResearchAgent(BaseAgent):
    """
    í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ë™ì˜ìƒ ë“± ë‹¤ì–‘í•œ ë¯¸ë””ì–´ë¥¼ í™œìš©í•œ ì—°êµ¬
    """
    
    def analyze_visual_content(self, image_urls: List[str]) -> Dict:
        """Gemini Visionì„ í™œìš©í•œ ì´ë¯¸ì§€ ë¶„ì„"""
        visual_insights = {}
        
        for url in image_urls:
            analysis = gemini_vision.analyze_image(
                image_url=url,
                prompt="ì´ ì´ë¯¸ì§€ì—ì„œ ì—°êµ¬ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”."
            )
            visual_insights[url] = analysis
            
        return visual_insights
    
    def synthesize_multimodal_answer(self, text_data: Dict, visual_data: Dict):
        """í…ìŠ¤íŠ¸ì™€ ì‹œê°ì  ì •ë³´ë¥¼ ì¢…í•©í•œ ë‹µë³€ ìƒì„±"""
        pass
```

### 3. ì‹¤ì‹œê°„ í˜‘ì—… ì—°êµ¬

```python
class CollaborativeResearchAgent:
    """
    ì—¬ëŸ¬ ì‚¬ìš©ìê°€ ë™ì‹œì— ì—°êµ¬ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆëŠ” í˜‘ì—… ì—ì´ì „íŠ¸
    """
    
    def __init__(self):
        self.shared_knowledge_base = SharedKnowledgeBase()
        self.collaboration_handler = CollaborationHandler()
    
    async def collaborative_search(
        self, 
        user_id: str, 
        question: str, 
        session_id: str
    ):
        """ë‹¤ì¤‘ ì‚¬ìš©ì í˜‘ì—… ê²€ìƒ‰"""
        
        # ê¸°ì¡´ ì„¸ì…˜ ì •ë³´ í™œìš©
        existing_research = await self.get_session_research(session_id)
        
        # ìƒˆë¡œìš´ ê´€ì  ì¶”ê°€
        new_queries = self.generate_complementary_queries(
            question, existing_research
        )
        
        # ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
        await self.broadcast_updates(session_id, new_queries)
```

## ì„±ëŠ¥ ìµœì í™” ë° ëª¨ë‹ˆí„°ë§

### LangSmith í†µí•©

```python
from langsmith import Client

langsmith_client = Client()

def trace_agent_execution(func):
    """ì—ì´ì „íŠ¸ ì‹¤í–‰ ê³¼ì •ì„ LangSmithë¡œ ì¶”ì """
    
    @wraps(func)
    async def wrapper(*args, **kwargs):
        with langsmith_client.trace(
            name=func.__name__,
            inputs={"args": args, "kwargs": kwargs}
        ) as trace:
            result = await func(*args, **kwargs)
            trace.outputs = {"result": result}
            return result
    
    return wrapper

@trace_agent_execution
async def research_workflow(question: str):
    """ì „ì²´ ì—°êµ¬ ì›Œí¬í”Œë¡œìš° ì¶”ì """
    pass
```

### ìºì‹± ì „ëµ

```python
import redis
from functools import wraps

redis_client = redis.Redis(host='localhost', port=6379, db=0)

def cache_search_results(expiry_hours: int = 24):
    """ê²€ìƒ‰ ê²°ê³¼ ìºì‹±ìœ¼ë¡œ API í˜¸ì¶œ ìµœì í™”"""
    
    def decorator(func):
        @wraps(func)
        async def wrapper(query: str, *args, **kwargs):
            cache_key = f"search:{hash(query)}"
            
            # ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
            cached_result = redis_client.get(cache_key)
            if cached_result:
                return json.loads(cached_result)
            
            # ìºì‹œ ë¯¸ìŠ¤ ì‹œ ì‹¤ì œ ê²€ìƒ‰ ìˆ˜í–‰
            result = await func(query, *args, **kwargs)
            
            # ê²°ê³¼ ìºì‹±
            redis_client.setex(
                cache_key, 
                expiry_hours * 3600, 
                json.dumps(result)
            )
            
            return result
        return wrapper
    return decorator
```

## ê¸°ìˆ  ìŠ¤íƒ ìƒì„¸ ë¶„ì„

### í”„ë¡ íŠ¸ì—”ë“œ

- **React 18 + Vite**: ìµœì‹  ê°œë°œ ë„êµ¬ì²´ì¸ìœ¼ë¡œ ë¹ ë¥¸ ê°œë°œ ê²½í—˜
- **Tailwind CSS**: ìœ í‹¸ë¦¬í‹° ìš°ì„  CSS í”„ë ˆì„ì›Œí¬
- **Shadcn UI**: ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ê³ í’ˆì§ˆ ì»´í¬ë„ŒíŠ¸
- **TypeScript**: íƒ€ì… ì•ˆì „ì„± ë³´ì¥

### ë°±ì—”ë“œ

- **LangGraph**: ë³µì¡í•œ ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬
- **FastAPI**: ê³ ì„±ëŠ¥ ë¹„ë™ê¸° ì›¹ í”„ë ˆì„ì›Œí¬
- **Google Gemini 2.5**: ìµœì‹  ë©€í‹°ëª¨ë‹¬ LLM
- **Redis**: ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ë° ìºì‹±
- **PostgreSQL**: ì—ì´ì „íŠ¸ ìƒíƒœ ë° ëŒ€í™” ê¸°ë¡ ì €ì¥

## ì‹¤ì „ í™œìš© ì‹œë‚˜ë¦¬ì˜¤

### 1. í•™ìˆ  ì—°êµ¬ ì§€ì›

```python
academic_agent = AcademicResearchAgent(
    domains=["computer_science", "artificial_intelligence"],
    paper_sources=["arxiv", "acm", "ieee"],
    citation_style="APA"
)

result = await academic_agent.research(
    "Transformer ì•„í‚¤í…ì²˜ì˜ ìµœì‹  ë°œì „ê³¼ í•œê³„ì ì€?"
)
```

### 2. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤

```python
business_agent = BusinessIntelligenceAgent(
    market_sources=["bloomberg", "reuters", "sec_filings"],
    analysis_depth="comprehensive"
)

market_analysis = await business_agent.research(
    "2025ë…„ AI ì¹©ì…‹ ì‹œì¥ ì „ë§ê³¼ ì£¼ìš” í”Œë ˆì´ì–´ ë¶„ì„"
)
```

### 3. ê¸°ìˆ  ë¬¸ì„œí™”

```python
tech_doc_agent = TechnicalDocumentationAgent(
    code_repositories=["github", "gitlab"],
    documentation_sources=["stackoverflow", "official_docs"]
)

documentation = await tech_doc_agent.research(
    "React Server Components êµ¬í˜„ ëª¨ë²” ì‚¬ë¡€"
)
```

## ê²°ë¡  ë° í–¥í›„ ì „ë§

[Google Gemini Fullstack LangGraph Quickstart](https://github.com/google-gemini/gemini-fullstack-langgraph-quickstart)ëŠ” **"ê²€ìƒ‰ Â· ë°˜ì„± Â· ì‘ë‹µ í•©ì„±"** ê³¼ì •ì„ LangGraphë¡œ ëª¨ë¸ë§í•´, ì—°êµ¬í˜• ì—ì´ì „íŠ¸ë¥¼ í’€ìŠ¤íƒìœ¼ë¡œ êµ¬í˜„í•˜ë ¤ëŠ” ê°œë°œìì—ê²Œ í›Œë¥­í•œ í…œí”Œë¦¿ì„ ì œê³µí•©ë‹ˆë‹¤. 

### í•µì‹¬ ê°€ì¹˜

- **ì™„ì „í•œ í’€ìŠ¤íƒ ì†”ë£¨ì…˜**: React UIÂ·Graph ë°±ì—”ë“œÂ·ì¸í”„ë¼ ë°°í¬ê¹Œì§€ í•œ ë²ˆì— ì œê³µ
- **ì‹¤ì „ ê¸°ëŠ¥ í™•ì¥ ê¸°ë°˜**: ê²€ìƒ‰ ë„êµ¬ ì¶”ê°€, LLM êµì²´, ì¥ê¸° ë©”ëª¨ë¦¬ í™•ì¥ ë“±ì˜ ì‹¤í—˜ì— ìµœì 
- **ì‹œê°ì  ë””ë²„ê¹…**: LangGraph Studioë¥¼ í†µí•œ íˆ¬ëª…í•œ ì—ì´ì „íŠ¸ í”Œë¡œìš° ëª¨ë‹ˆí„°ë§
- **í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜**: Redis ìŠ¤íŠ¸ë¦¬ë°ê³¼ PostgreSQL ê¸°ë°˜ì˜ ëŒ€ê·œëª¨ ì‹œìŠ¤í…œ ëŒ€ì‘

### í”„ë¡œì íŠ¸ì˜ ì˜ì˜

ë°˜ë³µì  ê²€ìƒ‰ê³¼ ì§€ì‹ ê²©ì°¨ ë¶„ì„ì„ í†µí•œ ê³ ë„í™”ëœ ì—°êµ¬ í”„ë¡œì„¸ìŠ¤ëŠ” ê¸°ì¡´ RAG ì‹œìŠ¤í…œì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ , ë³´ë‹¤ ì‹ ë¢°í•  ìˆ˜ ìˆê³  í¬ê´„ì ì¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ êµ¬ì¶•ì˜ ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. íŠ¹íˆ **ì¸ìš© ê¸°ë°˜ ë‹µë³€ ìƒì„±**ê³¼ **ë°˜ì‚¬ì  ì¶”ë¡ **ì€ ì •ë³´ì˜ ì‹ ë¢°ì„±ê³¼ íˆ¬ëª…ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

### í™œìš© ê¶Œì¥ ì‚¬í•­

| ì‚¬ìš© ì‚¬ë¡€ | ì¶”ì²œ ì •ë„ | ë¹„ê³  |
|---------|---------|------|
| ì—°êµ¬ ì—ì´ì „íŠ¸ í”„ë¡œí† íƒ€ì… | â­â­â­â­â­ | ì™„ë²½í•œ ì¶œë°œì  |
| êµìœ¡ìš© LangGraph í•™ìŠµ | â­â­â­â­â­ | ì‹œê°ì  ë””ë²„ê¹… í¬í•¨ |
| í”„ë¡œë•ì…˜ ê¸°ë°˜ í™•ì¥ | â­â­â­â­ | ì»¤ìŠ¤í„°ë§ˆì´ì§• í•„ìš” |
| ì—”í„°í”„ë¼ì´ì¦ˆ ë°°í¬ | â­â­â­ | ë³´ì•ˆÂ·ìŠ¤ì¼€ì¼ë§ ê³ ë ¤ í•„ìš” |

11.6k ìŠ¤íƒ€ì™€ í™œë°œí•œ ì»¤ë®¤ë‹ˆí‹° ì°¸ì—¬ëŠ” ì´ í”„ë¡œì íŠ¸ì˜ ì‹¤ìš©ì„±ê³¼ í™•ì¥ì„±ì„ ì…ì¦í•˜ë©°, Googleì˜ ê³µì‹ ì§€ì›ìœ¼ë¡œ ì§€ì†ì ì¸ ì—…ë°ì´íŠ¸ì™€ ê°œì„ ì´ ê¸°ëŒ€ë©ë‹ˆë‹¤. **ëŒ€ê·œëª¨ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ë ¤ëŠ” íŒ€ì—ê²Œ ì¤‘ìš”í•œ ë ˆí¼ëŸ°ìŠ¤**ê°€ ë  ê²ƒì´ë©°, AI ì—ì´ì „íŠ¸ ê°œë°œì— ê´€ì‹¬ì´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ ì°¸ê³ í•´ì•¼ í•  í•„ìˆ˜ ë¦¬ì†ŒìŠ¤ì…ë‹ˆë‹¤. 