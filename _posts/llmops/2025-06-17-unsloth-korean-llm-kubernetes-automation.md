---
title: "Unsloth+TRL í•œêµ­ì–´ LLM í•™ìŠµ ìë™í™” - 2í¸: ì¿ ë²„ë„¤í‹°ìŠ¤ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•"
excerpt: "ì¿ ë²„ë„¤í‹°ìŠ¤ë¡œ Unsloth+TRL ê¸°ë°˜ í•œêµ­ì–´ LLM í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ ì™„ì „ ìë™í™”í•˜ëŠ” ì‹¤ë¬´ ê°€ì´ë“œ"
date: 2025-06-17
categories:
  - llmops
tags:
  - Kubernetes
  - Unsloth
  - Korean LLM
  - MLOps
  - Automation
  - Pipeline
  - GPU Scheduling
  - Distributed Training
author_profile: true
toc: true
toc_label: "ëª©ì°¨"
---

## ê°œìš”

ë³¸ ê°€ì´ë“œëŠ” [Unsloth+TRL í•œêµ­ì–´ LLM í•™ìŠµ ê°€ì´ë“œ - 1í¸]({% post_url 2025-06-17-unsloth-korean-llm-training-guide %})ì˜ ì—°ì¥ì„ ìœ¼ë¡œ, ì¿ ë²„ë„¤í‹°ìŠ¤ë¥¼ í™œìš©í•˜ì—¬ í•œêµ­ì–´ íŠ¹í™” LLM í•™ìŠµ ê³¼ì •ì„ ì™„ì „ ìë™í™”í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.

**í•™ìŠµ ëª©í‘œ**:

- ğŸš€ **ìë™í™”ëœ í•™ìŠµ íŒŒì´í”„ë¼ì¸**: CPT â†’ SFT â†’ RLHF ìë™ ì‹¤í–‰
- ğŸ¯ **GPU ë¦¬ì†ŒìŠ¤ ìµœì í™”**: ë™ì  ìŠ¤ì¼€ì¤„ë§ ë° íš¨ìœ¨ì  í™œìš©
- ğŸ“Š **ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…**: ì‹¤ì‹œê°„ í•™ìŠµ ìƒíƒœ ì¶”ì 
- âš¡ **í™•ì¥ì„±**: ë‹¤ì¤‘ ëª¨ë¸ ë™ì‹œ í•™ìŠµ ì§€ì›

---

## 1. ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„° ì¤€ë¹„

### 1.1 GPU ë…¸ë“œ êµ¬ì„±

```yaml
# gpu-node-pool.yaml
apiVersion: v1
kind: Node
metadata:
  name: gpu-node-1
  labels:
    node-type: gpu-training
    gpu-type: h100
    gpu-count: "8"
spec:
  capacity:
    nvidia.com/gpu: "8"
    memory: 1000Gi
    cpu: "128"
  allocatable:
    nvidia.com/gpu: "8"
    memory: 900Gi
    cpu: "120"
```

### 1.2 í•„ìˆ˜ ì»´í¬ë„ŒíŠ¸ ì„¤ì¹˜

```bash
# NVIDIA GPU Operator ì„¤ì¹˜
kubectl create namespace gpu-operator
helm repo add nvidia https://helm.ngc.nvidia.com/nvidia
helm install --wait gpu-operator nvidia/gpu-operator \
  --namespace gpu-operator \
  --set driver.enabled=true

# Kubeflow Training Operator ì„¤ì¹˜
kubectl apply -k "github.com/kubeflow/training-operator/manifests/overlays/standalone"

# Argo Workflows ì„¤ì¹˜
kubectl create namespace argo
kubectl apply -n argo -f https://github.com/argoproj/argo-workflows/releases/download/v3.5.0/install.yaml
```

### 1.3 ìŠ¤í† ë¦¬ì§€ êµ¬ì„±

```yaml
# nfs-storage.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: llm-training-data
spec:
  capacity:
    storage: 10Ti
  accessModes:
    - ReadWriteMany
  nfs:
    server: nfs-server.example.com
    path: /data/llm-training
  storageClassName: nfs-storage

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: llm-training-data-pvc
  namespace: llm-training
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 10Ti
  storageClassName: nfs-storage
```

---

## 2. ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ì¤€ë¹„

### 2.1 ë² ì´ìŠ¤ ì´ë¯¸ì§€ êµ¬ì„±

```dockerfile
# Dockerfile.unsloth-korean
FROM nvidia/cuda:11.8-devel-ubuntu20.04

# ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    python3 python3-pip git wget curl \
    && rm -rf /var/lib/apt/lists/*

# Python í™˜ê²½ ì„¤ì •
RUN pip3 install --upgrade pip

# Unsloth ë° ì˜ì¡´ì„± ì„¤ì¹˜
RUN pip3 install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"
RUN pip3 install --no-deps xformers trl peft accelerate bitsandbytes
RUN pip3 install datasets transformers tokenizers sentencepiece
RUN pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# í•œêµ­ì–´ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
RUN pip3 install konlpy kss soynlp

# ëª¨ë‹ˆí„°ë§ ë„êµ¬
RUN pip3 install wandb tensorboard prometheus_client

# í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ë³µì‚¬
COPY scripts/ /app/scripts/
COPY configs/ /app/configs/

WORKDIR /app
CMD ["python3", "-u", "scripts/train.py"]
```

### 2.2 ì´ë¯¸ì§€ ë¹Œë“œ ë° í‘¸ì‹œ

```bash
# ì´ë¯¸ì§€ ë¹Œë“œ
docker build -t your-registry/unsloth-korean:latest -f Dockerfile.unsloth-korean .

# ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— í‘¸ì‹œ
docker push your-registry/unsloth-korean:latest
```

---

## 3. í•™ìŠµ íŒŒì´í”„ë¼ì¸ êµ¬ì„±

### 3.1 CPT (ì§€ì†ì  ì‚¬ì „í•™ìŠµ) Job

```yaml
# cpt-job.yaml
apiVersion: kubeflow.org/v1
kind: PyTorchJob
metadata:
  name: korean-llm-cpt
  namespace: llm-training
spec:
  pytorchReplicaSpecs:
    Master:
      replicas: 1
      restartPolicy: OnFailure
      template:
        spec:
          containers:
          - name: pytorch
            image: your-registry/unsloth-korean:latest
            command: ["python3", "-u", "scripts/cpt_train.py"]
            env:
            - name: STAGE
              value: "CPT"
            - name: MODEL_SIZE
              value: "7B"
            - name: WANDB_PROJECT
              value: "korean-llm-cpt"
            resources:
              requests:
                nvidia.com/gpu: 4
                memory: 200Gi
                cpu: 32
              limits:
                nvidia.com/gpu: 4
                memory: 200Gi
                cpu: 32
            volumeMounts:
            - name: training-data
              mountPath: /data
            - name: model-output
              mountPath: /output
          volumes:
          - name: training-data
            persistentVolumeClaim:
              claimName: llm-training-data-pvc
          - name: model-output
            persistentVolumeClaim:
              claimName: model-output-pvc
          nodeSelector:
            node-type: gpu-training
          tolerations:
          - key: nvidia.com/gpu
            operator: Exists
            effect: NoSchedule
```

### 3.2 SFT (ì§€ë„ ë¯¸ì„¸ì¡°ì •) Job

```yaml
# sft-job.yaml
apiVersion: kubeflow.org/v1
kind: PyTorchJob
metadata:
  name: korean-llm-sft
  namespace: llm-training
spec:
  pytorchReplicaSpecs:
    Master:
      replicas: 1
      restartPolicy: OnFailure
      template:
        spec:
          containers:
          - name: pytorch
            image: your-registry/unsloth-korean:latest
            command: ["python3", "-u", "scripts/sft_train.py"]
            env:
            - name: STAGE
              value: "SFT"
            - name: BASE_MODEL_PATH
              value: "/output/cpt_model"
            - name: WANDB_PROJECT
              value: "korean-llm-sft"
            resources:
              requests:
                nvidia.com/gpu: 2
                memory: 100Gi
                cpu: 16
              limits:
                nvidia.com/gpu: 2
                memory: 100Gi
                cpu: 16
            volumeMounts:
            - name: training-data
              mountPath: /data
            - name: model-output
              mountPath: /output
          volumes:
          - name: training-data
            persistentVolumeClaim:
              claimName: llm-training-data-pvc
          - name: model-output
            persistentVolumeClaim:
              claimName: model-output-pvc
          nodeSelector:
            node-type: gpu-training
```

### 3.3 RLHF (ê°•í™”í•™ìŠµ) Job

```yaml
# rlhf-job.yaml
apiVersion: kubeflow.org/v1
kind: PyTorchJob
metadata:
  name: korean-llm-rlhf
  namespace: llm-training
spec:
  pytorchReplicaSpecs:
    Master:
      replicas: 1
      restartPolicy: OnFailure
      template:
        spec:
          containers:
          - name: pytorch
            image: your-registry/unsloth-korean:latest
            command: ["python3", "-u", "scripts/rlhf_train.py"]
            env:
            - name: STAGE
              value: "RLHF"
            - name: BASE_MODEL_PATH
              value: "/output/sft_model"
            - name: WANDB_PROJECT
              value: "korean-llm-rlhf"
            resources:
              requests:
                nvidia.com/gpu: 2
                memory: 100Gi
                cpu: 16
              limits:
                nvidia.com/gpu: 2
                memory: 100Gi
                cpu: 16
            volumeMounts:
            - name: training-data
              mountPath: /data
            - name: model-output
              mountPath: /output
          volumes:
          - name: training-data
            persistentVolumeClaim:
              claimName: llm-training-data-pvc
          - name: model-output
            persistentVolumeClaim:
              claimName: model-output-pvc
          nodeSelector:
            node-type: gpu-training
```

---

## 4. Argo Workflows íŒŒì´í”„ë¼ì¸

### 4.1 ì „ì²´ í•™ìŠµ ì›Œí¬í”Œë¡œìš°

```yaml
# korean-llm-pipeline.yaml
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: korean-llm-training-
  namespace: llm-training
spec:
  entrypoint: korean-llm-pipeline
  
  templates:
  - name: korean-llm-pipeline
    dag:
      tasks:
      - name: data-preprocessing
        template: preprocess-data
      - name: cpt-training
        template: cpt-stage
        dependencies: [data-preprocessing]
      - name: sft-training
        template: sft-stage
        dependencies: [cpt-training]
      - name: rlhf-training
        template: rlhf-stage
        dependencies: [sft-training]
      - name: model-evaluation
        template: evaluate-model
        dependencies: [rlhf-training]
      - name: model-deployment
        template: deploy-model
        dependencies: [model-evaluation]

  - name: preprocess-data
    container:
      image: your-registry/unsloth-korean:latest
      command: ["python3", "-u", "scripts/preprocess.py"]
      volumeMounts:
      - name: training-data
        mountPath: /data
      resources:
        requests:
          memory: 32Gi
          cpu: 8

  - name: cpt-stage
    resource:
      action: create
      successCondition: status.conditions.0.type == Succeeded
      failureCondition: status.conditions.0.type == Failed
      manifest: |
        apiVersion: kubeflow.org/v1
        kind: PyTorchJob
        metadata:
          generateName: cpt-job-
          namespace: llm-training
        spec:
          pytorchReplicaSpecs:
            Master:
              replicas: 1
              restartPolicy: OnFailure
              template:
                spec:
                  containers:
                  - name: pytorch
                    image: your-registry/unsloth-korean:latest
                    command: ["python3", "-u", "scripts/cpt_train.py"]
                    env:
                    - name: STAGE
                      value: "CPT"
                    resources:
                      requests:
                        nvidia.com/gpu: 4
                        memory: 200Gi
                        cpu: 32
                    volumeMounts:
                    - name: training-data
                      mountPath: /data
                    - name: model-output
                      mountPath: /output
                  volumes:
                  - name: training-data
                    persistentVolumeClaim:
                      claimName: llm-training-data-pvc
                  - name: model-output
                    persistentVolumeClaim:
                      claimName: model-output-pvc
                  nodeSelector:
                    node-type: gpu-training

  - name: sft-stage
    resource:
      action: create
      successCondition: status.conditions.0.type == Succeeded
      failureCondition: status.conditions.0.type == Failed
      manifest: |
        apiVersion: kubeflow.org/v1
        kind: PyTorchJob
        metadata:
          generateName: sft-job-
          namespace: llm-training
        spec:
          pytorchReplicaSpecs:
            Master:
              replicas: 1
              restartPolicy: OnFailure
              template:
                spec:
                  containers:
                  - name: pytorch
                    image: your-registry/unsloth-korean:latest
                    command: ["python3", "-u", "scripts/sft_train.py"]
                    env:
                    - name: STAGE
                      value: "SFT"
                    - name: BASE_MODEL_PATH
                      value: "/output/cpt_model"
                    resources:
                      requests:
                        nvidia.com/gpu: 2
                        memory: 100Gi
                        cpu: 16
                    volumeMounts:
                    - name: training-data
                      mountPath: /data
                    - name: model-output
                      mountPath: /output
                  volumes:
                  - name: training-data
                    persistentVolumeClaim:
                      claimName: llm-training-data-pvc
                  - name: model-output
                    persistentVolumeClaim:
                      claimName: model-output-pvc
                  nodeSelector:
                    node-type: gpu-training

  - name: rlhf-stage
    resource:
      action: create
      successCondition: status.conditions.0.type == Succeeded
      failureCondition: status.conditions.0.type == Failed
      manifest: |
        apiVersion: kubeflow.org/v1
        kind: PyTorchJob
        metadata:
          generateName: rlhf-job-
          namespace: llm-training
        spec:
          pytorchReplicaSpecs:
            Master:
              replicas: 1
              restartPolicy: OnFailure
              template:
                spec:
                  containers:
                  - name: pytorch
                    image: your-registry/unsloth-korean:latest
                    command: ["python3", "-u", "scripts/rlhf_train.py"]
                    env:
                    - name: STAGE
                      value: "RLHF"
                    - name: BASE_MODEL_PATH
                      value: "/output/sft_model"
                    resources:
                      requests:
                        nvidia.com/gpu: 2
                        memory: 100Gi
                        cpu: 16
                    volumeMounts:
                    - name: training-data
                      mountPath: /data
                    - name: model-output
                      mountPath: /output
                  volumes:
                  - name: training-data
                    persistentVolumeClaim:
                      claimName: llm-training-data-pvc
                  - name: model-output
                    persistentVolumeClaim:
                      claimName: model-output-pvc
                  nodeSelector:
                    node-type: gpu-training

  - name: evaluate-model
    container:
      image: your-registry/unsloth-korean:latest
      command: ["python3", "-u", "scripts/evaluate.py"]
      env:
      - name: MODEL_PATH
        value: "/output/rlhf_model"
      volumeMounts:
      - name: model-output
        mountPath: /output
      resources:
        requests:
          nvidia.com/gpu: 1
          memory: 50Gi
          cpu: 8

  - name: deploy-model
    container:
      image: your-registry/unsloth-korean:latest
      command: ["python3", "-u", "scripts/deploy.py"]
      env:
      - name: MODEL_PATH
        value: "/output/rlhf_model"
      - name: DEPLOYMENT_TARGET
        value: "production"
      volumeMounts:
      - name: model-output
        mountPath: /output

  volumeClaimTemplates:
  - metadata:
      name: training-data
    spec:
      accessModes: ["ReadWriteMany"]
      resources:
        requests:
          storage: 10Ti
      storageClassName: nfs-storage
  - metadata:
      name: model-output
    spec:
      accessModes: ["ReadWriteMany"]
      resources:
        requests:
          storage: 2Ti
      storageClassName: nfs-storage
```

---

## 5. í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ êµ¬ì„±

### 5.1 CPT í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

```python
# scripts/cpt_train.py
import os
import torch
from unsloth import FastLanguageModel
from datasets import load_dataset
from transformers import TrainingArguments
from trl import SFTTrainer
import wandb

def main():
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    stage = os.getenv("STAGE", "CPT")
    model_size = os.getenv("MODEL_SIZE", "7B")
    
    # Wandb ì´ˆê¸°í™”
    wandb.init(
        project=os.getenv("WANDB_PROJECT", "korean-llm-cpt"),
        name=f"cpt-{model_size}-{wandb.util.generate_id()}"
    )
    
    # ëª¨ë¸ ë¡œë”©
    model_name = f"unsloth/Qwen2.5-{model_size}-bnb-4bit"
    model, tokenizer = FastLanguageModel.from_pretrained(
        model_name=model_name,
        max_seq_length=131072,
        dtype=None,
        load_in_4bit=True,
    )
    
    # LoRA ì„¤ì •
    model = FastLanguageModel.get_peft_model(
        model,
        r=64,
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj",
                       "gate_proj", "up_proj", "down_proj"],
        lora_alpha=16,
        lora_dropout=0.1,
        bias="none",
        use_gradient_checkpointing="unsloth",
        random_state=3407,
    )
    
    # ë°ì´í„°ì…‹ ë¡œë”©
    dataset = load_dataset("json", data_files="/data/korean_corpus.jsonl", split="train")
    
    def tokenize_function(examples):
        return tokenizer(
            examples["text"],
            truncation=True,
            padding=False,
            max_length=4096,
            return_overflowing_tokens=True,
        )
    
    tokenized_dataset = dataset.map(
        tokenize_function,
        batched=True,
        batch_size=1000,
        num_proc=4,
        remove_columns=dataset.column_names,
    )
    
    # í•™ìŠµ ì„¤ì •
    training_args = TrainingArguments(
        output_dir="/output/cpt_model",
        overwrite_output_dir=True,
        num_train_epochs=2,
        per_device_train_batch_size=2,
        gradient_accumulation_steps=32,
        learning_rate=1e-5,
        weight_decay=0.01,
        logging_steps=100,
        save_steps=2000,
        save_total_limit=3,
        warmup_steps=1000,
        fp16=True,
        gradient_checkpointing=True,
        dataloader_pin_memory=False,
        remove_unused_columns=False,
        report_to="wandb",
    )
    
    # íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”
    trainer = SFTTrainer(
        model=model,
        tokenizer=tokenizer,
        args=training_args,
        train_dataset=tokenized_dataset,
        dataset_text_field="text",
        max_seq_length=4096,
        packing=True,
    )
    
    # í•™ìŠµ ì‹¤í–‰
    trainer.train()
    
    # ëª¨ë¸ ì €ì¥
    trainer.save_model("/output/cpt_model")
    
    # Wandb ì¢…ë£Œ
    wandb.finish()

if __name__ == "__main__":
    main()
```

### 5.2 ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼

```python
{% raw %}
# scripts/monitor.py
import os
import time
import requests
from kubernetes import client, config
from prometheus_client.parser import text_string_to_metric_families

class TrainingMonitor:
    def __init__(self):
        config.load_incluster_config()
        self.v1 = client.CoreV1Api()
        self.batch_v1 = client.BatchV1Api()
        
    def check_job_status(self, job_name, namespace="llm-training"):
        """Job ìƒíƒœ í™•ì¸"""
        try:
            job = self.batch_v1.read_namespaced_job(job_name, namespace)
            return job.status
        except Exception as e:
            print(f"Error checking job status: {e}")
            return None
    
    def get_gpu_utilization(self, pod_name, namespace="llm-training"):
        """GPU ì‚¬ìš©ë¥  í™•ì¸"""
        try:
            # Prometheusì—ì„œ GPU ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            response = requests.get(
                f"http://prometheus:9090/api/v1/query",
                params={
                    "query": f'nvidia_gpu_utilization{{pod="{pod_name}"}}'
                }
            )
            data = response.json()
            return data["data"]["result"]
        except Exception as e:
            print(f"Error getting GPU utilization: {e}")
            return None
    
    def send_slack_notification(self, message):
        """Slack ì•Œë¦¼ ì „ì†¡"""
        webhook_url = os.getenv("SLACK_WEBHOOK_URL")
        if webhook_url:
            payload = {"text": message}
            requests.post(webhook_url, json=payload)
    
    def monitor_training(self):
        """í•™ìŠµ ëª¨ë‹ˆí„°ë§ ë©”ì¸ ë£¨í”„"""
        while True:
            # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ Job í™•ì¸
            jobs = self.batch_v1.list_namespaced_job("llm-training")
            
            for job in jobs.items:
                job_name = job.metadata.name
                status = job.status
                
                if status.failed:
                    message = f"ğŸš¨ Training job {job_name} failed!"
                    self.send_slack_notification(message)
                elif status.succeeded:
                    message = f"âœ… Training job {job_name} completed successfully!"
                    self.send_slack_notification(message)
                
                # GPU ì‚¬ìš©ë¥  í™•ì¸
                if status.active:
                    gpu_util = self.get_gpu_utilization(job_name)
                    if gpu_util and gpu_util[0]["value"][1] < "50":
                        message = f"âš ï¸ Low GPU utilization in {job_name}: {gpu_util[0]['value'][1]}%"
                        self.send_slack_notification(message)
            
            time.sleep(300)  # 5ë¶„ë§ˆë‹¤ í™•ì¸

if __name__ == "__main__":
    monitor = TrainingMonitor()
    monitor.monitor_training()
{% endraw %}
```

---

## 6. ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### 6.1 Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘

```yaml
# monitoring/prometheus-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
    
    scrape_configs:
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
    
    - job_name: 'nvidia-dcgm'
      static_configs:
      - targets: ['nvidia-dcgm-exporter:9400']
```

### 6.2 Grafana ëŒ€ì‹œë³´ë“œ

```json
{
  "dashboard": {
    "title": "Korean LLM Training Dashboard",
    "panels": [
      {
        "title": "GPU Utilization",
        "type": "graph",
        "targets": [
          {
            "expr": "nvidia_gpu_utilization",
            "legendFormat": "GPU {{gpu}}"
          }
        ]
      },
      {
        "title": "Memory Usage",
        "type": "graph", 
        "targets": [
          {
            "expr": "nvidia_gpu_memory_used_bytes / nvidia_gpu_memory_total_bytes * 100",
            "legendFormat": "GPU Memory {{gpu}}"
          }
        ]
      },
      {
        "title": "Training Loss",
        "type": "graph",
        "targets": [
          {
            "expr": "training_loss",
            "legendFormat": "Loss"
          }
        ]
      }
    ]
  }
}
```

---

## 7. ìë™ ìŠ¤ì¼€ì¼ë§ ë° ë¦¬ì†ŒìŠ¤ ê´€ë¦¬

### 7.1 HPA (Horizontal Pod Autoscaler)

```yaml
# hpa-config.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: llm-training-hpa
  namespace: llm-training
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: llm-inference-server
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

### 7.2 GPU ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •

```yaml
# gpu-scheduler.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: gpu-scheduler-config
  namespace: kube-system
data:
  config.yaml: |
    apiVersion: kubescheduler.config.k8s.io/v1beta3
    kind: KubeSchedulerConfiguration
    profiles:
    - schedulerName: gpu-scheduler
      plugins:
        score:
          enabled:
          - name: NodeResourcesFit
          - name: NodeAffinity
        filter:
          enabled:
          - name: NodeResourcesFit
          - name: NodeAffinity
      pluginConfig:
      - name: NodeResourcesFit
        args:
          scoringStrategy:
            type: LeastAllocated
            resources:
            - name: nvidia.com/gpu
              weight: 100
```

---

## 8. íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë° ê´€ë¦¬

### 8.1 ì›Œí¬í”Œë¡œìš° ì‹¤í–‰

```bash
# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±
kubectl create namespace llm-training

# ì‹œí¬ë¦¿ ì„¤ì • (Wandb API Key)
kubectl create secret generic wandb-secret \
  --from-literal=api-key=YOUR_WANDB_API_KEY \
  -n llm-training

# ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
argo submit korean-llm-pipeline.yaml -n llm-training

# ì‹¤í–‰ ìƒíƒœ í™•ì¸
argo list -n llm-training
argo get korean-llm-training-xxxxx -n llm-training

# ë¡œê·¸ í™•ì¸
argo logs korean-llm-training-xxxxx -n llm-training
```

### 8.2 íŒŒì´í”„ë¼ì¸ ê´€ë¦¬ ìŠ¤í¬ë¦½íŠ¸

```python
# scripts/pipeline_manager.py
import subprocess
import json
import time
from kubernetes import client, config

class PipelineManager:
    def __init__(self):
        config.load_incluster_config()
        self.custom_api = client.CustomObjectsApi()
    
    def submit_workflow(self, workflow_file, parameters=None):
        """ì›Œí¬í”Œë¡œìš° ì œì¶œ"""
        cmd = ["argo", "submit", workflow_file, "-n", "llm-training"]
        
        if parameters:
            for key, value in parameters.items():
                cmd.extend(["-p", f"{key}={value}"])
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        return result.stdout.strip()
    
    def get_workflow_status(self, workflow_name):
        """ì›Œí¬í”Œë¡œìš° ìƒíƒœ í™•ì¸"""
        try:
            workflow = self.custom_api.get_namespaced_custom_object(
                group="argoproj.io",
                version="v1alpha1",
                namespace="llm-training",
                plural="workflows",
                name=workflow_name
            )
            return workflow["status"]["phase"]
        except Exception as e:
            print(f"Error getting workflow status: {e}")
            return None
    
    def wait_for_completion(self, workflow_name, timeout=86400):
        """ì›Œí¬í”Œë¡œìš° ì™„ë£Œ ëŒ€ê¸°"""
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            status = self.get_workflow_status(workflow_name)
            
            if status in ["Succeeded", "Failed", "Error"]:
                return status
            
            time.sleep(60)
        
        return "Timeout"
    
    def cleanup_completed_workflows(self, days=7):
        """ì™„ë£Œëœ ì›Œí¬í”Œë¡œìš° ì •ë¦¬"""
        cmd = [
            "argo", "delete", "-n", "llm-training",
            "--completed", f"--older={days}d"
        ]
        
        subprocess.run(cmd)

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    manager = PipelineManager()
    
    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    workflow_name = manager.submit_workflow(
        "korean-llm-pipeline.yaml",
        parameters={
            "model-size": "7B",
            "learning-rate": "2e-5"
        }
    )
    
    print(f"Submitted workflow: {workflow_name}")
    
    # ì™„ë£Œ ëŒ€ê¸°
    status = manager.wait_for_completion(workflow_name)
    print(f"Workflow completed with status: {status}")
    
    # ì •ë¦¬
    manager.cleanup_completed_workflows()
```

---

## 9. ê³ ê¸‰ ê¸°ëŠ¥

### 9.1 ë‹¤ì¤‘ ëª¨ë¸ ë™ì‹œ í•™ìŠµ

```yaml
# multi-model-pipeline.yaml
apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: multi-model-training
  namespace: llm-training
spec:
  entrypoint: multi-model-pipeline
  
  templates:
  - name: multi-model-pipeline
    steps:
    - - name: train-7b-model
        template: single-model-training
        arguments:
          parameters:
          - name: model-size
            value: "7B"
          - name: gpu-count
            value: "4"
      - name: train-72b-model
        template: single-model-training
        arguments:
          parameters:
          - name: model-size
            value: "72B"
          - name: gpu-count
            value: "8"
  
  - name: single-model-training
    inputs:
      parameters:
      - name: model-size
      - name: gpu-count
    dag:
      tasks:
      - name: cpt
        template: cpt-training
        arguments:
          parameters:
          - name: model-size
            value: "{{inputs.parameters.model-size}}"
          - name: gpu-count
            value: "{{inputs.parameters.gpu-count}}"
      - name: sft
        template: sft-training
        dependencies: [cpt]
        arguments:
          parameters:
          - name: model-size
            value: "{{inputs.parameters.model-size}}"
      - name: rlhf
        template: rlhf-training
        dependencies: [sft]
        arguments:
          parameters:
          - name: model-size
            value: "{{inputs.parameters.model-size}}"
```

### 9.2 ì‹¤í—˜ ì¶”ì  ë° ë²„ì „ ê´€ë¦¬

```python
# scripts/experiment_tracker.py
import mlflow
import wandb
from datetime import datetime

class ExperimentTracker:
    def __init__(self):
        # MLflow ì„¤ì •
        mlflow.set_tracking_uri("http://mlflow-server:5000")
        mlflow.set_experiment("korean-llm-training")
        
        # Wandb ì„¤ì •
        wandb.login(key=os.getenv("WANDB_API_KEY"))
    
    def start_experiment(self, config):
        """ì‹¤í—˜ ì‹œì‘"""
        # MLflow ì‹¤í–‰ ì‹œì‘
        self.mlflow_run = mlflow.start_run(
            run_name=f"korean-llm-{datetime.now().strftime('%Y%m%d-%H%M%S')}"
        )
        
        # Wandb ì‹¤í–‰ ì‹œì‘
        wandb.init(
            project="korean-llm-training",
            config=config,
            name=self.mlflow_run.info.run_name
        )
        
        # íŒŒë¼ë¯¸í„° ë¡œê¹…
        mlflow.log_params(config)
    
    def log_metrics(self, metrics, step=None):
        """ë©”íŠ¸ë¦­ ë¡œê¹…"""
        mlflow.log_metrics(metrics, step)
        wandb.log(metrics, step=step)
    
    def log_model(self, model_path, model_name):
        """ëª¨ë¸ ë¡œê¹…"""
        mlflow.log_artifacts(model_path, model_name)
        wandb.save(f"{model_path}/*")
    
    def end_experiment(self):
        """ì‹¤í—˜ ì¢…ë£Œ"""
        mlflow.end_run()
        wandb.finish()
```

---

## ê²°ë¡ 

ë³¸ ê°€ì´ë“œë¥¼ í†µí•´ ì¿ ë²„ë„¤í‹°ìŠ¤ ê¸°ë°˜ì˜ ì™„ì „ ìë™í™”ëœ í•œêµ­ì–´ LLM í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤.

**ì£¼ìš” ì„±ê³¼**:

- ğŸš€ **ì™„ì „ ìë™í™”**: CPT â†’ SFT â†’ RLHF ìˆœì°¨ ì‹¤í–‰
- ğŸ“Š **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: GPU ì‚¬ìš©ë¥ , í•™ìŠµ ì§„í–‰ë„ ì¶”ì 
- âš¡ **íš¨ìœ¨ì  ë¦¬ì†ŒìŠ¤ ê´€ë¦¬**: ë™ì  ìŠ¤ì¼€ì¤„ë§ ë° ìë™ ìŠ¤ì¼€ì¼ë§
- ğŸ”„ **ì¬í˜„ ê°€ëŠ¥ì„±**: ë²„ì „ ê´€ë¦¬ ë° ì‹¤í—˜ ì¶”ì 

**ì‹¤ë¬´ì  ê°€ì¹˜**:

- **ìš´ì˜ íš¨ìœ¨ì„±**: ìˆ˜ë™ ê°œì… ìµœì†Œí™”ë¡œ 24/7 í•™ìŠµ ê°€ëŠ¥
- **ë¹„ìš© ìµœì í™”**: ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ìµœì í™”ë¡œ í´ë¼ìš°ë“œ ë¹„ìš© ì ˆê°
- **í™•ì¥ì„±**: ë‹¤ì¤‘ ëª¨ë¸ ë™ì‹œ í•™ìŠµ ì§€ì›
- **ì•ˆì •ì„±**: ì¥ì•  ë³µêµ¬ ë° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•

ì´ ì‹œë¦¬ì¦ˆì˜ ë‹¤ë¥¸ ê¸€ ë³´ê¸°:

- [1í¸: Unslothë¥¼ í™œìš©í•œ í•œêµ­ì–´ íŠ¹í™” LLM í•™ìŠµ ì™„ì „ ê°€ì´ë“œ]({% post_url 2025-06-17-unsloth-korean-llm-training-guide %})
- 2í¸: Unsloth í•œêµ­ì–´ LLM í•™ìŠµ ìë™í™” - ì¿ ë²„ë„¤í‹°ìŠ¤ íŒŒì´í”„ë¼ì¸ êµ¬ì¶• (í˜„ì¬ ê¸€)

ì´ëŸ¬í•œ ìë™í™” ì‹œìŠ¤í…œì„ í†µí•´ í•œêµ­ì–´ íŠ¹í™” LLM ê°œë°œì˜ ìƒì‚°ì„±ê³¼ í’ˆì§ˆì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
