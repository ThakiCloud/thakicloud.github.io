#!/usr/bin/env python3
"""
LangExtract ê³ ê¸‰ ì‚¬ìš©ë²• í…ŒìŠ¤íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì‹¤ì œ APIë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³ ë„ LangExtractì˜ ê¸°ëŠ¥ì„ ì‹œì—°í•©ë‹ˆë‹¤.
"""

import os
import json
import sys
from typing import Dict, List, Any

try:
    import langextract as lx
    print("âœ… LangExtract ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì„±ê³µ")
except ImportError as e:
    print(f"âŒ LangExtract ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    sys.exit(1)

# í•œêµ­ì–´ ìƒ˜í”Œ ë°ì´í„°
SAMPLE_TEXTS = {
    "medical": """
    í™˜ì: ê¹€ì˜í¬ (65ì„¸, ì—¬ì„±)
    ì§„ë‹¨: ê³ í˜ˆì••, ë‹¹ë‡¨ë³‘
    ì²˜ë°©ì•½: 
    - ë¡œì‚¬ë¥´íƒ„ 50mg, 1ì¼ 1íšŒ ì•„ì¹¨ ì‹í›„ ë³µìš©
    - ë©”íŠ¸í¬ë¥´ë¯¼ 500mg, 1ì¼ 2íšŒ ì‹í›„ ë³µìš©
    - ì•„ìŠ¤í”¼ë¦° 100mg, 1ì¼ 1íšŒ ì €ë… ì‹í›„ ë³µìš©
    ë‹¤ìŒ ì§„ë£Œ ì˜ˆì•½: 2024ë…„ 2ì›” 15ì¼
    """,
    
    "business": """
    íšŒì‚¬ëª…: (ì£¼)ë””ì§€í„¸ì´ë…¸ë² ì´ì…˜
    ëŒ€í‘œì´ì‚¬: ë°•ì°½ì‹  (52ì„¸)
    ì„¤ë¦½ì¼: 2019ë…„ 3ì›” 15ì¼
    ì£¼ì†Œ: ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ 123
    ì‚¬ì—…ë¶„ì•¼: AI ì†”ë£¨ì…˜ ê°œë°œ, í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤
    ì§ì›ìˆ˜: 85ëª…
    ì—°ë§¤ì¶œ: 120ì–µì› (2023ë…„ ê¸°ì¤€)
    ì£¼ìš” ê³ ê°: ì‚¼ì„±ì „ì, LGì „ì, ë„¤ì´ë²„
    """,
    
    "academic": """
    ë…¼ë¬¸ ì œëª©: "ë”¥ëŸ¬ë‹ì„ í™œìš©í•œ ìì—°ì–´ ì²˜ë¦¬ ì„±ëŠ¥ í–¥ìƒ ì—°êµ¬"
    ì €ì: ì´ë¯¼ìˆ˜, ê¹€ë°ì´í„°, ë°•ì•Œê³ ë¦¬ì¦˜
    ì†Œì†: ì„œìš¸ëŒ€í•™êµ ì»´í“¨í„°ê³µí•™ë¶€
    ë°œí‘œì¼: 2024ë…„ 1ì›” 20ì¼
    í•™íšŒ: í•œêµ­ì •ë³´ê³¼í•™íšŒ ë™ê³„í•™ìˆ ëŒ€íšŒ
    í‚¤ì›Œë“œ: ë”¥ëŸ¬ë‹, ìì—°ì–´ì²˜ë¦¬, BERT, í•œêµ­ì–´, ì„±ëŠ¥ìµœì í™”
    """,
    
    "news": """
    [ì†ë³´] AI ìŠ¤íƒ€íŠ¸ì—… 'ë¸Œë ˆì¸í…Œí¬', 200ì–µì› ì‹œë¦¬ì¦ˆ B íˆ¬ì ìœ ì¹˜
    
    ì¸ê³µì§€ëŠ¥ ê¸°ìˆ  ì „ë¬¸ ìŠ¤íƒ€íŠ¸ì—… ë¸Œë ˆì¸í…Œí¬(ëŒ€í‘œ ìµœí˜ì‹ )ê°€ ê¸€ë¡œë²Œ ë²¤ì²˜ìºí”¼í„¸ë¡œë¶€í„° 
    200ì–µì› ê·œëª¨ì˜ ì‹œë¦¬ì¦ˆ B íˆ¬ìë¥¼ ìœ ì¹˜í–ˆë‹¤ê³  8ì¼ ë°œí‘œí–ˆë‹¤.
    
    ì´ë²ˆ íˆ¬ìì—ëŠ” ì‹¤ë¦¬ì½˜ë°¸ë¦¬ì˜ ABCë²¤ì²˜ìŠ¤, êµ­ë‚´ ëŒ€ê¸°ì—… ê³„ì—´ CVCì¸ í…Œí¬ì¸ë² ìŠ¤íŠ¸ë¨¼íŠ¸ ë“±ì´ ì°¸ì—¬í–ˆë‹¤.
    ë¸Œë ˆì¸í…Œí¬ëŠ” 2020ë…„ ì„¤ë¦½ ì´í›„ ìì—°ì–´ ì²˜ë¦¬ì™€ ì»´í“¨í„° ë¹„ì „ ë¶„ì•¼ì—ì„œ í˜ì‹ ì ì¸ ê¸°ìˆ ì„ ê°œë°œí•´ì™”ë‹¤.
    """
}

# ì¶”ì¶œ ìŠ¤í‚¤ë§ˆ ì˜ˆì‹œ
EXTRACTION_SCHEMAS = {
    "medical": [
        {
            "patient_name": "í™ê¸¸ë™",
            "age": 45,
            "gender": "ë‚¨ì„±",
            "diagnosis": ["ê³ í˜ˆì••"],
            "medications": [
                {
                    "name": "ë¦¬ì‹œë…¸í”„ë¦´",
                    "dosage": "10mg",
                    "frequency": "1ì¼ 1íšŒ",
                    "timing": "ì•„ì¹¨ ì‹í›„"
                }
            ],
            "next_appointment": "2024-01-30"
        }
    ],
    
    "business": [
        {
            "company_name": "í…Œí¬ì†”ë£¨ì…˜ì¦ˆ",
            "ceo": {
                "name": "ê¹€ëŒ€í‘œ",
                "age": 48
            },
            "establishment_date": "2020-05-10",
            "address": "ë¶€ì‚°ê´‘ì—­ì‹œ í•´ìš´ëŒ€êµ¬ ì„¼í…€ë¡œ 99",
            "business_fields": ["ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ", "IT ì»¨ì„¤íŒ…"],
            "employee_count": 120,
            "annual_revenue": "80ì–µì›",
            "major_clients": ["í˜„ëŒ€ìë™ì°¨", "í¬ìŠ¤ì½”"]
        }
    ],
    
    "academic": [
        {
            "title": "ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ì˜ˆì¸¡ ëª¨ë¸ ì—°êµ¬",
            "authors": ["ê¹€ì—°êµ¬", "ì´ë…¼ë¬¸"],
            "affiliation": "KAIST ì „ì‚°í•™ë¶€",
            "publication_date": "2024-03-15",
            "conference": "í•œêµ­ì»´í“¨í„°ì¢…í•©í•™ìˆ ëŒ€íšŒ",
            "keywords": ["ë¨¸ì‹ ëŸ¬ë‹", "ì˜ˆì¸¡ëª¨ë¸", "ë°ì´í„°ë¶„ì„"]
        }
    ],
    
    "news": [
        {
            "headline": "ìŠ¤íƒ€íŠ¸ì—… íˆ¬ì ìœ ì¹˜ ì†Œì‹",
            "company": "ì´ë…¸ë² ì´ì…˜ë©",
            "ceo": "ë°•ì°½ì—…",
            "investment_amount": "150ì–µì›",
            "investment_round": "ì‹œë¦¬ì¦ˆ A",
            "investors": ["ì½”ë¦¬ì•„ë²¤ì²˜ìŠ¤", "ìŠ¤íƒ€íŠ¸ì—…í€ë“œ"],
            "establishment_year": 2021,
            "business_area": ["í•€í…Œí¬", "ë¸”ë¡ì²´ì¸"]
        }
    ]
}

def demonstrate_extraction_structure():
    """ì¶”ì¶œ êµ¬ì¡° ì‹œì—°"""
    print("\nğŸ—ï¸  ì¶”ì¶œ êµ¬ì¡° ì‹œì—°")
    print("=" * 50)
    
    for category, text in SAMPLE_TEXTS.items():
        print(f"\nğŸ“‚ ì¹´í…Œê³ ë¦¬: {category.upper()}")
        print(f"ğŸ“„ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)} ê¸€ì")
        print(f"ğŸ“‹ ì¶”ì¶œ ìŠ¤í‚¤ë§ˆ ì˜ˆì‹œ:")
        
        schema = EXTRACTION_SCHEMAS[category][0]
        print(json.dumps(schema, ensure_ascii=False, indent=2))
        
        print(f"ğŸ“ ì›ë³¸ í…ìŠ¤íŠ¸:")
        print(text.strip())
        print("-" * 30)

def simulate_extraction_process():
    """ì¶”ì¶œ ê³¼ì • ì‹œë®¬ë ˆì´ì…˜"""
    print("\nğŸ”„ ì¶”ì¶œ ê³¼ì • ì‹œë®¬ë ˆì´ì…˜")
    print("=" * 50)
    
    # ì˜ë£Œ í…ìŠ¤íŠ¸ ì˜ˆì‹œë¡œ ì‹œë®¬ë ˆì´ì…˜
    medical_text = SAMPLE_TEXTS["medical"]
    medical_schema = EXTRACTION_SCHEMAS["medical"][0]
    
    print("ğŸ“‹ ì¶”ì¶œ ì„¤ì •:")
    print(f"   â€¢ ëª¨ë¸: gemini-2.5-flash (ì‹œë®¬ë ˆì´ì…˜)")
    print(f"   â€¢ ì¶”ì¶œ íŒ¨ìŠ¤: 2íšŒ")
    print(f"   â€¢ ìµœëŒ€ ì‘ì—…ì: 5ê°œ")
    print(f"   â€¢ í…ìŠ¤íŠ¸ ë²„í¼: 1000ê¸€ì")
    
    print("\nğŸ¯ ì¶”ì¶œ í”„ë¡¬í”„íŠ¸:")
    prompt = """
    ì˜ë£Œ ê¸°ë¡ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”:
    - í™˜ì ì •ë³´ (ì´ë¦„, ë‚˜ì´, ì„±ë³„)
    - ì§„ë‹¨ëª…
    - ì²˜ë°© ì•½ë¬¼ (ì´ë¦„, ìš©ëŸ‰, ë³µìš©ë²•)
    - ì˜ˆì•½ ì •ë³´
    """
    print(prompt)
    
    print("\nğŸ“Š ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼:")
    simulated_result = {
        "patient_name": "ê¹€ì˜í¬",
        "age": 65,
        "gender": "ì—¬ì„±",
        "diagnosis": ["ê³ í˜ˆì••", "ë‹¹ë‡¨ë³‘"],
        "medications": [
            {
                "name": "ë¡œì‚¬ë¥´íƒ„",
                "dosage": "50mg",
                "frequency": "1ì¼ 1íšŒ",
                "timing": "ì•„ì¹¨ ì‹í›„"
            },
            {
                "name": "ë©”íŠ¸í¬ë¥´ë¯¼",
                "dosage": "500mg",
                "frequency": "1ì¼ 2íšŒ",
                "timing": "ì‹í›„"
            },
            {
                "name": "ì•„ìŠ¤í”¼ë¦°",
                "dosage": "100mg",
                "frequency": "1ì¼ 1íšŒ",
                "timing": "ì €ë… ì‹í›„"
            }
        ],
        "next_appointment": "2024-02-15"
    }
    
    print(json.dumps(simulated_result, ensure_ascii=False, indent=2))

def demonstrate_visualization_concept():
    """ì‹œê°í™” ê°œë… ì„¤ëª…"""
    print("\nğŸ¨ ì‹œê°í™” ê¸°ëŠ¥ ê°œë…")
    print("=" * 50)
    
    print("LangExtractëŠ” ì¶”ì¶œëœ ê²°ê³¼ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì‹œê°í™”í•©ë‹ˆë‹¤:")
    print("\n1. ğŸ“„ ì›ë³¸ í…ìŠ¤íŠ¸ í‘œì‹œ")
    print("   â€¢ ì¶”ì¶œëœ ë¶€ë¶„ì´ í•˜ì´ë¼ì´íŠ¸ë¨")
    print("   â€¢ ìƒ‰ìƒë³„ë¡œ ì—”í‹°í‹° êµ¬ë¶„")
    
    print("\n2. ğŸ·ï¸  ì¶”ì¶œëœ ì—”í‹°í‹° ëª©ë¡")
    print("   â€¢ êµ¬ì¡°í™”ëœ ë°ì´í„° í˜•íƒœë¡œ í‘œì‹œ")
    print("   â€¢ ì›ë³¸ í…ìŠ¤íŠ¸ì™€ ì—°ê²°ëœ ì¦ê±° í¬í•¨")
    
    print("\n3. ğŸ”— ìƒí˜¸ì‘ìš© ê¸°ëŠ¥")
    print("   â€¢ ì—”í‹°í‹° í´ë¦­ ì‹œ ì›ë³¸ ìœ„ì¹˜ë¡œ ì´ë™")
    print("   â€¢ í•„í„°ë§ ë° ê²€ìƒ‰ ê¸°ëŠ¥")
    print("   â€¢ JSON/CSV ë‚´ë³´ë‚´ê¸°")
    
    # ì‹œê°í™” HTML êµ¬ì¡° ì˜ˆì‹œ
    html_example = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>LangExtract ê²°ê³¼ ì‹œê°í™”</title>
        <style>
            .entity-person { background-color: #ffeb3b; }
            .entity-medication { background-color: #4caf50; }
            .entity-date { background-color: #2196f3; }
        </style>
    </head>
    <body>
        <div class="text-display">
            í™˜ì: <span class="entity-person">ê¹€ì˜í¬</span> (65ì„¸, ì—¬ì„±)
            ì²˜ë°©ì•½: <span class="entity-medication">ë¡œì‚¬ë¥´íƒ„ 50mg</span>
            ì˜ˆì•½: <span class="entity-date">2024ë…„ 2ì›” 15ì¼</span>
        </div>
        <div class="entities-list">
            <!-- ì¶”ì¶œëœ ì—”í‹°í‹° ëª©ë¡ -->
        </div>
    </body>
    </html>
    """
    
    print("\nğŸ“ HTML ì‹œê°í™” ì˜ˆì‹œ êµ¬ì¡°:")
    print(html_example)

def create_test_scripts():
    """ì‹¤ì œ ì‚¬ìš©ì„ ìœ„í•œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
    print("\nğŸ“ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±")
    print("=" * 50)
    
    # ì‹¤ì œ API í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
    api_test_script = '''#!/usr/bin/env python3
"""
LangExtract API í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì‹¤ì œ API í‚¤ë¥¼ ì„¤ì •í•œ í›„ ì‹¤í–‰í•˜ì„¸ìš”.
"""

import os
import langextract as lx

def test_with_api():
    """ì‹¤ì œ APIë¥¼ ì‚¬ìš©í•œ í…ŒìŠ¤íŠ¸"""
    
    # API í‚¤ í™•ì¸
    api_key = os.getenv('LANGEXTRACT_API_KEY')
    if not api_key:
        print("âŒ LANGEXTRACT_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”")
        return
    
    # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
    text = """
    ê¹€ì² ìˆ˜ëŠ” 30ì„¸ì˜ ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
    ì„œìš¸ì— ê±°ì£¼í•˜ë©° Python, R, SQLì„ ë‹¤ë£¹ë‹ˆë‹¤.
    í˜„ì¬ í•€í…Œí¬ íšŒì‚¬ì—ì„œ ML ì—”ì§€ë‹ˆì–´ë¡œ ê·¼ë¬´ ì¤‘ì…ë‹ˆë‹¤.
    """
    
    # ì¶”ì¶œ ì˜ˆì‹œ
    examples = [
        {
            "name": "ë°•ì˜í¬",
            "age": 28,
            "profession": "ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´",
            "location": "ë¶€ì‚°",
            "skills": ["Java", "Spring", "React"]
        }
    ]
    
    # ì¶”ì¶œ ì‹¤í–‰
    try:
        result = lx.extract(
            text_or_documents=text,
            prompt_description="ì¸ë¬¼ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”",
            examples=examples,
            model_id="gemini-2.5-flash"
        )
        
        print("âœ… ì¶”ì¶œ ì„±ê³µ!")
        print("ê²°ê³¼:", result)
        
        # ê²°ê³¼ ì €ì¥
        lx.io.save_annotated_documents(
            [result], 
            output_name="test_results.jsonl", 
            output_dir="."
        )
        
        # ì‹œê°í™” ìƒì„±
        html_content = lx.visualize("test_results.jsonl")
        with open("test_visualization.html", "w", encoding="utf-8") as f:
            f.write(html_content)
        
        print("âœ… ì‹œê°í™” íŒŒì¼ ìƒì„±: test_visualization.html")
        
    except Exception as e:
        print(f"âŒ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    test_with_api()
'''
    
    with open('test_api_usage.py', 'w', encoding='utf-8') as f:
        f.write(api_test_script)
    
    print("âœ… test_api_usage.py ìƒì„±ë¨")
    
    # ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
    install_script = '''#!/bin/bash
# LangExtract ì„¤ì¹˜ ë° ì„¤ì • ìŠ¤í¬ë¦½íŠ¸

echo "ğŸš€ LangExtract ì„¤ì¹˜ ì‹œì‘"

# ê°€ìƒí™˜ê²½ ìƒì„± (ì„ íƒì‚¬í•­)
read -p "ê°€ìƒí™˜ê²½ì„ ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): " create_venv
if [ "$create_venv" = "y" ]; then
    python -m venv langextract_env
    source langextract_env/bin/activate
    echo "âœ… ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™” ì™„ë£Œ"
fi

# LangExtract ì„¤ì¹˜
pip install langextract

# API í‚¤ ì„¤ì • ê°€ì´ë“œ
echo ""
echo "ğŸ”‘ API í‚¤ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤:"
echo "1. Gemini API: https://ai.google.dev/"
echo "2. OpenAI API: https://platform.openai.com/"
echo ""
echo "API í‚¤ë¥¼ ë°›ì€ í›„ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:"
echo ""
echo "ë°©ë²• 1: í™˜ê²½ë³€ìˆ˜ ì„¤ì •"
echo "export LANGEXTRACT_API_KEY='your-api-key'"
echo ""
echo "ë°©ë²• 2: .env íŒŒì¼ ìƒì„±"
echo "echo 'LANGEXTRACT_API_KEY=your-api-key' > .env"
echo ""

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
echo "ğŸ“‹ ì„¤ì¹˜ í™•ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰..."
python test_langextract_basic.py

echo "âœ… LangExtract ì„¤ì¹˜ ì™„ë£Œ!"
'''
    
    with open('install_langextract.sh', 'w', encoding='utf-8') as f:
        f.write(install_script)
    
    os.chmod('install_langextract.sh', 0o755)
    print("âœ… install_langextract.sh ìƒì„±ë¨ (ì‹¤í–‰ê¶Œí•œ ë¶€ì—¬)")

def generate_zshrc_aliases():
    """zshrc aliases ìƒì„±"""
    print("\nâš¡ zshrc Aliases ê°€ì´ë“œ")
    print("=" * 50)
    
    aliases = '''
# LangExtract ê´€ë ¨ aliases
alias lx-install="pip install langextract"
alias lx-test="python test_langextract_basic.py"
alias lx-api-test="python test_api_usage.py"
alias lx-demo="python test_langextract_advanced.py"

# API í‚¤ ì„¤ì • helper
alias lx-setkey="echo 'export LANGEXTRACT_API_KEY=your-api-key-here' >> ~/.zshrc && source ~/.zshrc"

# ê²°ê³¼ íŒŒì¼ ê´€ë¦¬
alias lx-results="ls -la *.jsonl *.html"
alias lx-clean="rm -f *.jsonl *.html test_*.py"

# ê°€ìƒí™˜ê²½ ê´€ë¦¬
alias lx-venv="python -m venv langextract_env && source langextract_env/bin/activate"
alias lx-activate="source langextract_env/bin/activate"
'''
    
    print("ë‹¤ìŒ aliasesë¥¼ ~/.zshrcì— ì¶”ê°€í•˜ì„¸ìš”:")
    print(aliases)
    
    # aliases íŒŒì¼ë¡œ ì €ì¥
    with open('langextract_aliases.sh', 'w', encoding='utf-8') as f:
        f.write(aliases)
    
    print("âœ… langextract_aliases.sh íŒŒì¼ë¡œ ì €ì¥ë¨")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ”¬ LangExtract ê³ ê¸‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # ì¶”ì¶œ êµ¬ì¡° ì‹œì—°
    demonstrate_extraction_structure()
    
    # ì¶”ì¶œ ê³¼ì • ì‹œë®¬ë ˆì´ì…˜  
    simulate_extraction_process()
    
    # ì‹œê°í™” ê°œë… ì„¤ëª…
    demonstrate_visualization_concept()
    
    # í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    create_test_scripts()
    
    # zshrc aliases ìƒì„±
    generate_zshrc_aliases()
    
    print("\n" + "=" * 60)
    print("ğŸ¯ ê³ ê¸‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("\nğŸ“ ìƒì„±ëœ íŒŒì¼:")
    print("   â€¢ test_api_usage.py - ì‹¤ì œ API í…ŒìŠ¤íŠ¸")
    print("   â€¢ install_langextract.sh - ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸")
    print("   â€¢ langextract_aliases.sh - zshrc aliases")
    
    print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print("   1. API í‚¤ ì„¤ì •")
    print("   2. test_api_usage.py ì‹¤í–‰")
    print("   3. ì‹œê°í™” ê²°ê³¼ í™•ì¸")

if __name__ == "__main__":
    main()