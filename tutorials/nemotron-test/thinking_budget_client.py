#!/usr/bin/env python3
"""
NVIDIA Nemotron Nano 2 9B Thinking Budget í´ë¼ì´ì–¸íŠ¸
macOS í™˜ê²½ì—ì„œ Thinking Budget ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„
"""

from typing import Any, Dict, List
import openai
import time
import sys

try:
    from transformers import AutoTokenizer
except ImportError:
    print("âŒ transformers íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("ì„¤ì¹˜ ëª…ë ¹ì–´: pip install transformers")
    sys.exit(1)

class ThinkingBudgetClient:
    def __init__(self, base_url: str, api_key: str, tokenizer_name_or_path: str):
        self.base_url = base_url
        self.api_key = api_key
        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name_or_path)
        self.client = openai.OpenAI(base_url=self.base_url, api_key=self.api_key)

    def chat_completion(
        self,
        model: str,
        messages: List[Dict[str, Any]],
        max_thinking_budget: int = 512,
        max_tokens: int = 1024,
        **kwargs,
    ) -> Dict[str, Any]:
        assert (
            max_tokens > max_thinking_budget
        ), f"thinking budgetì€ ìµœëŒ€ í† í° ìˆ˜ë³´ë‹¤ ì‘ì•„ì•¼ í•©ë‹ˆë‹¤. ì£¼ì–´ì§„ ê°’: {max_tokens=}, {max_thinking_budget=}"

        # 1ë‹¨ê³„: ì¶”ë¡  ì½˜í…ì¸  ìƒì„±ì„ ìœ„í•œ ì²« ë²ˆì§¸ í˜¸ì¶œ
        try:
            response = self.client.chat.completions.create(
                model=model, 
                messages=messages, 
                max_tokens=max_thinking_budget, 
                **kwargs
            )
            content = response.choices[0].message.content
        except Exception as e:
            return {"error": f"ì²« ë²ˆì§¸ API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"}

        reasoning_content = content
        if not "</think>" in reasoning_content:
            # ì¶”ë¡  ì½˜í…ì¸ ê°€ ë„ˆë¬´ ê¸¸ë©´ ë§ˆì¹¨í‘œë¡œ ì¢…ë£Œ
            reasoning_content = f"{reasoning_content}.\n</think>\n\n"
        
        reasoning_tokens_len = len(
            self.tokenizer.encode(reasoning_content, add_special_tokens=False)
        )
        remaining_tokens = max_tokens - reasoning_tokens_len
        
        assert (
            remaining_tokens > 0
        ), f"ë‚¨ì€ í† í°ì´ ì–‘ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬ ê°’: {remaining_tokens=}. max_tokensë¥¼ ëŠ˜ë¦¬ê±°ë‚˜ max_thinking_budgetì„ ë‚®ì¶”ì„¸ìš”."

        # 2ë‹¨ê³„: ì¶”ë¡  ì½˜í…ì¸ ë¥¼ ë©”ì‹œì§€ì— ì¶”ê°€í•˜ê³  ì™„ì„± í˜¸ì¶œ
        messages.append({"role": "assistant", "content": reasoning_content})
        prompt = self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            continue_final_message=True,
        )
        
        try:
            response = self.client.completions.create(
                model=model, 
                prompt=prompt, 
                max_tokens=remaining_tokens, 
                **kwargs
            )
        except Exception as e:
            return {"error": f"ë‘ ë²ˆì§¸ API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"}

        response_data = {
            "reasoning_content": reasoning_content.strip().strip("</think>").strip(),
            "content": response.choices[0].text,
            "finish_reason": response.choices[0].finish_reason,
            "thinking_tokens": reasoning_tokens_len,
            "response_tokens": len(self.tokenizer.encode(response.choices[0].text, add_special_tokens=False))
        }
        return response_data

def test_thinking_budget():
    """Thinking Budget ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§  NVIDIA Nemotron Nano 2 9B Thinking Budget í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    tokenizer_name_or_path = "nvidia/NVIDIA-Nemotron-Nano-9B-v2"
    
    try:
        client = ThinkingBudgetClient(
            base_url="http://localhost:8000/v1",
            api_key="EMPTY",
            tokenizer_name_or_path=tokenizer_name_or_path,
        )
        print("âœ… í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        print("ğŸ’¡ í•´ê²° ë°©ë²•:")
        print("1. vLLM ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸: http://localhost:8000")
        print("2. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜: pip install vllm openai transformers")
        return

    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤
    test_cases = [
        {
            "name": "ê°„ë‹¨í•œ ìˆ˜í•™ ë¬¸ì œ",
            "messages": [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. /think"},
                {"role": "user", "content": "2 + 2 = ?"}
            ],
            "thinking_budget": 128
        },
        {
            "name": "ë³µì¡í•œ ìˆ˜í•™ ë¬¸ì œ", 
            "messages": [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. /think"},
                {"role": "user", "content": "ë³µì¡í•œ ìˆ˜í•™ ë¬¸ì œ: 2^10 + 3^5 - 4^3 = ?"}
            ],
            "thinking_budget": 512
        },
        {
            "name": "ì½”ë”© ë¬¸ì œ",
            "messages": [
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. /think"},
                {"role": "user", "content": "Pythonìœ¼ë¡œ í”¼ë³´ë‚˜ì¹˜ ìˆ˜ì—´ì„ êµ¬í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."}
            ],
            "thinking_budget": 1024
        }
    ]

    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ“‹ í…ŒìŠ¤íŠ¸ {i}: {test_case['name']}")
        print(f"ğŸ’­ Thinking Budget: {test_case['thinking_budget']} í† í°")
        
        start_time = time.time()
        result = client.chat_completion(
            model="nvidia/NVIDIA-Nemotron-Nano-9B-v2",
            messages=test_case["messages"],
            max_thinking_budget=test_case["thinking_budget"],
            max_tokens=2048,
            temperature=0.6,
            top_p=0.95,
        )
        end_time = time.time()
        
        if "error" in result:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {result['error']}")
            continue
        
        print(f"â±ï¸  ì‘ë‹µ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
        print(f"ğŸ§  ì‚¬ê³  í† í°: {result.get('thinking_tokens', 0)}ê°œ")
        print(f"ğŸ’¬ ì‘ë‹µ í† í°: {result.get('response_tokens', 0)}ê°œ")
        print("ğŸ¤” ì¶”ë¡  ê³¼ì •:")
        print(f"   {result['reasoning_content'][:200]}...")
        print("âœ… ìµœì¢… ë‹µë³€:")
        print(f"   {result['content'][:200]}...")

def test_budget_comparison():
    """ë‹¤ì–‘í•œ Thinking Budget ë¹„êµ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ“Š Thinking Budget ë¹„êµ ë¶„ì„ ì‹œì‘...")
    
    tokenizer_name_or_path = "nvidia/NVIDIA-Nemotron-Nano-9B-v2"
    
    try:
        client = ThinkingBudgetClient(
            base_url="http://localhost:8000/v1",
            api_key="EMPTY",
            tokenizer_name_or_path=tokenizer_name_or_path,
        )
    except Exception as e:
        print(f"âŒ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        return

    question = "ë³µì¡í•œ ë…¼ë¦¬ ë¬¸ì œ: ë§Œì•½ ëª¨ë“  ê³ ì–‘ì´ê°€ ë™ë¬¼ì´ê³ , ëª¨ë“  ë™ë¬¼ì´ ìƒëª…ì²´ë¼ë©´, ëª¨ë“  ê³ ì–‘ì´ëŠ” ìƒëª…ì²´ì¸ê°€?"
    budgets = [64, 128, 256, 512, 1024]
    
    print(f"ğŸ¯ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: {question}")
    print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚ Budget      â”‚ ì‘ë‹µì‹œê°„    â”‚ ì‚¬ê³ í† í°    â”‚ ì‘ë‹µí† í°    â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    
    for budget in budgets:
        start_time = time.time()
        result = client.chat_completion(
            model="nvidia/NVIDIA-Nemotron-Nano-9B-v2",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë…¼ë¦¬ì  ì‚¬ê³ ë¥¼ í•˜ëŠ” AIì…ë‹ˆë‹¤. /think"},
                {"role": "user", "content": question}
            ],
            max_thinking_budget=budget,
            max_tokens=2048,
            temperature=0.6,
            top_p=0.95,
        )
        end_time = time.time()
        
        if "error" in result:
            print(f"â”‚ {budget:11d} â”‚ ERROR       â”‚ ERROR       â”‚ ERROR       â”‚")
            continue
            
        response_time = end_time - start_time
        thinking_tokens = result.get('thinking_tokens', 0)
        response_tokens = result.get('response_tokens', 0)
        
        print(f"â”‚ {budget:11d} â”‚ {response_time:9.2f}s â”‚ {thinking_tokens:9d} â”‚ {response_tokens:9d} â”‚")
    
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Nemotron Nano 2 Thinking Budget í…ŒìŠ¤íŠ¸")
    parser.add_argument("--test", choices=["basic", "comparison", "all"], 
                       default="basic", help="ì‹¤í–‰í•  í…ŒìŠ¤íŠ¸ ìœ í˜•")
    
    args = parser.parse_args()
    
    if args.test in ["basic", "all"]:
        test_thinking_budget()
    
    if args.test in ["comparison", "all"]:
        test_budget_comparison()
    
    print("\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("ğŸ’¡ ë” ë§ì€ ì •ë³´: https://huggingface.co/nvidia/NVIDIA-Nemotron-Nano-9B-v2")
