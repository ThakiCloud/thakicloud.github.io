#!/usr/bin/env python3
"""
Firecrawl Python SDK í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì‘ì„±ì: Thaki Cloud
ë‚ ì§œ: 2025-08-21
"""

import os
import json
from pydantic import BaseModel, Field
from typing import List, Optional
from firecrawl import Firecrawl

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ
def load_api_key():
    try:
        with open('.env', 'r') as f:
            for line in f:
                if line.startswith('FIRECRAWL_API_KEY='):
                    return line.split('=', 1)[1].strip()
    except FileNotFoundError:
        pass
    
    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì‹œë„
    api_key = os.getenv('FIRECRAWL_API_KEY')
    if not api_key:
        print("âŒ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— FIRECRAWL_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        return None
    return api_key

# Pydantic ìŠ¤í‚¤ë§ˆ ì •ì˜
class Article(BaseModel):
    title: str
    points: int
    by: str
    commentsURL: str

class TopArticles(BaseModel):
    top: List[Article] = Field(..., description="ìƒìœ„ 5ê°œ ê¸°ì‚¬")

class CompanyInfo(BaseModel):
    company_name: Optional[str] = Field(description="íšŒì‚¬ëª…")
    mission: Optional[str] = Field(description="íšŒì‚¬ ë¯¸ì…˜")
    website: Optional[str] = Field(description="ì›¹ì‚¬ì´íŠ¸ URL")

def test_basic_scraping(firecrawl):
    """ê¸°ë³¸ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” 1. ê¸°ë³¸ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸")
    print("-" * 40)
    
    try:
        doc = firecrawl.scrape(
            "https://firecrawl.dev",
            formats=["markdown", "html"],
        )
        
        print(f"âœ… ìŠ¤í¬ë˜í•‘ ì„±ê³µ!")
        print(f"ğŸ“„ ë§ˆí¬ë‹¤ìš´ ê¸¸ì´: {len(doc.markdown)} ë¬¸ì")
        print(f"ğŸ·ï¸ HTML ê¸¸ì´: {len(doc.html)} ë¬¸ì")
        print(f"ğŸ“ ì œëª©: {doc.metadata.get('title', 'N/A')}")
        
        # ë§ˆí¬ë‹¤ìš´ ì¼ë¶€ ì¶œë ¥
        markdown_preview = doc.markdown[:200] + "..." if len(doc.markdown) > 200 else doc.markdown
        print(f"ğŸ“– ë§ˆí¬ë‹¤ìš´ ë¯¸ë¦¬ë³´ê¸°:\n{markdown_preview}")
        
        return True
    except Exception as e:
        print(f"âŒ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
        return False

def test_structured_extraction(firecrawl):
    """êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ“Š 2. êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
    print("-" * 40)
    
    try:
        # Hacker Newsì—ì„œ ìƒìœ„ ê¸°ì‚¬ ì¶”ì¶œ
        doc = firecrawl.scrape(
            "https://news.ycombinator.com",
            formats=[{"type": "json", "schema": TopArticles}],
        )
        
        print(f"âœ… êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ ì„±ê³µ!")
        
        if doc.json and 'top' in doc.json:
            articles = doc.json['top']
            print(f"ğŸ“° ì¶”ì¶œëœ ê¸°ì‚¬ ìˆ˜: {len(articles)}")
            
            for i, article in enumerate(articles[:3], 1):
                print(f"{i}. {article.get('title', 'N/A')} ({article.get('points', 0)} points)")
        
        return True
    except Exception as e:
        print(f"âŒ êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return False

def test_batch_scraping(firecrawl):
    """ë°°ì¹˜ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸"""
    print("\nâš¡ 3. ë°°ì¹˜ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸")
    print("-" * 40)
    
    try:
        # ì—¬ëŸ¬ URL ë™ì‹œ ìŠ¤í¬ë˜í•‘
        urls = [
            "https://firecrawl.dev",
            "https://docs.firecrawl.dev"
        ]
        
        response = firecrawl.batch_scrape(
            urls=urls,
            formats=["markdown"]
        )
        
        print(f"âœ… ë°°ì¹˜ ìŠ¤í¬ë˜í•‘ ì‘ì—… ì‹œì‘!")
        print(f"ğŸ†” ì‘ì—… ID: {response.get('jobId', 'N/A')}")
        print(f"ğŸ“‹ ìƒíƒœ: {response.get('status', 'N/A')}")
        
        return True
    except Exception as e:
        print(f"âŒ ë°°ì¹˜ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
        return False

def test_crawling(firecrawl):
    """ì›¹ì‚¬ì´íŠ¸ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ•·ï¸ 4. ì›¹ì‚¬ì´íŠ¸ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸")
    print("-" * 40)
    
    try:
        # ì œí•œëœ í¬ë¡¤ë§ (ë¹„ìš© ì ˆì•½ì„ ìœ„í•´ 5í˜ì´ì§€ë¡œ ì œí•œ)
        response = firecrawl.crawl(
            "https://docs.firecrawl.dev",
            limit=5,
            scrape_options={"formats": ["markdown"]},
        )
        
        print(f"âœ… í¬ë¡¤ë§ ì„±ê³µ!")
        print(f"ğŸ“„ í¬ë¡¤ë§ëœ í˜ì´ì§€ ìˆ˜: {len(response.get('data', []))}")
        
        for i, page in enumerate(response.get('data', [])[:3], 1):
            title = page.get('metadata', {}).get('title', 'N/A')
            url = page.get('metadata', {}).get('url', 'N/A')
            print(f"{i}. {title} - {url}")
        
        return True
    except Exception as e:
        print(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        return False

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸ”¥ Firecrawl Python SDK í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    # API í‚¤ ë¡œë“œ
    api_key = load_api_key()
    if not api_key:
        return
    
    # Firecrawl í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    try:
        firecrawl = Firecrawl(api_key=api_key)
        print(f"âœ… Firecrawl í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
    except Exception as e:
        print(f"âŒ Firecrawl í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    tests = [
        test_basic_scraping,
        test_structured_extraction,
        test_batch_scraping,
        test_crawling
    ]
    
    passed = 0
    total = len(tests)
    
    for test_func in tests:
        try:
            if test_func(firecrawl):
                passed += 1
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # ê²°ê³¼ ìš”ì•½
    print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼")
    print("=" * 50)
    print(f"âœ… í†µê³¼: {passed}/{total}")
    print(f"âŒ ì‹¤íŒ¨: {total - passed}/{total}")
    
    if passed == total:
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µí–ˆìŠµë‹ˆë‹¤!")
    else:
        print("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ì™€ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()
