#!/usr/bin/env python3
"""
Simba RAG ì‹œìŠ¤í…œ ê°„ë‹¨ ë°ëª¨ ìŠ¤í¬ë¦½íŠ¸
ì‹¤ì œ ì™¸ë¶€ íŒ¨í‚¤ì§€ ì—†ì´ RAG ê°œë…ì„ ì‹œì—°í•˜ëŠ” ë°ëª¨ì…ë‹ˆë‹¤.
"""

import json
import re
import math
from collections import Counter
from typing import List, Dict, Any, Tuple
import os

class SimpleRAGDemo:
    """ê°„ë‹¨í•œ RAG ì‹œìŠ¤í…œ ë°ëª¨"""
    
    def __init__(self):
        self.knowledge_base = []
        self.index = {}
        
    def add_document(self, doc_id: str, content: str, metadata: Dict = None):
        """ë¬¸ì„œ ì¶”ê°€"""
        chunks = self._split_text(content)
        
        for i, chunk in enumerate(chunks):
            chunk_id = f"{doc_id}_chunk_{i}"
            doc_chunk = {
                'id': chunk_id,
                'content': chunk,
                'metadata': metadata or {},
                'doc_id': doc_id,
                'chunk_index': i
            }
            
            self.knowledge_base.append(doc_chunk)
            self._add_to_index(chunk_id, chunk)
    
    def _split_text(self, text: str, chunk_size: int = 200) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
        sentences = re.split(r'[.!?]+', text)
        chunks = []
        current_chunk = ""
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
                
            if len(current_chunk) + len(sentence) < chunk_size:
                current_chunk += sentence + ". "
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence + ". "
        
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        return chunks
    
    def _add_to_index(self, chunk_id: str, content: str):
        """ì¸ë±ìŠ¤ì— ì¶”ê°€"""
        words = self._tokenize(content)
        
        for word in words:
            if word not in self.index:
                self.index[word] = []
            self.index[word].append(chunk_id)
    
    def _tokenize(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ í† í°í™”"""
        # í•œê¸€ê³¼ ì˜ì–´ ë‹¨ì–´ ì¶”ì¶œ
        words = re.findall(r'[ê°€-í£]+|[a-zA-Z]+', text.lower())
        return words
    
    def search(self, query: str, top_k: int = 3) -> List[Dict]:
        """ê²€ìƒ‰ ìˆ˜í–‰"""
        query_words = self._tokenize(query)
        
        # ë¬¸ì„œë³„ ì ìˆ˜ ê³„ì‚°
        doc_scores = {}
        
        for word in query_words:
            if word in self.index:
                for chunk_id in self.index[word]:
                    if chunk_id not in doc_scores:
                        doc_scores[chunk_id] = 0
                    doc_scores[chunk_id] += 1
        
        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_docs = sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)
        
        # ìƒìœ„ kê°œ ë¬¸ì„œ ë°˜í™˜
        results = []
        for chunk_id, score in sorted_docs[:top_k]:
            for doc in self.knowledge_base:
                if doc['id'] == chunk_id:
                    results.append({
                        'content': doc['content'],
                        'metadata': doc['metadata'],
                        'score': score,
                        'chunk_id': chunk_id
                    })
                    break
        
        return results
    
    def generate_answer(self, query: str, context_docs: List[Dict]) -> str:
        """ë‹µë³€ ìƒì„± (ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜)"""
        if not context_docs:
            return "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ì»¨í…ìŠ¤íŠ¸ ê²°í•©
        context = " ".join([doc['content'] for doc in context_docs])
        
        # ê°„ë‹¨í•œ ë‹µë³€ ìƒì„± ë¡œì§
        query_words = self._tokenize(query)
        
        # ì§ˆë¬¸ ìœ í˜• íŒë‹¨
        if any(word in query_words for word in ['ë¬´ì—‡', 'ë­', 'what']):
            answer_type = "ì •ì˜"
        elif any(word in query_words for word in ['ì–´ë–»ê²Œ', 'how']):
            answer_type = "ë°©ë²•"
        elif any(word in query_words for word in ['ì™œ', 'why']):
            answer_type = "ì´ìœ "
        else:
            answer_type = "ì¼ë°˜"
        
        # ë‹µë³€ ìƒì„±
        answer = f"ì œê³µëœ ë¬¸ì„œì— ë”°ë¥´ë©´, {context[:200]}..."
        
        return answer
    
    def query(self, question: str, top_k: int = 3) -> Dict:
        """ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        # ê²€ìƒ‰
        search_results = self.search(question, top_k)
        
        # ë‹µë³€ ìƒì„±
        answer = self.generate_answer(question, search_results)
        
        return {
            'question': question,
            'answer': answer,
            'sources': search_results
        }

def setup_demo_knowledge_base():
    """ë°ëª¨ìš© ì§€ì‹ë² ì´ìŠ¤ ì„¤ì •"""
    rag = SimpleRAGDemo()
    
    # ìƒ˜í”Œ ë¬¸ì„œë“¤ ì¶”ê°€
    documents = [
        {
            'id': 'ai_basics',
            'content': '''
            ì¸ê³µì§€ëŠ¥(AI)ì€ ì»´í“¨í„° ì‹œìŠ¤í…œì´ ì¸ê°„ì˜ ì§€ëŠ¥ì„ ëª¨ë°©í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.
            ë¨¸ì‹ ëŸ¬ë‹ì€ ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì„ í•™ìŠµí•˜ëŠ” AIì˜ í•œ ë¶„ì•¼ì…ë‹ˆë‹¤.
            ë”¥ëŸ¬ë‹ì€ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ì˜ í•œ ë°©ë²•ì…ë‹ˆë‹¤.
            ìì—°ì–´ì²˜ë¦¬ëŠ” ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ê³  ìƒì„±í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.
            ì»´í“¨í„° ë¹„ì „ì€ ì»´í“¨í„°ê°€ ì´ë¯¸ì§€ì™€ ë¹„ë””ì˜¤ë¥¼ ë¶„ì„í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.
            ''',
            'metadata': {'topic': 'AI ê¸°ì´ˆ', 'author': 'Demo'}
        },
        {
            'id': 'rag_systems',
            'content': '''
            RAG(Retrieval-Augmented Generation)ëŠ” ì •ë³´ ê²€ìƒ‰ê³¼ ìƒì„±ì„ ê²°í•©í•œ AI ê¸°ìˆ ì…ë‹ˆë‹¤.
            RAG ì‹œìŠ¤í…œì€ ë¬¸ì„œ ì €ì¥ì†Œ, ê²€ìƒ‰ ì—”ì§„, ìƒì„± ëª¨ë¸, ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
            RAGì˜ ì¥ì ì€ ìµœì‹  ì •ë³´ í™œìš©, í™˜ê° ê°ì†Œ, ë„ë©”ì¸ íŠ¹í™” ì§€ì‹ ì œê³µì…ë‹ˆë‹¤.
            RAG ì‹œìŠ¤í…œ êµ¬ì¶• ê³¼ì •ì€ ë¬¸ì„œ ìˆ˜ì§‘, ì²­í¬ ë¶„í• , ì„ë² ë”©, ë²¡í„° ì €ì¥, ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•ì…ë‹ˆë‹¤.
            ''',
            'metadata': {'topic': 'RAG ì‹œìŠ¤í…œ', 'author': 'Demo'}
        },
        {
            'id': 'vector_db',
            'content': '''
            ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ëŠ” ê³ ì°¨ì› ë²¡í„° ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
            ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì˜ íŠ¹ì§•ì€ ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰, ê³ ì°¨ì› ë°ì´í„° ì§€ì›, ë¹ ë¥¸ ê²€ìƒ‰ ì„±ëŠ¥ì…ë‹ˆë‹¤.
            ì¸ê¸° ìˆëŠ” ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¡œëŠ” ChromaDB, Pinecone, Weaviate, Milvusê°€ ìˆìŠµë‹ˆë‹¤.
            ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ëŠ” ì˜ë¯¸ ê²€ìƒ‰, ì¶”ì²œ ì‹œìŠ¤í…œ, ì´ë¯¸ì§€ ê²€ìƒ‰ì— í™œìš©ë©ë‹ˆë‹¤.
            ''',
            'metadata': {'topic': 'ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤', 'author': 'Demo'}
        }
    ]
    
    # ë¬¸ì„œë“¤ì„ ì§€ì‹ë² ì´ìŠ¤ì— ì¶”ê°€
    for doc in documents:
        rag.add_document(doc['id'], doc['content'], doc['metadata'])
    
    return rag

def run_demo():
    """ë°ëª¨ ì‹¤í–‰"""
    print("ğŸ¤– Simba RAG ì‹œìŠ¤í…œ ê°„ë‹¨ ë°ëª¨")
    print("=" * 50)
    
    # ì§€ì‹ë² ì´ìŠ¤ ì„¤ì •
    print("ğŸ“š ì§€ì‹ë² ì´ìŠ¤ ì„¤ì • ì¤‘...")
    rag = setup_demo_knowledge_base()
    print(f"âœ… ì§€ì‹ë² ì´ìŠ¤ ì„¤ì • ì™„ë£Œ ({len(rag.knowledge_base)} ë¬¸ì„œ ì²­í¬)")
    
    # ìƒ˜í”Œ ì§ˆë¬¸ë“¤
    sample_questions = [
        "ì¸ê³µì§€ëŠ¥ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?",
        "RAG ì‹œìŠ¤í…œì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì˜ íŠ¹ì§•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "ë¨¸ì‹ ëŸ¬ë‹ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "ë”¥ëŸ¬ë‹ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    ]
    
    print("\nğŸ” ì§ˆë¬¸ ë‹µë³€ ë°ëª¨:")
    print("-" * 50)
    
    for i, question in enumerate(sample_questions, 1):
        print(f"\n{i}. ì§ˆë¬¸: {question}")
        
        result = rag.query(question, top_k=2)
        
        print(f"   ë‹µë³€: {result['answer']}")
        print(f"   ì°¸ì¡° ë¬¸ì„œ ìˆ˜: {len(result['sources'])}")
        
        if result['sources']:
            print("   ì°¸ì¡° ë‚´ìš©:")
            for j, source in enumerate(result['sources']):
                print(f"     {j+1}. {source['content'][:50]}... (ì ìˆ˜: {source['score']})")
    
    print("\n" + "=" * 50)
    print("ğŸ’¡ ì´ê²ƒì€ ì‹¤ì œ Simba RAG ì‹œìŠ¤í…œì˜ ê°„ë‹¨í•œ ë°ëª¨ì…ë‹ˆë‹¤.")
    print("ì‹¤ì œ ì‹œìŠ¤í…œì—ì„œëŠ” OpenAI ì„ë² ë”©ê³¼ ChromaDBë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    print("=" * 50)

def interactive_demo():
    """ëŒ€í™”í˜• ë°ëª¨"""
    print("\nğŸ—£ï¸ ëŒ€í™”í˜• ë°ëª¨ ëª¨ë“œ")
    print("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ì…ë ¥):")
    print("-" * 50)
    
    rag = setup_demo_knowledge_base()
    
    while True:
        try:
            question = input("\nì§ˆë¬¸: ").strip()
            
            if question.lower() in ['quit', 'exit', 'q', 'ì¢…ë£Œ']:
                print("ğŸ‘‹ ë°ëª¨ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            if not question:
                continue
            
            result = rag.query(question, top_k=3)
            
            print(f"ë‹µë³€: {result['answer']}")
            
            if result['sources']:
                print("ì°¸ì¡° ë¬¸ì„œ:")
                for i, source in enumerate(result['sources'], 1):
                    print(f"  {i}. {source['content'][:100]}...")
        
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ë°ëª¨ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

if __name__ == "__main__":
    print("ğŸš€ Simba RAG ë°ëª¨ ì‹œì‘")
    print("=" * 50)
    
    try:
        # ê¸°ë³¸ ë°ëª¨ ì‹¤í–‰
        run_demo()
        
        # ëŒ€í™”í˜• ëª¨ë“œ ì œì•ˆ
        response = input("\nëŒ€í™”í˜• ëª¨ë“œë¥¼ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
        if response in ['y', 'yes', 'ì˜ˆ']:
            interactive_demo()
        
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ë°ëª¨ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}") 